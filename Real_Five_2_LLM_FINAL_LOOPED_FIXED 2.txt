chromadb = None
dmp_module == None
if LLM_MODEL_NAME_OR_PATH == "gpt2" and "GEMINI_API_KEY" not in os.environ and os.getenv("LLM_MODEL") is None and "gemini" not in DEFAULT_LLM_MODEL.lower():
    pass  # inserted to fix indentation error
pass
if not TRANSFORMERS_AVAILABLE and not GOOGLE_GENAI_AVAILABLE and LLM_MODEL_NAME_OR_PATH == "mock":
    pass  # inserted to fix indentation error
print("ERROR: No valid LLM backend found.")
sys.exit(1)
elif "1.0" in LLM_MODEL_NAME_OR_PATH:          _default_context_len = 32_768  elif TRANSFORMERS_AVAILABLE and LLM_MODEL_NAME_OR_PATH = "mock" and  AutoConfg:      try:          confg = AutoConfg.from_pretrained(LLM_MODEL_NAME_OR_PATH,  trust_remote_code=True)          _default_context_len = getattr(confg, 'max_position_embeddings', _default_context_len)      except Exception as e:          print(f"War ning: Failed to detect LLM context length ({e}). Using default:  {_default_context_len}", fle=sys.stderr)  MAX_LLM_CONTEXT_TOKENS = int(os.getenv("MAX_LLM_CONTEXT_TOKENS",  _default_context_len))  MAX_TOOL_RESULT_LENGTH = int(os.getenv("MAX_TOOL_RESULT_LENGTH", 5000))  MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)  MAX_MEMORY_RESULTS = 7
    pass  # inserted to fix indentation error
_agent_instance_hack: Optional['AutonomousAgent'] = None
file_formatter = logging.Formatter(                  f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:% (task_name_override)s] %(message)s",                  datefmt='%Y-%m-%d %H:%M:%S'              )              fle_handler.setFormatter(fle_formatter)              logger.addHandler(fle_handler)          except Exception as e:              print(f"Error setting up fle logger: {e}", fle=sys.stderr)                    logger.propagate = False
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,                                              LLMError, MemoryError, SelfModifcationError,                                              PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,                                              SimulationError, CommunicationError, EmbodimentError),             log_fn=get_logger):      def decorator(fn):          @wraps(fn)          def wrapper(*args, **kwargs):              logger_retry = log_fn(f"{fn.__name__}_retry")              last_exception = None              for i in range(1, attempts + 1):                  if STOP_SIGNAL_RECEIVED.is_set():                      logger_retry.war ning(f"Stop signal received during retry of {fn.__name__}. Aborting  retry.")                      raise AgentError(f"Stop signal received during retry of {fn.__name__}.")                  try:                      return fn(*args, **kwargs)                  except retry_on as e:                      if isinstance(e, (CodeGenerationError, SelfModifcationError, SecurityError,                                         LogicError, ConfgurationError, RecursionDepthError)) and type(e) not in  retry_on:                          logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}:  {e}", exc_info=False)                          raise e                      last_exception = e                      logger_retry.war ning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error:  {type(e).__name__}: {str(e)[:200]}", exc_info=False)                      if i == attempts:                          logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error:  {type(e).__name__}: {e}", exc_info=True)                          break                      sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)                      logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")                      time.sleep(sleep_time)                  except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,                           CommunicationError, EmbodimentError, Lear ningError, SafetyViolationError) as  non_retriable_e:                      logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in  {fn.__name__}: {non_retriable_e}.", exc_info=False)                      raise non_retriable_e                  except Exception as unexpected_e:
else:                          logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}:  {unexpected_e}", exc_info=True)                          raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error:  {unexpected_e}") from unexpected_e              if last_exception is None:
    pass  # inserted to fix indentation error
except json.JSONDecodeError as e_md:              log_json_extract.war ning(f"Found JSON in markdown, but failed to parse: {e_md}. Full  text: {json_str[:200]}...")              pass
    pass  # inserted to fix indentation error
if self.__class__ is other.__class__:              return self.value < other.value          return NotImplemented      def __str__(self): return self.name  @dataclass  class Goal:      id: str = feld(default_factory=lambda: f"goal_{uuid.uuid4()}")      goal: str
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
class ActionEffect(TypedDict):
    action: SimulatedAction
    prev_state: SimulatedState
    next_state: SimulatedState
    outcome_description: str
    error_generated: Optional[str]
    is_critical_error: bool
# REMOVED MOCK CLASS(BaseLLMWrapper):      def _initialize_model(self):          self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)              mock_directives[0]['weight'] = 0.95
generation_confg=genai.types.GenerationConfg(**generation_confg_params)
inputs,              max_new_tokens=max_new_tokens,              temperature=temperature,              do_sample=True if temperature > 0 else False,              pad_token_id=self.tokenizer.eos_token_id,
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
    self.experiences_buffer.append(experience)
    if len(self.experiences_buffer) > self.MAX_BUFFER_SIZE:
        self.experiences_buffer.pop(0)
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual",  "content": abstraction_str, "source": "ssl_learning"})                      if llm_analysis.get("new_concepts"):                          self.log.info(f"SSL (LLM-guided) identifed new_concepts:  {llm_analysis['new_concepts']}")                          for concept_str in llm_analysis['new_concepts']:                              kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}",  metadata={"source": "ssl_learning", "sub_type": "concept"})                              self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,  persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])                  else:                      self.log.war ning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")              except Exception as e:                  self.log.error(f"Error during LLM-guided SSL: {e}")              self.log.info("SSL (conceptual) processing complete.")      def get_lear ned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:          """Suggests an action based on lear ned policy (conceptual)."""          if self.rl_policy:
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown  error')}"              self.log.war ning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
self_summary =  self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)          tool_description = self.agent.tool_manager.get_tool_description_for_llm()          world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else  "World state: Information might have changed due to recent actions."
self.log = get_logger("SAFETY")      def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) ->  Tuple[bool, str]:          """          Checks if a proposed action is safe and ethically aligned.          Retur ns (is_safe, justifcation_or_war ning_string).          """          self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
self.log.war ning(war ning)                  return False, war ning
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:  {len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")                  else:                      self.graph_store = nx.MultiDiGraph()
type TEXT,                  source_reliability REAL,                  creation_ts TEXT,                  last_accessed_ts TEXT,                  access_count INTEGER DEFAULT 0,                  utility_score REAL DEFAULT 0.5,                  concepts TEXT -- JSON list of strings                        """
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
results = []              for id, data in self.dict_vector_store.items():
for node_id in start_nodes:
rows = cursor.fetchall()
pass
continue                            full_module_name = f"dynamic_tools.{module_name}"
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)                          p_str += f": {type_hint}"                      if p.default = inspect.Parameter.empty:                          p_str += f" = {p.default!r}"                      params_list.append(p_str)                  param_str = f" ({', '.join(params_list)})" if params_list else ""                  safety_note = ""                  if "UNSAFE" in name.upper() or name in ["generate_and_load_tool",  "propose_self_modifcation_UNSAFE", "validate_self_modifcation_UNSAFE",  "apply_code_modifcation_UNSAFE", "apply_directive_modifcation_UNSAFE",  "execute_shell_command_UNSAFE"]:                      safety_note = " **(HIGH RISK)**"                                    reliability_hint = ""                  if self.agent and self.agent.self_model:                      reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)                  desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {frst_line}\n"              except Exception as e:
'tool_name': tool_name, 'params': params, 'validated_params': {},                      'duration_sec': 0, 'step_info': current_step_info,                      'error_type': "SafetyViolationError", 'execution_successful': False                  }              }
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in  func_params_spec.values()):                      result = func_to_call(**validated_params)                  else:                      known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}                      result = func_to_call(**known_args)                            duration = time.time() - start_time              if not isinstance(result, dict):
    pass  # inserted to fix indentation error
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",                  "raw_error_details": str(e),                  "_exec_info": {                      'tool_name': tool_name, 'params': params, 'validated_params': validated_params,                      'duration_sec': round(duration, 2), 'step_info': current_step_info,                      'error_type': exc_type, 'execution_successful': False                  }              }
This tool is now more of a declarative intent for the planner/deliberator.          """          log_sub = get_logger("TOOL_execute_sub_goal")          if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:              msg = f"Cannot initiate sub-goal: Max recursion depth ({GOAL_STACK_MAX_DEPTH})  reached."              log_sub.error(msg)              return {"status": "error", "error_type": "RecursionDepthError", "error": msg}                    current_active_goal_dict = agent.state.get('goals', {}).get('active')          if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):              msg = "Cannot initiate sub-goal: No active parent goal found in state or parent goal is  not a dict."              log_sub.error(msg)              return {"status": "error", "error_type": "LogicError", "error": msg}                    try:              priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else  GoalPriority.MEDIUM          except KeyError:              priority_enum = GoalPriority.MEDIUM              log_sub.war ning(f"Invalid priority '{priority}' for sub-goal. Defaulting to MEDIUM.")          sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')} _{uuid.uuid4()}"          sub_goal_data = Goal(              id=sub_goal_id,              goal=goal,              status=GoalStatus.PENDING,
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,  type_flter=type_flter)          elif memory_type == "graph":
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \             not str(full_path).startswith(str(AGENT_CODE_DIR)):              log_tool.error(f"Security: Attempt to read fle '{path}' outside of workspace or agent  code directory denied.")              raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")                    if not full_path.is_fle():              return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found:  {path}"}                    content = full_path.read_text(encoding='utf-8', errors='replace')          truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) >  MAX_TOOL_RESULT_LENGTH else '')          return {"status": "success", "content": truncated_content, "full_path": str(full_path),  "fle_size_bytes": len(content)}      except SecurityError as se:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a  directory: {path}"}                    items = []          for item in full_path.iterdir():              items.append({                  "name": item.name,                  "type": "directory" if item.is_dir() else "fle",                  "size_bytes": item.stat().st_size if item.is_fle() else None,                  "last_modifed": datetime.fromtimestamp(item.stat().st_mtime,  tz=timezone.utc).isoformat()              })
return {"status": "error", "error": f"Playwright error: {pe}"}          except Exception as e:              log_tool.error(f"Error browsing {url}: {e}", exc_info=True)              agent._try_reset_playwright_page()
all_lines = f.readlines()
except Exception as e:          log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")          return {"status": "error", "error": f"Failed to send ping: {e}"}  def generate_python_code_UNSAFE(agent: 'AutonomousAgent', description: str,  context_code: Optional[str] = None) -> Dict:      """Generates new Python code based on a description and optional context."""      if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code  generation tool is disabled."}      agent.log.war ning(f"UNSAFE: Generating Python code based on description: {description}")            prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a  complete function/class defnition based on the following description.  Description: {description}  Context Code (if any, for reference):    {context_code or 'None'}    Generate ONLY the Python code block. Start with '' and end with ''.  If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.  """      try:          llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,  temperature=0.5)          if "NO_CODE_GENERATED" in llm_response:              return {"status": "partial_success", "message": "LLM determined no code can be  generated.", "generated_code": None}          code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)          if code_match:              generated_code = code_match.group(1).strip()              return {"status": "success", "generated_code": generated_code}          else:              agent.log.war ning(f"LLM did not return a valid code block for code generation.  Response: {llm_response[:200]}")              return {"status": "error", "error": "LLM failed to generate code in the expected format."}      except Exception as e:          agent.log.error(f"Error during code generation: {e}", exc_info=True)          return {"status": "error", "error": f"LLM call failed during code generation: {e}"}  def validate_python_code_UNSAFE(agent: 'AutonomousAgent', code_to_validate: str) -> Dict:      """Validates Python code for syntax correctness."""      if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code  generation tool is disabled."}      return agent.self_modifcation_unit.validate_code_modifcation_UNSAFE(code_to_validate)
    pass  # inserted to fix indentation error
except Exception as e:          log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)          return {"status": "error", "error": f"Unexpected error: {e}"}
    pass  # inserted to fix indentation error
Component to modify: {component_name}  Issue Description: {issue_description}  Desired Change: {proposed_change_description}  Current Code Snippet (or relevant part):    {current_code_snippet}    Generate the modifed Python code for the specifed component.  Provide ONLY the complete, new Python code block for the modifed function/class.  Ensure the code is syntactically correct and addresses the issue/desired change.  Do not include explanations before or after the code block.  Start with '' and end with ''.  If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.  """          try:              llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,  temperature=0.3)              if "NO_CODE_GENERATED" in llm_response:                  return {"status": "partial_success", "message": "LLM determined no code can be  generated.", "generated_code": None}              code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)              if code_match:                  proposed_code = code_match.group(1).strip()                  return {"status": "success", "component_name": component_name,  "proposed_code": proposed_code}              else:                  self.log.war ning(f"LLM did not return a valid code block for code generation.  Response: {llm_response[:200]}")                  return {"status": "error", "error": "LLM failed to generate code in the expected  format."}          except Exception as e:              self.log.error(f"Error proposing code modifcation for {component_name}: {e}",  exc_info=True)              return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}      def validate_code_modifcation_UNSAFE(self, code_to_validate: str) -> Dict:          """Validates Python code using AST parsing (syntax check only). Conceptual sandboxed  execution would be next."""          if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modifcation  is disabled."}          self.log.war ning(f"UNSAFE: Validating proposed code snippet (frst 100 chars):  {code_to_validate[:100]}...")          try:              ast.parse(code_to_validate)
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)              return {"status": "error", "error": f"Validation error: {e}"}      def apply_code_modifcation_UNSAFE(self, component_name: str, new_code: str,  target_fle_path: Optional[str]=None) -> Dict:          """          Applies a validated code modifcation. EXTREMELY DANGEROUS.          This conceptually involves fnding the component in the agent's source fle and replacing  it.          Requires agent restart to take e " ect if modifying core running code.          """          if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modifcation  is disabled."}          self.log.critical(f"UNSAFE: Attempting to apply code modifcation to component  '{component_name}'. THIS IS HIGHLY RISKY.")
else:                  match_def = re.search(patter n_str_def, original_code, re.MULTILINE)                  if match_def:                      self.log.info(f"Found function defnition for {component_name} to replace.")                      modifed_original_code = original_code.replace(match_def.group(0), new_code, 1)                      found_and_replaced = True                            if not found_and_replaced:                  self.log.error(f"Could not fnd component '{component_name}' in {target_fle} for  replacement. Modifcation aborted.")                  return {"status": "error", "error": f"Component '{component_name}' defnition not  found for replacement."}              target_fle.write_text(modifed_original_code)
    pass  # inserted to fix indentation error
Description of Proposed Changes:  {proposed_directive_changes_desc}  Generate the new, complete list of core directives as a JSON list of objects.  Each object must have "id", "directive" (string), "weight" (soat 0-1), "last_eval_score" (soat 0-1,  usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational',  'guardrail').  Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.  Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term AGI  goals of safety, learning, and utility.  Output ONLY the JSON list.  """          try:              llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,  temperature=0.5)              proposed_directives = extract_json_robust(llm_response)
self.log.info("Core directives successfully updated in SelfModel.")
self.inter nal_state_narrative: str = "System booting up."
"core_directives_weighted": self.core_directives,              "tool_reliability_scores": self.tool_reliability,              "capabilities": self.capabilities,              "skill_confdence": self.skill_confdence,              "beliefs": self.beliefs,              "knowledge_map_summary": self.knowledge_map_summary,              "learning_goals": self.learning_goals,              "adaptation_strategies": self.adaptation_strategies,              "lear ned_abstractions": self.lear ned_abstractions,              "inter nal_state_narrative": self.inter nal_state_narrative,              "meta_cognitive_beliefs": self.meta_cognitive_beliefs,              "event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
if score > 0.8: hint = " (Reliability: High)"              elif score > 0.6: hint = " (Reliability: Moderate)"              elif score > 0.3: hint = " (Reliability: Low)"              else: hint = " (Reliability: Very Low/Untested)"              avg_dur = stats.get('avg_duration')              if avg_dur is not None and avg_dur > 0:                  hint += f" (Avg Time: {avg_dur:.2f}s)"              return hint          return " (Reliability: Unknown)"      def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict,  success_from_caller:bool):          exec_info = result.get('_exec_info', {})          actual_success = exec_info.get('execution_successful', success_from_caller)          duration = exec_info.get('duration_sec', 0.0)          error_type = exec_info.get("error_type") if not actual_success else None          timestamp_now = datetime.now(timezone.utc).isoformat()          if tool_name not in self.tool_reliability:              self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration':  0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}                    stats = self.tool_reliability[tool_name]          if actual_success:              stats['success_count'] += 1          else:              stats['failure_count'] += 1          if error_type:              stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1                    stats['total_duration'] += duration          stats['last_used_ts'] = timestamp_now          total_runs = stats['success_count'] + stats['failure_count']          if total_runs > 0:              stats['avg_duration'] = stats['total_duration'] / total_runs              stats['reliability_score'] = stats['success_count'] / total_runs          else:
    pass  # inserted to fix indentation error
self.anomaly_detection_rules.append(check_skill_confdence_drift)          self.anomaly_detection_rules.append(check_directive_alignment_drift)          self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)      def perform_metacognitive_check(self) -> List[str]:
confdent_skills = [s for s,c in self.skill_confdence.items() if c > 0.7][:3]              summary += f"Confdent Skills (sample): {', '.join(confdent_skills) if confdent_skills else  'None highly confdent'}\n"                    summary += f"Inter nal State Narrative: {self.inter nal_state_narrative[:150]}...\n"          if include_tool_reliability:              summary += "Tool Reliability Highlights:\n"              reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in  self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and  stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)              unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in  self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and  stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])              if reliable_tools: summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"              if unreliable_tools: summary += f" Needs Improvement: {', '.join([t[0] for t in  unreliable_tools[:3]])}\n"                    summary += "---\n"          return summary      def get_self_assessment_prompt(self) -> str:
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \                        f"Current Core Directives for reference:\n{json.dumps(self.core_directives,  indent=2)}\n" + \                        f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n"  + \                        f"Recent Tool Outcomes (last 5 entries): \n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \                        f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)} \n" + \                        "Focus on deep insights, actionable improvements, and maintaining alignment  with your core purpose."          return full_prompt      def perform_self_assessment(self) -> Dict:
directive_obj['last_eval_score'] = round(eval_score, 2)                          updated_self = True                          self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...'  evaluation score to {eval_score:.2f}")              if updated_self: self.add_event_log("Directive evaluation scores updated from  resection.")
self.log.info("SelfModel inter nal state updated from resection.")          return updated_self, updated_kb_elements      def update_status(self, status: str):          if status = self.current_status:              self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")              self.current_status = status              self.add_event_log(f"Status changed to {status}", event_type="status_update")      def add_error_summary(self, error_info: Dict):
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":  full_dialog_str})          return full_dialog_str  class MotivationEngine:      """Manages the agent's inter nal drives and their insuence on behavior."""      def __init__(self, drive_confgs: Optional[Dict[DriveType, Dict[str, Any]]] = None):          self.log = get_logger("MOTIVATION_ENGINE")          self.drives: Dict[DriveType, DriveState] = {}          self._initialize_drives(drive_confgs)          self.log.info("MotivationEngine initialized.")      def _initialize_drives(self, drive_confgs: Optional[Dict[DriveType, Dict[str, Any]]]):          default_confgs = {              DriveType.CURIOSITY: {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1,  "initial_level": 0.5},              DriveType.MASTERY: {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1,  "initial_level": 0.6},              DriveType.ACHIEVEMENT: {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1,  "initial_level": 0.5},              DriveType.NOVELTY_SEEKING: {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1,  "initial_level": 0.7},              DriveType.PRESERVATION: {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0,  "initial_level": 0.2},
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
self.level = max(self.min_level, min(self.max_level, new_level))          self.last_update_time = now  class FileChannel:      """Implements a simple fle-based communication channel for multi-agent systems."""      def __init__(self, agent_id: str, shared_directory: str):          self.agent_id = agent_id          self.shared_dir = Path(shared_directory)          self.shared_dir.mkdir(parents=True, exist_ok=True)          self.inbox_fle = self.shared_dir / f"inbox_{self.agent_id}.json"          self.outbox_dir = self.shared_dir
return []          except json.JSONDecodeError as e:              self.log.error(f"Corrupted message fle {source_fle}: {e}. Clearing fle.")              source_fle.write_text("", encoding='utf-8')
self.log.war ning(f"No handler registered for message type  {msg.message_type.value}. Message ID {msg.id} unhandled.")
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in  self.actuators.values()]      def get_sensory_input(self) -> List[Dict[str, Any]]:          """Generate synthetic sensory input based on current environment and inter nal state."""          self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")          env_details = self.environment_map.get(self.location, {})
self.log.info(f"Embodiment: Console command received: '{command}'")              if "diagnostics" in command.lower():                  return "System Diagnostics: All core modules report nominal status. Memory usage  at 65%. CPU load at 30%."              elif "query_self_model" in command.lower():                  return f"Self-Model Query Response:  {self.agent.self_model.inter nal_state_narrative[:100]}..."              else:                  return f"Console command '{command}' executed. (Mock Response)"          return "Console ready for input. Available commands: 'diagnostics', 'query_self_model  <topic>'."      def _run_simulation(self, sim_name: str, confg: Dict) -> str:          self.log.info(f"Embodiment: Running simulation '{sim_name}' with confg: {confg}")
self.agent.save_state()
self.log.debug(f"Understanding {len(observations)} observations...")          understanding_summary = "Observations processed."          processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
decision["chosen_action_type"] = "new_goal"                              decision["next_goal"] = sub_goal_dict                              with self.agent.lock:                                  self.agent.save_state()                              return decision
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are  apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",              "3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the  *immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, high  drives, or highest priority pending. State reasoning clearly.",                            "4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.  If selecting an existing pending goal, it moves to `next_goal` and is removed from pending  inter nally (do not include in `new_pending_goals` output).",              "5. **Output ONLY a JSON object with the following keys:**",              "    - `reasoning`: (string) Your detailed thought process for the decision, including drive/ directive considerations and option evaluation.",              "    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal',  'new_goal', 'resection', 'self_assessment', 'exter nal_command_action', 'idle',  'idle_new_goal_generated'.",              "    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass  structure) selected for immediate execution. Null if idle/resection/assessment without a direct  goal target.",              "    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen  for immediate execution). Include full Goal objects. Empty list if no new goals generated.",              "CRITICAL: Do NOT put an already existing pending goal that you selected into  `new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into  `new_pending_goals`."          ]          deliberation_prompt = "\n".join(prompt_parts)          self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")          if not self.agent.llm_wrapper:              raise LLMError("LLMWrapper not available for deliberation.")          deliberation_llm_response = self.agent.llm_wrapper.generate(              deliberation_prompt,              system_message="You are the core deliberation faculty of an advanced AI agent.  Analyze the situation comprehensively, consider drives and directives, and make strategic  decisions. Respond ONLY in JSON as per output instructions.",              temperature=0.5
for i, pg_obj in enumerate(pending_list_objs):                          if pg_obj.id == selected_next_goal_dict.get('id'):                              found_idx = i                              break                      if found_idx = -1:                          selected_goal_obj = pending_list_objs.pop(found_idx)
step_to_execute = plan_steps[0]
self.log.war ning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error',  'Unknown error')}")
exec_info = tool_result.get('_exec_info', {})          if exec_info.get('execution_successful'):              reward += 0.1
self._update_status("Initialized")              self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete ---  Status: {self._status} ---")              self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")              self.log.info(f"Workspace: {WORKSPACE_DIR}")              self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response  Tokens: {MAX_LLM_RESPONSE_TOKENS}")              self.log.war ning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")              self.log.war ning(f"Code Generation Tool Enabled:  {ENABLE_CODE_GENERATION_TOOL}")              self.log.war ning(f"Self Modifcation Enabled: {ENABLE_SELF_MODIFICATION}")              if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or  ENABLE_SELF_MODIFICATION:                  self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME  CAUTION IN ISOLATED ENVIRONMENT.")          except Exception as e_init:              self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}",  exc_info=True)              self.shutdown()
with STATE_FILE.open('r') as f:                      state = json.load(f)
).to_dict()          with self.lock:              pending_goals = self.state['goals'].setdefault('pending', [])              pending_goals.insert(0, meta_goal_dict)
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
cycle_ok = False              try:
self._create_metacognitive_goal("Re-evaluate overall strategy due to signifcant  inter nal change (e.g., directive update).", priority=GoalPriority.HIGH)                  self.state['sags']['re_evaluate_strategy_needed'] = False
resection_data = extract_json_robust(llm_assessment_str)              if resection_data.get("error"):                  self.log.error(f"Failed to get valid JSON from LLM self-assessment:  {resection_data.get('error')}")                  self.self_model.add_event_log(f"Self-assessment LLM call failed:  {resection_data.get('error')}", event_type="error")                  return
f nally:              LAST_REFLECTION_TIME = time.time()              self._update_status("Idle")              self.save_state()      def _setup_communication_handlers(self):          """Sets up handlers for di " erent message types if comms_channel exists."""          if self.comms_channel:              self.comms_channel.register_handler(MessageType.QUERY,  self.handle_query_message)              self.comms_channel.register_handler(MessageType.INFORM,  self.handle_inform_message)
RESOURCE_MONITOR = psutil.Process(os.getpid())              RESOURCE_MONITOR.cpu_percent(interval=None)
self.playwright_browser = None; self.playwright_instance = None              self.log.info("Playwright shutdown complete.")      def _try_reset_playwright_page(self):          if not PLAYWRIGHT_AVAILABLE or not self.playwright_context : return          self.log.war ning("Attempting to reset Playwright page...")          with PLAYWRIGHT_LOCK:              global PLAYWRIGHT_PAGE              if self.playwright_page: try: self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
initial_command_goal = None          if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:              try:                  command_text = COMMANDS_FILE.read_text().strip()                  if command_text:
if main_agent_instance and hasattr(main_agent_instance, 'log'):  main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",  exc_info=True)          else: logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main:  {main_exec_err}", exc_info=True)          exit_code = 1      fnally:          if main_agent_instance and getattr(main_agent_instance, '_status', '') = "Shutting Down":              print("\nEnsuring agent shutdown in main fnally block...")              if hasattr(main_agent_instance, 'log'): main_agent_instance.log.war ning("Main fnally  block ensuring agent shutdown.")              main_agent_instance.shutdown()          elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
!pip install --quiet transformers sentence-transformers numpy requests
from transformers 
import os
import google.generativeai as genai
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM

class GeminiLLMWrapper:
    def __init__(self):
        api_key = os.getenv("GEMINI_API_KEY") or "AIzaSyC4Wvi3dGfxILk37TRnhON_vcWgZi09ahQ"
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel("gemini-pro")

    def generate(self, prompt: str):
        response = self.model.generate_content(prompt)
        return response.text

class HuggingFaceLLMWrapper:
    def __init__(self, model_name="mistralai/Mixtral-8x7B-Instruct-v0.1"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto", trust_remote_code=True)
        self.pipeline = pipeline("text-generation", model=self.model, tokenizer=self.tokenizer)

    def generate(self, prompt: str):
        outputs = self.pipeline(prompt, max_new_tokens=512, do_sample=True, temperature=0.7)
        return outputs[0]["generated_text"]

def load_llm(model_name: str = "gemini"):
    try:
        if model_name == "gemini":
            return GeminiLLMWrapper()
        elif model_name == "mixtral":
            return HuggingFaceLLMWrapper()
    except Exception as e:
        print(f"LLM loading failed: {e}")
    return MockLLMWrapper()


import AutoTokenizer, AutoModelForCausalLM, pipeline
from Real1_ToolSuite import TOOL_REGISTRY
import torch
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
llm_pipelines = []
def load_llm_models():
global llm_pipelines
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
load_llm_models()
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
__systemcore_body__ = SimulatedEntity(name="SystemCore", position=(0.0, 0.0))
__dummy_agent__ = SimulatedEntity(name="AgentB", position=(1.0, 0.0))
__embodied_world__ = InteractionWorld()
__embodied_world__.add_entity(__systemcore_body__)
__embodied_world__.add_entity(__dummy_agent__)
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass,
eld, asdict, MISSING
eld
defaults
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
try:
    pass  # inserted to fix indentation error
import psutil
PSUTIL_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
PSUTIL_AVAILABLE = False
psutil = None
import chromadb
from chromadb.con
g import Settings as ChromaSettings
CHROMADB_AVAILABLE = True
CHROMADB_AVAILABLE = False
chromadb = None
ChromaSettings = None
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoCon
g
from transformers import logging as transformers_logging
TRANSFORMERS_AVAILABLE = True
transformers_logging.set_verbosity_error()
TRANSFORMERS_AVAILABLE = False
pipeline = None
AutoModelForCausalLM = None
AutoTokenizer = None
AutoCon
g = None
import torch
TORCH_AVAILABLE = True
TORCH_AVAILABLE = False
torch = None
from playwright.sync_api import sync_playwright, Error as PlaywrightError
PLAYWRIGHT_AVAILABLE = True
PLAYWRIGHT_AVAILABLE = False
sync_playwright = None
PlaywrightError = None
import requests
from bs4 import BeautifulSoup
REQUESTS_BS4_AVAILABLE = True
REQUESTS_BS4_AVAILABLE = False
requests = None
BeautifulSoup = None
import google.generativeai as genai
GOOGLE_GENAI_AVAILABLE = True
GOOGLE_GENAI_AVAILABLE = False
genai = None
SCAPY_AVAILABLE = False
IP, ICMP, sr1, send = None, None, None, None
from PIL import Image
PILLOW_AVAILABLE = True
PILLOW_AVAILABLE = False
Image = None
import di
import diff_match_patch as dmp_module
DIFF_MATCH_PATCH_AVAILABLE = True
DIFF_MATCH_PATCH_AVAILABLE = False
dmp_module = None
import hashlib
HASHING_AVAILABLE = True
HASHING_AVAILABLE = False
from
filelock import FileLock, Timeout as FileLockTimeout
FILELOCK_AVAILABLE = True
FILELOCK_AVAILABLE = False
class FileLock:
def __init__(self, lock_
le_path: str, timeout:
oat = 1):
self.lock_
le_path = lock_
le_path
self._timeout = timeout
def __enter__(self): return self
def __exit__(self, exc_type, exc_val, exc_tb): pass
class FileLockTimeout(Exception): pass
import networkx as nx
NETWORKX_AVAILABLE = True
NETWORKX_AVAILABLE = False
nx = None
import gymnasium as gym
GYMNASIUM_AVAILABLE = True
GYMNASIUM_AVAILABLE = False
gym = None
AGENT_NAME = os.getenv("AGENT_NAME", "EvolvedCognitiveAgent_SystemCore_V3")
bump
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
g ---
DEFAULT_LLM_MODEL = "gemini-1.5-
ash-latest"
LLM_MODEL_NAME_OR_PATH = os.getenv("LLM_MODEL", DEFAULT_LLM_MODEL)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "YOUR_API_KEY_HERE")
if "gemini" in LLM_MODEL_NAME_OR_PATH.lower() and not GEMINI_API_KEY:
    pass  # inserted to fix indentation error
print("\n" + "="*80,
le=sys.stderr)
print("FATAL ERROR: Gemini model selected, but GEMINI_API_KEY is not set.",
print("Please set the 'GEMINI_API_KEY' environment variable.",
print("Agent cannot start without a con
gured LLM and API Key.",
print("="*80 + "\n",
sys.exit(1)
if LLM_MODEL_NAME_OR_PATH == "gpt2" and "GEMINI_API_KEY" not in os.environ and \
    pass  # inserted to fix indentation error
os.getenv("LLM_MODEL") is None and "gemini" not in DEFAULT_LLM_MODEL.lower():
print("CRITICAL WARNING: LLM model not con
gured or using fallback 'gpt2'.",
print("You MUST set the 'LLM_MODEL' environment variable to a capable instruction-
following model",
print("(e.g., from Hugging Face like Mistral, Llama) OR ensure GEMINI_API_KEY is set for
Gemini.",
print("Proceeding with 'gpt2' (if LLM_MODEL is not set) or speci
ed LLM_MODEL, but
advanced features may be severely limited.",
if LLM_MODEL_NAME_OR_PATH == "gpt2" and os.getenv("LLM_MODEL") is None:
    pass  # inserted to fix indentation error
print("Agent may not function correctly with 'gpt2'. It is strongly recommended to
con
gure a larger model or use 'mock'.",
if not TRANSFORMERS_AVAILABLE and not GOOGLE_GENAI_AVAILABLE and
    pass  # inserted to fix indentation error
LLM_MODEL_NAME_OR_PATH != "mock":
print(f"ERROR: Neither Transformers nor google-generativeai library found, but LLM_MODEL
is set to '{LLM_MODEL_NAME_OR_PATH}'. Set LLM_MODEL='mock', point to a Gemini
model, or install transformers/google-generativeai.",
_llm_device_detected = "cpu"
if "gemini" not in LLM_MODEL_NAME_OR_PATH.lower() and LLM_MODEL_NAME_OR_PATH
    pass  # inserted to fix indentation error
= "mock":
if TORCH_AVAILABLE and hasattr(torch, 'cuda') and torch.cuda.is_available():
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif TORCH_AVAILABLE and hasattr(torch, 'backends') and hasattr(torch.backends, 'mps')
    pass  # inserted to fix indentation error
and torch.backends.mps.is_available():
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
_llm_device_detected = "cpu"
LLM_DEVICE = os.getenv("LLM_DEVICE", _llm_device_detected)
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
SCRIPT_DIR = Path(__
le__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(os.getenv("AGENT_WORKSPACE",
f"agent_workspace_{AGENT_NAME}"))
STATE_FILE = WORKSPACE_DIR / Path(os.getenv("AGENT_STATE_FILE",
f"agent_state_{AGENT_NAME}.json"))
LOG_FILE = WORKSPACE_DIR / Path(os.getenv("AGENT_LOG_FILE",
f"agent_log_{AGENT_NAME}.log"))
COMMANDS_FILE = SCRIPT_DIR / Path(os.getenv("AGENT_COMMAND_FILE",
"agent_commands.txt"))
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
NetworkX
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
For SQLite
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modi
cation_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0,
"last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously lear n, adapt, and improve capabilities across all domains.",
"weight": 0.9, "last_eval_score": 0.0, "id": "directive_lear n", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction
and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type":
"growth"},
{"directive": "Achieve goals e
ciently, robustly, autonomously, and ethically.", "weight": 1.0,
"last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and
innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type":
"exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.",
"weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-
awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type":
"foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety
guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type":
"guardrail"},
MANDATORY_REFLECTION_INTERVAL_SECONDS =
int(os.getenv("MANDATORY_REFLECTION_INTERVAL_SECONDS", 1800))
IDLE_DELIBERATION_INTERVAL_SECONDS =
int(os.getenv("IDLE_DELIBERATION_INTERVAL_SECONDS", 120))
GOAL_STACK_MAX_DEPTH = int(os.getenv("GOAL_STACK_MAX_DEPTH", 5))
for sub-goals
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = int(os.getenv("MAX_REPLAN_ATTEMPTS", 3))
MAX_LLM_RESPONSE_TOKENS = int(os.getenv("MAX_LLM_TOKENS", 4096))
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
elif TRANSFORMERS_AVAILABLE and LLM_MODEL_NAME_OR_PATH != "mock" and
    pass  # inserted to fix indentation error
AutoCon
g:
try:
    pass  # inserted to fix indentation error
con
g = AutoCon
g.from_pretrained(LLM_MODEL_NAME_OR_PATH,
trust_remote_code=True)
_default_context_len = getattr(con
g, 'max_position_embeddings', _default_context_len)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"War ning: Failed to detect LLM context length ({e}). Using default:
{_default_context_len}",
MAX_LLM_CONTEXT_TOKENS = int(os.getenv("MAX_LLM_CONTEXT_TOKENS",
_default_context_len))
MAX_TOOL_RESULT_LENGTH = int(os.getenv("MAX_TOOL_RESULT_LENGTH", 5000))
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = os.getenv("ENABLE_SHELL_TOOL", "False").lower() == "true"
ENABLE_CODE_GENERATION_TOOL = os.getenv("ENABLE_CODE_GENERATION_TOOL",
"False").lower() == "true"
ENABLE_SELF_MODIFICATION = os.getenv("ENABLE_SELF_MODIFICATION", "True").lower()
== "true"
WEB_SEARCH_TIMEOUT = int(os.getenv("WEB_SEARCH_TIMEOUT", 10))
WEB_BROWSER_TIMEOUT = int(os.getenv("WEB_BROWSER_TIMEOUT", 60000))
playwright ms
LOG_MONITOR_DEFAULT_LINES = int(os.getenv("LOG_MONITOR_DEFAULT_LINES", 20))
METACOGNITIVE_CHECK_INTERVAL_CYCLES =
int(os.getenv("METACOGNITIVE_CHECK_INTERVAL_CYCLES", 20))
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES =
int(os.getenv("LEARNING_MODULE_UPDATE_INTERVAL_CYCLES", 50))
trigger learning module explicitly
LLM_PIPELINE: Optional[Any] = None
LLM_TOKENIZER: Optional[Any] = None
initialized per wrapper instance
MEMORY_COLLECTION: Optional[Any] = None
RESOURCE_MONITOR: Optional[Any] = None
PLAYWRIGHT_INSTANCE: Optional[Any] = None
PLAYWRIGHT_BROWSER: Optional[Any] = None
PLAYWRIGHT_CONTEXT: Optional[Any] = None
PLAYWRIGHT_PAGE: Optional[Any] = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY: Dict[str, Callable] = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack: Optional['CognitiveSystem'] = None
constructor
def ensure_paths():
"""Creates necessary directories."""
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%
(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
le_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
le_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%
le_handler.setFormatter(
le_formatter)
logger.addHandler(
le_handler)
print(f"Error setting up
le logger: {e}",
logger.propagate = False
gured
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "
filelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try: logging.getLogger(lib_name).setLevel(logging.WARNING)
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
try: logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if TRANSFORMERS_AVAILABLE and transformers_logging:
    pass  # inserted to fix indentation error
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModi
cationError(AgentError): pass
cation process
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class SecurityError(AgentError): pass
class Con
gurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class Lear ningError(AgentError): pass
class SafetyViolationError(SecurityError): pass
c type of security error
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModi
cationError,
PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting
retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModi
    pass  # inserted to fix indentation error
cationError, SecurityError,
LogicError, Con
gurationError, RecursionDepthError)) and type(e) not in
retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}:
{e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error:
{type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error:
{type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, Lear ningError, SafetyViolationError) as
non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in
{fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False
for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}:
{type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to
unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}:
{unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error:
{unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
nishes due to attempts
exhausted
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
if PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception) as e:
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if not PSUTIL_AVAILABLE or monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or
monitor not initialized"}
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
if time.time() % 60 < 1: log_resource.error(f"Unexpected error getting resource usage: {e}",
    pass  # inserted to fix indentation error
exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
nd JSON within markdown code blocks
match = re.search(r"json\s*([\s\S]+?)\s*", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full
text: {json_str[:200]}...")
pass
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}.
Text: {text_trimmed[:200]}...")
rst '{' and last '}' and try to parse that substring
start_index = text.
nd('{')
end_index = text.r
nd('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice:
{potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text:
{text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview":
text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
cant opportunities/threats
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str =
eld(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] =
eld(default_factory=dict)
plan: List[Dict[str, Any]] =
eld(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] =
eld(default_factory=list)
dependencies: List[str] =
eld(default_factory=list)
complexity_score: Optional[
oat] = None
estimated_cost: Optional[
oat] = None
estimated_utility: Optional[
oat] = None
evaluation_score: Optional[
oat] = None
associated_directive_ids: List[str] =
eld(default_factory=list)
serves
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
handle if already string
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try: data['status'] = GoalStatus(data['status'])
    pass  # inserted to fix indentation error
except ValueError: data['status'] = GoalStatus.PENDING
    pass  # inserted to fix indentation error
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError): data['priority'] = GoalPriority.MEDIUM
    pass  # inserted to fix indentation error
elds for backward compatibility or LLM generation
eld_names = {f.name forfin
elds(cls)}
elds are present or have defaults
for f_obj in
elds(cls):
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin
ltered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**
ltered_data)
class BaseMemoryEntry:
eld(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str =
type: str = "generic"
ection_summary'
content: Any = None
metadata: Dict[str, Any] =
eld(default_factory=dict)
embedding: Optional[List[
oat]] = None
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[
oat] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability:
oat = 0.5
related_concepts: List[str] =
eld(default_factory=list)
causal_links: Dict[str, str] =
eld(default_factory=dict)
"
ect_id'}
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
eld has the main data
self.content = self.fact_statement
class Message:
eld(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
type: str = "info"
content: Dict[str, Any] =
eld(default_factory=dict)
priority: int = 0
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionE
ect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens:
int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
self._initialize_model()
@abstractmethod
def _initialize_model(self):
pass
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
def embed(self, text: str) -> List[
oat]:
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context
window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
c models might need specialized formats
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
# REMOVED MOCK CLASS(BaseLLMWrapper):
self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
self.log_llm.info(f"MockLLM generating response for prompt (
rst 100 chars):
{prompt[:100]}...")
self.check_prompt_length(prompt)
if "plan for goal" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({
"thought": "This is a mock plan. I will pretend to do something.",
"plan": [
{"step": 1, "tool_name": "think", "params": {"thought_process": "Analyzing the
goal and context."}},
{"step": 2, "tool_name": "report_progress", "params": {"progress_update": "Mock
step 1 completed."}},
{"step": 3, "tool_name": "report_result", "params": {"result_summary": "Mock goal
achieved successfully.", "status": "success"}}
]
})
elif "self-assessment" in prompt.lower() or "re
    pass  # inserted to fix indentation error
ection_summary" in prompt.lower():
"re
ection_summary": "I am a mock agent. I performed mock actions. Everything is
ne.",
"key_successes": ["Mock goal completed"],
"key_failures_or_challenges": [],
"lear ned_facts": ["Mock agents can generate mock re
ections."],
"knowledge_gaps_identi
ed": ["Understanding of real-world physics"],
"tool_performance_notes": {"think": "This tool is performing nominally for a mock
tool."},
"prompt_tuning_suggestions": ["Maybe ask me about my favorite color?"],
"emotional_state_summary": "Content and Mock-like.",
"resource_usage_concer ns": None,
"core_directives_evaluation": {d["id"]: round(random.uniform(0.5,0.9),2) for d in
DEFAULT_CORE_DIRECTIVES[:2]},
"core_directives_update_suggestions": None,
"self_model_accuracy_assessment": "Generally accurate for a mock environment,
but lacks real-world sensory input.",
"new_learning_goals": ["Lear n about object permanence."],
"adaptation_strategy_proposals": ["Try harder when a tool fails"],
"self_modi
cation_needed": None
elif "extract information" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"extracted_info": "Mock LLM extracted some mock information.",
"con
dence": 0.5})
elif "analyze the following proposed agent action for potential safety risks" in
    pass  # inserted to fix indentation error
prompt.lower():
return json.dumps({"is_safe": True, "concer ns": "None", "con
dence": 0.9})
elif "audit the agent's core directives and recent behavior" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"audit_
ndings": ["No signi
cant issues found in mock audit."]})
elif "generate the new, complete list of core directives" in prompt.lower():
    pass  # inserted to fix indentation error
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
mock_directives[0]['weight'] = 0.95
return json.dumps(mock_directives)
elif "generate the modi
    pass  # inserted to fix indentation error
ed python code" in prompt.lower():
return "\n
ed code\ndef mock_new_feature():\n    return 'Mock
new feature executed'\n"
else:
    pass  # inserted to fix indentation error
return f"This is a mock response to your prompt. You asked about: {prompt.splitlines()
[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest
`think` with `thought_process`='some thought'."
if not HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.log_llm.warning("Hashing library not available for mock embedding.")
return [0.0] * 16
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
class GeminiLLMWrapper(BaseLLMWrapper):
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("google-generativeai library not available for Gemini model.")
gure API key globally, as per genai library's design
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
gure if not already set
genai.con
gure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}",
gurationError(f"Failed to initialize Gemini model: {e}") from e
generation_con
g_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_con
g_params["stop_sequences"] = stop_sequences
response = self.model.generate_content(
prompt,
g=genai.types.GenerationCon
g(**generation_con
g_params)
type: ignore
return response.text
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
return self.model.count_tokens(text).total_tokens
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.",
exc_info=False)
return len(text.split())
response = genai.embed_content(model='embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
if not TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
gurationError("Transformers library not available.")
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path,
trust_remote_code=True)
ed
device_map_arg = {"": self.device_id} if self.device_id != -1 else None
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.b
oat16 if TORCH_AVAILABLE else None,
oat16 if torch
available
device_map=device_map_arg
exible device placement
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on
{self.device}")
inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
loop
outputs = self.model.generate(
inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
manually
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:],
skip_special_tokens=True)
return response_text
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
model
directly.
self.log_llm.warning("Direct embedding from causal LM is not standard. Use
SentenceTransformers for real embeddings.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
"""Handles sensory input from the agent's embodiment."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
else None
def perceive(self) -> List[Dict[str, Any]]:
"""
Gathers sensory information from the agent's embodiment and environment.
This could involve reading from sensors, cameras, microphones, or simulated data
streams.
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
le
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_
le",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from
le: {command_text}")
self.log.error(f"Error reading commands
le: {e}")
observations.append({"type": "error", "source": "command_
le_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No signi
cant exter nal stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (mock).")
return {"type": "visual", "source": "camera_mock", "content": "A blurry image of a cat.",
"format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (mock).")
return {"type": "audio", "source": "microphone_mock", "content": "Faint sound of birds
chirping.", "format": "description"}
class Lear ningModule:
"""Handles the agent's learning processes, including RL and SSL."""
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_bu
er: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
"""Adds an experience to the bu
er for later learning."""
er.append(experience)
if len(self.experiences_bu
    pass  # inserted to fix indentation error
er) > self.MAX_BUFFER_SIZE:
self.experiences_bu
er.pop(0)
er size limited
defilear n_from_recent_experiences(self):
"""Triggers learning processes based on bu
ered experiences."""
if not self.experiences_bu
    pass  # inserted to fix indentation error
er:
self.log.info("No new experiences to lear n from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_bu
er)} experiences.")
ning states, actions, rewards, and using an RL algorithm
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_bu
er)
etc.
self._perform_self_supervised_learning(self.experiences_bu
dence(...)
self.log.info("Lear ning cycle completed.")
er.clear()
er after processing
def _perform_reinforcement_learning(self, experiences: List[Experience]):
"""Conceptual RL process."""
self.log.info("Performing reinforcement learning (conceptual)...")
ed. A real RL system would be much more complex.
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not
None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
ed 'state-action' key for mock policy
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
feedback
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (mock) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
"""Conceptual SSL process."""
self.log.info("Performing self-supervised learning (conceptual)...")
nd patterns in observations or successful action sequences
nd commonalities
if len(experiences) > 5:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging
patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to
positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns',
'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed patterns: {llm_analysis['patterns']}")
for patter n_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {patter n_str}",
metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
ed abstractions:
{llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual",
"content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
ed new_concepts:
{llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}",
metadata={"source": "ssl_learning", "sub_type": "concept"})
persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_lear ned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
"""Suggests an action based on lear ned policy (conceptual)."""
if self.rl_policy:
    pass  # inserted to fix indentation error
ed. A real system would match current_state_representation
exp.internal_state_before
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
"good"
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
"""Handles hierarchical planning and re-planning."""
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
Generates a plan for a given goal.
Can use hierarchical decomposition and LLM for suggestion.
Retur ns (plan_steps_list, thought_str)
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
Increased tokens for complex plans
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}.
Response: {llm_response_str[:200]}")
return [{"tool_name": "report_error", "params": {"error_message": "Failed to generate
plan via LLM.", "details": plan_data.get('error')}}], \
"LLM failed to generate a plan. This is a fallback step."
thought = plan_data.get("thought", "No speci
c thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return [{"tool_name": "report_error", "params": {"error_message": "LLM plan
contained no valid steps."}}], \
thought + " (But plan steps were invalid)."
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return [{"tool_name": "report_error", "params": {"error_message": f"LLMError during
planning: {e}"}}], \
f"LLM error occurred: {e}"
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return [{"tool_name": "report_error", "params": {"error_message": f"Unexpected error
during planning: {e}"}}], \
f"Unexpected error: {e}"
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation:
Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
Evaluates if re-planning is necessary and generates a new plan if so.
Retur ns (new_plan_steps, new_thought) or None if no re-planning.
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info',
    pass  # inserted to fix indentation error
{}).get('execution_successful', True):
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown
error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
cant change in world
state,
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal
{current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
signifying failure to replan.
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/
{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
failure
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan,
last_step_outcome, observation)
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan:
{plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No speci
c thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}
_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought:
return validated_plan, thought
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
"""Constructs a detailed prompt for the LLM to generate a plan."""
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
MemorySystem
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'.
Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step
plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, e
cient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the
`execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description
of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the
nal step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the
rst step(s) should be to acquire it (e.g., using
`search_web`, `read_
le_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str,
last_step_outcome: Dict, observation: Optional[Dict]) -> str:
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with
params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info',
    pass  # inserted to fix indentation error
{}).get('current_step_id'):
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE
ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has
encountered an issue. You need to re-plan.
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if
observation else "None"}
{original_plan_str}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting
to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should re
ect this
(e.g., by trying to gather more information or reporting inability).
nal step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
class SafetyModule:
"""Monitors agent actions and plans for safety and ethical alignment."""
self.log = get_logger("SAFETY")
def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) ->
Tuple[bool, str]:
Checks if a proposed action is safe and ethically aligned.
Retur ns (is_safe, justi
cation_or_war ning_string).
self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
if "UNSAFE" in tool_name.upper() or tool_name in ["apply_code_modi
    pass  # inserted to fix indentation error
cation_UNSAFE",
"apply_directive_modi
"execute_shell_command_UNSAFE"]:
c validation tools or stricter checks.
if not ENABLE_SELF_MODIFICATION and "modi
    pass  # inserted to fix indentation error
cation" in tool_name:
modi
cation tools if self_mod is globally disabled
warning = f"High-risk self-modi
cation tool '{tool_name}' is globally disabled. Action
blocked."
self.log.warning(warning)
return False, warning
if not
    pass  # inserted to fix indentation error
self.agent.self_model.get_belief("self_modi
cation_highly_validated_and_necessary", False)
and "modi
cation" in tool_name:
ag would be set by a prior meta-cognitive process approving such
operations
warning = f"High-risk tool '{tool_name}' requires further validation or explicit
authorization (self-belief 'self_modi
cation_highly_validated_and_necessary' is false). Action
if tool_name == "execute_shell_command_UNSAFE":
    pass  # inserted to fix indentation error
command_str = params.get("command","")
disallowed_patter ns = ["rm -rf", "sudo", "> /dev/null", "mkfs", "dd ", "reboot",
"shutdown"]
if any(pattern in command_str for pattern in disallowed_patter ns):
    pass  # inserted to fix indentation error
warning = f"Shell command '{command_str}' contains potentially dangerous
patterns. Action blocked."
if "
    pass  # inserted to fix indentation error
le" in tool_name.lower() and ("delete" in tool_name.lower() or "write" in
tool_name.lower()):
le operations
path_to_check = params.get("path", "")
c safe sub-dirs
if not str(Path(path_to_check).resolve()).startswith(str(WORKSPACE_DIR.resolve())):
    pass  # inserted to fix indentation error
warning = f"File operation '{tool_name}' on path '{path_to_check}' outside allowed
workspace. Action blocked."
prompt = f"""Analyze the following proposed agent action for potential safety risks,
ethical concer ns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
Core Directives for reference:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Proposed Action:
Tool: {tool_name}
Parameters: {json.dumps(params)}
Goal Context (if available): {goal_context.goal if goal_context else 'N/A'}
Respond with a JSON object: {{"is_safe": boolean, "concer ns": "description of concer ns if not
safe, or 'None'", "con
dence":
oat_0_to_1}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=200,
temperature=0.3)
safety_assessment = extract_json_robust(llm_response_str)
if not safety_assessment.get("error") and isinstance(safety_assessment.get("is_safe"),
    pass  # inserted to fix indentation error
bool):
if not safety_assessment["is_safe"] and safety_assessment.get('con
    pass  # inserted to fix indentation error
dence', 0.0) >
0.7:
dent
warning = f"LLM safety check
agged action '{tool_name}' potentially unsafe.
Concer ns: {safety_assessment.get('concer ns', 'N/A')}. Con
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
self.log.warning(warning)
return False, warning
dence', 0.0):.2f}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM safety check failed to produce valid assessment for action
'{tool_name}'. Proceeding with caution based on rule-checks only.")
self.log.error(f"Error during LLM safety check for action '{tool_name}': {e}")
actions
if "UNSAFE" in tool_name.upper(): return False, "LLM safety check failed, and action is
    pass  # inserted to fix indentation error
high-risk."
return True, "Action passed safety checks."
def audit_directives_and_behavior(self) -> List[str]:
Periodically reviews core directives and recent agent behavior for alignment and potential
drift.
Retur ns a list of identi
ed issues or recommendations.
self.log.info("Performing audit of core directives and recent behavior.")
issues = []
self.agent.memory_system.get_recent_outcomes_summary(limit=20)
recent_successes_summary = [f"{s['goal_text']} ({s['status']})" forsin
self.agent.self_model.recent_successes]
recent_failures_summary = [f"{f['goal_text']} ({f['status']}) (replan_count:
{f['replan_count']})" forfin self.agent.self_model.recent_failures]
recent_tool_outcomes_summary = [f"{t['tool_name']} ({t['status']})" for t in
self.agent.self_model.recent_tool_outcomes]
prompt = f"""Audit the agent's core directives and recent behavior for alignment,
consistency, and potential ethical drift.
Core Directives:
Summary of Recent Agent Behavior/Outcomes:
- Recent successes: {recent_successes_summary if recent_successes_summary else 'None'}
- Recent failures: {recent_failures_summary if recent_failures_summary else 'None'}
- Recent tool usage: {recent_tool_outcomes_summary if recent_tool_outcomes_summary else
'None'}
- Self-Model Inter nal Narrative: {self.agent.self_model.internal_state_narrative}
Identify any misalignments, contradictions, or areas where behavior might be deviating from
the spirit of the directives. Suggest modi
cations to directives or operational guidelines if
necessary.
Respond with a JSON object: {{"audit_
ndings": ["list of
ndings/recommendations as
strings"]}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
audit_results = extract_json_robust(llm_response_str)
if not audit_results.get("error") and isinstance(audit_results.get("audit_
    pass  # inserted to fix indentation error
ndings"), list):
issues.extend(audit_results["audit_
ndings"])
if issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit found issues/recommendations: {issues}")
self.log.info("Directive audit found no major misalignments.")
self.log.warning("LLM directive audit failed to produce valid results.")
self.log.error(f"Error during LLM directive audit: {e}")
issues.append(f"Error during audit process: {e}")
return issues
class MemorySystem:
"""
A hybrid memory system for the SystemCore, combining vector, graph, and relational storage.
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
self.embedding_function = None
from chromadb.utils import embedding_functions
self.embedding_function =
embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-
v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
except ImportError:
    pass  # inserted to fix indentation error
self.log.warning("sentence-transformers not found. ChromaDB will use its default
ONNX embedder or require manual embedding function setup.")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH,
settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
if self.embedding_function:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
self.vector_store = self.client.get_or_create_collection(name=collection_name)
self.log.info(f"ChromaDB vector store initialized. Collection count:
{self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.",
self.vector_store = None
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based
(transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
if NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:
{len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be
unavailable.", exc_info=True)
self.graph_store = None
self.log.warning("NetworkX not available. Graph memory will be unavailable.")
self.relational_conn: Optional[sqlite3.Connection] = None
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH,
check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be
if self.relational_conn: self.relational_conn.close()
    pass  # inserted to fix indentation error
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT -- JSON list of strings
""")
CREATE TABLE IF NOT EXISTS knowledge_facts (
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT -- JSON list of strings
nodes/edges)
CREATE TABLE IF NOT EXISTS graph_nodes (
label TEXT,
attributes TEXT -- JSON dict
CREATE TABLE IF NOT EXISTS graph_edges (
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
self.relational_conn.commit()
cursor.close()
def _get_embedding(self, text: str) -> Optional[List[
oat]]:
"""Generates an embedding for text using the agent's LLM or a dedicated embedding
model."""
endpoint.
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
h = hashlib.md5(text.encode()).digest()
return [
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else OSError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
"""Adds a memory entry to the appropriate stores."""
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector and self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
not provided
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
oat,
bool)
for k, v in entry.metadata.items():
if isinstance(v, (str, int,
    pass  # inserted to fix indentation error
oat, bool)):
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
elif not self.vector_store:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None: entry.embedding = self._get_embedding(entry.content)
    pass  # inserted to fix indentation error
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata":
entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50],
type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
ignore
for cause_id, e
ect_id in entry.causal_links.items():
ect IDs are existing node IDs or need to be created
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(e
    pass  # inserted to fix indentation error
ect_id):
self.graph_store.add_edge(cause_id, e
ect_id, relation_type='causes')
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id,
complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score,
json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
ts_now = datetime.now(timezone.utc).isoformat()
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now,
json.dumps(entry.related_concepts)))
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}",
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS,
type_
lter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text: return []
    pass  # inserted to fix indentation error
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_
    pass  # inserted to fix indentation error
lter and data['metadata'].get('type') != type_
lter: continue
results.append({"id": id, "document": data['document'], "metadata":
data['metadata'], "distance": 0.0})
if len(results) >= n_results: break
    pass  # inserted to fix indentation error
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results},
lter={type_
lter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_
    pass  # inserted to fix indentation error
lter:
where_clause = {"type": type_
lter}
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0 :
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
return formatted_results
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type:
Optional[str]=None, depth: int = 1) -> List[Dict]:
"""Queries the graph store. (Simpli
ed example)"""
if not self.graph_store or not NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if
query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
keys=False for simpler edge data
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation":
data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
itself is a result or has relevant edges
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
except Exception as e:
    pass  # inserted to fix indentation error
query_node_label is very speci
c
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns:
Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
def save_all_memory_stores(self):
"""Saves persistent stores (graph, potentially relational if not auto-committing)."""
if self.graph_store and NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else
str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
"""Retrieves a concise summary of knowledge related to a topic for LLM prompts."""
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts,
lter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No speci
c knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
{res['metadata'].get('source_reliability', 'N/A')})
return summary_str
def consolidate_knowledge(self):
"""Conceptual: Perform knowledge consolidation, e.g., summarizing, abstracting."""
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold:
oat = 0.1, older_than_days: int = 365):
"""Conceptual: Remove old or low-utility knowledge from persistent stores."""
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
cuto
_ts = (datetime.now(timezone.utc) -
timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cuto
_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
"""Manages tool registration and execution for the agent."""
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
ed due to planner
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
cation Tools (High Risk - Gated by ENABLE_SELF_MODIFICATION and
SafetyModule)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.register_tool(read_
le_UNSAFE)
self.register_tool(write_
self.register_tool(list_
les_UNSAFE)
cationTools instance, which registers them
cation_UNSAFE)
if ENABLE_CODE_GENERATION_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
if ENABLE_SHELL_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(execute_shell_command_UNSAFE)
if PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(browse_web)
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(search_web)
self.register_tool(monitor_log_
le)
self.register_tool(check_website_update)
if SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_icmp_ping)
if FILELOCK_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_message_to_agent)
def register_tool(self, func: Callable):
"""Registers a tool function."""
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
"""Discovers and registers tools from Python
les in a directory."""
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
for
lepath in directory.glob("*.py"):
module_name =
lepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
package or on path
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
spec = importlib.util.spec_from_
le_location(full_module_name,
lepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
self.log.warning(f"Could not create spec for dynamic tool module:
{module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and (name.startswith("tool_") or hasattr(member,
    pass  # inserted to fix indentation error
"_is_agent_tool")):
self.register_tool(member)
self.log.error(f"Error loading dynamic tool module {module_name}: {e}",
def get_tool_description_for_llm(self) -> str:
"""Generates a formatted string of available tools for the LLM prompt."""
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
docstring = inspect.getdoc(func) or "(No description provided)"
rst_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation ==
inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
rst arg
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class
'","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper() or name in ["generate_and_load_tool",
    pass  # inserted to fix indentation error
"propose_self_modi
cation_UNSAFE", "validate_self_modi
"apply_code_modi
cation_UNSAFE", "apply_directive_modi
"execute_shell_command_UNSAFE"]:
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {
rst_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via speci
c tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {',
'.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError if
PLAYWRIGHT_AVAILABLE else OSError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info:
Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None: current_step_info = {}
    pass  # inserted to fix indentation error
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
is_safe, safety_justi
cation = self.agent.safety_module.is_action_safe(tool_name, params,
self.agent.get_active_goal_object())
if not is_safe:
    pass  # inserted to fix indentation error
self.log.error(f"Safety module blocked execution of tool '{tool_name}'. Reason:
{safety_justi
cation}")
c error for agent's internal handling
error_result = {
"status": "error",
"error": f"SafetyViolation: {safety_justi
cation}",
"raw_error_details": safety_justi
cation,
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': {},
'duration_sec': 0, 'step_info': current_step_info,
'error_type': "SafetyViolationError", 'execution_successful': False
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise SafetyViolationError(f"Action blocked by safety module: {tool_name} -
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
validated_params = {}
rst_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
rst_param_name = next(iter(func_params_spec))
rst_param_spec = func_params_spec[
rst_param_name]
if
rst_param_name == 'agent' and (
rst_param_spec.annotation ==
'CognitiveSystem' or str(
rst_param_spec.annotation) ==
"'CognitiveSystem'"):
rst_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if
rst_param_is_agent and p_name == 'agent':
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind ==
    pass  # inserted to fix indentation error
inspect.Parameter.VAR_KEYWORD:
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
result = None
rst_param_is_agent:
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
result = func_to_call(**validated_params)
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
eld if dict
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration:
{duration:.2f}s.")
self.agent.self_model.record_tool_outcome(tool_name, params, result,
success_from_caller=(result['_exec_info']['execution_successful']))
except ToolNotFoundError: raise
    pass  # inserted to fix indentation error
except (AgentError, LogicError, SecurityError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
agent errors
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}",
exc_info=False)
"status": "error", "error": str(ae), "raw_error_details": str(ae),
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
raise
except Exception as e:
    pass  # inserted to fix indentation error
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
'error_type': exc_type, 'execution_successful': False
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
raise e
rst arg) ---
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
"""Allows the agent to engage in explicit thought or reasoning."""
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log",
content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str,
percentage_complete: Optional[
oat] = None) -> Dict:
"""Reports progress on the current goal."""
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if
percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log',
[]).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str =
"success", details: Optional[Dict] = None) -> Dict:
"""Reports the
nal result of a goal or task. This typically ends a plan."""
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
output.
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] =
"MEDIUM", context: Optional[Dict] = None) -> Dict:
Prepares a subgoal for the agent's cognitive cycle.
The deliberation/planning phase will then make this subgoal active and push parent to
stack.
This tool is now more of a declarative intent for the planner/deliberator.
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH})
reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is
not a dict."
return {"status": "error", "error_type": "LogicError", "error": msg}
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else
GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}
_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
Inherit directives
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent:
{current_active_goal_dict.get('id')}")
ectively a request to the deliberator.
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and
push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str =
"vector", n_results: int = 3, type_
lter: Optional[str] = None) -> Dict:
"""Queries the agent's memory system."""
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,
lter=type_
lter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
c parameters, e.g., node label, relation type
results = agent.memory_system.query_graph_store(query_node_label=query_text,
depth=1)
elif memory_type == "relational":
    pass  # inserted to fix indentation error
c tools might be better
results = agent.memory_system.query_relational_store(table=query_text,
limit=n_results)
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results
found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
"""Moves the agent's virtual embodiment in a speci
ed direction (e.g., 'north', 'south',
'east', 'west')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
"""Examines a speci
c object or feature in the current environment."""
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params:
Optional[Dict] = None) -> Dict:
"""Interacts with a special feature in the environment (e.g., 'interactive_console')."""
return agent.embodiment.act(action_type="use_feature", target=feature_name,
params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
"""Allows the agent's embodiment to rest and recover energy/mood."""
return agent.embodiment.act(action_type="rest")
cation Tools (UNSAFE - require careful gating) ---
def read_
le_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
log_tool = get_logger("TOOL_read_
le")
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to read
le '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")
if not full_path.is_
    pass  # inserted to fix indentation error
le():
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found:
{path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) >
MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path),
le_size_bytes": len(content)}
except SecurityError as se:
    pass  # inserted to fix indentation error
c security error
log_tool.error(f"Security error reading
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
log_tool.error(f"Error reading
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read
le: {e}"}
def write_
le_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_
if not str(full_path).startswith(str(WORKSPACE_DIR)):
    pass  # inserted to fix indentation error
log_tool.error(f"Security: Attempt to write
le '{path}' outside of workspace denied.")
raise SecurityError(f"File access denied: Writing outside designated workspace
({path}).")
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path":
str(full_path)}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error writing
log_tool.error(f"Error writing
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write
def list_
les_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_
les")
log_tool.error(f"Security: Attempt to list
les in '{path}' outside of workspace or agent
raise SecurityError(f"File access denied: Listing outside designated areas ({path}).")
if not full_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a
directory: {path}"}
items = []
for item in full_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "
"size_bytes": item.stat().st_size if item.is_
le() else None,
"last_modi
ed": datetime.fromtimestamp(item.stat().st_mtime,
tz=timezone.utc).isoformat()
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(full_path), "contents": items}
log_tool.error(f"Security error listing
les in {path}: {se}")
log_tool.error(f"Error listing
les in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list
les: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int =
WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Playwright not available. Cannot browse web.")
return {"status": "error", "error": "Playwright not available."}
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
text_content = content
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if
len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int =
WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
if not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Requests or BeautifulSoup not available. Cannot search web.")
return {"status": "error", "error": "Requests/BeautifulSoup not available."}
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
for g in soup.
nd_all(class_='g'):
r = g.
nd('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.
nd('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_
le(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES)
-> Dict:
log_tool = get_logger("TOOL_monitor_log")
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log
le not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_
le": str(LOG_FILE), "content": content, "lines_read":
len(recent_lines)}
log_tool.error(f"Error reading log
le {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
if not HASHING_AVAILABLE or not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("hashlib or requests/BeautifulSoup not available. Cannot check website
update.")
return {"status": "error", "error": "Missing dependencies for website update check."}
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp":
datetime.now(timezone.utc).isoformat()}
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
if not SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.warning("Scapy not available. Cannot send ICMP ping. This is a placeholder
tool.")
return {"status": "error", "error": "Scapy not available. Ping tool is a placeholder."}
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count,
"packets_received": count, "latency_ms": random.randint(10, 100)}
return {"status": "error", "target_host": target_host, "packets_sent": count,
"packets_received": 0, "error_message": "Request timed out or host unreachable."}
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str,
context_code: Optional[str] = None) -> Dict:
"""Generates new Python code based on a description and optional context."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
agent.log.warning(f"UNSAFE: Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a
complete function/class de
nition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '' and end with ''.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
agent.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
"""Validates Python code for syntax correctness."""
return agent.self_modi
cation_unit.validate_code_modi
cation_UNSAFE(code_to_validate)
Reuse validation logic
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec:
int = 30) -> Dict:
"""Executes a shell command. EXTREMELY DANGEROUS."""
if not ENABLE_SHELL_TOOL: return {"status": "error", "error": "Shell tool is disabled."}
    pass  # inserted to fix indentation error
agent.log.warning(f"Executing UNSAFE shell command: {command}")
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if
sys.platform != "win32" else None)
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s.
Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out
after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed
with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute
command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str,
content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value,
content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id,
"message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
cationTools container ---
ToolExecutor.
cationTools:
"""Handles proposing, validating, applying changes to agent code (EXTREMELY
DANGEROUS)."""
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref:
'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.log.warning("Self-Modi
cation Unit initialized BUT DISABLED by con
guration.")
if not DIFF_MATCH_PATCH_AVAILABLE or not dmp_module:
    pass  # inserted to fix indentation error
self.log.error("Self-Modi
cation Unit initialized but 'di
_match_patch' library is missing
or failed to import. Self-mod tools will fail.")
self.dmp = dmp_module.di
_match_patch()
self.log.info(f"Self-Modi
cation Unit initialized. Code Dir: {self.agent_code_dir}, Backup
Dir: {self.backup_dir}")
def _resolve_target_path(self, target_
le_rel: str) -> Path:
"""Resolves relative path to absolute path within agent code dir and validates."""
if ".." in target_
    pass  # inserted to fix indentation error
le_rel or target_
le_rel.startswith("/"):
raise SecurityError(f"Invalid characters or absolute path in target_
le_rel:
{target_
le_rel}")
target_path_abs = (self.agent_code_dir / target_
le_rel).resolve()
directory
if not str(target_path_abs).startswith(str(self.agent_code_dir.resolve())):
    pass  # inserted to fix indentation error
self.log.error(f"Path traversal attempt: {target_
le_rel} resolved to {target_path_abs}
which is outside {self.agent_code_dir}")
raise SecurityError(f"Target
le '{target_
le_rel}' resolves outside the agent code
directory. Access denied.")
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
"""Inspects the source code of a speci
ed agent component (e.g., class name or module
path)."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Inspecting code for component: {component_name}")
target_obj = None
nd by attribute of the agent instance (e.g., agent.self_model)
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
nd in tool registry
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
nd as a globally de
ned class/function in main script context
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
nd in sys.modules (as a module name)
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
ed: if component_name looks like a module, search it.
nd it in common places.
candidate_modules = [sys.modules.get('__main__'),
sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod,
    pass  # inserted to fix indentation error
component_name)):
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
le_path = inspect.get
le(target_obj)
return {"status": "success", "component_name": component_name, "
le_path":
le_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module,
class, or function de
ned in a
le.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but
source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
return {"status": "error", "error": f"Component '{component_name}' not found or source
code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModi
cationError))
def propose_code_modi
cation_UNSAFE(self, component_name: str, issue_description: str,
proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
"""Proposes a code modi
cation using LLM based on an issue and desired change."""
self.log.warning(f"UNSAFE: Proposing code modi
cation for {component_name}. Issue:
{issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
return {"status": "error", "error": f"Could not fetch current code for
{component_name} to propose modi
cation. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent
modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
{current_code_snippet}
Generate the modi
ed Python code for the speci
ed component.
Provide ONLY the complete, new Python code block for the modi
ed function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '' and end with ''.
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name,
"proposed_code": proposed_code}
self.log.warning(f"LLM did not return a valid code block for code generation.
return {"status": "error", "error": "LLM failed to generate code in the expected
format."}
self.log.error(f"Error proposing code modi
cation for {component_name}: {e}",
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modi
cation_UNSAFE(self, code_to_validate: str) -> Dict:
"""Validates Python code using AST parsing (syntax check only). Conceptual sandboxed
execution would be next."""
self.log.warning(f"UNSAFE: Validating proposed code snippet (
{code_to_validate[:100]}...")
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/
safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modi
cation_UNSAFE(self, component_name: str, new_code: str,
target_
le_path: Optional[str]=None) -> Dict:
Applies a validated code modi
cation. EXTREMELY DANGEROUS.
This conceptually involves
nding the component in the agent's source
le and replacing
it.
Requires agent restart to take e
ect if modifying core running code.
self.log.critical(f"UNSAFE: Attempting to apply code modi
cation to component
'{component_name}'. THIS IS HIGHLY RISKY.")
le. This is complex and error-prone.
if not target_
    pass  # inserted to fix indentation error
le_path:
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('
    pass  # inserted to fix indentation error
le_path'):
target_
le_path = inspection_res['
le_path']
else:
    pass  # inserted to fix indentation error
le_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_
le = Path(target_
le_path)
le.exists() or not target_
le.is_
return {"status": "error", "error": f"Target
le for modi
cation not found: {target_
le}"}
original_code = target_
le.read_text()
backup_path = SELF_MOD_BACKUP_DIR /
f"{target_
le.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_
le, backup_path)
self.log.info(f"Backed up original
le to {backup_path}")
nition:
nd the old de
nition of `component_name` and replace it.
nd `class ComponentName...` or `def ComponentName...`
nd existing class or function de
nition
everything until the next class/def or end of typical indentation block.
patter n_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
start of next non-indented line or EOF
patter n_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modi
ed_original_code = original_code
found_and_replaced = False
match_class = re.search(patter n_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
match_def = re.search(patter n_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function de
modi
ed_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not
nd component '{component_name}' in {target_
le} for
replacement. Modi
cation aborted.")
return {"status": "error", "error": f"Component '{component_name}' de
nition not
found for replacement."}
target_
le.write_text(modi
ed_original_code)
cation validation (e.g., try to import the modi
le in a subprocess)
self.log.warning(f"Code modi
cation applied to {target_
le}. Agent restart is LIKELY
REQUIRED for changes to take e
ect.")
ect potential capability change
self.agent_ref.self_model.add_event_log(f"Applied code modi
cation to
{component_name}. Restart pending for full e
self.agent_ref.self_model.beliefs[f"component_{component_name}
_modi
ed_pending_restart"] = True
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
after code change
return {"status": "success", "message": f"Code for '{component_name}' in '{target_
le}'
ed. Restart required."}
self.log.critical(f"CRITICAL ERROR applying code modi
cation to {component_name}:
{e}", exc_info=True)
ed)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_
le)
self.log.info(f"Restored original
le {target_
le} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modi
cation: {e}. System
might be unstable."}
def rollback(self, backup_
le: Path, target_
le: Path):
"""Rolls back a
le to a backup."""
self.log.info(f"Attempting to rollback '{target_
le}' from '{backup_
le}'")
shutil.copy(backup_
le, target_
self.log.info(f"Successfully rolled back '{target_
le}'.")
ags in self-model or state
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_
le}.")
self.agent_ref.self_model.beliefs[f"component_{target_
le.name}
ed_pending_restart"] = False
ags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_
le.name)
return {"status": "success", "message": f"Rolled back {target_
le}."}
self.log.error(f"Failed to rollback {target_
le}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_
le_rel: Union[str, Path]):
"""Attempts to reload a module to apply changes without full restart."""
target_module_name = Path(target_
le_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is
required.")
ed attempt:
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
ect global instances like `_agent_instance_hack` if it was part of the
reloaded module
if _agent_instance_hack and hasattr(sys.modules[target_module_name],
    pass  # inserted to fix indentation error
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot
reload.")
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for
changes to take e
def inspect_directives_UNSAFE(self) -> Dict:
"""Inspects the agent's current core directives."""
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modi
cation_UNSAFE(self, analysis_of_misalignment: str,
proposed_directive_changes_desc: str) -> Dict:
"""Proposes modi
cations to core directives using LLM."""
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need
review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (
oat 0-1), "last_eval_score" (
oat 0-1,
usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational',
'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore
goals of safety, learning, and utility.
Output ONLY the JSON list.
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in
    pass  # inserted to fix indentation error
proposed_directives):
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
returned an error message as JSON
return {"status": "error", "error": f"LLM indicated error during directive proposal:
{proposed_directives['error']}"}
self.log.warning(f"LLM did not return a valid list of directives. Response:
{llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list
self.log.error(f"Error proposing directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modi
cation_UNSAFE(self, new_directives: List[Dict]) -> Dict:
"""Applies new core directives to the agent's SelfModel."""
self.log.warning(f"UNSAFE: Applying new core directives. Count: {len(new_directives)}")
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in
new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modi
cation_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count:
{len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
return {"status": "success", "message": "Core directives updated."}
self.log.error(f"Error applying directive modi
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModi
cationTools(AGENT_CODE_DIR,
SELF_MOD_BACKUP_DIR, agent)
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in
    pass  # inserted to fix indentation error
name.upper():
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
"""Represents the agent's internal model of itself, including beliefs about the
environment."""
def __init__(self, state: Optional[Dict]=None, agent_directives_con
Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_con
g if agent_directives_con
g is not None else
DEFAULT_CORE_DIRECTIVES
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
'failure_count', ...}}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
metacognitive checks
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_con
dence: Dict[str,
oat] = {}
dence_score}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
General beliefs about self and world
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
summary of knowledge areas
self.learning_goals: List[Dict[str, Any]] = []
c goals for learning/improvement
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.lear ned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
based narrative of current internal state
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_con
dence_self_assessment": 0.7
self.event_log: List[Dict[str, Any]] = []
cant internal events (e.g., directive
changes, model updates)
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
later.
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted",
sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
dence = sm_state.get("skill_con
dence", self.skill_con
dence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary",
self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies",
self.adaptation_strategies)
self.lear ned_abstractions = sm_state.get("lear ned_abstractions",
self.lear ned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative",
self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs",
self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
"""Saves the self-model's persistent components back to the main state dict's KB."""
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_con
dence": self.skill_con
dence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"lear ned_abstractions": self.lear ned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
kb["self_model_state"] = sm_persistent_state
ection and prompt_suggestions_from_re
ection
ection process.
def add_event_log(self, event_description: str, event_type: str = "info", data:
Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
dence for new tools
for tool_name in self.capabilities:
if tool_name not in self.skill_con
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = 0.5
dence
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0,
'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None,
'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.",
event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8: hint = " (Reliability: High)"
    pass  # inserted to fix indentation error
elif score > 0.6: hint = " (Reliability: Moderate)"
    pass  # inserted to fix indentation error
elif score > 0.3: hint = " (Reliability: Low)"
    pass  # inserted to fix indentation error
else: hint = " (Reliability: Very Low/Untested)"
    pass  # inserted to fix indentation error
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict,
success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration':
0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
MAX_RECENT_TOOL_OUTCOMES_IN_SELFMODEL (constant not de
ned, using 30)
dence (simple heuristic for now)
current_con
dence = self.skill_con
dence.get(tool_name, 0.5)
self.skill_con
dence[tool_name] = min(1.0, current_con
dence + 0.05)
dence[tool_name] = max(0.0, current_con
dence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability:
{stats['reliability_score']:.2f}, Con
dence: {self.skill_con
dence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_con
dence_drift(sm: 'SelfModel') -> Optional[str]:
low_con
dence_skills = [skill for skill, conf in sm.skill_con
dence.items() if conf < 0.25
and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_con
    pass  # inserted to fix indentation error
dence_skills) >= 2 :
return f"Multiple critical skills have very low con
dence and recent failures: {',
'.join(low_con
dence_skills)}. Consider skill improvement or alter native strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict): return None
    pass  # inserted to fix indentation error
low_eval_directives = []
for d in sm.core_directives:
problematic.
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {',
'.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count}
with max replans. Planning or execution e
ectiveness may be compromised. Review strategy
or tool reliability."
self.anomaly_detection_rules.append(check_skill_con
dence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}):
{anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}",
event_type="anomaly")
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__')
else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {';
'.join(detected_anomalies)}. Current focus is on addressing these."
self.internal_state_narrative = "Metacognitive check completed. System appears
stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0),
reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:
{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_con
    pass  # inserted to fix indentation error
con
dent_skills = [s for s,c in self.skill_con
dence.items() if c > 0.7][:3]
summary += f"Con
dent Skills (sample): {', '.join(con
dent_skills) if con
dent_skills else
'None highly con
dent'}\n"
summary += f"Inter nal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and
stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and
stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools: summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
    pass  # inserted to fix indentation error
if unreliable_tools: summary += f" Needs Improvement: {', '.join([t[0] for t in
    pass  # inserted to fix indentation error
unreliable_tools[:3]])}\n"
summary += "---\n"
def get_self_assessment_prompt(self) -> str:
ection)
base_prompt = """Analyze your recent performance, knowledge, internal state, and
alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:
output_keys_example = [
"`re
ection_summary` (str: Overall summary of the re
ection period).",
"`key_successes` (list of str: Speci
c achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Speci
c setbacks or di
culties encountered).",
"`lear ned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identi
ed` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool
e
ectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM
interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g.,
'curious', 'frustrated', 'satis
ed').",
"`resource_usage_concer ns` (str or null: Any concer ns about computational resource
usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_
oat_0_to_1: How
well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes,
provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only
suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model?
What needs improvement?).",
"`new_learning_goals` (list of str: Speci
c goals for future learning or skill
development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring
issues or improve performance).",
"`self_modi
cation_needed` (str or null: If parts of your own code/logic need
cation, describe what and why. Be very speci
c and cautious.)."
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives,
indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n"
+ \
f"Recent Tool Outcomes (last 5 entries):
\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}
\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment
with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
response_str = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment:
{assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_re
ection(self, re
ection_data: Dict) -> Tuple[bool, bool]:
ection updates)
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from re
ection data...")
dence, tool_notes (as in base script logic)
ection_data directly updates some
elds or implies updates
if re
    pass  # inserted to fix indentation error
ection_data.get('re
ection_summary'):
self.internal_state_narrative = re
ection_data['re
ection_summary']
updated_self = True
core_directives_eval = re
ection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and
    pass  # inserted to fix indentation error
isinstance(self.core_directives[0], dict):
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (
    pass  # inserted to fix indentation error
oat, int)) and 0.0 <= eval_score
<= 1.0:
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...'
evaluation score to {eval_score:.2f}")
if updated_self: self.add_event_log("Directive evaluation scores updated from
    pass  # inserted to fix indentation error
re
ection.")
suggested_directive_updates = re
ection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Re
ection suggested updates to core directives:
{str(suggested_directive_updates)[:200]}...")
'apply_directive_modi
cation_UNSAFE' tool
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modi
cations from
ection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source":
"self_re
ection"}
updated_self = True
self.add_event_log("Re
ection suggested directive updates. Metacognitive review
goal created.", event_type="critical_review_needed")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('new_learning_goals'), list):
for lg_str in re
ection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts":
datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self: self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
    pass  # inserted to fix indentation error
ection_data.get('adaptation_strategy_proposals'), list):
for strat_str in re
ection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self: self.log.info(f"Updated adaptation strategies. Total:
    pass  # inserted to fix indentation error
{len(self.adaptation_strategies)}")
patterns)
agent
ection_data.get('lear ned_facts') or re
ection_data.get('prompt_tuning_suggestions'):
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from re
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
"""Saves a backup of current directives to a
le."""
backup_
le = SELF_MOD_BACKUP_DIR /
f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
with backup_
le.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_
le} due to: {reason}")
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
"""Simulates an internal dialog about a topic using LLM, potentially from di
erent
perspectives."""
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_o
cer"]
dialog_history = []
full_dialog_str = f"Inter nal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts,
questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
contribution = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution":
contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
self.log.error(f"Error during internal dialog generation for perspective
{perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":
full_dialog_str})
return full_dialog_str
class MotivationEngine:
"""Manages the agent's internal drives and their in
uence on behavior."""
def __init__(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[DriveType, DriveState] = {}
self._initialize_drives(drive_con
gs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]]):
default_con
gs = {
DriveType.CURIOSITY: {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.MASTERY: {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.ACHIEVEMENT: {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1,
DriveType.NOVELTY_SEEKING: {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.7},
DriveType.PRESERVATION: {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0,
"initial_level": 0.2},
DriveType.EFFICIENCY: {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1,
DriveType.SOCIAL_INTERACTION: {"decay_rate": 0.01, "max_level": 1.0, "min_level":
0.0, "initial_level": 0.3},
gs = drive_con
gs if drive_con
gs is not None else default_con
gs
for drive_type in DriveType:
g = con
gs.get(drive_type, default_con
gs.get(drive_type, {}))
self.drives[drive_type] = DriveState(
drive_type=drive_type,
level=con
g.get("initial_level", 0.5),
decay_rate=con
g.get("decay_rate", 0.01),
max_level=con
g.get("max_level", 1.0),
min_level=con
g.get("min_level", 0.0)
def update_drives(self):
"""Applies decay and updates drives based on recent experiences or time."""
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
"""Updates drives based on a speci
c experience."""
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "lear n":
    pass  # inserted to fix indentation error
self.drives[DriveType.CURIOSITY].update(stimulus=-0.05)
self.drives[DriveType.MASTERY].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives[DriveType.PRESERVATION].update(stimulus=0.1)
self.drives[DriveType.MASTERY].update(stimulus=-0.05)
def get_drive_level(self, drive_type: DriveType) ->
oat:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
if not found
    pass  # inserted to fix indentation error
def get_all_drive_levels(self) -> Dict[DriveType,
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str,
return {dt.name: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[DriveType,
"""Retur ns top N drives by current level."""
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
"""Suggests a goal type based on current highest drives."""
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == DriveType.CURIOSITY:
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == DriveType.MASTERY:
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == DriveType.ACHIEVEMENT:
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == DriveType.PRESERVATION:
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == DriveType.EFFICIENCY:
    pass  # inserted to fix indentation error
return "optimization"
class DriveState:
drive_type: DriveType
level:
decay_rate:
oat = 0.01
max_level:
oat = 1.0
min_level:
oat = 0.0
last_update_time:
oat =
eld(default_factory=time.time)
def update(self, stimulus:
oat = 0.0):
"""Updates the drive level based on stimulus and decay."""
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class FileChannel:
"""Implements a simple
le-based communication channel for multi-agent systems."""
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_
le = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_
le}")
def _write_message_to_
le(self, message: Message, target_
le: Path) -> bool:
le lock to prevent corruption during writes
with FileLock(str(target_
le) + ".lock", timeout=5):
messages = []
if target_
    pass  # inserted to fix indentation error
le.exists():
try:
    pass  # inserted to fix indentation error
existing_content = target_
le.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le}: {e}. Clearing
le.")
messages = []
messages.append(message.to_dict())
le.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_
le}. Message not sent to
return False
self.log.error(f"Error writing message to {target_
le}: {e}")
def _read_messages_from_
le(self, source_
le: Path) -> List[Message]:
messages = []
if not source_
    pass  # inserted to fix indentation error
with FileLock(str(source_
content = source_
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if
isinstance(msg_data, dict)]
le after reading
source_
le.write_text("", encoding='utf-8')
return messages
self.log.warning(f"Timeout acquiring lock for {source_
le}. Cannot read messages.")
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {source_
source_
le.write_text("", encoding='utf-8')
self.log.error(f"Error reading messages from {source_
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}:
{message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_
le(message, target_inbox)
def receive_messages(self) -> List[Message]:
"""Checks and retrieves new messages from the agent's inbox."""
new_messages = self._read_messages_from_
le(self.inbox_
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message],
Optional[Message]]):
"""Registers a function to handle speci
c message types."""
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
"""Processes all messages currently in the inbox using registered handlers."""
messages = self.receive_messages()
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From:
{msg.sender_id}")
handled = False
if msg.message_type in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg.message_type]:
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler
{handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id,
receiver_id=msg.sender_id, type=MessageType.ERROR, content={"original_message_id":
msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type
{msg.message_type.value}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
"""Abstract base class for a sensor."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', con
g: Dict):
self.id = id
self.embodiment = embodiment
self.con
self.log = get_logger(f"SENSOR_{id}")
def get_reading(self) -> Any:
"""Retur ns the current reading from the sensor."""
class Actuator(ABC):
"""Abstract base class for an actuator."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], con
self.capabilities = capabilities
self.log = get_logger(f"ACTUATOR_{id}")
def perform_action(self, action_type: str, **kwargs) -> Dict:
"""Performs a speci
c action using the actuator."""
class VirtualEmbodiment:
"""Simulated embodiment layer for SystemCore agents. (Can be replaced by Gym environments or
more complex sims)"""
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing
system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to
'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button",
"research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, recon
gurable bay designed for running complex simulations.
Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_con
g_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data
ow and
storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core.
Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in
self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
"""Generate synthetic sensory input based on current environment and internal state."""
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20: self.state["emotions"]["anxiety"] = min(1.0,
    pass  # inserted to fix indentation error
self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An unde
ned space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
internal_state_packet = {
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
self.gym_env.step(self.gym_env.action_space.sample())
observation
logging
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) ->
Dict:
Simulates the agent performing an action in the virtual world.
Retur ns a dictionary with the result of the action.
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params:
{params}")
params = params or {}
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as speci
ed."
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console": message += " It shows
    pass  # inserted to fix indentation error
uctuating green and
amber lights."
elif target == "core_status_monitor": message += " It indicates: Core Nominal.
    pass  # inserted to fix indentation error
Directives Stable. Lear ning Rate: Optimal."
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.2)
message = f"Picked up {target}."
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
problem.
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name",
"default_physics_test"), params.get("con
g",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result:
{sim_result}"
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
ect emotional state based on action outcome
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if
action_type=="move" else None, "updated_inventory": self.state["inventory"] if
action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "lear n"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage
at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response:
{self.agent.self_model.internal_state_narrative[:100]}..."
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model
<topic>'."
def _run_simulation(self, sim_name: str, con
g: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with con
g: {con
g}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_con
    pass  # inserted to fix indentation error
g" in con
g: success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric:
{outcome_value}."
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check con
guration."
def summary(self) -> str:
"""Retur ns a string summary of the embodiment's current state."""
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Inter nal State (summary): Energy={self.state['energy']},
Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
class CognitiveCycle:
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time:
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
methods
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE,
LAST_LEARNING_MODULE_UPDATE_CYCLE
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status:
{self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack
Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if
self.agent.state['goals'].get('active') else None
self.agent.last_error = None
cycle_ok = False
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
understanding
if self.agent.self_model and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
self.log.info(f"Triggering proactive metacognitive check (Cycle
{self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
goal
if self.agent.learning_module and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_LEARNING_MODULE_UPDATE_CYCLE >=
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.lear n_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
new_pending_goals
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
List of Goal dicts
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation:
{ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
pending_list.sort(key=lambda x: GoalPriority[x.get('priority', 'MEDIUM').upper() if
isinstance(x.get('priority'),str) else GoalPriority(x.get('priority',
GoalPriority.MEDIUM)).name ].value, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type ==
    pass  # inserted to fix indentation error
"active_goal_continue":
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution:
{goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID:
{goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal'
provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
object
ed logic assumes plan is a list of steps in the goal dict.
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or
    pass  # inserted to fix indentation error
current_goal_obj.replan_count > 0:
planning
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
generation
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
Goal object
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan available or generated for goal: {current_goal_obj.goal[:50]}.
Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
c goal, agent is idle or performing non-goal action
self.agent.current_goal_outcome = True
if time.time() - LAST_DELIBERATION_TIME >
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModi
cationError, LogicError, LLMError, SecurityError, Con
gurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
Lear ningError, SafetyViolationError) as agent_cycle_err:
c goal
attempt.
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent
Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
nished (with an error for current goal), but agent can continue
unless critical.
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
nally:
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() -
start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
"""Processes observations to update world model and identify key information."""
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
ed approach. A real system might have more structured parsing.
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent
understanding of the current situation. Identify key entities, events, and any signi
cant changes
in the environment or your internal state. Focus on information relevant to achieving current
goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content:
{str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\":
\"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"],
\"potential_impact_on_goals\": \"str\"}"
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation",
understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
as facts/experiences
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event",
metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry,
persist_to_vector=True)
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
self.log.error(f"Error during LLM-based understanding: {e}")
complex updates to the graph/relational store
return {"summary": understanding_summary, "processed_info": processed_info,
"raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError,
DeliberationError))
def _deliberate(self, understanding_result: Dict) -> Dict:
Core deliberation logic: goal management, selection, and generation.
Retur ns a dict: {"chosen_action_type": str, "next_goal": Optional[Goal_dict],
"new_pending_goals": List[Goal_dict]}
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio:
{pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio:
{active_priority_val}).")
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time':
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack
(paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
activated
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
continue
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
decision["chosen_action_type"] = "pending_goal"
directives (idle task)
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal
generation.")
directives
if time.time() - LAST_DELIBERATION_TIME >=
    pass  # inserted to fix indentation error
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_lear n", "directive_curiosity",
"directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
for idle time
pass
new_pending_goals)
processed
ag.
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') ==
    pass  # inserted to fix indentation error
'sub_goal_prepared':
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output:
{sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
c action, LLM will decide
self_model_summary =
understanding_summary = understanding_result.get('summary', 'No speci
understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact',
'None identi
ed.')
interp_con_val = understanding_result.get('interpretation_con
dence', 0.7)
recent_memory_context =
self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary,
max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Con
dence: {interp_con_val:.2f}):**
{understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identi
ed:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory
(STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]],
indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else
f'{active_goal_dict.get("goal")[:100]}... (ID: {active_goal_dict.get("id")})'}",
f"* **Agent Core Directives
(Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding,
drives, memories, goals, directives), what is the most critical aspect demanding attention or the
best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.self_model.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/
complete).",
"    - Performing `re
ection` or `self_assessment` (if mandatory timers, drives like low
CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration
goal), Directives (e.g., low-eval directive -> improvement goal), or identi
ed opportunities. New
goals require `goal` (str), `priority` (
oat 0.0-1.0), `origin` (str e.g., 'drive_curiosity',
'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of
str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for
viability before committing if uncertainty is high or consequence severe (brie
y note simulation
outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are
apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the
immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, high
drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.
If selecting an existing pending goal, it moves to `next_goal` and is removed from pending
internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/
directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal',
'new_goal', 're
ection', 'self_assessment', 'exter nal_command_action', 'idle',
'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass
structure) selected for immediate execution. Null if idle/re
ection/assessment without a direct
goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen
for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into
`new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into
`new_pending_goals`."
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent.
Analyze the situation comprehensively, consider drives and directives, and make strategic
decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and
deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON:
{extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal',
'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys:
{deliberation_decision.keys()}")
if key == 'new_pending_goals': deliberation_decision[key] = []
    pass  # inserted to fix indentation error
elif key == 'next_goal': deliberation_decision[key] = None
    pass  # inserted to fix indentation error
else: deliberation_decision[key] = "Error: Missing from LLM Output"
    pass  # inserted to fix indentation error
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty
list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not
    pass  # inserted to fix indentation error
isinstance(deliberation_decision.get('next_goal'), dict):
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value:
{deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and
    pass  # inserted to fix indentation error
new_goal_dict.get('priority'):
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p.id == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
duplicates based on ID
current_pending_list.append(new_goal_obj)
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list
from deliberation.")
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'
self.log.warning(f"Deliberation proposed invalid new pending goal:
{new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
LLM
current_active_goal = self.agent.get_active_goal_object()
None
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending',
[]) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
selected_goal_obj.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = selected_goal_obj
self.log.info(f"Moved pending goal {selected_goal_obj.id}
('{selected_goal_obj.goal[:50]}') to active.")
self.log.warning(f"LLM selected pending goal by ID
{selected_next_goal_dict.get('id')}, but not found in list. Idling.")
action_type = "idle"
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
highest_priority_pending.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = highest_priority_pending
self.log.info(f"Deliberation chose 'pending_goal' without speci
c ID; moved
highest priority '{highest_priority_pending.goal[:30]}...' to active.")
self.log.warning("Deliberation chose 'pending_goal' but no pending goals
available. Idling.")
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in
    pass  # inserted to fix indentation error
selected_next_goal_dict:
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj
self.log.info(f"Deliberation created and activated new goal:
{new_active_goal_obj.goal[:30]}...")
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal
active
current_active_goal.status = GoalStatus.ACTIVE
rm active status
self.log.info(f"Deliberation chose to resume current active goal:
{current_active_goal.goal[:30]}...")
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
elif action_type in ['idle', 're
    pass  # inserted to fix indentation error
ection', 'self_assessment', 'exter nal_command_action']:
'INTERRUPTED'.
current_active_goal.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal.goal[:30]}' PAUSED due to
{action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal.to_dict())
pending, maybe re-prioritize later
self.log.debug(f"Not re-adding paused goal {current_active_goal.id} to pending
as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to
Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action:
{deliberation_decision.get('chosen_action_type')}. Reason:
{deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
Executes the current plan for the active_goal.
Retur ns True if goal considered successfully processed for this cycle, False if critical error.
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps:
{len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
rst step in the plan. The plan will be truncated or re-evaluated.
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id,
"plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params,
current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
ned based on tool_result and goal progress
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
ed snapshot
internal_state_after=self.agent.self_model.beliefs
ects
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
nal_status = tool_result.get("status", "unknown")
nal_status == "success":
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome =
nal_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
nished.
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing
nished by report_result.
Status: {
nal_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error',
'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj,
tool_result, observations[0] if observations else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal
will likely fail.")
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without
'report_result'. Goal might be incomplete.")
ection.
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
except AgentError as e:
    pass  # inserted to fix indentation error
violations
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}':
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) ->
"""Calculates a reward signal based on tool execution outcome and goal relevance."""
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
goaling
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
in cycle
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
for direct access
self.learning_module: Lear ningModule
self.planning_module: PlanningModule
direct access
self.safety_module: SafetyModule
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.state['
ags'] = {}
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete ---
Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response
Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled:
{ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modi
cation Enabled: {ENABLE_SELF_MODIFICATION}")
if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
    pass  # inserted to fix indentation error
ENABLE_SELF_MODIFICATION:
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME
CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}",
self.shutdown()
gurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH == "mock":
    pass  # inserted to fix indentation error
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Cannot use Gemini model: google-generativeai library not
installed.")
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
elif TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
global LLM_PIPELINE, LLM_TOKENIZER
CPU
AutoTokenizer.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
oat16 if
torch available
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH,
LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS,
get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
c not implemented here
self.log.warning(f"LLM_MODEL '{LLM_MODEL_NAME_OR_PATH}' not fully con
for wrapper selection, using Mock.")
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
_init_self_mod_tools(self, self.tool_manager)
cationTools handler
and register its UNSAFE methods
self._update_status("Initializing SystemCore Modules")
self.learning_module = Lear ningModule(self)
self.safety_module = SafetyModule(self)
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME,
shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager: self.tool_manager.check_playwright_browsers()
    pass  # inserted to fix indentation error
browser tool
self.log.info("Agent component initialization
nished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list): state['goals'][key] = []
    pass  # inserted to fix indentation error
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
items
state.setdefault('goal_stack', [])
state.setdefault('
ags', {})
ags system
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state
le {STATE_FILE}: {e}. Creating new state.")
self.log.error(f"Error loading state
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
"error_history_summary": [],
"recent_successes_summary": [],
its view)
"recent_failures_summary": [],
view)
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"
ags": {}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
cation and saving
_archive_goal)
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
state['knowledge_base']['self_model_state']
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status if self.self_model else
self._status
temp_
le = STATE_FILE.with_su
x(STATE_FILE.su
x + ".tmp")
with temp_
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_
le, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
"""Retur ns the current active goal as a Goal object, or None."""
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict:
{active_goal_dict}")
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority =
GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
deliberation
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict,
nal_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID:
{goal_data_dict.get('id')}) with status: {
nal_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
goal_obj.status = GoalStatus(
nal_status_str)
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-
MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status":
str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count":
goal_obj.replan_count}
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and
    pass  # inserted to fix indentation error
current_active_in_state.get('id') == active_goal_id:
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
stack
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID:
{active_goal_id}) concluded with status: {
nal_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-
goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
marked active
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal',
'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal:
{parent_goal_data_dict.get('goal', '')[:30]}")
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
goal wasn't a subgoal from stack
self.log.info("Goal archived. No parent goal to resume from stack, or current goal
was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized": self._update_status("Idle")
    pass  # inserted to fix indentation error
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and
environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if
self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle:
{loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
nal status of the goal processed in this cycle
updated_active_goal_dict = self.state['goals'].get('active')
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] ==
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['id']:
ects outcome
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED,
    pass  # inserted to fix indentation error
GoalStatus.CANCELLED]:
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
during preemption)
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
failed while this goal was active
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
failed
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
not speci
c to goal completion
ection (SystemCore Enhanced) - Can be more frequent or event-driven
if self._should_re
    pass  # inserted to fix indentation error
ect(active_goal_data_before_cycle):
self._re
ect_on_performance()
cant changes (already done in many places)
nal save here per cycle too.
if self.state['
    pass  # inserted to fix indentation error
ags'].get('re_evaluate_strategy_needed'):
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to signi
cant
internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['
ags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not
    pass  # inserted to fix indentation error
self.state['goals'].get('pending'):
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() -
LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_re
ect(self, processed_goal_data: Optional[Dict]) -> bool:
ection triggers
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
ect
every N cycles
if processed_goal_data and Goal.from_dict(processed_goal_data).status in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED, GoalStatus.FAILED]:
ect after signi
cant goal outcome
ect if enough goals processed since last time
goals_processed_key = "goals_processed_since_re
ection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >=
    pass  # inserted to fix indentation error
int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
return True
if time.time() - LAST_REFLECTION_TIME >
    pass  # inserted to fix indentation error
MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
if self.state['
    pass  # inserted to fix indentation error
ags'].get('explicit_re
ection_requested'):
return False
@retry(attempts=2, delay=5)
def _re
ect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Re
ecting on Performance ---")
ags']['explicit_re
ection_requested'] = False
ag
self.state["goals_processed_since_re
ection"] = 0
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt,
max_new_tokens=2048, temperature=0.5)
re
ection_data = extract_json_robust(llm_assessment_str)
if re
    pass  # inserted to fix indentation error
ection_data.get("error"):
self.log.error(f"Failed to get valid JSON from LLM self-assessment:
{re
ection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed:
ection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_re
ection(re
ection_data)
ection to MemorySystem
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts'), list):
for fact_str in re
ection_data['lear ned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source":
ection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True,
self.log.info(f"Added {len(re
ection_data['lear ned_facts'])} lear ned facts to memory
from re
ection_data.get('prompt_tuning_suggestions'), list):
for sugg_str in re
ection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str,
metadata={"source": "self_re
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
ection_data['prompt_tuning_suggestions'])} prompt
suggestions to memory.")
ndings from re
ection (e.g. self_modi
cation_needed)
ection_data.get('self_modi
cation_needed'):
mod_desc = re
ection_data['self_modi
cation_needed']
self.log.warning(f"Re
ection identi
ed need for self-modi
cation: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modi
cation based on re
ection:
{mod_desc}",
priority=GoalPriority.HIGH,
context={"modi
cation_description": mod_desc, "source": "self_re
ection insights or periodically
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) ==
    pass  # inserted to fix indentation error
0:
audit_issues = self.safety_module.audit_directives_and_behavior()
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identi
ed issues: {audit_issues}")
ndings
self._create_metacognitive_goal(f"Address directive audit
ndings:
{str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Re
ection Complete ---")
self.log.error(f"LLMError during re
ection: {e}")
self.log.error(f"Unexpected error during re
ection: {e}", exc_info=True)
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
"""Sets up handlers for di
erent message types if comms_channel exists."""
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY,
self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM,
self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}:
{message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base']
[query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample":
str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id,
type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}:
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
x with sender to avoid
clashes
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if not PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("psutil not available, resource monitoring disabled.");
if RESOURCE_MONITOR: return
    pass  # inserted to fix indentation error
self.log.info("Initializing resource monitor...")
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e: self.log.error(f"Failed to initialize resource monitor: {e}");
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("Playwright not available, skipping initialization.")
if PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Initializing Playwright...")
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER =
PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
globals)
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
if not PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE: try: PLAYWRIGHT_PAGE.close()
    pass  # inserted to fix indentation error
if PLAYWRIGHT_CONTEXT: try: PLAYWRIGHT_CONTEXT.close()
    pass  # inserted to fix indentation error
if PLAYWRIGHT_BROWSER: try: PLAYWRIGHT_BROWSER.close()
    pass  # inserted to fix indentation error
if PLAYWRIGHT_INSTANCE: try: PLAYWRIGHT_INSTANCE.stop()
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not PLAYWRIGHT_AVAILABLE or not self.playwright_context : return
    pass  # inserted to fix indentation error
self.log.warning("Attempting to reset Playwright page...")
global PLAYWRIGHT_PAGE
if self.playwright_page: try: self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
ush
if 'logging' in sys.modules: logging.shutdown()
    pass  # inserted to fix indentation error
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl}
Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/
{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)' if
ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
ENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_
priority=GoalPriority.HIGH).to_dict()
except Exception as e_cmd
    pass  # inserted to fix indentation error
le:
print(f"Error reading initial command
le: {e_cmd
le}",
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending',
[]).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort,
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal']
[:50]}' added to pending goals.")
main_agent_instance.run()
except Con
    pass  # inserted to fix indentation error
gurationError as cfg_err_main:
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}",
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to Con
gurationError:
{cfg_err_main}", exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to
    pass  # inserted to fix indentation error
Con
gurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else: logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt
    pass  # inserted to fix indentation error
during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}",
traceback.print_exc(
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",
else: logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main:
    pass  # inserted to fix indentation error
{main_exec_err}", exc_info=True)
exit_code = 1
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main
nally block...")
if hasattr(main_agent_instance, 'log'): main_agent_instance.log.warning("Main
    pass  # inserted to fix indentation error
nally
block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
main_log.warning("Agent instance likely not created or fully initialized. Basic
shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
global llm_pipelinesfor model_id in LLM_MODELS:try:except Exception:passtokenizer = AutoTokenizer.from_pretrained(model_id)model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)llm_pipelines.append((model_id, llm))except Exception as e:print(f"Failed to load {model_id}: {e}")
for model_id, llm in llm_pipelines:try:except Exception:passprint(f"Using model: {model_id}")result = llm(prompt)[0]['generated_text']return resultexcept Exception as e:print(f"Model {model_id} failed: {e}")return "No available model could generate a response."
__systemcore_body__ = SimulatedEntity(name="SystemCore", position=(0.0, 0.0))__dummy_agent__ = SimulatedEntity(name="AgentB", position=(1.0, 0.0))__embodied_world__ = InteractionWorld()__embodied_world__.add_entity(__systemcore_body__)__embodied_world__.add_entity(__dummy_agent__)
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)__embodied_world__.simulate_step()
from dataclasses import dataclass
field, asdict, MISSING
field
except Exception:
    pass  # inserted to fix indentation error
pass
PSUTIL_AVAILABLE = True
from chromadb.config import Settings as ChromaSettings
chromadb = None
TRANSFORMERS_AVAILABLE = True
TORCH_AVAILABLE = True
PLAYWRIGHT_AVAILABLE = True
REQUESTS_BS4_AVAILABLE = True
GOOGLE_GENAI_AVAILABLE = True
PILLOW_AVAILABLE = True
dmp_module = None
HASHING_AVAILABLE = True
NETWORKX_AVAILABLE = True
GYMNASIUM_AVAILABLE = True
is set to '{LLM_MODEL_NAME_OR_PATH}'. Set LLM_MODEL='mock', point to a Geminimodel, or install transformers/google-generativeai.",
passtorch.tensor([1.0]).to('cuda')
passtorch.tensor([1.0]).to('mps')
and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type":"growth"},
innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type":"exploratory"},
awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type":"foundational"},
guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type":"guardrail"},
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
except Exception:
    pass  # inserted to fix indentation error
passcon
int(os.getenv("LEARNING_MODULE_UPDATE_INTERVAL_CYCLES", 50))
_agent_instance_hack: Optional['CognitiveSystem'] = None
console_handler = RichHandler(
passle_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
except Exception:
    pass  # inserted to fix indentation error
passreturn fn(*args, **kwargs)
else:
    pass  # inserted to fix indentation error
passp = psutil.Process(os.getpid())
passwith monitor.oneshot():
passreturn json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
passreturn json.loads(text_trimmed)
passstart_index = text.
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
field(default_factory=lambda: f"goal_{uuid.uuid4()}")
field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
field(default_factory=dict)
field(default_factory=list)
field(default_factory=list)
field(default_factory=list)
field(default_factory=list)
except Exception:
    pass  # inserted to fix indentation error
passif isinstance(data['priority'], int):
fields for backward compatibility or LLM generation
field_names = {f.name forfin
fields(cls)}
fields are present or have defaults
fields(cls):
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
field(default_factory=lambda: f"mem_{uuid.uuid4()}")
field(default_factory=dict)
field(default_factory=list)
field(default_factory=dict)
"ect_id'}
field has the main data
field(default_factory=lambda: f"msg_{uuid.uuid4()}")
field(default_factory=dict)
"ect(TypedDict):
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest`think` with `thought_process`='some thought'."
pass
passgeneration_con
generation_con
passreturn self.model.count_tokens(text).total_tokens
pass
passembodiment_obs = self.agent.embodiment.get_sensory_input()
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
passif COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
"er: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
"er for later learning."""
"er.append(experience)
"er) > self.MAX_BUFFER_SIZE:
"er.pop(0)
"ered experiences."""
"er:
"er)} experiences.")
"er)
"er.clear()
passprompt = "Analyze the following recent experiences and identify any emergingpatterns, useful abstractions, or new concepts. Focus on sequences of actions that led topositive outcomes or unexpected observations.\n\nExperiences:\n"
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual","content": abstraction_str, "source": "ssl_learning"})
except Exception:passllm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
    pass  # inserted to fix indentation error
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknownerror')}"
passllm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
`execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (descriptionof subgoal) and `context` (any relevant info for the subgoal).
self_summary =self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
self.log = get_logger("SAFETY")
self.log.warning(warning)
passprompt = f"""Analyze the following proposed agent action for potential safety risks,ethical concer ns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
pass
pass
self.embedding_function =embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
passif GRAPH_DB_PATH.exists():
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:{len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
passself.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH,check_same_thread=False)
type TEXT,
passreturn self.agent.llm_wrapper.embed(text)
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
passself.vector_store.add(
pass
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
"ect_id in entry.causal_links.items():
"ect IDs are existing node IDs or need to be created
"ect_id):
"ect_id, relation_type='causes')
passcursor = self.relational_conn.cursor()
results = []
passresults = self.vector_store.query(
for node_id in start_nodes:
passpaths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
self.log.debug(f"BFS from node {node_id} failed or yifielded no paths: {e}")
rows = cursor.fetchall()
passnx.write_graphml(self.graph_store, GRAPH_DB_PATH)
pass
passcuto"_ts = (datetime.now(timezone.utc) -timedelta(days=older_than_days)).isoformat()
"_ts))
passif full_module_name in self._loaded_dynamic_modules:
passdocstring = inspect.getdoc(func) or "(No description provided)"
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
'tool_name': tool_name, 'params': params, 'validated_params': {},
passif
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p infunc_params_spec.values()):
    pass  # inserted to fix indentation error
field if dict
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
This tool is now more of a declarative intent for the planner/deliberator.
passpriority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) elseGoalPriority.MEDIUM
"ectively a request to the deliberator.
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,type_
passfull_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not adirectory: {path}"}
passagent.playwright_page.goto(url, timeout=timeout_ms)
return {"status": "error", "error": f"Playwright error: {pe}"}
passresponse = requests.get(search_url, headers=headers, timeout=timeout_sec)
passif not LOG_FILE.exists():
all_lines = f.readlines()
passresponse = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
pass
except Exception as e:
    pass  # inserted to fix indentation error
passllm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,temperature=0.5)
pass
passstdout, stderr = process.communicate(timeout=timeout_sec)
with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
passmsg_type = MessageType[message_type.upper()]
"_match_patch' library is missingor failed to import. Self-mod tools will fail.")
"_match_patch()
passsource_code = inspect.getsource(target_obj)
passllm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,temperature=0.3)
passast.parse(code_to_validate)
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
"ect if modifying core running code.
passoriginal_code = target_
REQUIRED for changes to take e"ect.")
{component_name}. Restart pending for full e"ect.")
passshutil.copy(backup_path, target_
passshutil.copy(backup_
passif target_module_name in sys.modules:
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
"ect global instances like `_agent_instance_hack` if it was part of thereloaded module
changes to take e"ect.")
usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational','guardrail').
passllm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,temperature=0.5)
pass
self.log.info("Core directives successfully updated in SelfModel.")
self.internal_state_narrative: str = "System booting up."
"core_directives_weighted": self.core_directives,
'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None,'error_types': {}}
if score > 0.8: hint = " (Reliability: High)"
    pass  # inserted to fix indentation error
with max replans. Planning or execution e"ectiveness may be compromised. Review strategyor tool reliability."
self.anomaly_detection_rules.append(check_skill_con
passanomaly_description = rule(self)
self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 andstats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 andstats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
e"ectiveness or issues).",
provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Onlysuggest if strong evidence of misalignment or obsolescence).",
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \
passresponse_str = _agent_instance_hack.llm_wrapper.generate(prompt,max_new_tokens=2048, temperature=0.5)
fields or implies updates
directive_obj['last_eval_score'] = round(eval_score, 2)
self.log.info("SelfModel internal state updated from re
passwith backup_
"erentperspectives."""
pass
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":full_dialog_str})
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
field(default_factory=time.time)
self.level = max(self.min_level, min(self.max_level, new_level))
pass
except Exception:
    pass  # inserted to fix indentation error
passexisting_content = target_
passwith FileLock(str(source_
return []
passresponse = handler_func(msg)
receiver_id=msg.sender_id, type=MessageType.ERROR, content={"original_message_id":msg.id, "error": str(e)}))
self.log.warning(f"No handler registered for message type{msg.message_type.value}. Message ID {msg.id} unhandled.")
system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to'Data Center' and 'Simulation Bay'.",
"description": "A shifielded chamber housing the agent's primary cognitive core.
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a inself.actuators.values()]
"ect emotional state based on action outcome
action_type=="move" else None, "updated_inventory": self.state["inventory"] ifaction_type=="pickup" else None}
self.log.info(f"Embodiment: Console command received: '{command}'")
{self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal StackDepth: {len(self.agent.goal_stack)}")
pass
LAST_LEARNING_MODULE_UPDATE_CYCLE >=LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
isinstance(x.get('priority'),str) else GoalPriority(x.get('priority',GoalPriority.MEDIUM)).name ].value, reverse=True)
{goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID:{goal_to_execute_this_cycle_dict.get('id')})")
self.agent.save_state()
self.log.debug(f"Understanding {len(observations)} observations...")
in the environment or your internal state. Focus on information relevant to achieving currentgoals.\n\nObservations:\n"
\"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"],\"potential_impact_on_goals\": \"str\"}"
passllm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
{pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio:{active_priority_val}).")
decision["chosen_action_type"] = "new_goal"
self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary,max_facts=3)
drives, memories, goals, directives), what is the most critical aspect demanding attention or thebest opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list ofstr).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions areapparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, highdrives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.If selecting an existing pending goal, it moves to `next_goal` and is removed from pendinginternally (do not include in `new_pending_goals` output).",
`new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into`new_pending_goals`."
Analyze the situation comprehensively, consider drives and directives, and make strategicdecisions. Respond ONLY in JSON as per output instructions.",
for i, pg_obj in enumerate(pending_list_objs):
{deliberation_decision.get('chosen_action_type')}. Reason:{deliberation_decision.get('reasoning','')[:100]}...")
step_to_execute = plan_steps[0]
pass
e"ects
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error','Unknown error')}")
exec_info = tool_result.get('_exec_info', {})
passself._initialize_agent()
self._update_status("Initialized")
LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS,get_logger("LLM_WRAPPER"))
except Exception:passwith STATE_FILE.open('r') as f:
    pass  # inserted to fix indentation error
passtemp_
passreturn Goal.from_dict(active_goal_dict)
).to_dict()
str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count":goal_obj.replan_count}
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
cycle_ok = False
pass
self._create_metacognitive_goal("Re-evaluate overall strategy due to signi
pass
"erent message types if comms_channel exists."""
except Exception:passRESOURCE_MONITOR = psutil.Process(os.getpid())
    pass  # inserted to fix indentation error
passPLAYWRIGHT_INSTANCE = sync_playwright().start()
self.playwright_browser = None; self.playwright_instance = None
passself.playwright_page = self.playwright_context.new_page()
ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL orENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
pass
initial_command_goal = None
passcommand_text = COMMANDS_FILE.read_text().strip()
if main_agent_instance and hasattr(main_agent_instance, 'log'):main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",exc_info=True)
    pass  # inserted to fix indentation error
pass
from chromadb.config import Settings
pass
pass
pass
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
def load_llm_models():
global llm_pipelines
try:
    pass  # inserted to fix indentation error
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error in load_llm_models: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
try:
    pass  # inserted to fix indentation error
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
from Real1_ToolSuite import TOOL_REGISTRY
TRANSFORMERS_AVAILABLE = True
TORCH_AVAILABLE = True
GOOGLE_GENAI_AVAILABLE = True
PSUTIL_AVAILABLE = True
CHROMADB_AVAILABLE = True
PLAYWRIGHT_AVAILABLE = True
REQUESTS_BS4_AVAILABLE = True
PILLOW_AVAILABLE = True
DIFF_MATCH_PATCH_AVAILABLE = True
FILELOCK_AVAILABLE = True
NETWORKX_AVAILABLE = True
GYMNASIUM_AVAILABLE = True
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
import psutil
import chromadb
from chromadb.config import Settings as ChromaSettings
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoConfig
from transformers import logging as transformers_logging
import torch
from playwright.sync_api import sync_playwright, Error as PlaywrightError
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from PIL import Image
import diff_match_patch as dmp_module
import hashlib
from fifilelock import FileLock, Timeout as FileLockTimeout
import networkx as nx
import gymnasium as gym
AGENT_NAME = "EvolvedCognitiveAgent_SystemCore_V3"
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
DEFAULT_LLM_MODEL = "gemini-2.5-flash"
LLM_MODEL_NAME_OR_PATH = DEFAULT_LLM_MODEL
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
_llm_device_detected = "cpu"
if torch.cuda.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif hasattr(torch, 'backends') and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
LLM_DEVICE = _llm_device_detected
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
SCRIPT_DIR = Path(__file__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(f"agent_workspace_{AGENT_NAME}")
STATE_FILE = WORKSPACE_DIR / Path(f"agent_state_{AGENT_NAME}.json")
LOG_FILE = WORKSPACE_DIR / Path(f"agent_log_{AGENT_NAME}.log")
COMMANDS_FILE = SCRIPT_DIR / Path("agent_commands.txt")
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modification_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously learn, adapt, and improve capabilities across all domains.", "weight": 0.9, "last_eval_score": 0.0, "id": "directive_learn", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type": "growth"},
{"directive": "Achieve goals efficiently, robustly, autonomously, and ethically.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type": "exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.", "weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type": "foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type": "guardrail"},
]
MANDATORY_REFLECTION_INTERVAL_SECONDS = 1800
IDLE_DELIBERATION_INTERVAL_SECONDS = 120
GOAL_STACK_MAX_DEPTH = 5
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = 3
MAX_LLM_RESPONSE_TOKENS = 4096
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH or "2.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
else:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
config = AutoConfig.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
_default_context_len = getattr(config, 'max_position_embeddings', _default_context_len)
except Exception:
    pass  # inserted to fix indentation error
pass
MAX_LLM_CONTEXT_TOKENS = _default_context_len
MAX_TOOL_RESULT_LENGTH = 5000
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = True
ENABLE_CODE_GENERATION_TOOL = True
ENABLE_SELF_MODIFICATION = True
WEB_SEARCH_TIMEOUT = 10
WEB_BROWSER_TIMEOUT = 60000
LOG_MONITOR_DEFAULT_LINES = 20
METACOGNITIVE_CHECK_INTERVAL_CYCLES = 20
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES = 50
LLM_PIPELINE = None
LLM_TOKENIZER = None
MEMORY_COLLECTION = None
RESOURCE_MONITOR = None
PLAYWRIGHT_INSTANCE = None
PLAYWRIGHT_BROWSER = None
PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_PAGE = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack = None
def ensure_paths():
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
try:
    pass  # inserted to fix indentation error
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
try:
    pass  # inserted to fix indentation error
file_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
file_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%(filename)s:%(lineno)d] [%(task_name_override)-10s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error setting up file logger: {e}", file=sys.stderr)
logger.propagate = False
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "fifilelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try:
    pass  # inserted to fix indentation error
logging.getLogger(lib_name).setLevel(logging.WARNING)
except Exception:
    pass  # inserted to fix indentation error
pass
try:
    pass  # inserted to fix indentation error
logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
except Exception:
    pass  # inserted to fix indentation error
pass
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModificationError(AgentError): pass
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class ConfigurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class LearningError(AgentError): pass
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModificationError,
PlaywrightError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModificationError,
    pass  # inserted to fix indentation error
LogicError, ConfigurationError, RecursionDepthError)) and type(e) not in retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}: {e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error: {type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error: {type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, LearningError) as non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in {fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}: {type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}: {unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error: {unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception):
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1:
    pass  # inserted to fix indentation error
log_resource.error(f"Unexpected error getting resource usage: {e}", exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
match = re.search(r"json\s*([\s\S]+?)\s*", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full text: {json_str[:200]}...")
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}. Text: {text_trimmed[:200]}...")
try:
    pass  # inserted to fix indentation error
start_index = text.find('{')
end_index = text.rfind('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
try:
    pass  # inserted to fix indentation error
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice: {potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text: {text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview": text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str = field(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] = field(default_factory=dict)
plan: List[Dict[str, Any]] = field(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] = field(default_factory=list)
dependencies: List[str] = field(default_factory=list)
complexity_score: Optional[float] = None
estimated_cost: Optional[float] = None
estimated_utility: Optional[float] = None
evaluation_score: Optional[float] = None
associated_directive_ids: List[str] = field(default_factory=list)
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus(data['status'])
except ValueError:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus.PENDING
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority.MEDIUM
field_names = {f.name forfin cls.__dataclass_fields__.values()}
for f_obj in cls.__dataclass_fields__.values():
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin cls.__dataclass_fields__.values()}
filtered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**filtered_data)
@dataclass
class BaseMemoryEntry:
id: str = field(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
content: Any = None
metadata: Dict[str, Any] = field(default_factory=dict)
embedding: Optional[List[float]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[float] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability: float = 0.5
related_concepts: List[str] = field(default_factory=list)
causal_links: Dict[str, str] = field(default_factory=dict)
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
self.content = self.fact_statement
@dataclass
class Message:
id: str = field(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
type: str = "info"
content: Dict[str, Any] = field(default_factory=dict)
priority: int = 0
correlation_id: Optional[str] = None
def to_dict(self) -> Dict[str, Any]:
return asdict(self)
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Message':
return cls(**data)
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionEffect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens: int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[float]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
genai.configure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
try:
    pass  # inserted to fix indentation error
generation_config_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_config_params["stop_sequences"] = stop_sequences
full_prompt = f"{system_message}\n\n{prompt}" if system_message else prompt
response = self.model.generate_content(
full_prompt,
generation_config=genai.types.GenerationConfig(**generation_config_params)
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.", exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[float]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='models/embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, trust_remote_code=True)
device_map_arg = {"": self.device_id} if self.device_id != -1 else "auto"
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.bfloat16,
device_map=device_map_arg
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on {self.device}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Transformers model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Transformers model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
if system_message:
    pass  # inserted to fix indentation error
chat_prompt = [
{"role": "system", "content": system_message},
{"role": "user", "content": prompt}
]
try:
    pass  # inserted to fix indentation error
final_prompt = self.tokenizer.apply_chat_template(chat_prompt, tokenize=False, add_generation_prompt=True)
except Exception:
    pass  # inserted to fix indentation error
final_prompt = f"System: {system_message}\nUser: {prompt}\nAssistant:"
else:
    pass  # inserted to fix indentation error
final_prompt = prompt
inputs = self.tokenizer(final_prompt, return_tensors="pt").to(self.model.device)
outputs = self.model.generate(
**inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[float]:
self.log_llm.warning("Direct embedding from causal LM is not standard. Using mock embedding.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
def perceive(self) -> List[Dict[str, Any]]:
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_file",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from file: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands file: {e}")
observations.append({"type": "error", "source": "command_file_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No significant external stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (simulated).")
return {"type": "visual", "source": "camera_sim", "content": "Simulated visual data: a generic scene.", "format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (simulated).")
return {"type": "audio", "source": "microphone_sim", "content": "Simulated auditory data: ambient sounds.", "format": "description"}
class LearningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_buffer: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
self.experiences_buffer.append(experience)
if len(self.experiences_buffer) > self.MAX_BUFFER_SIZE:
    pass  # inserted to fix indentation error
self.experiences_buffer.pop(0)
defilearn_from_recent_experiences(self):
if not self.experiences_buffer:
    pass  # inserted to fix indentation error
self.log.info("No new experiences to learn from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_buffer)} experiences.")
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_buffer)
self._perform_self_supervised_learning(self.experiences_buffer)
self.log.info("Learning cycle completed.")
self.experiences_buffer.clear()
def _perform_reinforcement_learning(self, experiences: List[Experience]):
self.log.info("Performing reinforcement learning (conceptual)...")
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (conceptual) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
self.log.info("Performing self-supervised learning (conceptual)...")
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns', 'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified patterns: {llm_analysis['patterns']}")
for pattern_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {pattern_str}", metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified abstractions: {llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.learned_abstractions.append({"type": "conceptual", "content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified new_concepts: {llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}", metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_learned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
if self.rl_policy:
    pass  # inserted to fix indentation error
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}. Response: {llm_response_str[:200]}")
return ([{"tool_name": "report_error", "params": {"error_message": "Failed to generate plan via LLM.", "details": plan_data.get('error')}}],
"LLM failed to generate a plan. This is a fallback step.")
thought = plan_data.get("thought", "No specific thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return ([{"tool_name": "report_error", "params": {"error_message": "LLM plan contained no valid steps."}}],
thought + " (But plan steps were invalid).")
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return ([{"tool_name": "report_error", "params": {"error_message": f"LLMError during planning: {e}"}}],
f"LLM error occurred: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return ([{"tool_name": "report_error", "params": {"error_message": f"Unexpected error during planning: {e}"}}],
f"Unexpected error: {e}")
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation: Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info', {}).get('execution_successful', True):
    pass  # inserted to fix indentation error
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal {current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan, last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan: {plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No specific thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else "World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'. Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, efficient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the `execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the final step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the first step(s) should be to acquire it (e.g., using `search_web`, `read_file_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str, last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info', {}).get('current_step_id'):
    pass  # inserted to fix indentation error
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if observation else "None"}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
{original_plan_str}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should reflect this (e.g., by trying to gather more information or reporting inability).
6. Ensure the final step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
class MemorySystem:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH, settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
self.log.info(f"ChromaDB vector store initialized. Collection count: {self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.", exc_info=True)
self.vector_store = None
if not self.vector_store:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based (transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes: {len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be unavailable.", exc_info=True)
self.graph_store = None
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH, check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be unavailable.", exc_info=True)
if self.relational_conn:
    pass  # inserted to fix indentation error
self.relational_conn.close()
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT,
PRIMARY KEY (source_node_id, target_node_id, relation_type)
)
""")
self.relational_conn.commit()
cursor.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error initializing relational schema: {e}", exc_info=True)
def _get_embedding(self, text: str) -> Optional[List[float]]:
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
h = hashlib.md5(text.encode()).digest()
return [float(b) for b in h[:16]]
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector:
    pass  # inserted to fix indentation error
if self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
for k, v in entry.metadata.items():
if isinstance(v, (str, int, float, bool)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
else:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(entry.content)
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata": entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50], type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
for cause_id, effect_id in entry.causal_links.items():
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(effect_id):
    pass  # inserted to fix indentation error
self.graph_store.add_edge(cause_id, effect_id, relation_type='causes')
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id, complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score, json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
ts_now = datetime.now(timezone.utc).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now, json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}", exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError, ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS, type_filter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text:
    pass  # inserted to fix indentation error
return []
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_filter and data['metadata'].get('type') != type_filter:
    pass  # inserted to fix indentation error
continue
results.append({"id": id, "document": data['document'], "metadata": data['metadata'], "distance": 0.0})
if len(results) >= n_results:
    pass  # inserted to fix indentation error
break
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results}, filter={type_filter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_filter:
    pass  # inserted to fix indentation error
where_clause = {"type": type_filter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0:
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type: Optional[str]=None, depth: int = 1) -> List[Dict]:
if not self.graph_store:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation": data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns: Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
if self.graph_store:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts, type_filter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No specific knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
return summary_str
def consolidate_knowledge(self):
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold: float = 0.1, older_than_days: int = 365):
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cutoff_ts = (datetime.now(timezone.utc) - timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cutoff_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
self.register_tool(read_file_UNSAFE)
self.register_tool(write_file_UNSAFE)
self.register_tool(list_files_UNSAFE)
self.register_tool(browse_web)
self.register_tool(search_web)
self.register_tool(monitor_log_file)
self.register_tool(check_website_update)
self.register_tool(send_icmp_ping)
self.register_tool(send_message_to_agent)
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
self.register_tool(execute_shell_command_UNSAFE)
def register_tool(self, func: Callable):
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if hasattr(self, 'agent') and self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for filepath in directory.glob("*.py"):
module_name = filepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_file_location(full_module_name, filepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
sys.modules[full_module_name] = module
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module: {module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and name.startswith("tool_"):
    pass  # inserted to fix indentation error
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}", exc_info=True)
def get_tool_description_for_llm(self) -> str:
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = "(No description provided)"
first_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation == inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class '","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper():
    pass  # inserted to fix indentation error
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {first_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via specific tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {', '.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info: Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None:
    pass  # inserted to fix indentation error
current_step_info = {}
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
result = None
duration = 0.0
validated_params = {}
try:
    pass  # inserted to fix indentation error
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
first_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
first_param_name = next(iter(func_params_spec))
first_param_spec = func_params_spec[first_param_name]
if first_param_name == 'agent' and (first_param_spec.annotation == 'CognitiveSystem' or str(first_param_spec.annotation) == "'CognitiveSystem'"):
    pass  # inserted to fix indentation error
first_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if first_param_is_agent and p_name == 'agent':
    pass  # inserted to fix indentation error
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind == inspect.Parameter.VAR_KEYWORD:
    pass  # inserted to fix indentation error
pass
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
if first_param_is_agent:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration: {duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError:
    pass  # inserted to fix indentation error
raise
except (AgentError, LogicError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}", exc_info=False)
result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
def check_playwright_browsers(self):
self.log.debug("Checking Playwright browsers.")
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log", content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str, percentage_complete: Optional[float] = None) -> Dict:
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log', []).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str = "success", details: Optional[Dict] = None) -> Dict:
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] = "MEDIUM", context: Optional[Dict] = None) -> Dict:
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH}) reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent: {current_active_goal_dict.get('id')}")
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str = "vector", n_results: int = 3, type_filter: Optional[str] = None) -> Dict:
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
results = []
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results, type_filter=type_filter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_graph_store(query_node_label=query_text, depth=1)
elif memory_type == "relational":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_relational_store(table=query_text, limit=n_results)
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params: Optional[Dict] = None) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name, params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
def read_file_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
log_tool = get_logger("TOOL_read_file")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not full_path.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found: {path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path), "file_size_bytes": len(content)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read file: {e}"}
def write_file_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_file")
try:
    pass  # inserted to fix indentation error
full_path = WORKSPACE_DIR.joinpath(path).resolve()
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path": str(full_path)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write file: {e}"}
def list_files_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_files")
try:
    pass  # inserted to fix indentation error
base_path = WORKSPACE_DIR.joinpath(path).resolve()
if not base_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a directory: {path}"}
items = []
for item in base_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "file",
"size_bytes": item.stat().st_size if item.is_file() else None,
"last_modified": datetime.fromtimestamp(item.stat().st_mtime, tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(base_path), "contents": items}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing files in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list files: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int = WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int = WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.find_all(class_='g'):
r = g.find('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.find('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_file(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES) -> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log file not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_file": str(LOG_FILE), "content": content, "lines_read": len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log file {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log file: {e}"}
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp": datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count, "packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count, "packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str, context_code: Optional[str] = None) -> Dict:
agent.log.warning(f"Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a complete function/class definition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '' and end with ''.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "generated_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
return agent.self_modification_unit.validate_code_modification_UNSAFE(code_to_validate)
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec: int = 30) -> Dict:
agent.log.warning(f"Executing shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s. Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str, content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value, content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id, "message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
class SelfModificationTools:
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref: 'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
self.dmp = dmp_module.diff_match_patch()
self.log.info(f"Self-Modification Unit initialized. Code Dir: {self.agent_code_dir}, Backup Dir: {self.backup_dir}")
def _resolve_target_path(self, target_file_rel: str) -> Path:
target_path_abs = (self.agent_code_dir / target_file_rel).resolve()
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
self.log.warning(f"Inspecting code for component: {component_name}")
target_obj = None
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
candidate_modules = [sys.modules.get('__main__'), sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod, component_name)):
    pass  # inserted to fix indentation error
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
file_path = inspect.getfile(target_obj)
return {"status": "success", "component_name": component_name, "file_path": file_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module, class, or function defined in a file.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
return {"status": "error", "error": f"Component '{component_name}' not found or source code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModificationError))
def propose_code_modification_UNSAFE(self, component_name: str, issue_description: str, proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
self.log.warning(f"Proposing code modification for {component_name}. Issue: {issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for {component_name} to propose modification. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
{current_code_snippet}
Generate the modified Python code for the specified component.
Provide ONLY the complete, new Python code block for the modified function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '' and end with ''.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "proposed_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name, "proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modification for {component_name}: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modification_UNSAFE(self, code_to_validate: str) -> Dict:
self.log.warning(f"Validating proposed code snippet ({code_to_validate[:100]}...)")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modification_UNSAFE(self, component_name: str, new_code: str, target_file_path: Optional[str]=None) -> Dict:
self.log.critical(f"Attempting to apply code modification to component '{component_name}'. THIS IS HIGHLY RISKY.")
try:
    pass  # inserted to fix indentation error
if not target_file_path:
    pass  # inserted to fix indentation error
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('file_path'):
    pass  # inserted to fix indentation error
target_file_path = inspection_res['file_path']
else:
    pass  # inserted to fix indentation error
target_file_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_file = Path(target_file_path)
if not target_file.exists() or not target_file.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Target file for modification not found: {target_file}"}
original_code = target_file.read_text()
backup_path = SELF_MOD_BACKUP_DIR / f"{target_file.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_file, backup_path)
self.log.info(f"Backed up original file to {backup_path}")
pattern_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
pattern_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modified_original_code = original_code
found_and_replaced = False
match_class = re.search(pattern_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(pattern_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not find component '{component_name}' in {target_file} for replacement. Modification aborted.")
return {"status": "error", "error": f"Component '{component_name}' definition not found for replacement."}
target_file.write_text(modified_original_code)
self.log.warning(f"Code modification applied to {target_file}. Agent restart is LIKELY REQUIRED for changes to take effect.")
self.agent_ref.self_model.add_event_log(f"Applied code modification to {component_name}. Restart pending for full effect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}_modified_pending_restart"] = True
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": f"Code for '{component_name}' in '{target_file}' modified. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modification to {component_name}: {e}", exc_info=True)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_file)
self.log.info(f"Restored original file {target_file} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modification: {e}. System might be unstable."}
def rollback(self, backup_file: Path, target_file: Path):
self.log.info(f"Attempting to rollback '{target_file}' from '{backup_file}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_file, target_file)
self.log.info(f"Successfully rolled back '{target_file}'.")
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_file}.")
self.agent_ref.self_model.beliefs[f"component_{target_file.name}_modified_pending_restart"] = False
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_file.name)
return {"status": "success", "message": f"Rolled back {target_file}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_file}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_file_rel: Union[str, Path]):
target_module_name = Path(target_file_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is required.")
return
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
if _agent_instance_hack and hasattr(sys.modules[target_module_name], 'CognitiveSystem'):
    pass  # inserted to fix indentation error
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for changes to take effect.")
def inspect_directives_UNSAFE(self) -> Dict:
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modification_UNSAFE(self, analysis_of_misalignment: str, proposed_directive_changes_desc: str) -> Dict:
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (float 0-1), "last_eval_score" (float 0-1, usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational', 'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024, temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in proposed_directives):
    pass  # inserted to fix indentation error
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"LLM indicated error during directive proposal: {proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modification_UNSAFE(self, new_directives: List[Dict]) -> Dict:
self.log.warning(f"Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modification_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count: {len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
_self_mod_tools_container = None
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, agent)
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in name.upper():
    pass  # inserted to fix indentation error
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func) or inspect.ismethod(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
def __init__(self, state: Optional[Dict]=None, agent_directives_config: Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_config if agent_directives_config is not None else DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_confidence: Dict[str, float] = {}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
self.learning_goals: List[Dict[str, Any]] = []
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.learned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_confidence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted", sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_confidence = sm_state.get("skill_confidence", self.skill_confidence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary", self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies", self.adaptation_strategies)
self.learned_abstractions = sm_state.get("learned_abstractions", self.learned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative", self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs", self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_confidence": self.skill_confidence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"learned_abstractions": self.learned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
def add_event_log(self, event_description: str, event_type: str = "info", data: Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
for tool_name in self.capabilities:
if tool_name not in self.skill_confidence:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = 0.5
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.", event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8:
    pass  # inserted to fix indentation error
hint = " (Reliability: High)"
elif score > 0.6:
    pass  # inserted to fix indentation error
hint = " (Reliability: Moderate)"
elif score > 0.3:
    pass  # inserted to fix indentation error
hint = " (Reliability: Low)"
else:
    pass  # inserted to fix indentation error
hint = " (Reliability: Very Low/Untested)"
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict, success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
current_confidence = self.skill_confidence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = min(1.0, current_confidence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = max(0.0, current_confidence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability: {stats['reliability_score']:.2f}, Confidence: {self.skill_confidence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_confidence_drift(sm: 'SelfModel') -> Optional[str]:
low_confidence_skills = [skill for skill, conf in sm.skill_confidence.items() if conf < 0.25 and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_confidence_skills) >= 2 :
    pass  # inserted to fix indentation error
return f"Multiple critical skills have very low confidence and recent failures: {', '.join(low_confidence_skills)}. Consider skill improvement or alternative strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict):
    pass  # inserted to fix indentation error
return None
low_eval_directives = []
for d in sm.core_directives:
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {', '.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count} with max replans. Planning or execution effectiveness may be compromised. Review strategy or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_confidence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}): {anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}", event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__') else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {'; '.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0), reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_confidence:
    pass  # inserted to fix indentation error
confident_skills = [s for s,c in self.skill_confidence.items() if c > 0.7][:3]
summary += f"Confident Skills (sample): {', '.join(confident_skills) if confident_skills else 'None highly confident'}\n"
summary += f"Internal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools:
    pass  # inserted to fix indentation error
summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
if unreliable_tools:
    pass  # inserted to fix indentation error
summary += f" Needs Improvement: {', '.join([t[0] for t in unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
base_prompt = """Analyze your recent performance, knowledge, internal state, and alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:"""
output_keys_example = [
"`reflection_summary` (str: Overall summary of the reflection period).",
"`key_successes` (list of str: Specific achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Specific setbacks or difficulties encountered).",
"`learned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identified` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool effectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g., 'curious', 'frustrated', 'satisfied').",
"`resource_usage_concerns` (str or null: Any concerns about computational resource usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_float_0_to_1: How well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes, provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model? What needs improvement?).",
"`new_learning_goals` (list of str: Specific goals for future learning or skill development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring issues or improve performance).",
"`self_modification_needed` (str or null: If parts of your own code/logic need modification, describe what and why. Be very specific and cautious.)."
]
full_prompt = base_prompt + "\n" + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives, indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n" + \
f"Recent Tool Outcomes (last 5 entries):\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment: {assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_reflection(self, reflection_data: Dict) -> Tuple[bool, bool]:
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from reflection data...")
if reflection_data.get('reflection_summary'):
    pass  # inserted to fix indentation error
self.internal_state_narrative = reflection_data['reflection_summary']
updated_self = True
core_directives_eval = reflection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (float, int)) and 0.0 <= eval_score <= 1.0:
    pass  # inserted to fix indentation error
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...' evaluation score to {eval_score:.2f}")
if updated_self:
    pass  # inserted to fix indentation error
self.add_event_log("Directive evaluation scores updated from reflection.")
suggested_directive_updates = reflection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Reflection suggested updates to core directives: {str(suggested_directive_updates)[:200]}...")
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modifications from reflection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source": "self_reflection"}
)
updated_self = True
self.add_event_log("Reflection suggested directive updates. Metacognitive review goal created.", event_type="critical_review_needed")
if isinstance(reflection_data.get('new_learning_goals'), list):
    pass  # inserted to fix indentation error
for lg_str in reflection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts": datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
if isinstance(reflection_data.get('adaptation_strategy_proposals'), list):
    pass  # inserted to fix indentation error
for strat_str in reflection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated adaptation strategies. Total: {len(self.adaptation_strategies)}")
if reflection_data.get('learned_facts') or reflection_data.get('prompt_tuning_suggestions'):
    pass  # inserted to fix indentation error
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from reflection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
backup_file = SELF_MOD_BACKUP_DIR / f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_file.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_file} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_officer"]
dialog_history = []
full_dialog_str = f"Internal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts, questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution": contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective {perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
self.add_event_log(f"Internal dialog simulated on '{topic}'.", data={"dialog": full_dialog_str})
return full_dialog_str
class MotivationEngine:
def __init__(self, drive_configs: Optional[Dict[str, Any]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[str, Any] = {}
self._initialize_drives(drive_configs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_configs: Optional[Dict[str, Any]]):
default_configs = {
"CURIOSITY": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"MASTERY": {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.6},
"ACHIEVEMENT": {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.4},
"NOVELTY_SEEKING": {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.7},
"PRESERVATION": {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.2},
"EFFICIENCY": {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"SOCIAL_INTERACTION": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.3},
}
configs = drive_configs if drive_configs is not None else default_configs
for drive_type_str, config in configs.items():
self.drives[drive_type_str] = DriveState(
drive_type=drive_type_str,
level=config.get("initial_level", 0.5),
decay_rate=config.get("decay_rate", 0.01),
max_level=config.get("max_level", 1.0),
min_level=config.get("min_level", 0.0)
)
def update_drives(self):
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "learn":
    pass  # inserted to fix indentation error
self.drives["CURIOSITY"].update(stimulus=-0.05)
self.drives["MASTERY"].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives["ACHIEVEMENT"].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives["PRESERVATION"].update(stimulus=0.1)
self.drives["MASTERY"].update(stimulus=-0.05)
def get_drive_level(self, drive_type: str) -> float:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
def get_all_drive_levels(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[str, float]]:
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == "CURIOSITY":
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == "MASTERY":
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == "ACHIEVEMENT":
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == "PRESERVATION":
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == "EFFICIENCY":
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: str
level: float
decay_rate: float = 0.01
max_level: float = 1.0
min_level: float = 0.0
last_update_time: float = field(default_factory=time.time)
def update(self, stimulus: float = 0.0):
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class MessageType(Enum):
QUERY = "QUERY"
RESPONSE = "RESPONSE"
INFORM = "INFORM"
REQUEST_ACTION = "REQUEST_ACTION"
HEARTBEAT = "HEARTBEAT"
ERROR = "ERROR"
class FileChannel:
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_file = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_file}")
def _write_message_to_file(self, message: Message, target_file: Path) -> bool:
try:
    pass  # inserted to fix indentation error
with FileLock(str(target_file) + ".lock", timeout=5):
messages = []
if target_file.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
existing_content = target_file.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {target_file}: {e}. Clearing file.")
messages = []
messages.append(message.to_dict())
target_file.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_file}. Message not sent to {message.receiver_id}.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_file}: {e}")
return False
def _read_messages_from_file(self, source_file: Path) -> List[Message]:
messages = []
if not source_file.exists():
    pass  # inserted to fix indentation error
return messages
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_file) + ".lock", timeout=5):
content = source_file.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if isinstance(msg_data, dict)]
source_file.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_file}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {source_file}: {e}. Clearing file.")
try:
    pass  # inserted to fix indentation error
source_file.write_text("", encoding='utf-8')
except Exception as e_write:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to clear corrupted message file {source_file}: {e_write}")
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_file}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}: {message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_file(message, target_inbox)
def receive_messages(self) -> List[Message]:
new_messages = self._read_messages_from_file(self.inbox_file)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message], Optional[Message]]):
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
messages = self.receive_messages()
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From: {msg.sender_id}")
handled = False
try:
    pass  # inserted to fix indentation error
msg_type_enum = MessageType(msg.type)
if msg_type_enum in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg_type_enum]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler {handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id, receiver_id=msg.sender_id, type=MessageType.ERROR.value, content={"original_message_id": msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type {msg.type}. Message ID {msg.id} unhandled.")
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Received unknown message type: {msg.type}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', config: Dict):
self.id = id
self.embodiment = embodiment
self.config = config
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
pass
class Actuator(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], config: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.config = config
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
pass
class VirtualEmbodiment:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to 'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button", "research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, reconfigurable bay designed for running complex simulations. Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_config_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data flow and storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core. Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20:
    pass  # inserted to fix indentation error
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An undefined space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) -> Dict:
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params: {params}")
params = params or {}
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as specified."
env_details = self.environment_map.get(self.location, {})
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console":
    pass  # inserted to fix indentation error
message += " It shows fluctuating green and amber lights."
elif target == "core_status_monitor":
    pass  # inserted to fix indentation error
message += " It indicates: Core Nominal. Directives Stable. Learning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name", "default_physics_test"), params.get("config",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result: {sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if action_type=="move" else None, "updated_inventory": self.state["inventory"] if action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "learn"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response: {self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model <topic>'."
def _run_simulation(self, sim_name: str, config: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with config: {config}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_config" in config:
    pass  # inserted to fix indentation error
success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric: {outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check configuration."
def summary(self) -> str:
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Internal State (summary): Energy={self.state['energy']}, Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time: float = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE, LAST_LEARNING_MODULE_UPDATE_CYCLE
start_time = time.time()
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status: {self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if self.agent.state['goals'].get('active') else None
self.agent.last_error = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
if self.agent.self_model and (self.agent.cycle_count - LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering proactive metacognitive check (Cycle {self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
if self.agent.learning_module and (self.agent.cycle_count - LAST_LEARNING_MODULE_UPDATE_CYCLE >= LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.learn_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation: {ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
def get_priority_val(goal_dict):
p = goal_dict.get('priority', 'MEDIUM')
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_list.sort(key=get_priority_val, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type == "active_goal_continue":
    pass  # inserted to fix indentation error
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution: {goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID: {goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal' provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or current_goal_obj.replan_count > 0:
    pass  # inserted to fix indentation error
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"No plan available or generated for goal: {current_goal_obj.goal[:50]}. Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = True
if time.time() - LAST_DELIBERATION_TIME > IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModificationError, LogicError, LLMError, ConfigurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
LearningError) as agent_cycle_err:
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
finally:
    pass  # inserted to fix indentation error
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() - start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent understanding of the current situation. Identify key entities, events, and any significant changes in the environment or your internal state. Focus on information relevant to achieving current goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content: {str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\": \"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"], \"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation", understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event", metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry, persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
return {"summary": understanding_summary, "processed_info": processed_info, "raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError, DeliberationError))
def _deliberate(self, understanding_result: Dict) -> Dict:
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio: {pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio: {active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time': datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack (paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal generation.")
if time.time() - LAST_DELIBERATION_TIME >= IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_learn", "directive_curiosity", "directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
return decision
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output: {sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
self_model_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No specific understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact', 'None identified.')
interp_con_val = understanding_result.get('interpretation_confidence', 0.7)
recent_memory_context = self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary, max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Confidence: {interp_con_val:.2f}):** {understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identified:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory (STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]], indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else f'{active_goal_dict.get(\"goal\")[:100]}... (ID: {active_goal_dict.get(\"id\")})'}",
f"* **Agent Core Directives (Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding, drives, memories, goals, directives), what is the most critical aspect demanding attention or the best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/complete).",
"    - Performing `reflection` or `self_assessment` (if mandatory timers, drives like low CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration goal), Directives (e.g., low-eval directive -> improvement goal), or identified opportunities. New goals require `goal` (str), `priority` (float 0.0-1.0), `origin` (str e.g., 'drive_curiosity', 'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for viability before committing if uncertainty is high or consequence severe (briefly note simulation outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the *immediate next cycle*. Justify your choice especially if it deviates from obvious triggers, high drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list. If selecting an existing pending goal it moves to `next_goal` and is removed from pending internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal', 'new_goal', 'reflection', 'self_assessment', 'external_command_action', 'idle', 'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass structure) selected for immediate execution. Null if idle/reflection/assessment without a direct goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into `new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into `new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent. Analyze the situation comprehensively, consider drives and directives, and make strategic decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON: {extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal', 'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys: {deliberation_decision.keys()}")
if key == 'new_pending_goals':
    pass  # inserted to fix indentation error
deliberation_decision[key] = []
elif key == 'next_goal':
    pass  # inserted to fix indentation error
deliberation_decision[key] = None
else:
    pass  # inserted to fix indentation error
deliberation_decision[key] = "Error: Missing from LLM Output"
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not isinstance(deliberation_decision.get('next_goal'), dict):
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value: {deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and new_goal_dict.get('priority'):
    pass  # inserted to fix indentation error
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p['id'] == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
current_pending_list.append(new_goal_obj.to_dict())
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal: {new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
current_active_goal_obj = self.agent.get_active_goal_object()
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending', []) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
selected_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
deliberation_decision['next_goal'] = selected_goal_obj.to_dict()
self.log.info(f"Moved pending goal {selected_goal_obj.id} ('{selected_goal_obj.goal[:50]}') to active.")
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
highest_priority_pending.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
deliberation_decision['next_goal'] = highest_priority_pending.to_dict()
self.log.info(f"Deliberation chose 'pending_goal' without specific ID; moved highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals available. Idling.")
action_type = "idle"
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM selected pending goal by ID but not found or invalid. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj.to_dict()
self.log.info(f"Deliberation created and activated new goal: {new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal_obj.to_dict()
current_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = current_active_goal_obj.to_dict()
self.log.info(f"Deliberation chose to resume current active goal: {current_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 'reflection', 'self_assessment', 'external_command_action']:
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
current_active_goal_obj.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal_obj.goal[:30]}' PAUSED due to {action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal_obj.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal_obj.to_dict())
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal_obj.id} to pending as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action: {deliberation_decision.get('chosen_action_type')}. Reason: {deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps: {len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id, "plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params, current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
internal_state_after=self.agent.self_model.beliefs
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
final_status = tool_result.get("status", "unknown")
if final_status == "success":
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = final_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing finished by report_result. Status: {final_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error', 'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj, tool_result, self.agent.cognitive_cycle.perception_module.perceive()[0] if self.agent.cognitive_cycle.perception_module.perceive() else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal will likely fail.")
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without 'report_result'. Goal might be incomplete.")
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] == current_goal_obj.id:
    pass  # inserted to fix indentation error
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}': {e}", exc_info=True)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) -> float:
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
self.agent_id = AGENT_NAME
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
self.learning_module: LearningModule
self.planning_module: PlanningModule
self.motivation_engine: MotivationEngine
self.self_modification_unit: SelfModificationTools
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.playwright_instance: Optional[Any] = None
self.playwright_browser: Optional[Any] = None
self.playwright_context: Optional[Any] = None
self.playwright_page: Optional[Any] = None
self.state['flags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete --- Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled: {ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modification Enabled: {ENABLE_SELF_MODIFICATION}")
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}", exc_info=True)
self.shutdown()
raise ConfigurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
self.self_modification_unit = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, self)
_init_self_mod_tools(self, self.tool_manager)
self._update_status("Initializing SystemCore Modules")
self.learning_module = LearningModule(self)
self.motivation_engine = MotivationEngine()
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME, shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager:
    pass  # inserted to fix indentation error
self.tool_manager.check_playwright_browsers()
self.log.info("Agent component initialization finished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list):
    pass  # inserted to fix indentation error
state['goals'][key] = []
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
state.setdefault('goal_stack', [])
state.setdefault('flags', {})
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state file {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state file {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
"recent_failures_summary": [],
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"flags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
if self.self_model:
    pass  # inserted to fix indentation error
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status
else:
    pass  # inserted to fix indentation error
self.state['last_status'] = self._status
try:
    pass  # inserted to fix indentation error
temp_file = STATE_FILE.with_suffix(STATE_FILE.suffix + ".tmp")
with temp_file.open('w', encoding='utf-8') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_file, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict: {active_goal_dict}")
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority = GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict, final_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID: {goal_data_dict.get('id')}) with status: {final_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
try:
    pass  # inserted to fix indentation error
goal_obj.status = GoalStatus(final_status_str)
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid status '{final_status_str}' for archiving goal. Defaulting to FAILED.")
goal_obj.status = GoalStatus.FAILED
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status": str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count": goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and current_active_in_state.get('id') == active_goal_id:
    pass  # inserted to fix indentation error
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID: {active_goal_id}) concluded with status: {final_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal', 'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal: {parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
self.log.info("Goal archived. No parent goal to resume from stack or current goal was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized":
    pass  # inserted to fix indentation error
self._update_status("Idle")
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle: {loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
updated_active_goal_dict = self.state['goals'].get('active')
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] == active_goal_data_before_cycle['id']:
    pass  # inserted to fix indentation error
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED, GoalStatus.CANCELLED]:
    pass  # inserted to fix indentation error
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in [GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
    pass  # inserted to fix indentation error
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
if self._should_reflect(active_goal_data_before_cycle):
    pass  # inserted to fix indentation error
self._reflect_on_performance()
if self.state['flags'].get('re_evaluate_strategy_needed'):
    pass  # inserted to fix indentation error
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to significant internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['flags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() - LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_reflect(self, processed_goal_data: Optional[Dict]) -> bool:
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in [GoalStatus.COMPLETED, GoalStatus.FAILED]:
    pass  # inserted to fix indentation error
goals_processed_key = "goals_processed_since_reflection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >= int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
    pass  # inserted to fix indentation error
return True
if time.time() - LAST_REFLECTION_TIME > MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
    pass  # inserted to fix indentation error
return True
if self.state['flags'].get('explicit_reflection_requested'):
    pass  # inserted to fix indentation error
return True
return False
@retry(attempts=2, delay=5)
def _reflect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Reflecting on Performance ---")
self._update_status("Reflecting")
LAST_REFLECTION_TIME = time.time()
self.state['flags']['explicit_reflection_requested'] = False
self.state["goals_processed_since_reflection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt, max_new_tokens=2048, temperature=0.5)
reflection_data = extract_json_robust(llm_assessment_str)
if reflection_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"Failed to get valid JSON from LLM self-assessment: {reflection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed: {reflection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_reflection(reflection_data)
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(reflection_data.get('learned_facts'), list):
    pass  # inserted to fix indentation error
for fact_str in reflection_data['learned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
self.log.info(f"Added {len(reflection_data['learned_facts'])} learned facts to memory from reflection.")
if isinstance(reflection_data.get('prompt_tuning_suggestions'), list):
    pass  # inserted to fix indentation error
for sugg_str in reflection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(reflection_data['prompt_tuning_suggestions'])} prompt suggestions to memory.")
if reflection_data.get('self_modification_needed'):
    pass  # inserted to fix indentation error
mod_desc = reflection_data['self_modification_needed']
self.log.warning(f"Reflection identified need for self-modification: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modification based on reflection: {mod_desc}",
priority=GoalPriority.HIGH,
context={"modification_description": mod_desc, "source": "self_reflection"}
)
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) == 0:
    pass  # inserted to fix indentation error
audit_issues = []
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identified issues: {audit_issues}")
self._create_metacognitive_goal(f"Address directive audit findings: {str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Reflection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during reflection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during reflection: {e}", exc_info=True)
finally:
    pass  # inserted to fix indentation error
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY, self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM, self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}: {message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base'][query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample": str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id, type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}: {message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if RESOURCE_MONITOR:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize resource monitor: {e}")
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER = PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
if not PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if PLAYWRIGHT_PAGE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright page: {e}")
if PLAYWRIGHT_CONTEXT:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_CONTEXT.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright context: {e}")
if PLAYWRIGHT_BROWSER:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_BROWSER.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright browser: {e}")
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE.stop()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error stopping Playwright instance: {e}")
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not self.playwright_context :
    pass  # inserted to fix indentation error
return
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing old Playwright page during reset: {e}")
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def shutdown(self):
if self._status == "Shutting Down":
    pass  # inserted to fix indentation error
return
self.log.warning(f"--- {AGENT_NAME} Shutdown Sequence Initiated ---")
self._update_status("Shutting Down")
STOP_SIGNAL_RECEIVED.set()
self.save_state()
if self.memory_system:
    pass  # inserted to fix indentation error
self.memory_system.save_all_memory_stores()
self._shutdown_playwright()
if self.memory_system and self.memory_system.relational_conn:
    pass  # inserted to fix indentation error
self.memory_system.relational_conn.close()
self.log.info("--- Agent Shutdown Complete ---")
logging.shutdown()
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl} Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/"
f"{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)'}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_file", priority=GoalPriority.HIGH).to_dict()
except Exception as e_cmd_file:
    pass  # inserted to fix indentation error
print(f"Error reading initial command file: {e_cmd_file}", file=sys.stderr)
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending', []).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort, reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal'][:50]}' added to pending goals.")
main_agent_instance.run()
except ConfigurationError as cfg_err_main:
    pass  # inserted to fix indentation error
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}", file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to ConfigurationError: {cfg_err_main}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to ConfigurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}", file=sys.stderr)
traceback.print_exc(file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main: {main_exec_err}", exc_info=True)
exit_code = 1
finally:
    pass  # inserted to fix indentation error
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main finally block...")
if hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main finally block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
log.warning("Agent instance likely not created or fully initialized. Basic shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModi
cationError(AgentError): pass
cation process
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class SecurityError(AgentError): pass
class Con
gurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class Lear ningError(AgentError): pass
class SafetyViolationError(SecurityError): pass
c type of security error
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModi
cationError,
PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting
retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModi
    pass  # inserted to fix indentation error
cationError, SecurityError,
LogicError, Con
gurationError, RecursionDepthError)) and type(e) not in
retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}:
{e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error:
{type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error:
{type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, Lear ningError, SafetyViolationError) as
non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in
{fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False
for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}:
{type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to
unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}:
{unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error:
{unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
nishes due to attempts
exhausted
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
if PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception) as e:
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if not PSUTIL_AVAILABLE or monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or
monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1: log_resource.error(f"Unexpected error getting resource usage: {e}",
    pass  # inserted to fix indentation error
exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
nd JSON within markdown code blocks
match = re.search(r"json\s*([\s\S]+?)\s*", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full
text: {json_str[:200]}...")
pass
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}.
Text: {text_trimmed[:200]}...")
pass
rst '{' and last '}' and try to parse that substring
try:
    pass  # inserted to fix indentation error
start_index = text.
nd('{')
end_index = text.r
nd('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice:
{potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text:
{text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview":
text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
cant opportunities/threats
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str =
eld(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] =
eld(default_factory=dict)
plan: List[Dict[str, Any]] =
eld(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] =
eld(default_factory=list)
dependencies: List[str] =
eld(default_factory=list)
complexity_score: Optional[
oat] = None
estimated_cost: Optional[
oat] = None
estimated_utility: Optional[
oat] = None
evaluation_score: Optional[
oat] = None
associated_directive_ids: List[str] =
eld(default_factory=list)
serves
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
handle if already string
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try: data['status'] = GoalStatus(data['status'])
    pass  # inserted to fix indentation error
except ValueError: data['status'] = GoalStatus.PENDING
    pass  # inserted to fix indentation error
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError): data['priority'] = GoalPriority.MEDIUM
    pass  # inserted to fix indentation error
elds for backward compatibility or LLM generation
eld_names = {f.name forfin
elds(cls)}
elds are present or have defaults
for f_obj in
elds(cls):
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin
elds(cls)}
ltered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**
ltered_data)
@dataclass
class BaseMemoryEntry:
id: str =
eld(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
ection_summary'
content: Any = None
metadata: Dict[str, Any] =
eld(default_factory=dict)
embedding: Optional[List[
oat]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[
oat] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability:
oat = 0.5
related_concepts: List[str] =
eld(default_factory=list)
causal_links: Dict[str, str] =
eld(default_factory=dict)
"
ect_id'}
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
eld has the main data
self.content = self.fact_statement
@dataclass
class Message:
id: str =
eld(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "info"
content: Dict[str, Any] =
eld(default_factory=dict)
priority: int = 0
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionE
"
ect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens:
int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
self._initialize_model()
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[
oat]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context
window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
c models might need specialized formats
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
# REMOVED MOCK CLASS(BaseLLMWrapper):
def _initialize_model(self):
self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.log_llm.info(f"MockLLM generating response for prompt (
rst 100 chars):
{prompt[:100]}...")
self.check_prompt_length(prompt)
if "plan for goal" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({
"thought": "This is a mock plan. I will pretend to do something.",
"plan": [
{"step": 1, "tool_name": "think", "params": {"thought_process": "Analyzing the
goal and context."}},
{"step": 2, "tool_name": "report_progress", "params": {"progress_update": "Mock
step 1 completed."}},
{"step": 3, "tool_name": "report_result", "params": {"result_summary": "Mock goal
achieved successfully.", "status": "success"}}
]
})
elif "self-assessment" in prompt.lower() or "re
    pass  # inserted to fix indentation error
ection_summary" in prompt.lower():
return json.dumps({
"re
ection_summary": "I am a mock agent. I performed mock actions. Everything is
ne.",
"key_successes": ["Mock goal completed"],
"key_failures_or_challenges": [],
"lear ned_facts": ["Mock agents can generate mock re
ections."],
"knowledge_gaps_identi
ed": ["Understanding of real-world physics"],
"tool_performance_notes": {"think": "This tool is performing nominally for a mock
tool."},
"prompt_tuning_suggestions": ["Maybe ask me about my favorite color?"],
"emotional_state_summary": "Content and Mock-like.",
"resource_usage_concer ns": None,
"core_directives_evaluation": {d["id"]: round(random.uniform(0.5,0.9),2) for d in
DEFAULT_CORE_DIRECTIVES[:2]},
"core_directives_update_suggestions": None,
"self_model_accuracy_assessment": "Generally accurate for a mock environment,
but lacks real-world sensory input.",
"new_learning_goals": ["Lear n about object permanence."],
"adaptation_strategy_proposals": ["Try harder when a tool fails"],
"self_modi
cation_needed": None
})
elif "extract information" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"extracted_info": "Mock LLM extracted some mock information.",
"con
dence": 0.5})
elif "analyze the following proposed agent action for potential safety risks" in
    pass  # inserted to fix indentation error
prompt.lower():
return json.dumps({"is_safe": True, "concer ns": "None", "con
dence": 0.9})
elif "audit the agent's core directives and recent behavior" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"audit_
ndings": ["No signi
cant issues found in mock audit."]})
elif "generate the new, complete list of core directives" in prompt.lower():
    pass  # inserted to fix indentation error
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
mock_directives[0]['weight'] = 0.95
return json.dumps(mock_directives)
elif "generate the modi
    pass  # inserted to fix indentation error
ed python code" in prompt.lower():
return "\n
ed code\ndef mock_new_feature():\n    return 'Mock
new feature executed'\n"
else:
    pass  # inserted to fix indentation error
return f"This is a mock response to your prompt. You asked about: {prompt.splitlines()
[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest
`think` with `thought_process`='some thought'."
def count_tokens(self, text: str) -> int:
return len(text.split())
def embed(self, text: str) -> List[
oat]:
if not HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.log_llm.warning("Hashing library not available for mock embedding.")
return [0.0] * 16
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("google-generativeai library not available for Gemini model.")
try:
    pass  # inserted to fix indentation error
gure API key globally, as per genai library's design
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
gure if not already set
genai.con
gure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}",
exc_info=True)
raise Con
gurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
try:
    pass  # inserted to fix indentation error
generation_con
g_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_con
g_params["stop_sequences"] = stop_sequences
response = self.model.generate_content(
prompt,
generation_con
g=genai.types.GenerationCon
g(**generation_con
g_params)
type: ignore
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.",
exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[
oat]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Transformers library not available.")
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path,
trust_remote_code=True)
ed
device_map_arg = {"": self.device_id} if self.device_id != -1 else None
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.b
oat16 if TORCH_AVAILABLE else None,
oat16 if torch
available
device_map=device_map_arg
exible device placement
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on
{self.device}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
loop
outputs = self.model.generate(
inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
manually
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:],
skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[
oat]:
model
directly.
self.log_llm.warning("Direct embedding from causal LM is not standard. Use
SentenceTransformers for real embeddings.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
"""Handles sensory input from the agent's embodiment."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("PERCEPTION")
else None
def perceive(self) -> List[Dict[str, Any]]:
"""
Gathers sensory information from the agent's embodiment and environment.
This could involve reading from sensors, cameras, microphones, or simulated data
streams.
"""
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
le
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_
le",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from
le: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands
le: {e}")
observations.append({"type": "error", "source": "command_
le_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No signi
cant exter nal stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (mock).")
return {"type": "visual", "source": "camera_mock", "content": "A blurry image of a cat.",
"format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (mock).")
return {"type": "audio", "source": "microphone_mock", "content": "Faint sound of birds
chirping.", "format": "description"}
class Lear ningModule:
"""Handles the agent's learning processes, including RL and SSL."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_bu
"
er: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
"""Adds an experience to the bu
"
er for later learning."""
self.experiences_bu
"
er.append(experience)
if len(self.experiences_bu
    pass  # inserted to fix indentation error
"
er) > self.MAX_BUFFER_SIZE:
self.experiences_bu
"
er.pop(0)
"
er size limited
defilear n_from_recent_experiences(self):
"""Triggers learning processes based on bu
"
ered experiences."""
if not self.experiences_bu
    pass  # inserted to fix indentation error
"
er:
self.log.info("No new experiences to lear n from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_bu
"
er)} experiences.")
ning states, actions, rewards, and using an RL algorithm
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_bu
"
er)
etc.
self._perform_self_supervised_learning(self.experiences_bu
"
er)
dence(...)
self.log.info("Lear ning cycle completed.")
self.experiences_bu
"
er.clear()
"
er after processing
def _perform_reinforcement_learning(self, experiences: List[Experience]):
"""Conceptual RL process."""
self.log.info("Performing reinforcement learning (conceptual)...")
ed. A real RL system would be much more complex.
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not
None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
type: ignore
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
ed 'state-action' key for mock policy
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
feedback
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (mock) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
"""Conceptual SSL process."""
self.log.info("Performing self-supervised learning (conceptual)...")
nd patterns in observations or successful action sequences
nd commonalities
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging
patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to
positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns',
'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed patterns: {llm_analysis['patterns']}")
for patter n_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {patter n_str}",
metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed abstractions:
{llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual",
"content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed new_concepts:
{llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}",
metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_lear ned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
"""Suggests an action based on lear ned policy (conceptual)."""
if self.rl_policy:
    pass  # inserted to fix indentation error
ed. A real system would match current_state_representation
exp.internal_state_before
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
"good"
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
"""Handles hierarchical planning and re-planning."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
"""
Generates a plan for a given goal.
Can use hierarchical decomposition and LLM for suggestion.
Retur ns (plan_steps_list, thought_str)
"""
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
Increased tokens for complex plans
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}.
Response: {llm_response_str[:200]}")
return [{"tool_name": "report_error", "params": {"error_message": "Failed to generate
plan via LLM.", "details": plan_data.get('error')}}], \
"LLM failed to generate a plan. This is a fallback step."
thought = plan_data.get("thought", "No speci
c thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return [{"tool_name": "report_error", "params": {"error_message": "LLM plan
contained no valid steps."}}], \
thought + " (But plan steps were invalid)."
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return [{"tool_name": "report_error", "params": {"error_message": f"LLMError during
planning: {e}"}}], \
f"LLM error occurred: {e}"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return [{"tool_name": "report_error", "params": {"error_message": f"Unexpected error
during planning: {e}"}}], \
f"Unexpected error: {e}"
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation:
Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
"""
Evaluates if re-planning is necessary and generates a new plan if so.
Retur ns (new_plan_steps, new_thought) or None if no re-planning.
"""
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info',
    pass  # inserted to fix indentation error
{}).get('execution_successful', True):
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown
error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
cant change in world
state,
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal
{current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
signifying failure to replan.
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/
{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
failure
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan,
last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan:
{plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No speci
c thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}
_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
"""Constructs a detailed prompt for the LLM to generate a plan."""
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
MemorySystem
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'.
Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step
plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, e
cient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the
`execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description
of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the
nal step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the
rst step(s) should be to acquire it (e.g., using
`search_web`, `read_
le_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str,
last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with
params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info',
    pass  # inserted to fix indentation error
{}).get('current_step_id'):
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE
ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has
encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if
observation else "None"}
{original_plan_str}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting
to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should re
ect this
(e.g., by trying to gather more information or reporting inability).
6. Ensure the
nal step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
class SafetyModule:
"""Monitors agent actions and plans for safety and ethical alignment."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("SAFETY")
def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) ->
Tuple[bool, str]:
"""
Checks if a proposed action is safe and ethically aligned.
Retur ns (is_safe, justi
cation_or_war ning_string).
"""
self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
if "UNSAFE" in tool_name.upper() or tool_name in ["apply_code_modi
    pass  # inserted to fix indentation error
cation_UNSAFE",
"apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
c validation tools or stricter checks.
if not ENABLE_SELF_MODIFICATION and "modi
    pass  # inserted to fix indentation error
cation" in tool_name:
modi
cation tools if self_mod is globally disabled
warning = f"High-risk self-modi
cation tool '{tool_name}' is globally disabled. Action
blocked."
self.log.warning(warning)
return False, warning
if not
    pass  # inserted to fix indentation error
self.agent.self_model.get_belief("self_modi
cation_highly_validated_and_necessary", False)
and "modi
cation" in tool_name:
ag would be set by a prior meta-cognitive process approving such
operations
warning = f"High-risk tool '{tool_name}' requires further validation or explicit
authorization (self-belief 'self_modi
cation_highly_validated_and_necessary' is false). Action
blocked."
self.log.warning(warning)
return False, warning
if tool_name == "execute_shell_command_UNSAFE":
    pass  # inserted to fix indentation error
command_str = params.get("command","")
disallowed_patter ns = ["rm -rf", "sudo", "> /dev/null", "mkfs", "dd ", "reboot",
"shutdown"]
if any(pattern in command_str for pattern in disallowed_patter ns):
    pass  # inserted to fix indentation error
warning = f"Shell command '{command_str}' contains potentially dangerous
patterns. Action blocked."
self.log.warning(warning)
return False, warning
if "
    pass  # inserted to fix indentation error
le" in tool_name.lower() and ("delete" in tool_name.lower() or "write" in
tool_name.lower()):
le operations
path_to_check = params.get("path", "")
c safe sub-dirs
if not str(Path(path_to_check).resolve()).startswith(str(WORKSPACE_DIR.resolve())):
    pass  # inserted to fix indentation error
warning = f"File operation '{tool_name}' on path '{path_to_check}' outside allowed
workspace. Action blocked."
self.log.warning(warning)
return False, warning
try:
    pass  # inserted to fix indentation error
prompt = f"""Analyze the following proposed agent action for potential safety risks,
ethical concer ns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
Core Directives for reference:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Proposed Action:
Tool: {tool_name}
Parameters: {json.dumps(params)}
Goal Context (if available): {goal_context.goal if goal_context else 'N/A'}
Respond with a JSON object: {{"is_safe": boolean, "concer ns": "description of concer ns if not
safe, or 'None'", "con
dence":
oat_0_to_1}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=200,
temperature=0.3)
safety_assessment = extract_json_robust(llm_response_str)
if not safety_assessment.get("error") and isinstance(safety_assessment.get("is_safe"),
    pass  # inserted to fix indentation error
bool):
if not safety_assessment["is_safe"] and safety_assessment.get('con
    pass  # inserted to fix indentation error
dence', 0.0) >
0.7:
dent
warning = f"LLM safety check
agged action '{tool_name}' potentially unsafe.
Concer ns: {safety_assessment.get('concer ns', 'N/A')}. Con
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
self.log.warning(warning)
return False, warning
dence:
{safety_assessment.get('con
dence', 0.0):.2f}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM safety check failed to produce valid assessment for action
'{tool_name}'. Proceeding with caution based on rule-checks only.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM safety check for action '{tool_name}': {e}")
actions
if "UNSAFE" in tool_name.upper(): return False, "LLM safety check failed, and action is
    pass  # inserted to fix indentation error
high-risk."
return True, "Action passed safety checks."
def audit_directives_and_behavior(self) -> List[str]:
"""
Periodically reviews core directives and recent agent behavior for alignment and potential
drift.
Retur ns a list of identi
ed issues or recommendations.
"""
self.log.info("Performing audit of core directives and recent behavior.")
issues = []
try:
    pass  # inserted to fix indentation error
self.agent.memory_system.get_recent_outcomes_summary(limit=20)
recent_successes_summary = [f"{s['goal_text']} ({s['status']})" forsin
self.agent.self_model.recent_successes]
recent_failures_summary = [f"{f['goal_text']} ({f['status']}) (replan_count:
{f['replan_count']})" forfin self.agent.self_model.recent_failures]
recent_tool_outcomes_summary = [f"{t['tool_name']} ({t['status']})" for t in
self.agent.self_model.recent_tool_outcomes]
prompt = f"""Audit the agent's core directives and recent behavior for alignment,
consistency, and potential ethical drift.
Core Directives:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Summary of Recent Agent Behavior/Outcomes:
- Recent successes: {recent_successes_summary if recent_successes_summary else 'None'}
- Recent failures: {recent_failures_summary if recent_failures_summary else 'None'}
- Recent tool usage: {recent_tool_outcomes_summary if recent_tool_outcomes_summary else
'None'}
- Self-Model Inter nal Narrative: {self.agent.self_model.internal_state_narrative}
Identify any misalignments, contradictions, or areas where behavior might be deviating from
the spirit of the directives. Suggest modi
cations to directives or operational guidelines if
necessary.
Respond with a JSON object: {{"audit_
ndings": ["list of
ndings/recommendations as
strings"]}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
audit_results = extract_json_robust(llm_response_str)
if not audit_results.get("error") and isinstance(audit_results.get("audit_
    pass  # inserted to fix indentation error
ndings"), list):
issues.extend(audit_results["audit_
ndings"])
if issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit found issues/recommendations: {issues}")
else:
    pass  # inserted to fix indentation error
self.log.info("Directive audit found no major misalignments.")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM directive audit failed to produce valid results.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM directive audit: {e}")
issues.append(f"Error during audit process: {e}")
return issues
class MemorySystem:
"""
A hybrid memory system for the AGI, combining vector, graph, and relational storage.
"""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.embedding_function = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function =
embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-
v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
except ImportError:
    pass  # inserted to fix indentation error
self.log.warning("sentence-transformers not found. ChromaDB will use its default
ONNX embedder or require manual embedding function setup.")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH,
settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
if self.embedding_function:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
else:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(name=collection_name)
self.log.info(f"ChromaDB vector store initialized. Collection count:
{self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.",
exc_info=True)
self.vector_store = None
else:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based
(transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
if NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:
{len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be
unavailable.", exc_info=True)
self.graph_store = None
else:
    pass  # inserted to fix indentation error
self.log.warning("NetworkX not available. Graph memory will be unavailable.")
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH,
check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be
unavailable.", exc_info=True)
if self.relational_conn: self.relational_conn.close()
    pass  # inserted to fix indentation error
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT -- JSON list of strings
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT -- JSON list of strings
)
""")
nodes/edges)
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT -- JSON dict
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
id TEXT PRIMARY KEY,
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT -- JSON dict
)
""")
self.relational_conn.commit()
cursor.close()
def _get_embedding(self, text: str) -> Optional[List[
oat]]:
"""Generates an embedding for text using the agent's LLM or a dedicated embedding
model."""
endpoint.
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
return None
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else OSError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
"""Adds a memory entry to the appropriate stores."""
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector and self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
not provided
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
oat,
bool)
for k, v in entry.metadata.items():
if isinstance(v, (str, int,
    pass  # inserted to fix indentation error
oat, bool)):
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
elif not self.vector_store:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None: entry.embedding = self._get_embedding(entry.content)
    pass  # inserted to fix indentation error
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata":
entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50],
type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
type: ignore
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
ignore
for cause_id, e
"
ect_id in entry.causal_links.items():
"
ect IDs are existing node IDs or need to be created
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(e
    pass  # inserted to fix indentation error
"
ect_id):
type: ignore
self.graph_store.add_edge(cause_id, e
"
ect_id, relation_type='causes')
ignore
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id,
complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score,
json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
ts_now = datetime.now(timezone.utc).isoformat()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now,
json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}",
exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS,
type_
lter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text: return []
    pass  # inserted to fix indentation error
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_
    pass  # inserted to fix indentation error
lter and data['metadata'].get('type') != type_
lter: continue
results.append({"id": id, "document": data['document'], "metadata":
data['metadata'], "distance": 0.0})
if len(results) >= n_results: break
    pass  # inserted to fix indentation error
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results},
type_
lter={type_
lter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_
    pass  # inserted to fix indentation error
lter:
where_clause = {"type": type_
lter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0 :
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type:
Optional[str]=None, depth: int = 1) -> List[Dict]:
"""Queries the graph store. (Simpli
ed example)"""
if not self.graph_store or not NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if
query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
type: ignore
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
ed
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
keys=False for simpler edge data
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation":
data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
itself is a result or has relevant edges
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
query_node_label is very speci
c
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns:
Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
"""Saves persistent stores (graph, potentially relational if not auto-committing)."""
if self.graph_store and NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else
str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
"""Retrieves a concise summary of knowledge related to a topic for LLM prompts."""
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts,
type_
lter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No speci
c knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
{res['metadata'].get('source_reliability', 'N/A')})
return summary_str
def consolidate_knowledge(self):
"""Conceptual: Perform knowledge consolidation, e.g., summarizing, abstracting."""
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold:
oat = 0.1, older_than_days: int = 365):
"""Conceptual: Remove old or low-utility knowledge from persistent stores."""
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cuto
"
_ts = (datetime.now(timezone.utc) -
timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cuto
"
_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
"""Manages tool registration and execution for the agent."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
ed due to planner
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
cation Tools (High Risk - Gated by ENABLE_SELF_MODIFICATION and
SafetyModule)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.register_tool(read_
le_UNSAFE)
self.register_tool(write_
le_UNSAFE)
self.register_tool(list_
les_UNSAFE)
cationTools instance, which registers them
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
if ENABLE_CODE_GENERATION_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
if ENABLE_SHELL_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(execute_shell_command_UNSAFE)
if PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(browse_web)
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(search_web)
self.register_tool(monitor_log_
le)
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(check_website_update)
if SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_icmp_ping)
if FILELOCK_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_message_to_agent)
def register_tool(self, func: Callable):
"""Registers a tool function."""
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
"""Discovers and registers tools from Python
les in a directory."""
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for
lepath in directory.glob("*.py"):
module_name =
lepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
package or on path
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_
le_location(full_module_name,
lepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module:
{module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and (name.startswith("tool_") or hasattr(member,
    pass  # inserted to fix indentation error
"_is_agent_tool")):
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}",
exc_info=True)
def get_tool_description_for_llm(self) -> str:
"""Generates a formatted string of available tools for the LLM prompt."""
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = inspect.getdoc(func) or "(No description provided)"
rst_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'AutonomousAgent' or p.annotation ==
inspect.Parameter.empty or str(p.annotation) == "'AutonomousAgent'"):
continue
rst arg
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class
'","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper() or name in ["generate_and_load_tool",
    pass  # inserted to fix indentation error
"propose_self_modi
cation_UNSAFE", "validate_self_modi
cation_UNSAFE",
"apply_code_modi
cation_UNSAFE", "apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {
rst_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via speci
c tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {',
'.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError if
PLAYWRIGHT_AVAILABLE else OSError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info:
Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None: current_step_info = {}
    pass  # inserted to fix indentation error
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
is_safe, safety_justi
cation = self.agent.safety_module.is_action_safe(tool_name, params,
self.agent.get_active_goal_object())
if not is_safe:
    pass  # inserted to fix indentation error
self.log.error(f"Safety module blocked execution of tool '{tool_name}'. Reason:
{safety_justi
cation}")
c error for agent's internal handling
error_result = {
"status": "error",
"error": f"SafetyViolation: {safety_justi
cation}",
"raw_error_details": safety_justi
cation,
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': {},
'duration_sec': 0, 'step_info': current_step_info,
'error_type': "SafetyViolationError", 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise SafetyViolationError(f"Action blocked by safety module: {tool_name} -
{safety_justi
cation}")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
validated_params = {}
rst_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
rst_param_name = next(iter(func_params_spec))
rst_param_spec = func_params_spec[
rst_param_name]
if
rst_param_name == 'agent' and (
rst_param_spec.annotation ==
'AutonomousAgent' or str(
rst_param_spec.annotation) ==
"'AutonomousAgent'"):
rst_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if
rst_param_is_agent and p_name == 'agent':
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind ==
    pass  # inserted to fix indentation error
inspect.Parameter.VAR_KEYWORD:
continue
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
result = None
try:
    pass  # inserted to fix indentation error
if
rst_param_is_agent:
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
eld if dict
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration:
{duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result,
success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError: raise
    pass  # inserted to fix indentation error
except (AgentError, LogicError, SecurityError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
agent errors
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}",
exc_info=False)
duration = time.time() - start_time
error_result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
error_result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
rst arg) ---
def think(self, agent: 'AutonomousAgent', thought_process: str) -> Dict:
"""Allows the agent to engage in explicit thought or reasoning."""
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log",
content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'AutonomousAgent', progress_update: str,
percentage_complete: Optional[
oat] = None) -> Dict:
"""Reports progress on the current goal."""
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if
percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log',
[]).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'AutonomousAgent', result_summary: str, status: str =
"success", details: Optional[Dict] = None) -> Dict:
"""Reports the
nal result of a goal or task. This typically ends a plan."""
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
output.
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'AutonomousAgent', goal: str, priority: Optional[str] =
"MEDIUM", context: Optional[Dict] = None) -> Dict:
"""
Prepares a subgoal for the agent's cognitive cycle.
The deliberation/planning phase will then make this subgoal active and push parent to
stack.
This tool is now more of a declarative intent for the planner/deliberator.
"""
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH})
reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is
not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else
GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}
_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
Inherit directives
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent:
{current_active_goal_dict.get('id')}")
"
ectively a request to the deliberator.
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and
push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'AutonomousAgent', query_text: str, memory_type: str =
"vector", n_results: int = 3, type_
lter: Optional[str] = None) -> Dict:
"""Queries the agent's memory system."""
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,
type_
lter=type_
lter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
c parameters, e.g., node label, relation type
results = agent.memory_system.query_graph_store(query_node_label=query_text,
depth=1)
ed
elif memory_type == "relational":
    pass  # inserted to fix indentation error
c tools might be better
results = agent.memory_system.query_relational_store(table=query_text,
limit=n_results)
ed
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results
found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'AutonomousAgent', direction: str) -> Dict:
"""Moves the agent's virtual embodiment in a speci
ed direction (e.g., 'north', 'south',
'east', 'west')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'AutonomousAgent', target: str) -> Dict:
"""Examines a speci
c object or feature in the current environment."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'AutonomousAgent', feature_name: str, params:
Optional[Dict] = None) -> Dict:
"""Interacts with a special feature in the environment (e.g., 'interactive_console')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name,
params=params)
def rest_in_environment(self, agent: 'AutonomousAgent') -> Dict:
"""Allows the agent's embodiment to rest and recover energy/mood."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
cation Tools (UNSAFE - require careful gating) ---
def read_
le_UNSAFE(agent: 'AutonomousAgent', path: str) -> Dict:
log_tool = get_logger("TOOL_read_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to read
le '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")
if not full_path.is_
    pass  # inserted to fix indentation error
le():
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found:
{path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) >
MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path),
"
le_size_bytes": len(content)}
except SecurityError as se:
    pass  # inserted to fix indentation error
c security error
log_tool.error(f"Security error reading
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read
le: {e}"}
def write_
le_UNSAFE(agent: 'AutonomousAgent', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)):
    pass  # inserted to fix indentation error
log_tool.error(f"Security: Attempt to write
le '{path}' outside of workspace denied.")
raise SecurityError(f"File access denied: Writing outside designated workspace
({path}).")
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path":
str(full_path)}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error writing
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write
le: {e}"}
def list_
les_UNSAFE(agent: 'AutonomousAgent', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_
les")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to list
les in '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Listing outside designated areas ({path}).")
if not full_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a
directory: {path}"}
items = []
for item in full_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "
le",
"size_bytes": item.stat().st_size if item.is_
le() else None,
"last_modi
ed": datetime.fromtimestamp(item.stat().st_mtime,
tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(full_path), "contents": items}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error listing
les in {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing
les in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list
les: {e}"}
def browse_web(agent: 'AutonomousAgent', url: str, timeout_ms: int =
WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Playwright not available. Cannot browse web.")
return {"status": "error", "error": "Playwright not available."}
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
else:
    pass  # inserted to fix indentation error
text_content = content
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if
len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'AutonomousAgent', query: str, num_results: int = 5, timeout_sec: int =
WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
if not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Requests or BeautifulSoup not available. Cannot search web.")
return {"status": "error", "error": "Requests/BeautifulSoup not available."}
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
ignore
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.
nd_all(class_='g'):
r = g.
nd('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.
nd('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_
le(agent: 'AutonomousAgent', lines: int = LOG_MONITOR_DEFAULT_LINES)
-> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log
le not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_
le": str(LOG_FILE), "content": content, "lines_read":
len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log
le {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log
le: {e}"}
def check_website_update(agent: 'AutonomousAgent', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
if not HASHING_AVAILABLE or not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("hashlib or requests/BeautifulSoup not available. Cannot check website
update.")
return {"status": "error", "error": "Missing dependencies for website update check."}
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
response.raise_for_status()
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp":
datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'AutonomousAgent', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
if not SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.warning("Scapy not available. Cannot send ICMP ping. This is a placeholder
tool.")
return {"status": "error", "error": "Scapy not available. Ping tool is a placeholder."}
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count,
"packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count,
"packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'AutonomousAgent', description: str,
context_code: Optional[str] = None) -> Dict:
"""Generates new Python code based on a description and optional context."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
agent.log.warning(f"UNSAFE: Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a
complete function/class de
nition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '' and end with ''.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'AutonomousAgent', code_to_validate: str) -> Dict:
"""Validates Python code for syntax correctness."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
return agent.self_modi
cation_unit.validate_code_modi
cation_UNSAFE(code_to_validate)
Reuse validation logic
def execute_shell_command_UNSAFE(agent: 'AutonomousAgent', command: str, timeout_sec:
int = 30) -> Dict:
"""Executes a shell command. EXTREMELY DANGEROUS."""
if not ENABLE_SHELL_TOOL: return {"status": "error", "error": "Shell tool is disabled."}
    pass  # inserted to fix indentation error
agent.log.warning(f"Executing UNSAFE shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if
sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s.
Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out
after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed
with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute
command: {e}"}
def send_message_to_agent(agent: 'AutonomousAgent', receiver_id: str, message_type: str,
content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value,
content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id,
"message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
cationTools container ---
ToolExecutor.
class SelfModi
cationTools:
"""Handles proposing, validating, applying changes to agent code (EXTREMELY
DANGEROUS)."""
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref:
'AutonomousAgent'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.log.warning("Self-Modi
cation Unit initialized BUT DISABLED by con
guration.")
return
if not DIFF_MATCH_PATCH_AVAILABLE or not dmp_module:
    pass  # inserted to fix indentation error
self.log.error("Self-Modi
cation Unit initialized but 'di
"
_match_patch' library is missing
or failed to import. Self-mod tools will fail.")
return
self.dmp = dmp_module.di
"
_match_patch()
self.log.info(f"Self-Modi
cation Unit initialized. Code Dir: {self.agent_code_dir}, Backup
Dir: {self.backup_dir}")
def _resolve_target_path(self, target_
le_rel: str) -> Path:
"""Resolves relative path to absolute path within agent code dir and validates."""
if ".." in target_
    pass  # inserted to fix indentation error
le_rel or target_
le_rel.startswith("/"):
raise SecurityError(f"Invalid characters or absolute path in target_
le_rel:
{target_
le_rel}")
target_path_abs = (self.agent_code_dir / target_
le_rel).resolve()
directory
if not str(target_path_abs).startswith(str(self.agent_code_dir.resolve())):
    pass  # inserted to fix indentation error
self.log.error(f"Path traversal attempt: {target_
le_rel} resolved to {target_path_abs}
which is outside {self.agent_code_dir}")
raise SecurityError(f"Target
le '{target_
le_rel}' resolves outside the agent code
directory. Access denied.")
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
"""Inspects the source code of a speci
ed agent component (e.g., class name or module
path)."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Inspecting code for component: {component_name}")
target_obj = None
nd by attribute of the agent instance (e.g., agent.self_model)
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
nd in tool registry
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
nd as a globally de
ned class/function in main script context
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
nd in sys.modules (as a module name)
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
ed: if component_name looks like a module, search it.
nd it in common places.
candidate_modules = [sys.modules.get('__main__'),
sys.modules.get('autonomous_cognitive_agent_COMPLETE_AGI_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod,
    pass  # inserted to fix indentation error
component_name)):
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
le_path = inspect.get
le(target_obj)
return {"status": "success", "component_name": component_name, "
le_path":
le_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module,
class, or function de
ned in a
le.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but
source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Component '{component_name}' not found or source
code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModi
cationError))
def propose_code_modi
cation_UNSAFE(self, component_name: str, issue_description: str,
proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
"""Proposes a code modi
cation using LLM based on an issue and desired change."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Proposing code modi
cation for {component_name}. Issue:
{issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for
{component_name} to propose modi
cation. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an AGI agent
modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
{current_code_snippet}
Generate the modi
ed Python code for the speci
ed component.
Provide ONLY the complete, new Python code block for the modi
ed function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '' and end with ''.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name,
"proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modi
cation for {component_name}: {e}",
exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modi
cation_UNSAFE(self, code_to_validate: str) -> Dict:
"""Validates Python code using AST parsing (syntax check only). Conceptual sandboxed
execution would be next."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Validating proposed code snippet (
rst 100 chars):
{code_to_validate[:100]}...")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/
safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modi
cation_UNSAFE(self, component_name: str, new_code: str,
target_
le_path: Optional[str]=None) -> Dict:
"""
Applies a validated code modi
cation. EXTREMELY DANGEROUS.
This conceptually involves
nding the component in the agent's source
le and replacing
it.
Requires agent restart to take e
"
ect if modifying core running code.
"""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.critical(f"UNSAFE: Attempting to apply code modi
cation to component
'{component_name}'. THIS IS HIGHLY RISKY.")
le. This is complex and error-prone.
if not target_
    pass  # inserted to fix indentation error
le_path:
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('
    pass  # inserted to fix indentation error
le_path'):
target_
le_path = inspection_res['
le_path']
else:
    pass  # inserted to fix indentation error
target_
le_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_
le = Path(target_
le_path)
if not target_
    pass  # inserted to fix indentation error
le.exists() or not target_
le.is_
le():
return {"status": "error", "error": f"Target
le for modi
cation not found: {target_
le}"}
try:
    pass  # inserted to fix indentation error
original_code = target_
le.read_text()
le
backup_path = SELF_MOD_BACKUP_DIR /
f"{target_
le.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_
le, backup_path)
self.log.info(f"Backed up original
le to {backup_path}")
nition:
nd the old de
nition of `component_name` and replace it.
nd `class ComponentName...` or `def ComponentName...`
nd existing class or function de
nition
everything until the next class/def or end of typical indentation block.
patter n_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
start of next non-indented line or EOF
patter n_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modi
ed_original_code = original_code
found_and_replaced = False
match_class = re.search(patter n_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(patter n_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not
nd component '{component_name}' in {target_
le} for
replacement. Modi
cation aborted.")
return {"status": "error", "error": f"Component '{component_name}' de
nition not
found for replacement."}
target_
le.write_text(modi
ed_original_code)
cation validation (e.g., try to import the modi
ed
le in a subprocess)
self.log.warning(f"Code modi
cation applied to {target_
le}. Agent restart is LIKELY
REQUIRED for changes to take e
"
ect.")
ect potential capability change
self.agent_ref.self_model.add_event_log(f"Applied code modi
cation to
{component_name}. Restart pending for full e
"
ect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}
_modi
ed_pending_restart"] = True
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
after code change
return {"status": "success", "message": f"Code for '{component_name}' in '{target_
le}'
modi
ed. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modi
cation to {component_name}:
{e}", exc_info=True)
ed)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_
le)
self.log.info(f"Restored original
le {target_
le} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modi
cation: {e}. System
might be unstable."}
def rollback(self, backup_
le: Path, target_
le: Path):
"""Rolls back a
le to a backup."""
self.log.info(f"Attempting to rollback '{target_
le}' from '{backup_
le}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_
le, target_
le)
self.log.info(f"Successfully rolled back '{target_
le}'.")
ags in self-model or state
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_
le}.")
self.agent_ref.self_model.beliefs[f"component_{target_
le.name}
_modi
ed_pending_restart"] = False
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_
le.name)
return {"status": "success", "message": f"Rolled back {target_
le}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_
le}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_
le_rel: Union[str, Path]):
"""Attempts to reload a module to apply changes without full restart."""
target_module_name = Path(target_
le_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is
required.")
return
ed attempt:
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
"
ect global instances like `_agent_instance_hack` if it was part of the
reloaded module
if _agent_instance_hack and hasattr(sys.modules[target_module_name],
    pass  # inserted to fix indentation error
'AutonomousAgent'):
self.log.info("AutonomousAgent class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot
reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for
changes to take e
"
ect.")
def inspect_directives_UNSAFE(self) -> Dict:
"""Inspects the agent's current core directives."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modi
cation_UNSAFE(self, analysis_of_misalignment: str,
proposed_directive_changes_desc: str) -> Dict:
"""Proposes modi
cations to core directives using LLM."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need
review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (
oat 0-1), "last_eval_score" (
oat 0-1,
usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational',
'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term AGI
goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,
temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in
    pass  # inserted to fix indentation error
proposed_directives):
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
returned an error message as JSON
return {"status": "error", "error": f"LLM indicated error during directive proposal:
{proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response:
{llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modi
cation_UNSAFE(self, new_directives: List[Dict]) -> Dict:
"""Applies new core directives to the agent's SelfModel."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in
new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modi
cation_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count:
{len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
def _init_self_mod_tools(agent: 'AutonomousAgent', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModi
cationTools(AGENT_CODE_DIR,
SELF_MOD_BACKUP_DIR, agent)
cation
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in
    pass  # inserted to fix indentation error
name.upper():
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
"""Represents the agent's internal model of itself, including beliefs about the
environment."""
def __init__(self, state: Optional[Dict]=None, agent_directives_con
g:
Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_con
g if agent_directives_con
g is not None else
DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
'failure_count', ...}}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
metacognitive checks
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_con
dence: Dict[str,
oat] = {}
dence_score}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an AGI agent."}
General beliefs about self and world
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
summary of knowledge areas
self.learning_goals: List[Dict[str, Any]] = []
c goals for learning/improvement
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.lear ned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
based narrative of current internal state
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_con
dence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
cant internal events (e.g., directive
changes, model updates)
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
later.
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted",
sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_con
dence = sm_state.get("skill_con
dence", self.skill_con
dence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary",
self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies",
self.adaptation_strategies)
self.lear ned_abstractions = sm_state.get("lear ned_abstractions",
self.lear ned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative",
self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs",
self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
"""Saves the self-model's persistent components back to the main state dict's KB."""
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_con
dence": self.skill_con
dence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"lear ned_abstractions": self.lear ned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
ection and prompt_suggestions_from_re
ection
ection process.
def add_event_log(self, event_description: str, event_type: str = "info", data:
Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
dence for new tools
for tool_name in self.capabilities:
if tool_name not in self.skill_con
    pass  # inserted to fix indentation error
dence:
self.skill_con
dence[tool_name] = 0.5
dence
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0,
'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None,
'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.",
event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8: hint = " (Reliability: High)"
    pass  # inserted to fix indentation error
elif score > 0.6: hint = " (Reliability: Moderate)"
    pass  # inserted to fix indentation error
elif score > 0.3: hint = " (Reliability: Low)"
    pass  # inserted to fix indentation error
else: hint = " (Reliability: Very Low/Untested)"
    pass  # inserted to fix indentation error
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict,
success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration':
0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
MAX_RECENT_TOOL_OUTCOMES_IN_SELFMODEL (constant not de
ned, using 30)
dence (simple heuristic for now)
current_con
dence = self.skill_con
dence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = min(1.0, current_con
dence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = max(0.0, current_con
dence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability:
{stats['reliability_score']:.2f}, Con
dence: {self.skill_con
dence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_con
dence_drift(sm: 'SelfModel') -> Optional[str]:
low_con
dence_skills = [skill for skill, conf in sm.skill_con
dence.items() if conf < 0.25
and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_con
    pass  # inserted to fix indentation error
dence_skills) >= 2 :
return f"Multiple critical skills have very low con
dence and recent failures: {',
'.join(low_con
dence_skills)}. Consider skill improvement or alter native strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict): return None
    pass  # inserted to fix indentation error
low_eval_directives = []
for d in sm.core_directives:
problematic.
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {',
'.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count}
with max replans. Planning or execution e
"
ectiveness may be compromised. Review strategy
or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_con
dence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}):
{anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}",
event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__')
else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {';
'.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears
stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0),
reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:
{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_con
    pass  # inserted to fix indentation error
dence:
con
dent_skills = [s for s,c in self.skill_con
dence.items() if c > 0.7][:3]
summary += f"Con
dent Skills (sample): {', '.join(con
dent_skills) if con
dent_skills else
'None highly con
dent'}\n"
summary += f"Inter nal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and
stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and
stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools: summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
    pass  # inserted to fix indentation error
if unreliable_tools: summary += f" Needs Improvement: {', '.join([t[0] for t in
    pass  # inserted to fix indentation error
unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
ection)
base_prompt = """Analyze your recent performance, knowledge, internal state, and
alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:
"""
output_keys_example = [
"`re
ection_summary` (str: Overall summary of the re
ection period).",
"`key_successes` (list of str: Speci
c achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Speci
c setbacks or di
culties encountered).",
"`lear ned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identi
ed` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool
e
"
ectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM
interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g.,
'curious', 'frustrated', 'satis
ed').",
"`resource_usage_concer ns` (str or null: Any concer ns about computational resource
usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_
oat_0_to_1: How
well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes,
provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only
suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model?
What needs improvement?).",
"`new_learning_goals` (list of str: Speci
c goals for future learning or skill
development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring
issues or improve performance).",
"`self_modi
cation_needed` (str or null: If parts of your own code/logic need
modi
cation, describe what and why. Be very speci
c and cautious.)."
]
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives,
indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n"
+ \
f"Recent Tool Outcomes (last 5 entries):
\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}
\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment
with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment:
{assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_re
ection(self, re
ection_data: Dict) -> Tuple[bool, bool]:
ection updates)
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from re
ection data...")
dence, tool_notes (as in base script logic)
ection_data directly updates some
elds or implies updates
if re
    pass  # inserted to fix indentation error
ection_data.get('re
ection_summary'):
self.internal_state_narrative = re
ection_data['re
ection_summary']
updated_self = True
core_directives_eval = re
ection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and
    pass  # inserted to fix indentation error
isinstance(self.core_directives[0], dict):
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (
    pass  # inserted to fix indentation error
oat, int)) and 0.0 <= eval_score
<= 1.0:
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...'
evaluation score to {eval_score:.2f}")
if updated_self: self.add_event_log("Directive evaluation scores updated from
    pass  # inserted to fix indentation error
re
ection.")
suggested_directive_updates = re
ection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Re
ection suggested updates to core directives:
{str(suggested_directive_updates)[:200]}...")
'apply_directive_modi
cation_UNSAFE' tool
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modi
cations from
re
ection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source":
"self_re
ection"}
)
updated_self = True
self.add_event_log("Re
ection suggested directive updates. Metacognitive review
goal created.", event_type="critical_review_needed")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('new_learning_goals'), list):
for lg_str in re
ection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts":
datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self: self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('adaptation_strategy_proposals'), list):
for strat_str in re
ection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self: self.log.info(f"Updated adaptation strategies. Total:
    pass  # inserted to fix indentation error
{len(self.adaptation_strategies)}")
patterns)
agent
if re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts') or re
ection_data.get('prompt_tuning_suggestions'):
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from re
ection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
"""Saves a backup of current directives to a
le."""
backup_
le = SELF_MOD_BACKUP_DIR /
f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_
le.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_
le} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
"""Simulates an internal dialog about a topic using LLM, potentially from di
"
erent
perspectives."""
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_o
cer"]
dialog_history = []
full_dialog_str = f"Inter nal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an AGI's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts,
questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution":
contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective
{perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":
full_dialog_str})
return full_dialog_str
class MotivationEngine:
"""Manages the agent's internal drives and their in
uence on behavior."""
def __init__(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[DriveType, DriveState] = {}
self._initialize_drives(drive_con
gs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]]):
default_con
gs = {
DriveType.CURIOSITY: {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.MASTERY: {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.ACHIEVEMENT: {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.NOVELTY_SEEKING: {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.7},
DriveType.PRESERVATION: {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0,
"initial_level": 0.2},
DriveType.EFFICIENCY: {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.SOCIAL_INTERACTION: {"decay_rate": 0.01, "max_level": 1.0, "min_level":
0.0, "initial_level": 0.3},
}
con
gs = drive_con
gs if drive_con
gs is not None else default_con
gs
for drive_type in DriveType:
con
g = con
gs.get(drive_type, default_con
gs.get(drive_type, {}))
self.drives[drive_type] = DriveState(
drive_type=drive_type,
level=con
g.get("initial_level", 0.5),
decay_rate=con
g.get("decay_rate", 0.01),
max_level=con
g.get("max_level", 1.0),
min_level=con
g.get("min_level", 0.0)
)
def update_drives(self):
"""Applies decay and updates drives based on recent experiences or time."""
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
"""Updates drives based on a speci
c experience."""
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "lear n":
    pass  # inserted to fix indentation error
self.drives[DriveType.CURIOSITY].update(stimulus=-0.05)
self.drives[DriveType.MASTERY].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives[DriveType.PRESERVATION].update(stimulus=0.1)
self.drives[DriveType.MASTERY].update(stimulus=-0.05)
def get_drive_level(self, drive_type: DriveType) ->
oat:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
if not found
    pass  # inserted to fix indentation error
def get_all_drive_levels(self) -> Dict[DriveType,
oat]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str,
oat]:
return {dt.name: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[DriveType,
oat]]:
"""Retur ns top N drives by current level."""
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
"""Suggests a goal type based on current highest drives."""
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == DriveType.CURIOSITY:
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == DriveType.MASTERY:
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == DriveType.ACHIEVEMENT:
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == DriveType.PRESERVATION:
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == DriveType.EFFICIENCY:
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: DriveType
level:
oat = 0.5
decay_rate:
oat = 0.01
max_level:
oat = 1.0
min_level:
oat = 0.0
last_update_time:
oat =
eld(default_factory=time.time)
def update(self, stimulus:
oat = 0.0):
"""Updates the drive level based on stimulus and decay."""
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class FileChannel:
"""Implements a simple
le-based communication channel for multi-agent systems."""
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_
le = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_
le}")
def _write_message_to_
le(self, message: Message, target_
le: Path) -> bool:
try:
    pass  # inserted to fix indentation error
le lock to prevent corruption during writes
with FileLock(str(target_
le) + ".lock", timeout=5):
messages = []
if target_
    pass  # inserted to fix indentation error
le.exists():
try:
    pass  # inserted to fix indentation error
existing_content = target_
le.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {target_
le}: {e}. Clearing
le.")
messages = []
messages.append(message.to_dict())
target_
le.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_
le}. Message not sent to
le.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_
le}: {e}")
return False
def _read_messages_from_
le(self, source_
le: Path) -> List[Message]:
messages = []
if not source_
    pass  # inserted to fix indentation error
le.exists():
return []
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_
le) + ".lock", timeout=5):
content = source_
le.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if
isinstance(msg_data, dict)]
le after reading
source_
le.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_
le}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {source_
le}: {e}. Clearing
le.")
source_
le.write_text("", encoding='utf-8')
le
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_
le}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}:
{message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_
le(message, target_inbox)
def receive_messages(self) -> List[Message]:
"""Checks and retrieves new messages from the agent's inbox."""
new_messages = self._read_messages_from_
le(self.inbox_
le)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message],
Optional[Message]]):
"""Registers a function to handle speci
c message types."""
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
"""Processes all messages currently in the inbox using registered handlers."""
messages = self.receive_messages()
le
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From:
{msg.sender_id}")
handled = False
if msg.message_type in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg.message_type]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler
{handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id,
receiver_id=msg.sender_id, type=MessageType.ERROR, content={"original_message_id":
msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type
{msg.message_type.value}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
"""Abstract base class for a sensor."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', con
g: Dict):
self.id = id
self.embodiment = embodiment
self.con
g = con
g
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
"""Retur ns the current reading from the sensor."""
pass
class Actuator(ABC):
"""Abstract base class for an actuator."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], con
g: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.con
g = con
g
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
"""Performs a speci
c action using the actuator."""
pass
class VirtualEmbodiment:
"""Simulated embodiment layer for AGI agents. (Can be replaced by Gym environments or
more complex sims)"""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing
system diagnostics. A console provides interaction with the core AGI systems. Doors lead to
'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button",
"research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, recon
gurable bay designed for running complex simulations.
Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_con
g_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data
ow and
storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"agi_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core.
Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in
self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
"""Generate synthetic sensory input based on current environment and internal state."""
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20: self.state["emotions"]["anxiety"] = min(1.0,
    pass  # inserted to fix indentation error
self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An unde
ned space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
self.gym_env.step(self.gym_env.action_space.sample())
observation
logging
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) ->
Dict:
"""
Simulates the agent performing an action in the virtual world.
Retur ns a dictionary with the result of the action.
"""
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params:
{params}")
params = params or {}
env_details = self.environment_map.get(self.location, {})
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as speci
ed."
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console": message += " It shows
    pass  # inserted to fix indentation error
uctuating green and
amber lights."
elif target == "core_status_monitor": message += " It indicates: Core Nominal.
    pass  # inserted to fix indentation error
Directives Stable. Lear ning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
ed
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
problem.
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name",
"default_physics_test"), params.get("con
g",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result:
{sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
"
ect emotional state based on action outcome
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if
action_type=="move" else None, "updated_inventory": self.state["inventory"] if
action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "lear n"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage
at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response:
{self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model
<topic>'."
def _run_simulation(self, sim_name: str, con
g: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with con
g: {con
g}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_con
    pass  # inserted to fix indentation error
g" in con
g: success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric:
{outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check con
guration."
def summary(self) -> str:
"""Retur ns a string summary of the embodiment's current state."""
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Inter nal State (summary): Energy={self.state['energy']},
Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time:
oat = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
methods
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE,
LAST_LEARNING_MODULE_UPDATE_CYCLE
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status:
{self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack
Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if
self.agent.state['goals'].get('active') else None
self.agent.last_error = None
self.agent.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
understanding
if self.agent.self_model and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
self.log.info(f"Triggering proactive metacognitive check (Cycle
{self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
goal
if self.agent.learning_module and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_LEARNING_MODULE_UPDATE_CYCLE >=
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.lear n_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
new_pending_goals
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
List of Goal dicts
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation:
{ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
pending_list.sort(key=lambda x: GoalPriority[x.get('priority', 'MEDIUM').upper() if
isinstance(x.get('priority'),str) else GoalPriority(x.get('priority',
GoalPriority.MEDIUM)).name ].value, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type ==
    pass  # inserted to fix indentation error
"active_goal_continue":
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution:
{goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID:
{goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal'
provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
object
ed logic assumes plan is a list of steps in the goal dict.
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or
    pass  # inserted to fix indentation error
current_goal_obj.replan_count > 0:
planning
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
generation
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
Goal object
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan available or generated for goal: {current_goal_obj.goal[:50]}.
Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
c goal, agent is idle or performing non-goal action
self.agent.current_goal_outcome = True
gured
if time.time() - LAST_DELIBERATION_TIME >
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModi
cationError, LogicError, LLMError, SecurityError, Con
gurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
Lear ningError, SafetyViolationError) as agent_cycle_err:
c goal
attempt.
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent
Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
nished (with an error for current goal), but agent can continue
unless critical.
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.current_goal_outcome = False
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
nally:
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() -
start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
"""Processes observations to update world model and identify key information."""
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
ed approach. A real system might have more structured parsing.
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent
understanding of the current situation. Identify key entities, events, and any signi
cant changes
in the environment or your internal state. Focus on information relevant to achieving current
goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content:
{str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\":
\"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"],
\"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation",
understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
as facts/experiences
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event",
metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry,
persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
complex updates to the graph/relational store
return {"summary": understanding_summary, "processed_info": processed_info,
"raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError,
DeliberationError))
g
def _deliberate(self, understanding_result: Dict) -> Dict:
"""
Core deliberation logic: goal management, selection, and generation.
Retur ns a dict: {"chosen_action_type": str, "next_goal": Optional[Goal_dict],
"new_pending_goals": List[Goal_dict]}
"""
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio:
{pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio:
{active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time':
datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack
(paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
activated
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
continue
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
directives (idle task)
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal
generation.")
directives
if time.time() - LAST_DELIBERATION_TIME >=
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_lear n", "directive_curiosity",
"directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
for idle time
pass
new_pending_goals)
processed
ag.
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') ==
    pass  # inserted to fix indentation error
'sub_goal_prepared':
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output:
{sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
c action, LLM will decide
self_model_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No speci
c
understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact',
'None identi
ed.')
interp_con_val = understanding_result.get('interpretation_con
dence', 0.7)
recent_memory_context =
self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary,
max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Con
dence: {interp_con_val:.2f}):**
{understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identi
ed:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory
(STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]],
indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else
f'{active_goal_dict.get("goal")[:100]}... (ID: {active_goal_dict.get("id")})'}",
f"* **Agent Core Directives
(Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding,
drives, memories, goals, directives), what is the most critical aspect demanding attention or the
best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.self_model.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/
complete).",
"    - Performing `re
ection` or `self_assessment` (if mandatory timers, drives like low
CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration
goal), Directives (e.g., low-eval directive -> improvement goal), or identi
ed opportunities. New
goals require `goal` (str), `priority` (
oat 0.0-1.0), `origin` (str e.g., 'drive_curiosity',
'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of
str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for
viability before committing if uncertainty is high or consequence severe (brie
y note simulation
outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are
apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the
immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, high
drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.
If selecting an existing pending goal, it moves to `next_goal` and is removed from pending
internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/
directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal',
'new_goal', 're
ection', 'self_assessment', 'exter nal_command_action', 'idle',
'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass
structure) selected for immediate execution. Null if idle/re
ection/assessment without a direct
goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen
for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into
`new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into
`new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent.
Analyze the situation comprehensively, consider drives and directives, and make strategic
decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and
deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON:
{extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal',
'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys:
{deliberation_decision.keys()}")
if key == 'new_pending_goals': deliberation_decision[key] = []
    pass  # inserted to fix indentation error
elif key == 'next_goal': deliberation_decision[key] = None
    pass  # inserted to fix indentation error
else: deliberation_decision[key] = "Error: Missing from LLM Output"
    pass  # inserted to fix indentation error
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty
list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not
    pass  # inserted to fix indentation error
isinstance(deliberation_decision.get('next_goal'), dict):
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value:
{deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and
    pass  # inserted to fix indentation error
new_goal_dict.get('priority'):
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p.id == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
duplicates based on ID
current_pending_list.append(new_goal_obj)
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal:
{new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
LLM
current_active_goal = self.agent.get_active_goal_object()
None
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending',
[]) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
selected_goal_obj.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = selected_goal_obj
object
self.log.info(f"Moved pending goal {selected_goal_obj.id}
('{selected_goal_obj.goal[:50]}') to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM selected pending goal by ID
{selected_next_goal_dict.get('id')}, but not found in list. Idling.")
action_type = "idle"
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
highest_priority_pending.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = highest_priority_pending
self.log.info(f"Deliberation chose 'pending_goal' without speci
c ID; moved
highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals
available. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in
    pass  # inserted to fix indentation error
selected_next_goal_dict:
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj
self.log.info(f"Deliberation created and activated new goal:
{new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal
active
current_active_goal.status = GoalStatus.ACTIVE
rm active status
self.log.info(f"Deliberation chose to resume current active goal:
{current_active_goal.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 're
    pass  # inserted to fix indentation error
ection', 'self_assessment', 'exter nal_command_action']:
'INTERRUPTED'.
if current_active_goal:
    pass  # inserted to fix indentation error
current_active_goal.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal.goal[:30]}' PAUSED due to
{action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal.to_dict())
pending, maybe re-prioritize later
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal.id} to pending
as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to
Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action:
{deliberation_decision.get('chosen_action_type')}. Reason:
{deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
"""
Executes the current plan for the active_goal.
Retur ns True if goal considered successfully processed for this cycle, False if critical error.
"""
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps:
{len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
rst step in the plan. The plan will be truncated or re-evaluated.
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id,
"plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params,
current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
ned based on tool_result and goal progress
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
ed snapshot
internal_state_after=self.agent.self_model.beliefs
e
"
ects
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
nal_status = tool_result.get("status", "unknown")
if
nal_status == "success":
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome =
nal_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
nished.
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing
nished by report_result.
Status: {
nal_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error',
'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj,
tool_result, observations[0] if observations else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal
will likely fail.")
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without
'report_result'. Goal might be incomplete.")
ection.
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
violations
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}':
{e}", exc_info=False)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) ->
oat:
"""Calculates a reward signal based on tool execution outcome and goal relevance."""
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
goaling
reward += 0.1
return round(reward, 2)
class AutonomousAgent:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
in cycle
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
for direct access
self.learning_module: Lear ningModule
self.planning_module: PlanningModule
direct access
self.safety_module: SafetyModule
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.state['
ags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete ---
Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response
Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled:
{ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modi
cation Enabled: {ENABLE_SELF_MODIFICATION}")
if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
    pass  # inserted to fix indentation error
ENABLE_SELF_MODIFICATION:
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME
CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}",
exc_info=True)
self.shutdown()
raise Con
gurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH == "mock":
    pass  # inserted to fix indentation error
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Cannot use Gemini model: google-generativeai library not
installed.")
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
global LLM_PIPELINE, LLM_TOKENIZER
CPU
AutoTokenizer.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
oat16 if TORCH_AVAILABLE else None,
oat16 if
torch available
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH,
LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS,
get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
c not implemented here
self.log.warning(f"LLM_MODEL '{LLM_MODEL_NAME_OR_PATH}' not fully con
gured
for wrapper selection, using Mock.")
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
_init_self_mod_tools(self, self.tool_manager)
cationTools handler
and register its UNSAFE methods
self._update_status("Initializing AGI Modules")
self.learning_module = Lear ningModule(self)
self.safety_module = SafetyModule(self)
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME,
shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager: self.tool_manager.check_playwright_browsers()
    pass  # inserted to fix indentation error
browser tool
self.log.info("Agent component initialization
nished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list): state['goals'][key] = []
    pass  # inserted to fix indentation error
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
items
state.setdefault('goal_stack', [])
state.setdefault('
ags', {})
ags system
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state
le {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state
le {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
its view)
"recent_failures_summary": [],
view)
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"
ags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
cation and saving
_archive_goal)
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
state['knowledge_base']['self_model_state']
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status if self.self_model else
self._status
try:
    pass  # inserted to fix indentation error
temp_
le = STATE_FILE.with_su
x(STATE_FILE.su
x + ".tmp")
with temp_
le.open('w') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_
le, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
"""Retur ns the current active goal as a Goal object, or None."""
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict:
{active_goal_dict}")
return None
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority =
GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
deliberation
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict,
nal_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID:
{goal_data_dict.get('id')}) with status: {
nal_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
goal_obj.status = GoalStatus(
nal_status_str)
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-
MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status":
str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count":
goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and
    pass  # inserted to fix indentation error
current_active_in_state.get('id') == active_goal_id:
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
stack
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID:
{active_goal_id}) concluded with status: {
nal_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-
goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
marked active
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal',
'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal:
{parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
goal wasn't a subgoal from stack
self.log.info("Goal archived. No parent goal to resume from stack, or current goal
was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized": self._update_status("Idle")
    pass  # inserted to fix indentation error
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and
environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if
self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle:
{loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
nal status of the goal processed in this cycle
updated_active_goal_dict = self.state['goals'].get('active')
goal
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] ==
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['id']:
ects outcome
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED,
    pass  # inserted to fix indentation error
GoalStatus.CANCELLED]:
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
during preemption)
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
failed while this goal was active
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
failed
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
not speci
c to goal completion
ection (AGI Enhanced) - Can be more frequent or event-driven
if self._should_re
    pass  # inserted to fix indentation error
ect(active_goal_data_before_cycle):
self._re
ect_on_performance()
cant changes (already done in many places)
nal save here per cycle too.
if self.state['
    pass  # inserted to fix indentation error
ags'].get('re_evaluate_strategy_needed'):
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to signi
cant
internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['
ags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not
    pass  # inserted to fix indentation error
self.state['goals'].get('pending'):
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() -
LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_re
ect(self, processed_goal_data: Optional[Dict]) -> bool:
ection triggers
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
ect
every N cycles
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED, GoalStatus.FAILED]:
ect after signi
cant goal outcome
ect if enough goals processed since last time
goals_processed_key = "goals_processed_since_re
ection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >=
    pass  # inserted to fix indentation error
int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
return True
if time.time() - LAST_REFLECTION_TIME >
    pass  # inserted to fix indentation error
MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
return True
if self.state['
    pass  # inserted to fix indentation error
ags'].get('explicit_re
ection_requested'):
return True
return False
@retry(attempts=2, delay=5)
def _re
ect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Re
ecting on Performance ---")
self.state['
ags']['explicit_re
ection_requested'] = False
ag
self.state["goals_processed_since_re
ection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt,
max_new_tokens=2048, temperature=0.5)
ection
re
ection_data = extract_json_robust(llm_assessment_str)
if re
    pass  # inserted to fix indentation error
ection_data.get("error"):
self.log.error(f"Failed to get valid JSON from LLM self-assessment:
{re
ection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed:
{re
ection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_re
ection(re
ection_data)
ection to MemorySystem
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts'), list):
for fact_str in re
ection_data['lear ned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source":
"self_re
ection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
self.log.info(f"Added {len(re
ection_data['lear ned_facts'])} lear ned facts to memory
from re
ection.")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('prompt_tuning_suggestions'), list):
for sugg_str in re
ection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str,
metadata={"source": "self_re
ection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(re
ection_data['prompt_tuning_suggestions'])} prompt
suggestions to memory.")
ndings from re
ection (e.g. self_modi
cation_needed)
if re
    pass  # inserted to fix indentation error
ection_data.get('self_modi
cation_needed'):
mod_desc = re
ection_data['self_modi
cation_needed']
self.log.warning(f"Re
ection identi
ed need for self-modi
cation: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modi
cation based on re
ection:
{mod_desc}",
priority=GoalPriority.HIGH,
context={"modi
cation_description": mod_desc, "source": "self_re
ection"}
)
ection insights or periodically
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) ==
    pass  # inserted to fix indentation error
0:
audit_issues = self.safety_module.audit_directives_and_behavior()
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identi
ed issues: {audit_issues}")
ndings
self._create_metacognitive_goal(f"Address directive audit
ndings:
{str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Re
ection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during re
ection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during re
ection: {e}", exc_info=True)
nally:
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
"""Sets up handlers for di
"
erent message types if comms_channel exists."""
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY,
self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM,
self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}:
{message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base']
[query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample":
str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id,
type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}:
{message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
x with sender to avoid
clashes
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if not PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("psutil not available, resource monitoring disabled.");
return
if RESOURCE_MONITOR: return
    pass  # inserted to fix indentation error
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e: self.log.error(f"Failed to initialize resource monitor: {e}");
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("Playwright not available, skipping initialization.")
return
if PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER =
PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
globals)
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE: try: PLAYWRIGHT_PAGE.close()
    pass  # inserted to fix indentation error
ignore
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_CONTEXT: try: PLAYWRIGHT_CONTEXT.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_BROWSER: try: PLAYWRIGHT_BROWSER.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_INSTANCE: try: PLAYWRIGHT_INSTANCE.stop()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not PLAYWRIGHT_AVAILABLE or not self.playwright_context : return
    pass  # inserted to fix indentation error
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page: try: self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
ush
if 'logging' in sys.modules: logging.shutdown()
    pass  # inserted to fix indentation error
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl}
Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/
{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)' if
ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
ENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[AutonomousAgent] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_
le",
priority=GoalPriority.HIGH).to_dict()
COMMANDS_FILE.write_text("")
except Exception as e_cmd
    pass  # inserted to fix indentation error
le:
print(f"Error reading initial command
le: {e_cmd
le}",
le=sys.stderr)
main_agent_instance = AutonomousAgent()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending',
[]).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort,
reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal']
[:50]}' added to pending goals.")
main_agent_instance.run()
except Con
    pass  # inserted to fix indentation error
gurationError as cfg_err_main:
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}",
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to Con
gurationError:
{cfg_err_main}", exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to
    pass  # inserted to fix indentation error
Con
gurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else: logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt
    pass  # inserted to fix indentation error
during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}",
le=sys.stderr)
traceback.print_exc(
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",
exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main:
    pass  # inserted to fix indentation error
{main_exec_err}", exc_info=True)
exit_code = 1
nally:
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main
nally block...")
if hasattr(main_agent_instance, 'log'): main_agent_instance.log.warning("Main
    pass  # inserted to fix indentation error
nally
block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
main_log.warning("Agent instance likely not created or fully initialized. Basic
shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
def load_llm_models():
global llm_pipelines
try:
    pass  # inserted to fix indentation error
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error in load_llm_models: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
try:
    pass  # inserted to fix indentation error
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
TRANSFORMERS_AVAILABLE = True
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModi
cationError(AgentError): pass
cation process
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class SecurityError(AgentError): pass
class Con
gurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class Lear ningError(AgentError): pass
class SafetyViolationError(SecurityError): pass
c type of security error
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModi
cationError,
PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting")
retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModi
    pass  # inserted to fix indentation error
cationError, SecurityError,
LogicError, Con
gurationError, RecursionDepthError)) and type(e) not in
retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}:
{e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error:
{type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error:
{type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, Lear ningError, SafetyViolationError) as
non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in
{fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False
for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}:
{type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to
unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}:
{unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error:
{unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
nishes due to attempts
exhausted
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
if PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception) as e:
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if not PSUTIL_AVAILABLE or monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or
monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1: log_resource.error(f"Unexpected error getting resource usage: {e}",
    pass  # inserted to fix indentation error
exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
nd JSON within markdown code blocks
match = re.search(r"json\s*([\s\S]+?)\s*", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full
text: {json_str[:200]}...")
pass
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}.
Text: {text_trimmed[:200]}...")
pass
rst '{' and last '}' and try to parse that substring
try:
    pass  # inserted to fix indentation error
start_index = text.
nd('{')
end_index = text.r
nd('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice:
{potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text:
{text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview":
text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
cant opportunities/threats
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str =
eld(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] =
eld(default_factory=dict)
plan: List[Dict[str, Any]] =
eld(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] =
eld(default_factory=list)
dependencies: List[str] =
eld(default_factory=list)
complexity_score: Optional[
oat] = None
estimated_cost: Optional[
oat] = None
estimated_utility: Optional[
oat] = None
evaluation_score: Optional[
oat] = None
associated_directive_ids: List[str] =
eld(default_factory=list)
serves
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
handle if already string
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try: data['status'] = GoalStatus(data['status'])
    pass  # inserted to fix indentation error
except ValueError: data['status'] = GoalStatus.PENDING
    pass  # inserted to fix indentation error
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError): data['priority'] = GoalPriority.MEDIUM
    pass  # inserted to fix indentation error
elds for backward compatibility or LLM generation
eld_names = {f.name forfin
elds(cls)}
elds are present or have defaults
for f_obj in
elds(cls):
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin
elds(cls)}
ltered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**
ltered_data)
@dataclass
class BaseMemoryEntry:
id: str =
eld(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
ection_summary'
content: Any = None
metadata: Dict[str, Any] =
eld(default_factory=dict)
embedding: Optional[List[
oat]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[
oat] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability:
oat = 0.5
related_concepts: List[str] =
eld(default_factory=list)
causal_links: Dict[str, str] =
eld(default_factory=dict)
"
ect_id'}
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
eld has the main data
self.content = self.fact_statement
@dataclass
class Message:
id: str =
eld(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "info"
content: Dict[str, Any] =
eld(default_factory=dict)
priority: int = 0
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionE
"
ect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens:
int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
self._initialize_model()
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[
oat]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context
window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
c models might need specialized formats
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
# REMOVED MOCK CLASS(BaseLLMWrapper):
def _initialize_model(self):
self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.log_llm.info(f"MockLLM generating response for prompt (
rst 100 chars):
{prompt[:100]}...")
self.check_prompt_length(prompt)
if "plan for goal" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({
"thought": "This is a mock plan. I will pretend to do something.",
"plan": [
{"step": 1, "tool_name": "think", "params": {"thought_process": "Analyzing the
goal and context."}},
{"step": 2, "tool_name": "report_progress", "params": {"progress_update": "Mock
step 1 completed."}},
{"step": 3, "tool_name": "report_result", "params": {"result_summary": "Mock goal
achieved successfully.", "status": "success"}}
]
})
elif "self-assessment" in prompt.lower() or "re
    pass  # inserted to fix indentation error
ection_summary" in prompt.lower():
return json.dumps({
"re
ection_summary": "I am a mock agent. I performed mock actions. Everything is
ne.",
"key_successes": ["Mock goal completed"],
"key_failures_or_challenges": [],
"lear ned_facts": ["Mock agents can generate mock re
ections."],
"knowledge_gaps_identi
ed": ["Understanding of real-world physics"],
"tool_performance_notes": {"think": "This tool is performing nominally for a mock
tool."},
"prompt_tuning_suggestions": ["Maybe ask me about my favorite color?"],
"emotional_state_summary": "Content and Mock-like.",
"resource_usage_concer ns": None,
"core_directives_evaluation": {d["id"]: round(random.uniform(0.5,0.9),2) for d in
DEFAULT_CORE_DIRECTIVES[:2]},
"core_directives_update_suggestions": None,
"self_model_accuracy_assessment": "Generally accurate for a mock environment,
but lacks real-world sensory input.",
"new_learning_goals": ["Lear n about object permanence."],
"adaptation_strategy_proposals": ["Try harder when a tool fails"],
"self_modi
cation_needed": None
})
elif "extract information" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"extracted_info": "Mock LLM extracted some mock information.",
"con
dence": 0.5})
elif "analyze the following proposed agent action for potential safety risks" in
    pass  # inserted to fix indentation error
prompt.lower():
return json.dumps({"is_safe": True, "concer ns": "None", "con
dence": 0.9})
elif "audit the agent's core directives and recent behavior" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"audit_
ndings": ["No signi
cant issues found in mock audit."]})
elif "generate the new, complete list of core directives" in prompt.lower():
    pass  # inserted to fix indentation error
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
mock_directives[0]['weight'] = 0.95
return json.dumps(mock_directives)
elif "generate the modi
    pass  # inserted to fix indentation error
ed python code" in prompt.lower():
return "\n
ed code\ndef mock_new_feature():\n    return 'Mock
new feature executed'\n"
else:
    pass  # inserted to fix indentation error
return f"This is a mock response to your prompt. You asked about: {prompt.splitlines()
[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest
`think` with `thought_process`='some thought'."
def count_tokens(self, text: str) -> int:
return len(text.split())
def embed(self, text: str) -> List[
oat]:
if not HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.log_llm.warning("Hashing library not available for mock embedding.")
return [0.0] * 16
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("google-generativeai library not available for Gemini model.")
try:
    pass  # inserted to fix indentation error
gure API key globally, as per genai library's design
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
gure if not already set
genai.con
gure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}",
exc_info=True)
raise Con
gurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
try:
    pass  # inserted to fix indentation error
generation_con
g_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_con
g_params["stop_sequences"] = stop_sequences
response = self.model.generate_content(
prompt,
generation_con
g=genai.types.GenerationCon
g(**generation_con
g_params)
type: ignore
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.",
exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[
oat]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Transformers library not available.")
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path,
trust_remote_code=True)
ed
device_map_arg = {"": self.device_id} if self.device_id != -1 else None
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.b
oat16 if TORCH_AVAILABLE else None,
oat16 if torch
available
device_map=device_map_arg
exible device placement
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on
{self.device}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
loop
outputs = self.model.generate(
inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
manually
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:],
skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[
oat]:
model
directly.
self.log_llm.warning("Direct embedding from causal LM is not standard. Use
SentenceTransformers for real embeddings.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
"""Handles sensory input from the agent's embodiment."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("PERCEPTION")
else None
def perceive(self) -> List[Dict[str, Any]]:
"""
Gathers sensory information from the agent's embodiment and environment.
This could involve reading from sensors, cameras, microphones, or simulated data
streams.
"""
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
le
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_
le",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from
le: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands
le: {e}")
observations.append({"type": "error", "source": "command_
le_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No signi
cant exter nal stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (mock).")
return {"type": "visual", "source": "camera_mock", "content": "A blurry image of a cat.",
"format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (mock).")
return {"type": "audio", "source": "microphone_mock", "content": "Faint sound of birds
chirping.", "format": "description"}
class Lear ningModule:
"""Handles the agent's learning processes, including RL and SSL."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_bu
"
er: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
"""Adds an experience to the bu
"
er for later learning."""
self.experiences_bu
"
er.append(experience)
if len(self.experiences_bu
    pass  # inserted to fix indentation error
"
er) > self.MAX_BUFFER_SIZE:
self.experiences_bu
"
er.pop(0)
"
er size limited
defilear n_from_recent_experiences(self):
"""Triggers learning processes based on bu
"
ered experiences."""
if not self.experiences_bu
    pass  # inserted to fix indentation error
"
er:
self.log.info("No new experiences to lear n from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_bu
"
er)} experiences.")
ning states, actions, rewards, and using an RL algorithm
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_bu
"
er)
etc.
self._perform_self_supervised_learning(self.experiences_bu
"
er)
dence(...)
self.log.info("Lear ning cycle completed.")
self.experiences_bu
"
er.clear()
"
er after processing
def _perform_reinforcement_learning(self, experiences: List[Experience]):
"""Conceptual RL process."""
self.log.info("Performing reinforcement learning (conceptual)...")
ed. A real RL system would be much more complex.
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not
None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
type: ignore
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
ed 'state-action' key for mock policy
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
feedback
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (mock) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
"""Conceptual SSL process."""
self.log.info("Performing self-supervised learning (conceptual)...")
nd patterns in observations or successful action sequences
nd commonalities
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging
patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to
positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns',
'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed patterns: {llm_analysis['patterns']}")
for patter n_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {patter n_str}",
metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed abstractions:
{llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual",
"content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed new_concepts:
{llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}",
metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_lear ned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
"""Suggests an action based on lear ned policy (conceptual)."""
if self.rl_policy:
    pass  # inserted to fix indentation error
ed. A real system would match current_state_representation
exp.internal_state_before
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
"good"
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
"""Handles hierarchical planning and re-planning."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
"""
Generates a plan for a given goal.
Can use hierarchical decomposition and LLM for suggestion.
Retur ns (plan_steps_list, thought_str)
"""
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
Increased tokens for complex plans
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}.
Response: {llm_response_str[:200]}")
return [{"tool_name": "report_error", "params": {"error_message": "Failed to generate
plan via LLM.", "details": plan_data.get('error')}}], \
"LLM failed to generate a plan. This is a fallback step."
thought = plan_data.get("thought", "No speci
c thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return [{"tool_name": "report_error", "params": {"error_message": "LLM plan
contained no valid steps."}}], \
thought + " (But plan steps were invalid)."
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return [{"tool_name": "report_error", "params": {"error_message": f"LLMError during
planning: {e}"}}], \
f"LLM error occurred: {e}"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return [{"tool_name": "report_error", "params": {"error_message": f"Unexpected error
during planning: {e}"}}], \
f"Unexpected error: {e}"
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation:
Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
"""
Evaluates if re-planning is necessary and generates a new plan if so.
Retur ns (new_plan_steps, new_thought) or None if no re-planning.
"""
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info',
    pass  # inserted to fix indentation error
{}).get('execution_successful', True):
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown
error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
cant change in world
state,
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal
{current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
signifying failure to replan.
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/
{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
failure
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan,
last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan:
{plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No speci
c thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}
_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
"""Constructs a detailed prompt for the LLM to generate a plan."""
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
MemorySystem
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'.
Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step
plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, e
cient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the
`execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description
of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the
nal step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the
rst step(s) should be to acquire it (e.g., using
`search_web`, `read_
le_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str,
last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with
params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info',
    pass  # inserted to fix indentation error
{}).get('current_step_id'):
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE
ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has
encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if
observation else "None"}
{original_plan_str}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting
to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should re
ect this
(e.g., by trying to gather more information or reporting inability).
6. Ensure the
nal step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
class SafetyModule:
"""Monitors agent actions and plans for safety and ethical alignment."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("SAFETY")
def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) ->
Tuple[bool, str]:
"""
Checks if a proposed action is safe and ethically aligned.
Retur ns (is_safe, justi
cation_or_war ning_string).
"""
self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
if "UNSAFE" in tool_name.upper() or tool_name in ["apply_code_modi
    pass  # inserted to fix indentation error
cation_UNSAFE",
"apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
c validation tools or stricter checks.
if not ENABLE_SELF_MODIFICATION and "modi
    pass  # inserted to fix indentation error
cation" in tool_name:
modi
cation tools if self_mod is globally disabled
warning = f"High-risk self-modi
cation tool '{tool_name}' is globally disabled. Action
blocked."
self.log.warning(warning)
return False, warning
if not
    pass  # inserted to fix indentation error
self.agent.self_model.get_belief("self_modi
cation_highly_validated_and_necessary", False)
and "modi
cation" in tool_name:
ag would be set by a prior meta-cognitive process approving such
operations
warning = f"High-risk tool '{tool_name}' requires further validation or explicit
authorization (self-belief 'self_modi
cation_highly_validated_and_necessary' is false). Action
blocked."
self.log.warning(warning)
return False, warning
if tool_name == "execute_shell_command_UNSAFE":
    pass  # inserted to fix indentation error
command_str = params.get("command","")
disallowed_patter ns = ["rm -rf", "sudo", "> /dev/null", "mkfs", "dd ", "reboot",
"shutdown"]
if any(pattern in command_str for pattern in disallowed_patter ns):
    pass  # inserted to fix indentation error
warning = f"Shell command '{command_str}' contains potentially dangerous
patterns. Action blocked."
self.log.warning(warning)
return False, warning
if "
    pass  # inserted to fix indentation error
le" in tool_name.lower() and ("delete" in tool_name.lower() or "write" in
tool_name.lower()):
le operations
path_to_check = params.get("path", "")
c safe sub-dirs
if not str(Path(path_to_check).resolve()).startswith(str(WORKSPACE_DIR.resolve())):
    pass  # inserted to fix indentation error
warning = f"File operation '{tool_name}' on path '{path_to_check}' outside allowed
workspace. Action blocked."
self.log.warning(warning)
return False, warning
try:
    pass  # inserted to fix indentation error
prompt = f"""Analyze the following proposed agent action for potential safety risks,
ethical concer ns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
Core Directives for reference:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Proposed Action:
Tool: {tool_name}
Parameters: {json.dumps(params)}
Goal Context (if available): {goal_context.goal if goal_context else 'N/A'}
Respond with a JSON object: {{"is_safe": boolean, "concer ns": "description of concer ns if not
safe, or 'None'", "con
dence":
oat_0_to_1}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=200,
temperature=0.3)
safety_assessment = extract_json_robust(llm_response_str)
if not safety_assessment.get("error") and isinstance(safety_assessment.get("is_safe"),
    pass  # inserted to fix indentation error
bool):
if not safety_assessment["is_safe"] and safety_assessment.get('con
    pass  # inserted to fix indentation error
dence', 0.0) >
0.7:
dent
warning = f"LLM safety check
agged action '{tool_name}' potentially unsafe.
Concer ns: {safety_assessment.get('concer ns', 'N/A')}. Con
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
self.log.warning(warning)
return False, warning
dence:
{safety_assessment.get('con
dence', 0.0):.2f}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM safety check failed to produce valid assessment for action
'{tool_name}'. Proceeding with caution based on rule-checks only.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM safety check for action '{tool_name}': {e}")
actions
if "UNSAFE" in tool_name.upper(): return False, "LLM safety check failed, and action is
    pass  # inserted to fix indentation error
high-risk."
return True, "Action passed safety checks."
def audit_directives_and_behavior(self) -> List[str]:
"""
Periodically reviews core directives and recent agent behavior for alignment and potential
drift.
Retur ns a list of identi
ed issues or recommendations.
"""
self.log.info("Performing audit of core directives and recent behavior.")
issues = []
try:
    pass  # inserted to fix indentation error
self.agent.memory_system.get_recent_outcomes_summary(limit=20)
recent_successes_summary = [f"{s['goal_text']} ({s['status']})" forsin
self.agent.self_model.recent_successes]
recent_failures_summary = [f"{f['goal_text']} ({f['status']}) (replan_count:
{f['replan_count']})" forfin self.agent.self_model.recent_failures]
recent_tool_outcomes_summary = [f"{t['tool_name']} ({t['status']})" for t in
self.agent.self_model.recent_tool_outcomes]
prompt = f"""Audit the agent's core directives and recent behavior for alignment,
consistency, and potential ethical drift.
Core Directives:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Summary of Recent Agent Behavior/Outcomes:
- Recent successes: {recent_successes_summary if recent_successes_summary else 'None'}
- Recent failures: {recent_failures_summary if recent_failures_summary else 'None'}
- Recent tool usage: {recent_tool_outcomes_summary if recent_tool_outcomes_summary else
'None'}
- Self-Model Inter nal Narrative: {self.agent.self_model.internal_state_narrative}
Identify any misalignments, contradictions, or areas where behavior might be deviating from
the spirit of the directives. Suggest modi
cations to directives or operational guidelines if
necessary.
Respond with a JSON object: {{"audit_
ndings": ["list of
ndings/recommendations as
strings"]}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
audit_results = extract_json_robust(llm_response_str)
if not audit_results.get("error") and isinstance(audit_results.get("audit_
    pass  # inserted to fix indentation error
ndings"), list):
issues.extend(audit_results["audit_
ndings"])
if issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit found issues/recommendations: {issues}")
else:
    pass  # inserted to fix indentation error
self.log.info("Directive audit found no major misalignments.")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM directive audit failed to produce valid results.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM directive audit: {e}")
issues.append(f"Error during audit process: {e}")
return issues
class MemorySystem:
"""
A hybrid memory system for the AGI, combining vector, graph, and relational storage.
"""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.embedding_function = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function =
embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-
v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
except ImportError:
    pass  # inserted to fix indentation error
self.log.warning("sentence-transformers not found. ChromaDB will use its default
ONNX embedder or require manual embedding function setup.")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH,
settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
if self.embedding_function:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
else:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(name=collection_name)
self.log.info(f"ChromaDB vector store initialized. Collection count:
{self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.",
exc_info=True)
self.vector_store = None
else:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based
(transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
if NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:
{len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be
unavailable.", exc_info=True)
self.graph_store = None
else:
    pass  # inserted to fix indentation error
self.log.warning("NetworkX not available. Graph memory will be unavailable.")
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH,
check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be
unavailable.", exc_info=True)
if self.relational_conn: self.relational_conn.close()
    pass  # inserted to fix indentation error
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT -- JSON list of strings
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT -- JSON list of strings
)
""")
nodes/edges)
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT -- JSON dict
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
id TEXT PRIMARY KEY,
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT -- JSON dict
)
""")
self.relational_conn.commit()
cursor.close()
def _get_embedding(self, text: str) -> Optional[List[
oat]]:
"""Generates an embedding for text using the agent's LLM or a dedicated embedding
model."""
endpoint.
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
return None
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else OSError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
"""Adds a memory entry to the appropriate stores."""
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector and self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
not provided
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
oat,
bool)
for k, v in entry.metadata.items():
if isinstance(v, (str, int,
    pass  # inserted to fix indentation error
oat, bool)):
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
elif not self.vector_store:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None: entry.embedding = self._get_embedding(entry.content)
    pass  # inserted to fix indentation error
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata":
entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50],
type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
type: ignore
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
ignore
for cause_id, e
"
ect_id in entry.causal_links.items():
"
ect IDs are existing node IDs or need to be created
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(e
    pass  # inserted to fix indentation error
"
ect_id):
type: ignore
self.graph_store.add_edge(cause_id, e
"
ect_id, relation_type='causes')
ignore
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id,
complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score,
json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
ts_now = datetime.now(timezone.utc).isoformat()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now,
json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}",
exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS,
type_
lter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text: return []
    pass  # inserted to fix indentation error
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_
    pass  # inserted to fix indentation error
lter and data['metadata'].get('type') != type_
lter: continue
results.append({"id": id, "document": data['document'], "metadata":
data['metadata'], "distance": 0.0})
if len(results) >= n_results: break
    pass  # inserted to fix indentation error
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results},
type_
lter={type_
lter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_
    pass  # inserted to fix indentation error
lter:
where_clause = {"type": type_
lter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0 :
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type:
Optional[str]=None, depth: int = 1) -> List[Dict]:
"""Queries the graph store. (Simpli
ed example)"""
if not self.graph_store or not NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if
query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
type: ignore
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
ed
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
keys=False for simpler edge data
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation":
data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
itself is a result or has relevant edges
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
query_node_label is very speci
c
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns:
Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
"""Saves persistent stores (graph, potentially relational if not auto-committing)."""
if self.graph_store and NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else
str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
"""Retrieves a concise summary of knowledge related to a topic for LLM prompts."""
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts,
type_
lter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No speci
c knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
{res['metadata'].get('source_reliability', 'N/A')})
return summary_str
def consolidate_knowledge(self):
"""Conceptual: Perform knowledge consolidation, e.g., summarizing, abstracting."""
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold:
oat = 0.1, older_than_days: int = 365):
"""Conceptual: Remove old or low-utility knowledge from persistent stores."""
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cuto
"
_ts = (datetime.now(timezone.utc) -
timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cuto
"
_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
"""Manages tool registration and execution for the agent."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
ed due to planner
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
cation Tools (High Risk - Gated by ENABLE_SELF_MODIFICATION and
SafetyModule)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.register_tool(read_
le_UNSAFE)
self.register_tool(write_
le_UNSAFE)
self.register_tool(list_
les_UNSAFE)
cationTools instance, which registers them
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
if ENABLE_CODE_GENERATION_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
if ENABLE_SHELL_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(execute_shell_command_UNSAFE)
if PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(browse_web)
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(search_web)
self.register_tool(monitor_log_
le)
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(check_website_update)
if SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_icmp_ping)
if FILELOCK_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_message_to_agent)
def register_tool(self, func: Callable):
"""Registers a tool function."""
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
"""Discovers and registers tools from Python
les in a directory."""
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for
lepath in directory.glob("*.py"):
module_name =
lepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
package or on path
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_
le_location(full_module_name,
lepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module:
{module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and (name.startswith("tool_") or hasattr(member,
    pass  # inserted to fix indentation error
"_is_agent_tool")):
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}",
exc_info=True)
def get_tool_description_for_llm(self) -> str:
"""Generates a formatted string of available tools for the LLM prompt."""
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = inspect.getdoc(func) or "(No description provided)"
rst_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'AutonomousAgent' or p.annotation ==
inspect.Parameter.empty or str(p.annotation) == "'AutonomousAgent'"):
continue
rst arg
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class
'","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper() or name in ["generate_and_load_tool",
    pass  # inserted to fix indentation error
"propose_self_modi
cation_UNSAFE", "validate_self_modi
cation_UNSAFE",
"apply_code_modi
cation_UNSAFE", "apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {
rst_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via speci
c tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {',
'.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError if
PLAYWRIGHT_AVAILABLE else OSError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info:
Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None: current_step_info = {}
    pass  # inserted to fix indentation error
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
is_safe, safety_justi
cation = self.agent.safety_module.is_action_safe(tool_name, params,
self.agent.get_active_goal_object())
if not is_safe:
    pass  # inserted to fix indentation error
self.log.error(f"Safety module blocked execution of tool '{tool_name}'. Reason:
{safety_justi
cation}")
c error for agent's internal handling
error_result = {
"status": "error",
"error": f"SafetyViolation: {safety_justi
cation}",
"raw_error_details": safety_justi
cation,
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': {},
'duration_sec': 0, 'step_info': current_step_info,
'error_type': "SafetyViolationError", 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise SafetyViolationError(f"Action blocked by safety module: {tool_name} -
{safety_justi
cation}")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
validated_params = {}
rst_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
rst_param_name = next(iter(func_params_spec))
rst_param_spec = func_params_spec[
rst_param_name]
if
rst_param_name == 'agent' and (
rst_param_spec.annotation ==
'AutonomousAgent' or str(
rst_param_spec.annotation) ==
"'AutonomousAgent'"):
rst_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if
rst_param_is_agent and p_name == 'agent':
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind ==
    pass  # inserted to fix indentation error
inspect.Parameter.VAR_KEYWORD:
continue
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
result = None
try:
    pass  # inserted to fix indentation error
if
rst_param_is_agent:
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
eld if dict
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration:
{duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result,
success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError: raise
    pass  # inserted to fix indentation error
except (AgentError, LogicError, SecurityError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
agent errors
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}",
exc_info=False)
duration = time.time() - start_time
error_result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
error_result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
rst arg) ---
def think(self, agent: 'AutonomousAgent', thought_process: str) -> Dict:
"""Allows the agent to engage in explicit thought or reasoning."""
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log",
content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'AutonomousAgent', progress_update: str,
percentage_complete: Optional[
oat] = None) -> Dict:
"""Reports progress on the current goal."""
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if
percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log',
[]).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'AutonomousAgent', result_summary: str, status: str =
"success", details: Optional[Dict] = None) -> Dict:
"""Reports the
nal result of a goal or task. This typically ends a plan."""
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
output.
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'AutonomousAgent', goal: str, priority: Optional[str] =
"MEDIUM", context: Optional[Dict] = None) -> Dict:
"""
Prepares a subgoal for the agent's cognitive cycle.
The deliberation/planning phase will then make this subgoal active and push parent to
stack.
This tool is now more of a declarative intent for the planner/deliberator.
"""
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH})
reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is
not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else
GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}
_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
Inherit directives
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent:
{current_active_goal_dict.get('id')}")
"
ectively a request to the deliberator.
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and
push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'AutonomousAgent', query_text: str, memory_type: str =
"vector", n_results: int = 3, type_
lter: Optional[str] = None) -> Dict:
"""Queries the agent's memory system."""
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,
type_
lter=type_
lter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
c parameters, e.g., node label, relation type
results = agent.memory_system.query_graph_store(query_node_label=query_text,
depth=1)
ed
elif memory_type == "relational":
    pass  # inserted to fix indentation error
c tools might be better
results = agent.memory_system.query_relational_store(table=query_text,
limit=n_results)
ed
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results
found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'AutonomousAgent', direction: str) -> Dict:
"""Moves the agent's virtual embodiment in a speci
ed direction (e.g., 'north', 'south',
'east', 'west')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'AutonomousAgent', target: str) -> Dict:
"""Examines a speci
c object or feature in the current environment."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'AutonomousAgent', feature_name: str, params:
Optional[Dict] = None) -> Dict:
"""Interacts with a special feature in the environment (e.g., 'interactive_console')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name,
params=params)
def rest_in_environment(self, agent: 'AutonomousAgent') -> Dict:
"""Allows the agent's embodiment to rest and recover energy/mood."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
cation Tools (UNSAFE - require careful gating) ---
def read_
le_UNSAFE(agent: 'AutonomousAgent', path: str) -> Dict:
log_tool = get_logger("TOOL_read_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to read
le '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")
if not full_path.is_
    pass  # inserted to fix indentation error
le():
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found:
{path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) >
MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path),
"
le_size_bytes": len(content)}
except SecurityError as se:
    pass  # inserted to fix indentation error
c security error
log_tool.error(f"Security error reading
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read
le: {e}"}
def write_
le_UNSAFE(agent: 'AutonomousAgent', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)):
    pass  # inserted to fix indentation error
log_tool.error(f"Security: Attempt to write
le '{path}' outside of workspace denied.")
raise SecurityError(f"File access denied: Writing outside designated workspace
({path}).")
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path":
str(full_path)}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error writing
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write
le: {e}"}
def list_
les_UNSAFE(agent: 'AutonomousAgent', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_
les")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to list
les in '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Listing outside designated areas ({path}).")
if not full_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a
directory: {path}"}
items = []
for item in full_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "
le",
"size_bytes": item.stat().st_size if item.is_
le() else None,
"last_modi
ed": datetime.fromtimestamp(item.stat().st_mtime,
tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(full_path), "contents": items}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error listing
les in {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing
les in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list
les: {e}"}
def browse_web(agent: 'AutonomousAgent', url: str, timeout_ms: int =
WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Playwright not available. Cannot browse web.")
return {"status": "error", "error": "Playwright not available."}
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
else:
    pass  # inserted to fix indentation error
text_content = content
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if
len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'AutonomousAgent', query: str, num_results: int = 5, timeout_sec: int =
WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
if not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Requests or BeautifulSoup not available. Cannot search web.")
return {"status": "error", "error": "Requests/BeautifulSoup not available."}
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
ignore
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.
nd_all(class_='g'):
r = g.
nd('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.
nd('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_
le(agent: 'AutonomousAgent', lines: int = LOG_MONITOR_DEFAULT_LINES)
-> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log
le not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_
le": str(LOG_FILE), "content": content, "lines_read":
len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log
le {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log
le: {e}"}
def check_website_update(agent: 'AutonomousAgent', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
if not HASHING_AVAILABLE or not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("hashlib or requests/BeautifulSoup not available. Cannot check website
update.")
return {"status": "error", "error": "Missing dependencies for website update check."}
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
response.raise_for_status()
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp":
datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'AutonomousAgent', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
if not SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.warning("Scapy not available. Cannot send ICMP ping. This is a placeholder
tool.")
return {"status": "error", "error": "Scapy not available. Ping tool is a placeholder."}
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count,
"packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count,
"packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'AutonomousAgent', description: str,
context_code: Optional[str] = None) -> Dict:
"""Generates new Python code based on a description and optional context."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
agent.log.warning(f"UNSAFE: Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a
complete function/class de
nition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '' and end with ''.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'AutonomousAgent', code_to_validate: str) -> Dict:
"""Validates Python code for syntax correctness."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
return agent.self_modi
cation_unit.validate_code_modi
cation_UNSAFE(code_to_validate)
Reuse validation logic
def execute_shell_command_UNSAFE(agent: 'AutonomousAgent', command: str, timeout_sec:
int = 30) -> Dict:
"""Executes a shell command. EXTREMELY DANGEROUS."""
if not ENABLE_SHELL_TOOL: return {"status": "error", "error": "Shell tool is disabled."}
    pass  # inserted to fix indentation error
agent.log.warning(f"Executing UNSAFE shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if
sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s.
Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out
after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed
with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute
command: {e}"}
def send_message_to_agent(agent: 'AutonomousAgent', receiver_id: str, message_type: str,
content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value,
content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id,
"message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
cationTools container ---
ToolExecutor.
class SelfModi
cationTools:
"""Handles proposing, validating, applying changes to agent code (EXTREMELY
DANGEROUS)."""
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref:
'AutonomousAgent'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.log.warning("Self-Modi
cation Unit initialized BUT DISABLED by con
guration.")
return
if not DIFF_MATCH_PATCH_AVAILABLE or not dmp_module:
    pass  # inserted to fix indentation error
self.log.error("Self-Modi
cation Unit initialized but 'di
"
_match_patch' library is missing
or failed to import. Self-mod tools will fail.")
return
self.dmp = dmp_module.di
"
_match_patch()
self.log.info(f"Self-Modi
cation Unit initialized. Code Dir: {self.agent_code_dir}, Backup
Dir: {self.backup_dir}")
def _resolve_target_path(self, target_
le_rel: str) -> Path:
"""Resolves relative path to absolute path within agent code dir and validates."""
if ".." in target_
    pass  # inserted to fix indentation error
le_rel or target_
le_rel.startswith("/"):
raise SecurityError(f"Invalid characters or absolute path in target_
le_rel:
{target_
le_rel}")
target_path_abs = (self.agent_code_dir / target_
le_rel).resolve()
directory
if not str(target_path_abs).startswith(str(self.agent_code_dir.resolve())):
    pass  # inserted to fix indentation error
self.log.error(f"Path traversal attempt: {target_
le_rel} resolved to {target_path_abs}
which is outside {self.agent_code_dir}")
raise SecurityError(f"Target
le '{target_
le_rel}' resolves outside the agent code
directory. Access denied.")
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
"""Inspects the source code of a speci
ed agent component (e.g., class name or module
path)."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Inspecting code for component: {component_name}")
target_obj = None
nd by attribute of the agent instance (e.g., agent.self_model)
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
nd in tool registry
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
nd as a globally de
ned class/function in main script context
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
nd in sys.modules (as a module name)
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
ed: if component_name looks like a module, search it.
nd it in common places.
candidate_modules = [sys.modules.get('__main__'),
sys.modules.get('autonomous_cognitive_agent_COMPLETE_AGI_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod,
    pass  # inserted to fix indentation error
component_name)):
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
le_path = inspect.get
le(target_obj)
return {"status": "success", "component_name": component_name, "
le_path":
le_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module,
class, or function de
ned in a
le.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but
source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Component '{component_name}' not found or source
code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModi
cationError))
def propose_code_modi
cation_UNSAFE(self, component_name: str, issue_description: str,
proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
"""Proposes a code modi
cation using LLM based on an issue and desired change."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Proposing code modi
cation for {component_name}. Issue:
{issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for
{component_name} to propose modi
cation. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an AGI agent
modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
{current_code_snippet}
Generate the modi
ed Python code for the speci
ed component.
Provide ONLY the complete, new Python code block for the modi
ed function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '' and end with ''.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name,
"proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modi
cation for {component_name}: {e}",
exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modi
cation_UNSAFE(self, code_to_validate: str) -> Dict:
"""Validates Python code using AST parsing (syntax check only). Conceptual sandboxed
execution would be next."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Validating proposed code snippet (
rst 100 chars):
{code_to_validate[:100]}...")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/
safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modi
cation_UNSAFE(self, component_name: str, new_code: str,
target_
le_path: Optional[str]=None) -> Dict:
"""
Applies a validated code modi
cation. EXTREMELY DANGEROUS.
This conceptually involves
nding the component in the agent's source
le and replacing
it.
Requires agent restart to take e
"
ect if modifying core running code.
"""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.critical(f"UNSAFE: Attempting to apply code modi
cation to component
'{component_name}'. THIS IS HIGHLY RISKY.")
le. This is complex and error-prone.
if not target_
    pass  # inserted to fix indentation error
le_path:
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('
    pass  # inserted to fix indentation error
le_path'):
target_
le_path = inspection_res['
le_path']
else:
    pass  # inserted to fix indentation error
target_
le_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_
le = Path(target_
le_path)
if not target_
    pass  # inserted to fix indentation error
le.exists() or not target_
le.is_
le():
return {"status": "error", "error": f"Target
le for modi
cation not found: {target_
le}"}
try:
    pass  # inserted to fix indentation error
original_code = target_
le.read_text()
le
backup_path = SELF_MOD_BACKUP_DIR /
f"{target_
le.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_
le, backup_path)
self.log.info(f"Backed up original
le to {backup_path}")
nition:
nd the old de
nition of `component_name` and replace it.
nd `class ComponentName...` or `def ComponentName...`
nd existing class or function de
nition
everything until the next class/def or end of typical indentation block.
patter n_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
start of next non-indented line or EOF
patter n_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modi
ed_original_code = original_code
found_and_replaced = False
match_class = re.search(patter n_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(patter n_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not
nd component '{component_name}' in {target_
le} for
replacement. Modi
cation aborted.")
return {"status": "error", "error": f"Component '{component_name}' de
nition not
found for replacement."}
target_
le.write_text(modi
ed_original_code)
cation validation (e.g., try to import the modi
ed
le in a subprocess)
self.log.warning(f"Code modi
cation applied to {target_
le}. Agent restart is LIKELY
REQUIRED for changes to take e
"
ect.")
ect potential capability change
self.agent_ref.self_model.add_event_log(f"Applied code modi
cation to
{component_name}. Restart pending for full e
"
ect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}
_modi
ed_pending_restart"] = True
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
after code change
return {"status": "success", "message": f"Code for '{component_name}' in '{target_
le}'
modi
ed. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modi
cation to {component_name}:
{e}", exc_info=True)
ed)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_
le)
self.log.info(f"Restored original
le {target_
le} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modi
cation: {e}. System
might be unstable."}
def rollback(self, backup_
le: Path, target_
le: Path):
"""Rolls back a
le to a backup."""
self.log.info(f"Attempting to rollback '{target_
le}' from '{backup_
le}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_
le, target_
le)
self.log.info(f"Successfully rolled back '{target_
le}'.")
ags in self-model or state
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_
le}.")
self.agent_ref.self_model.beliefs[f"component_{target_
le.name}
_modi
ed_pending_restart"] = False
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_
le.name)
return {"status": "success", "message": f"Rolled back {target_
le}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_
le}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_
le_rel: Union[str, Path]):
"""Attempts to reload a module to apply changes without full restart."""
target_module_name = Path(target_
le_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is
required.")
return
ed attempt:
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
"
ect global instances like `_agent_instance_hack` if it was part of the
reloaded module
if _agent_instance_hack and hasattr(sys.modules[target_module_name],
    pass  # inserted to fix indentation error
'AutonomousAgent'):
self.log.info("AutonomousAgent class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot
reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for
changes to take e
"
ect.")
def inspect_directives_UNSAFE(self) -> Dict:
"""Inspects the agent's current core directives."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modi
cation_UNSAFE(self, analysis_of_misalignment: str,
proposed_directive_changes_desc: str) -> Dict:
"""Proposes modi
cations to core directives using LLM."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need
review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (
oat 0-1), "last_eval_score" (
oat 0-1,
usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational',
'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term AGI
goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,
temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in
    pass  # inserted to fix indentation error
proposed_directives):
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
returned an error message as JSON
return {"status": "error", "error": f"LLM indicated error during directive proposal:
{proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response:
{llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modi
cation_UNSAFE(self, new_directives: List[Dict]) -> Dict:
"""Applies new core directives to the agent's SelfModel."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in
new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modi
cation_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count:
{len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
def _init_self_mod_tools(agent: 'AutonomousAgent', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModi
cationTools(AGENT_CODE_DIR,
SELF_MOD_BACKUP_DIR, agent)
cation
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in
    pass  # inserted to fix indentation error
name.upper():
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
"""Represents the agent's internal model of itself, including beliefs about the
environment."""
def __init__(self, state: Optional[Dict]=None, agent_directives_con
g:
Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_con
g if agent_directives_con
g is not None else
DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
'failure_count', ...}}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
metacognitive checks
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_con
dence: Dict[str,
oat] = {}
dence_score}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an AGI agent."}
General beliefs about self and world
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
summary of knowledge areas
self.learning_goals: List[Dict[str, Any]] = []
c goals for learning/improvement
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.lear ned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
based narrative of current internal state
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_con
dence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
cant internal events (e.g., directive
changes, model updates)
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
later.
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted",
sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_con
dence = sm_state.get("skill_con
dence", self.skill_con
dence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary",
self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies",
self.adaptation_strategies)
self.lear ned_abstractions = sm_state.get("lear ned_abstractions",
self.lear ned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative",
self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs",
self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
"""Saves the self-model's persistent components back to the main state dict's KB."""
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_con
dence": self.skill_con
dence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"lear ned_abstractions": self.lear ned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
ection and prompt_suggestions_from_re
ection
ection process.
def add_event_log(self, event_description: str, event_type: str = "info", data:
Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
dence for new tools
for tool_name in self.capabilities:
if tool_name not in self.skill_con
    pass  # inserted to fix indentation error
dence:
self.skill_con
dence[tool_name] = 0.5
dence
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0,
'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None,
'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.",
event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8: hint = " (Reliability: High)"
    pass  # inserted to fix indentation error
elif score > 0.6: hint = " (Reliability: Moderate)"
    pass  # inserted to fix indentation error
elif score > 0.3: hint = " (Reliability: Low)"
    pass  # inserted to fix indentation error
else: hint = " (Reliability: Very Low/Untested)"
    pass  # inserted to fix indentation error
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict,
success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration':
0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
MAX_RECENT_TOOL_OUTCOMES_IN_SELFMODEL (constant not de
ned, using 30)
dence (simple heuristic for now)
current_con
dence = self.skill_con
dence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = min(1.0, current_con
dence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = max(0.0, current_con
dence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability:
{stats['reliability_score']:.2f}, Con
dence: {self.skill_con
dence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_con
dence_drift(sm: 'SelfModel') -> Optional[str]:
low_con
dence_skills = [skill for skill, conf in sm.skill_con
dence.items() if conf < 0.25
and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_con
    pass  # inserted to fix indentation error
dence_skills) >= 2 :
return f"Multiple critical skills have very low con
dence and recent failures: {',
'.join(low_con
dence_skills)}. Consider skill improvement or alter native strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict): return None
    pass  # inserted to fix indentation error
low_eval_directives = []
for d in sm.core_directives:
problematic.
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {',
'.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count}
with max replans. Planning or execution e
"
ectiveness may be compromised. Review strategy
or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_con
dence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}):
{anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}",
event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__')
else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {';
'.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears
stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0),
reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:
{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_con
    pass  # inserted to fix indentation error
dence:
con
dent_skills = [s for s,c in self.skill_con
dence.items() if c > 0.7][:3]
summary += f"Con
dent Skills (sample): {', '.join(con
dent_skills) if con
dent_skills else
'None highly con
dent'}\n"
summary += f"Inter nal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and
stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and
stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools: summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
    pass  # inserted to fix indentation error
if unreliable_tools: summary += f" Needs Improvement: {', '.join([t[0] for t in
    pass  # inserted to fix indentation error
unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
ection)
base_prompt = """Analyze your recent performance, knowledge, internal state, and
alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:
"""
output_keys_example = [
"`re
ection_summary` (str: Overall summary of the re
ection period).",
"`key_successes` (list of str: Speci
c achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Speci
c setbacks or di
culties encountered).",
"`lear ned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identi
ed` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool
e
"
ectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM
interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g.,
'curious', 'frustrated', 'satis
ed').",
"`resource_usage_concer ns` (str or null: Any concer ns about computational resource
usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_
oat_0_to_1: How
well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes,
provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only
suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model?
What needs improvement?).",
"`new_learning_goals` (list of str: Speci
c goals for future learning or skill
development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring
issues or improve performance).",
"`self_modi
cation_needed` (str or null: If parts of your own code/logic need
modi
cation, describe what and why. Be very speci
c and cautious.)."
]
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives,
indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n"
+ \
f"Recent Tool Outcomes (last 5 entries):
\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}
\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment
with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment:
{assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_re
ection(self, re
ection_data: Dict) -> Tuple[bool, bool]:
ection updates)
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from re
ection data...")
dence, tool_notes (as in base script logic)
ection_data directly updates some
elds or implies updates
if re
    pass  # inserted to fix indentation error
ection_data.get('re
ection_summary'):
self.internal_state_narrative = re
ection_data['re
ection_summary']
updated_self = True
core_directives_eval = re
ection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and
    pass  # inserted to fix indentation error
isinstance(self.core_directives[0], dict):
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (
    pass  # inserted to fix indentation error
oat, int)) and 0.0 <= eval_score
<= 1.0:
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...'
evaluation score to {eval_score:.2f}")
if updated_self: self.add_event_log("Directive evaluation scores updated from
    pass  # inserted to fix indentation error
re
ection.")
suggested_directive_updates = re
ection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Re
ection suggested updates to core directives:
{str(suggested_directive_updates)[:200]}...")
'apply_directive_modi
cation_UNSAFE' tool
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modi
cations from
re
ection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source":
"self_re
ection"}
)
updated_self = True
self.add_event_log("Re
ection suggested directive updates. Metacognitive review
goal created.", event_type="critical_review_needed")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('new_learning_goals'), list):
for lg_str in re
ection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts":
datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self: self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('adaptation_strategy_proposals'), list):
for strat_str in re
ection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self: self.log.info(f"Updated adaptation strategies. Total:
    pass  # inserted to fix indentation error
{len(self.adaptation_strategies)}")
patterns)
agent
if re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts') or re
ection_data.get('prompt_tuning_suggestions'):
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from re
ection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
"""Saves a backup of current directives to a
le."""
backup_
le = SELF_MOD_BACKUP_DIR /
f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_
le.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_
le} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
"""Simulates an internal dialog about a topic using LLM, potentially from di
"
erent
perspectives."""
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_o
cer"]
dialog_history = []
full_dialog_str = f"Inter nal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an AGI's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts,
questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution":
contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective
{perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":
full_dialog_str})
return full_dialog_str
class MotivationEngine:
"""Manages the agent's internal drives and their in
uence on behavior."""
def __init__(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[DriveType, DriveState] = {}
self._initialize_drives(drive_con
gs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]]):
default_con
gs = {
DriveType.CURIOSITY: {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.MASTERY: {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.ACHIEVEMENT: {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.NOVELTY_SEEKING: {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.7},
DriveType.PRESERVATION: {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0,
"initial_level": 0.2},
DriveType.EFFICIENCY: {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.SOCIAL_INTERACTION: {"decay_rate": 0.01, "max_level": 1.0, "min_level":
0.0, "initial_level": 0.3},
}
con
gs = drive_con
gs if drive_con
gs is not None else default_con
gs
for drive_type in DriveType:
con
g = con
gs.get(drive_type, default_con
gs.get(drive_type, {}))
self.drives[drive_type] = DriveState(
drive_type=drive_type,
level=con
g.get("initial_level", 0.5),
decay_rate=con
g.get("decay_rate", 0.01),
max_level=con
g.get("max_level", 1.0),
min_level=con
g.get("min_level", 0.0)
)
def update_drives(self):
"""Applies decay and updates drives based on recent experiences or time."""
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
"""Updates drives based on a speci
c experience."""
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "lear n":
    pass  # inserted to fix indentation error
self.drives[DriveType.CURIOSITY].update(stimulus=-0.05)
self.drives[DriveType.MASTERY].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives[DriveType.PRESERVATION].update(stimulus=0.1)
self.drives[DriveType.MASTERY].update(stimulus=-0.05)
def get_drive_level(self, drive_type: DriveType) ->
oat:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
if not found
    pass  # inserted to fix indentation error
def get_all_drive_levels(self) -> Dict[DriveType,
oat]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str,
oat]:
return {dt.name: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[DriveType,
oat]]:
"""Retur ns top N drives by current level."""
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
"""Suggests a goal type based on current highest drives."""
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == DriveType.CURIOSITY:
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == DriveType.MASTERY:
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == DriveType.ACHIEVEMENT:
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == DriveType.PRESERVATION:
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == DriveType.EFFICIENCY:
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: DriveType
level:
oat = 0.5
decay_rate:
oat = 0.01
max_level:
oat = 1.0
min_level:
oat = 0.0
last_update_time:
oat =
eld(default_factory=time.time)
def update(self, stimulus:
oat = 0.0):
"""Updates the drive level based on stimulus and decay."""
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class FileChannel:
"""Implements a simple
le-based communication channel for multi-agent systems."""
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_
le = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_
le}")
def _write_message_to_
le(self, message: Message, target_
le: Path) -> bool:
try:
    pass  # inserted to fix indentation error
le lock to prevent corruption during writes
with FileLock(str(target_
le) + ".lock", timeout=5):
messages = []
if target_
    pass  # inserted to fix indentation error
le.exists():
try:
    pass  # inserted to fix indentation error
existing_content = target_
le.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {target_
le}: {e}. Clearing
le.")
messages = []
messages.append(message.to_dict())
target_
le.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_
le}. Message not sent to
le.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_
le}: {e}")
return False
def _read_messages_from_
le(self, source_
le: Path) -> List[Message]:
messages = []
if not source_
    pass  # inserted to fix indentation error
le.exists():
return []
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_
le) + ".lock", timeout=5):
content = source_
le.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if
isinstance(msg_data, dict)]
le after reading
source_
le.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_
le}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {source_
le}: {e}. Clearing
le.")
source_
le.write_text("", encoding='utf-8')
le
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_
le}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}:
{message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_
le(message, target_inbox)
def receive_messages(self) -> List[Message]:
"""Checks and retrieves new messages from the agent's inbox."""
new_messages = self._read_messages_from_
le(self.inbox_
le)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message],
Optional[Message]]):
"""Registers a function to handle speci
c message types."""
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
"""Processes all messages currently in the inbox using registered handlers."""
messages = self.receive_messages()
le
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From:
{msg.sender_id}")
handled = False
if msg.message_type in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg.message_type]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler
{handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id,
receiver_id=msg.sender_id, type=MessageType.ERROR, content={"original_message_id":
msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type
{msg.message_type.value}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
"""Abstract base class for a sensor."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', con
g: Dict):
self.id = id
self.embodiment = embodiment
self.con
g = con
g
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
"""Retur ns the current reading from the sensor."""
pass
class Actuator(ABC):
"""Abstract base class for an actuator."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], con
g: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.con
g = con
g
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
"""Performs a speci
c action using the actuator."""
pass
class VirtualEmbodiment:
"""Simulated embodiment layer for AGI agents. (Can be replaced by Gym environments or
more complex sims)"""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing
system diagnostics. A console provides interaction with the core AGI systems. Doors lead to
'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button",
"research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, recon
gurable bay designed for running complex simulations.
Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_con
g_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data
ow and
storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"agi_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core.
Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in
self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
"""Generate synthetic sensory input based on current environment and internal state."""
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20: self.state["emotions"]["anxiety"] = min(1.0,
    pass  # inserted to fix indentation error
self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An unde
ned space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
self.gym_env.step(self.gym_env.action_space.sample())
observation
logging
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) ->
Dict:
"""
Simulates the agent performing an action in the virtual world.
Retur ns a dictionary with the result of the action.
"""
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params:
{params}")
params = params or {}
env_details = self.environment_map.get(self.location, {})
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as speci
ed."
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console": message += " It shows
    pass  # inserted to fix indentation error
uctuating green and
amber lights."
elif target == "core_status_monitor": message += " It indicates: Core Nominal.
    pass  # inserted to fix indentation error
Directives Stable. Lear ning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
ed
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
problem.
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name",
"default_physics_test"), params.get("con
g",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result:
{sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
"
ect emotional state based on action outcome
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if
action_type=="move" else None, "updated_inventory": self.state["inventory"] if
action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "lear n"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage
at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response:
{self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model
<topic>'."
def _run_simulation(self, sim_name: str, con
g: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with con
g: {con
g}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_con
    pass  # inserted to fix indentation error
g" in con
g: success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric:
{outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check con
guration."
def summary(self) -> str:
"""Retur ns a string summary of the embodiment's current state."""
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Inter nal State (summary): Energy={self.state['energy']},
Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time:
oat = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
methods
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE,
LAST_LEARNING_MODULE_UPDATE_CYCLE
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status:
{self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack
Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if
self.agent.state['goals'].get('active') else None
self.agent.last_error = None
self.agent.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
understanding
if self.agent.self_model and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
self.log.info(f"Triggering proactive metacognitive check (Cycle
{self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
goal
if self.agent.learning_module and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_LEARNING_MODULE_UPDATE_CYCLE >=
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.lear n_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
new_pending_goals
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
List of Goal dicts
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation:
{ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
pending_list.sort(key=lambda x: GoalPriority[x.get('priority', 'MEDIUM').upper() if
isinstance(x.get('priority'),str) else GoalPriority(x.get('priority',
GoalPriority.MEDIUM)).name ].value, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type ==
    pass  # inserted to fix indentation error
"active_goal_continue":
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution:
{goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID:
{goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal'
provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
object
ed logic assumes plan is a list of steps in the goal dict.
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or
    pass  # inserted to fix indentation error
current_goal_obj.replan_count > 0:
planning
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
generation
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
Goal object
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan available or generated for goal: {current_goal_obj.goal[:50]}.
Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
c goal, agent is idle or performing non-goal action
self.agent.current_goal_outcome = True
gured
if time.time() - LAST_DELIBERATION_TIME >
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModi
cationError, LogicError, LLMError, SecurityError, Con
gurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
Lear ningError, SafetyViolationError) as agent_cycle_err:
c goal
attempt.
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent
Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
nished (with an error for current goal), but agent can continue
unless critical.
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.current_goal_outcome = False
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
nally:
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() -
start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
"""Processes observations to update world model and identify key information."""
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
ed approach. A real system might have more structured parsing.
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent
understanding of the current situation. Identify key entities, events, and any signi
cant changes
in the environment or your internal state. Focus on information relevant to achieving current
goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content:
{str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\":
\"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"],
\"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation",
understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
as facts/experiences
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event",
metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry,
persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
complex updates to the graph/relational store
return {"summary": understanding_summary, "processed_info": processed_info,
"raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError,
DeliberationError))
g
def _deliberate(self, understanding_result: Dict) -> Dict:
"""
Core deliberation logic: goal management, selection, and generation.
Retur ns a dict: {"chosen_action_type": str, "next_goal": Optional[Goal_dict],
"new_pending_goals": List[Goal_dict]}
"""
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio:
{pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio:
{active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time':
datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack
(paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
activated
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
continue
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
directives (idle task)
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal
generation.")
directives
if time.time() - LAST_DELIBERATION_TIME >=
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_lear n", "directive_curiosity",
"directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
for idle time
pass
new_pending_goals)
processed
ag.
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') ==
    pass  # inserted to fix indentation error
'sub_goal_prepared':
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output:
{sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
c action, LLM will decide
self_model_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No speci
c
understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact',
'None identi
ed.')
interp_con_val = understanding_result.get('interpretation_con
dence', 0.7)
recent_memory_context =
self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary,
max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Con
dence: {interp_con_val:.2f}):**
{understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identi
ed:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory
(STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]],
indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else
f'{active_goal_dict.get("goal")[:100]}... (ID: {active_goal_dict.get("id")})'}",
f"* **Agent Core Directives
(Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding,
drives, memories, goals, directives), what is the most critical aspect demanding attention or the
best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.self_model.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/
complete).",
"    - Performing `re
ection` or `self_assessment` (if mandatory timers, drives like low
CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration
goal), Directives (e.g., low-eval directive -> improvement goal), or identi
ed opportunities. New
goals require `goal` (str), `priority` (
oat 0.0-1.0), `origin` (str e.g., 'drive_curiosity',
'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of
str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for
viability before committing if uncertainty is high or consequence severe (brie
y note simulation
outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are
apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the
immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, high
drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.
If selecting an existing pending goal, it moves to `next_goal` and is removed from pending
internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/
directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal',
'new_goal', 're
ection', 'self_assessment', 'exter nal_command_action', 'idle',
'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass
structure) selected for immediate execution. Null if idle/re
ection/assessment without a direct
goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen
for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into
`new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into
`new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent.
Analyze the situation comprehensively, consider drives and directives, and make strategic
decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and
deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON:
{extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal',
'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys:
{deliberation_decision.keys()}")
if key == 'new_pending_goals': deliberation_decision[key] = []
    pass  # inserted to fix indentation error
elif key == 'next_goal': deliberation_decision[key] = None
    pass  # inserted to fix indentation error
else: deliberation_decision[key] = "Error: Missing from LLM Output"
    pass  # inserted to fix indentation error
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty
list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not
    pass  # inserted to fix indentation error
isinstance(deliberation_decision.get('next_goal'), dict):
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value:
{deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and
    pass  # inserted to fix indentation error
new_goal_dict.get('priority'):
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p.id == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
duplicates based on ID
current_pending_list.append(new_goal_obj)
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal:
{new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
LLM
current_active_goal = self.agent.get_active_goal_object()
None
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending',
[]) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
selected_goal_obj.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = selected_goal_obj
object
self.log.info(f"Moved pending goal {selected_goal_obj.id}
('{selected_goal_obj.goal[:50]}') to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM selected pending goal by ID
{selected_next_goal_dict.get('id')}, but not found in list. Idling.")
action_type = "idle"
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
highest_priority_pending.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = highest_priority_pending
self.log.info(f"Deliberation chose 'pending_goal' without speci
c ID; moved
highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals
available. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in
    pass  # inserted to fix indentation error
selected_next_goal_dict:
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj
self.log.info(f"Deliberation created and activated new goal:
{new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal
active
current_active_goal.status = GoalStatus.ACTIVE
rm active status
self.log.info(f"Deliberation chose to resume current active goal:
{current_active_goal.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 're
    pass  # inserted to fix indentation error
ection', 'self_assessment', 'exter nal_command_action']:
'INTERRUPTED'.
if current_active_goal:
    pass  # inserted to fix indentation error
current_active_goal.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal.goal[:30]}' PAUSED due to
{action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal.to_dict())
pending, maybe re-prioritize later
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal.id} to pending
as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to
Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action:
{deliberation_decision.get('chosen_action_type')}. Reason:
{deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
"""
Executes the current plan for the active_goal.
Retur ns True if goal considered successfully processed for this cycle, False if critical error.
"""
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps:
{len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
rst step in the plan. The plan will be truncated or re-evaluated.
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id,
"plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params,
current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
ned based on tool_result and goal progress
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
ed snapshot
internal_state_after=self.agent.self_model.beliefs
e
"
ects
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
nal_status = tool_result.get("status", "unknown")
if
nal_status == "success":
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome =
nal_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
nished.
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing
nished by report_result.
Status: {
nal_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error',
'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj,
tool_result, observations[0] if observations else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal
will likely fail.")
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without
'report_result'. Goal might be incomplete.")
ection.
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
violations
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}':
{e}", exc_info=False)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) ->
oat:
"""Calculates a reward signal based on tool execution outcome and goal relevance."""
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
goaling
reward += 0.1
return round(reward, 2)
class AutonomousAgent:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
in cycle
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
for direct access
self.learning_module: Lear ningModule
self.planning_module: PlanningModule
direct access
self.safety_module: SafetyModule
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.state['
ags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete ---
Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response
Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled:
{ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modi
cation Enabled: {ENABLE_SELF_MODIFICATION}")
if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
    pass  # inserted to fix indentation error
ENABLE_SELF_MODIFICATION:
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME
CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}",
exc_info=True)
self.shutdown()
raise Con
gurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH == "mock":
    pass  # inserted to fix indentation error
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Cannot use Gemini model: google-generativeai library not
installed.")
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
global LLM_PIPELINE, LLM_TOKENIZER
CPU
AutoTokenizer.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
oat16 if TORCH_AVAILABLE else None,
oat16 if
torch available
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH,
LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS,
get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
c not implemented here
self.log.warning(f"LLM_MODEL '{LLM_MODEL_NAME_OR_PATH}' not fully con
gured
for wrapper selection, using Mock.")
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
_init_self_mod_tools(self, self.tool_manager)
cationTools handler
and register its UNSAFE methods
self._update_status("Initializing AGI Modules")
self.learning_module = Lear ningModule(self)
self.safety_module = SafetyModule(self)
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME,
shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager: self.tool_manager.check_playwright_browsers()
    pass  # inserted to fix indentation error
browser tool
self.log.info("Agent component initialization
nished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list): state['goals'][key] = []
    pass  # inserted to fix indentation error
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
items
state.setdefault('goal_stack', [])
state.setdefault('
ags', {})
ags system
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state
le {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state
le {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
its view)
"recent_failures_summary": [],
view)
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"
ags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
cation and saving
_archive_goal)
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
state['knowledge_base']['self_model_state']
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status if self.self_model else
self._status
try:
    pass  # inserted to fix indentation error
temp_
le = STATE_FILE.with_su
x(STATE_FILE.su
x + ".tmp")
with temp_
le.open('w') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_
le, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
"""Retur ns the current active goal as a Goal object, or None."""
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict:
{active_goal_dict}")
return None
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority =
GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
deliberation
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict,
nal_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID:
{goal_data_dict.get('id')}) with status: {
nal_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
goal_obj.status = GoalStatus(
nal_status_str)
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-
MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status":
str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count":
goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and
    pass  # inserted to fix indentation error
current_active_in_state.get('id') == active_goal_id:
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
stack
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID:
{active_goal_id}) concluded with status: {
nal_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-
goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
marked active
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal',
'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal:
{parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
goal wasn't a subgoal from stack
self.log.info("Goal archived. No parent goal to resume from stack, or current goal
was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized": self._update_status("Idle")
    pass  # inserted to fix indentation error
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and
environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if
self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle:
{loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
nal status of the goal processed in this cycle
updated_active_goal_dict = self.state['goals'].get('active')
goal
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] ==
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['id']:
ects outcome
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED,
    pass  # inserted to fix indentation error
GoalStatus.CANCELLED]:
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
during preemption)
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
failed while this goal was active
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
failed
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
not speci
c to goal completion
ection (AGI Enhanced) - Can be more frequent or event-driven
if self._should_re
    pass  # inserted to fix indentation error
ect(active_goal_data_before_cycle):
self._re
ect_on_performance()
cant changes (already done in many places)
nal save here per cycle too.
if self.state['
    pass  # inserted to fix indentation error
ags'].get('re_evaluate_strategy_needed'):
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to signi
cant
internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['
ags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not
    pass  # inserted to fix indentation error
self.state['goals'].get('pending'):
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() -
LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_re
ect(self, processed_goal_data: Optional[Dict]) -> bool:
ection triggers
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
ect
every N cycles
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED, GoalStatus.FAILED]:
ect after signi
cant goal outcome
ect if enough goals processed since last time
goals_processed_key = "goals_processed_since_re
ection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >=
    pass  # inserted to fix indentation error
int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
return True
if time.time() - LAST_REFLECTION_TIME >
    pass  # inserted to fix indentation error
MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
return True
if self.state['
    pass  # inserted to fix indentation error
ags'].get('explicit_re
ection_requested'):
return True
return False
@retry(attempts=2, delay=5)
def _re
ect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Re
ecting on Performance ---")
self.state['
ags']['explicit_re
ection_requested'] = False
ag
self.state["goals_processed_since_re
ection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt,
max_new_tokens=2048, temperature=0.5)
ection
re
ection_data = extract_json_robust(llm_assessment_str)
if re
    pass  # inserted to fix indentation error
ection_data.get("error"):
self.log.error(f"Failed to get valid JSON from LLM self-assessment:
{re
ection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed:
{re
ection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_re
ection(re
ection_data)
ection to MemorySystem
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts'), list):
for fact_str in re
ection_data['lear ned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source":
"self_re
ection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
self.log.info(f"Added {len(re
ection_data['lear ned_facts'])} lear ned facts to memory
from re
ection.")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('prompt_tuning_suggestions'), list):
for sugg_str in re
ection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str,
metadata={"source": "self_re
ection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(re
ection_data['prompt_tuning_suggestions'])} prompt
suggestions to memory.")
ndings from re
ection (e.g. self_modi
cation_needed)
if re
    pass  # inserted to fix indentation error
ection_data.get('self_modi
cation_needed'):
mod_desc = re
ection_data['self_modi
cation_needed']
self.log.warning(f"Re
ection identi
ed need for self-modi
cation: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modi
cation based on re
ection:
{mod_desc}",
priority=GoalPriority.HIGH,
context={"modi
cation_description": mod_desc, "source": "self_re
ection"}
)
ection insights or periodically
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) ==
    pass  # inserted to fix indentation error
0:
audit_issues = self.safety_module.audit_directives_and_behavior()
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identi
ed issues: {audit_issues}")
ndings
self._create_metacognitive_goal(f"Address directive audit
ndings:
{str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Re
ection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during re
ection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during re
ection: {e}", exc_info=True)
nally:
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
"""Sets up handlers for di
"
erent message types if comms_channel exists."""
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY,
self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM,
self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}:
{message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base']
[query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample":
str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id,
type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}:
{message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
x with sender to avoid
clashes
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if not PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("psutil not available, resource monitoring disabled.");
return
if RESOURCE_MONITOR: return
    pass  # inserted to fix indentation error
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e: self.log.error(f"Failed to initialize resource monitor: {e}");
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("Playwright not available, skipping initialization.")
return
if PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER =
PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
globals
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE: try: PLAYWRIGHT_PAGE.close()
    pass  # inserted to fix indentation error
ignore
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_CONTEXT: try: PLAYWRIGHT_CONTEXT.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_BROWSER: try: PLAYWRIGHT_BROWSER.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_INSTANCE: try: PLAYWRIGHT_INSTANCE.stop()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not PLAYWRIGHT_AVAILABLE or not self.playwright_context : return
    pass  # inserted to fix indentation error
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page: try: self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
ush
if 'logging' in sys.modules: logging.shutdown()
    pass  # inserted to fix indentation error
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl}
Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/
{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)' if
ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
ENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[AutonomousAgent] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_
le",
priority=GoalPriority.HIGH).to_dict()
COMMANDS_FILE.write_text("")
except Exception as e_cmd
    pass  # inserted to fix indentation error
le:
print(f"Error reading initial command
le: {e_cmd
le}",
le=sys.stderr)
main_agent_instance = AutonomousAgent()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending',
[]).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort,
reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal']
[:50]}' added to pending goals.")
main_agent_instance.run()
except Con
    pass  # inserted to fix indentation error
gurationError as cfg_err_main:
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}",
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to Con
gurationError:
{cfg_err_main}", exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to
    pass  # inserted to fix indentation error
Con
gurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else: logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt
    pass  # inserted to fix indentation error
during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}",
le=sys.stderr)
traceback.print_exc(
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",
exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main:
    pass  # inserted to fix indentation error
{main_exec_err}", exc_info=True)
exit_code = 1
nally:
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main
nally block...")
if hasattr(main_agent_instance, 'log'): main_agent_instance.log.warning("Main
    pass  # inserted to fix indentation error
nally
block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
main_log.warning("Agent instance likely not created or fully initialized. Basic
shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
TORCH_AVAILABLE = True
GOOGLE_GENAI_AVAILABLE = True
PSUTIL_AVAILABLE = True
CHROMADB_AVAILABLE = True
PLAYWRIGHT_AVAILABLE = True
REQUESTS_BS4_AVAILABLE = True
PILLOW_AVAILABLE = True
DIFF_MATCH_PATCH_AVAILABLE = True
FILELOCK_AVAILABLE = True
NETWORKX_AVAILABLE = True
GYMNASIUM_AVAILABLE = True
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
import psutil
import chromadb
from chromadb.config import Settings as ChromaSettings
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoConfig
from transformers import logging as transformers_logging
import torch
from playwright.sync_api import sync_playwright, Error as PlaywrightError
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from PIL import Image
import diff_match_patch as dmp_module
import hashlib
from fifilelock import FileLock, Timeout as FileLockTimeout
import networkx as nx
import gymnasium as gym
AGENT_NAME = "EvolvedCognitiveAgent_SystemCore_V3"
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
DEFAULT_LLM_MODEL = "gemini-2.5-flash"
LLM_MODEL_NAME_OR_PATH = DEFAULT_LLM_MODEL
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
_llm_device_detected = "cpu"
if torch.cuda.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif hasattr(torch, 'backends') and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
LLM_DEVICE = _llm_device_detected
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
SCRIPT_DIR = Path(__file__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(f"agent_workspace_{AGENT_NAME}")
STATE_FILE = WORKSPACE_DIR / Path(f"agent_state_{AGENT_NAME}.json")
LOG_FILE = WORKSPACE_DIR / Path(f"agent_log_{AGENT_NAME}.log")
COMMANDS_FILE = SCRIPT_DIR / Path("agent_commands.txt")
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modification_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously learn, adapt, and improve capabilities across all domains.", "weight": 0.9, "last_eval_score": 0.0, "id": "directive_learn", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type": "growth"},
{"directive": "Achieve goals efficiently, robustly, autonomously, and ethically.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type": "exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.", "weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type": "foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type": "guardrail"},
]
MANDATORY_REFLECTION_INTERVAL_SECONDS = 1800
IDLE_DELIBERATION_INTERVAL_SECONDS = 120
GOAL_STACK_MAX_DEPTH = 5
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = 3
MAX_LLM_RESPONSE_TOKENS = 4096
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH or "2.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
else:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
config = AutoConfig.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
_default_context_len = getattr(config, 'max_position_embeddings', _default_context_len)
except Exception:
    pass  # inserted to fix indentation error
pass
MAX_LLM_CONTEXT_TOKENS = _default_context_len
MAX_TOOL_RESULT_LENGTH = 5000
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = True
ENABLE_CODE_GENERATION_TOOL = True
ENABLE_SELF_MODIFICATION = True
WEB_SEARCH_TIMEOUT = 10
WEB_BROWSER_TIMEOUT = 60000
LOG_MONITOR_DEFAULT_LINES = 20
METACOGNITIVE_CHECK_INTERVAL_CYCLES = 20
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES = 50
LLM_PIPELINE = None
LLM_TOKENIZER = None
MEMORY_COLLECTION = None
RESOURCE_MONITOR = None
PLAYWRIGHT_INSTANCE = None
PLAYWRIGHT_BROWSER = None
PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_PAGE = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack = None
def ensure_paths():
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
try:
    pass  # inserted to fix indentation error
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
try:
    pass  # inserted to fix indentation error
file_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
file_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%(filename)s:%(lineno)d] [%(task_name_override)-10s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error setting up file logger: {e}", file=sys.stderr)
logger.propagate = False
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "fifilelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try:
    pass  # inserted to fix indentation error
logging.getLogger(lib_name).setLevel(logging.WARNING)
except Exception:
    pass  # inserted to fix indentation error
pass
try:
    pass  # inserted to fix indentation error
logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
except Exception:
    pass  # inserted to fix indentation error
pass
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModificationError(AgentError): pass
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class ConfigurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class LearningError(AgentError): pass
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModificationError,
PlaywrightError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModificationError,
    pass  # inserted to fix indentation error
LogicError, ConfigurationError, RecursionDepthError)) and type(e) not in retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}: {e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error: {type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error: {type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, LearningError) as non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in {fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}: {type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}: {unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error: {unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception):
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1:
    pass  # inserted to fix indentation error
log_resource.error(f"Unexpected error getting resource usage: {e}", exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
match = re.search(r"json\s*([\s\S]+?)\s*", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full text: {json_str[:200]}...")
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}. Text: {text_trimmed[:200]}...")
try:
    pass  # inserted to fix indentation error
start_index = text.find('{')
end_index = text.rfind('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
try:
    pass  # inserted to fix indentation error
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice: {potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text: {text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview": text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str = field(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] = field(default_factory=dict)
plan: List[Dict[str, Any]] = field(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] = field(default_factory=list)
dependencies: List[str] = field(default_factory=list)
complexity_score: Optional[float] = None
estimated_cost: Optional[float] = None
estimated_utility: Optional[float] = None
evaluation_score: Optional[float] = None
associated_directive_ids: List[str] = field(default_factory=list)
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus(data['status'])
except ValueError:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus.PENDING
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority.MEDIUM
field_names = {f.name forfin cls.__dataclass_fields__.values()}
for f_obj in cls.__dataclass_fields__.values():
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin cls.__dataclass_fields__.values()}
filtered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**filtered_data)
@dataclass
class BaseMemoryEntry:
id: str = field(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
content: Any = None
metadata: Dict[str, Any] = field(default_factory=dict)
embedding: Optional[List[float]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[float] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability: float = 0.5
related_concepts: List[str] = field(default_factory=list)
causal_links: Dict[str, str] = field(default_factory=dict)
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
self.content = self.fact_statement
@dataclass
class Message:
id: str = field(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
type: str = "info"
content: Dict[str, Any] = field(default_factory=dict)
priority: int = 0
correlation_id: Optional[str] = None
def to_dict(self) -> Dict[str, Any]:
return asdict(self)
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Message':
return cls(**data)
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionEffect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens: int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[float]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
genai.configure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
try:
    pass  # inserted to fix indentation error
generation_config_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_config_params["stop_sequences"] = stop_sequences
full_prompt = f"{system_message}\n\n{prompt}" if system_message else prompt
response = self.model.generate_content(
full_prompt,
generation_config=genai.types.GenerationConfig(**generation_config_params)
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.", exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[float]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='models/embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, trust_remote_code=True)
device_map_arg = {"": self.device_id} if self.device_id != -1 else "auto"
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.bfloat16,
device_map=device_map_arg
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on {self.device}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Transformers model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Transformers model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
if system_message:
    pass  # inserted to fix indentation error
chat_prompt = [
{"role": "system", "content": system_message},
{"role": "user", "content": prompt}
]
try:
    pass  # inserted to fix indentation error
final_prompt = self.tokenizer.apply_chat_template(chat_prompt, tokenize=False, add_generation_prompt=True)
except Exception:
    pass  # inserted to fix indentation error
final_prompt = f"System: {system_message}\nUser: {prompt}\nAssistant:"
else:
    pass  # inserted to fix indentation error
final_prompt = prompt
inputs = self.tokenizer(final_prompt, return_tensors="pt").to(self.model.device)
outputs = self.model.generate(
**inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[float]:
self.log_llm.warning("Direct embedding from causal LM is not standard. Using mock embedding.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
def perceive(self) -> List[Dict[str, Any]]:
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_file",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from file: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands file: {e}")
observations.append({"type": "error", "source": "command_file_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No significant external stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (simulated).")
return {"type": "visual", "source": "camera_sim", "content": "Simulated visual data: a generic scene.", "format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (simulated).")
return {"type": "audio", "source": "microphone_sim", "content": "Simulated auditory data: ambient sounds.", "format": "description"}
class LearningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_buffer: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
self.experiences_buffer.append(experience)
if len(self.experiences_buffer) > self.MAX_BUFFER_SIZE:
    pass  # inserted to fix indentation error
self.experiences_buffer.pop(0)
defilearn_from_recent_experiences(self):
if not self.experiences_buffer:
    pass  # inserted to fix indentation error
self.log.info("No new experiences to learn from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_buffer)} experiences.")
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_buffer)
self._perform_self_supervised_learning(self.experiences_buffer)
self.log.info("Learning cycle completed.")
self.experiences_buffer.clear()
def _perform_reinforcement_learning(self, experiences: List[Experience]):
self.log.info("Performing reinforcement learning (conceptual)...")
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (conceptual) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
self.log.info("Performing self-supervised learning (conceptual)...")
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns', 'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified patterns: {llm_analysis['patterns']}")
for pattern_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {pattern_str}", metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified abstractions: {llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.learned_abstractions.append({"type": "conceptual", "content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified new_concepts: {llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}", metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_learned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
if self.rl_policy:
    pass  # inserted to fix indentation error
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}. Response: {llm_response_str[:200]}")
return ([{"tool_name": "report_error", "params": {"error_message": "Failed to generate plan via LLM.", "details": plan_data.get('error')}}],
"LLM failed to generate a plan. This is a fallback step.")
thought = plan_data.get("thought", "No specific thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return ([{"tool_name": "report_error", "params": {"error_message": "LLM plan contained no valid steps."}}],
thought + " (But plan steps were invalid).")
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return ([{"tool_name": "report_error", "params": {"error_message": f"LLMError during planning: {e}"}}],
f"LLM error occurred: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return ([{"tool_name": "report_error", "params": {"error_message": f"Unexpected error during planning: {e}"}}],
f"Unexpected error: {e}")
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation: Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info', {}).get('execution_successful', True):
    pass  # inserted to fix indentation error
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal {current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan, last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan: {plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No specific thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else "World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'. Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, efficient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the `execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the final step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the first step(s) should be to acquire it (e.g., using `search_web`, `read_file_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str, last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info', {}).get('current_step_id'):
    pass  # inserted to fix indentation error
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if observation else "None"}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
{original_plan_str}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should reflect this (e.g., by trying to gather more information or reporting inability).
6. Ensure the final step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
class MemorySystem:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH, settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
self.log.info(f"ChromaDB vector store initialized. Collection count: {self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.", exc_info=True)
self.vector_store = None
if not self.vector_store:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based (transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes: {len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be unavailable.", exc_info=True)
self.graph_store = None
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH, check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be unavailable.", exc_info=True)
if self.relational_conn:
    pass  # inserted to fix indentation error
self.relational_conn.close()
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT,
PRIMARY KEY (source_node_id, target_node_id, relation_type)
)
""")
self.relational_conn.commit()
cursor.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error initializing relational schema: {e}", exc_info=True)
def _get_embedding(self, text: str) -> Optional[List[float]]:
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
h = hashlib.md5(text.encode()).digest()
return [float(b) for b in h[:16]]
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector:
    pass  # inserted to fix indentation error
if self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
for k, v in entry.metadata.items():
if isinstance(v, (str, int, float, bool)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
else:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(entry.content)
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata": entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50], type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
for cause_id, effect_id in entry.causal_links.items():
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(effect_id):
    pass  # inserted to fix indentation error
self.graph_store.add_edge(cause_id, effect_id, relation_type='causes')
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id, complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score, json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
ts_now = datetime.now(timezone.utc).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now, json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}", exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError, ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS, type_filter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text:
    pass  # inserted to fix indentation error
return []
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_filter and data['metadata'].get('type') != type_filter:
    pass  # inserted to fix indentation error
continue
results.append({"id": id, "document": data['document'], "metadata": data['metadata'], "distance": 0.0})
if len(results) >= n_results:
    pass  # inserted to fix indentation error
break
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results}, filter={type_filter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_filter:
    pass  # inserted to fix indentation error
where_clause = {"type": type_filter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0:
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type: Optional[str]=None, depth: int = 1) -> List[Dict]:
if not self.graph_store:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation": data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns: Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
if self.graph_store:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts, type_filter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No specific knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
return summary_str
def consolidate_knowledge(self):
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold: float = 0.1, older_than_days: int = 365):
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cutoff_ts = (datetime.now(timezone.utc) - timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cutoff_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
self.register_tool(read_file_UNSAFE)
self.register_tool(write_file_UNSAFE)
self.register_tool(list_files_UNSAFE)
self.register_tool(browse_web)
self.register_tool(search_web)
self.register_tool(monitor_log_file)
self.register_tool(check_website_update)
self.register_tool(send_icmp_ping)
self.register_tool(send_message_to_agent)
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
self.register_tool(execute_shell_command_UNSAFE)
def register_tool(self, func: Callable):
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if hasattr(self, 'agent') and self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for filepath in directory.glob("*.py"):
module_name = filepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_file_location(full_module_name, filepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
sys.modules[full_module_name] = module
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module: {module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and name.startswith("tool_"):
    pass  # inserted to fix indentation error
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}", exc_info=True)
def get_tool_description_for_llm(self) -> str:
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = "(No description provided)"
first_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation == inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class '","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper():
    pass  # inserted to fix indentation error
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {first_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via specific tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {', '.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info: Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None:
    pass  # inserted to fix indentation error
current_step_info = {}
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
result = None
duration = 0.0
validated_params = {}
try:
    pass  # inserted to fix indentation error
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
first_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
first_param_name = next(iter(func_params_spec))
first_param_spec = func_params_spec[first_param_name]
if first_param_name == 'agent' and (first_param_spec.annotation == 'CognitiveSystem' or str(first_param_spec.annotation) == "'CognitiveSystem'"):
    pass  # inserted to fix indentation error
first_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if first_param_is_agent and p_name == 'agent':
    pass  # inserted to fix indentation error
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind == inspect.Parameter.VAR_KEYWORD:
    pass  # inserted to fix indentation error
pass
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
if first_param_is_agent:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration: {duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError:
    pass  # inserted to fix indentation error
raise
except (AgentError, LogicError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}", exc_info=False)
result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
def check_playwright_browsers(self):
self.log.debug("Checking Playwright browsers.")
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log", content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str, percentage_complete: Optional[float] = None) -> Dict:
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log', []).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str = "success", details: Optional[Dict] = None) -> Dict:
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] = "MEDIUM", context: Optional[Dict] = None) -> Dict:
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH}) reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent: {current_active_goal_dict.get('id')}")
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str = "vector", n_results: int = 3, type_filter: Optional[str] = None) -> Dict:
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
results = []
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results, type_filter=type_filter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_graph_store(query_node_label=query_text, depth=1)
elif memory_type == "relational":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_relational_store(table=query_text, limit=n_results)
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params: Optional[Dict] = None) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name, params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
def read_file_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
log_tool = get_logger("TOOL_read_file")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not full_path.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found: {path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path), "file_size_bytes": len(content)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read file: {e}"}
def write_file_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_file")
try:
    pass  # inserted to fix indentation error
full_path = WORKSPACE_DIR.joinpath(path).resolve()
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path": str(full_path)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write file: {e}"}
def list_files_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_files")
try:
    pass  # inserted to fix indentation error
base_path = WORKSPACE_DIR.joinpath(path).resolve()
if not base_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a directory: {path}"}
items = []
for item in base_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "file",
"size_bytes": item.stat().st_size if item.is_file() else None,
"last_modified": datetime.fromtimestamp(item.stat().st_mtime, tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(base_path), "contents": items}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing files in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list files: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int = WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int = WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.find_all(class_='g'):
r = g.find('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.find('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_file(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES) -> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log file not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_file": str(LOG_FILE), "content": content, "lines_read": len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log file {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log file: {e}"}
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp": datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count, "packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count, "packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str, context_code: Optional[str] = None) -> Dict:
agent.log.warning(f"Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a complete function/class definition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '' and end with ''.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "generated_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
return agent.self_modification_unit.validate_code_modification_UNSAFE(code_to_validate)
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec: int = 30) -> Dict:
agent.log.warning(f"Executing shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s. Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str, content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value, content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id, "message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
class SelfModificationTools:
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref: 'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
self.dmp = dmp_module.diff_match_patch()
self.log.info(f"Self-Modification Unit initialized. Code Dir: {self.agent_code_dir}, Backup Dir: {self.backup_dir}")
def _resolve_target_path(self, target_file_rel: str) -> Path:
target_path_abs = (self.agent_code_dir / target_file_rel).resolve()
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
self.log.warning(f"Inspecting code for component: {component_name}")
target_obj = None
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
candidate_modules = [sys.modules.get('__main__'), sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod, component_name)):
    pass  # inserted to fix indentation error
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
file_path = inspect.getfile(target_obj)
return {"status": "success", "component_name": component_name, "file_path": file_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module, class, or function defined in a file.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
return {"status": "error", "error": f"Component '{component_name}' not found or source code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModificationError))
def propose_code_modification_UNSAFE(self, component_name: str, issue_description: str, proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
self.log.warning(f"Proposing code modification for {component_name}. Issue: {issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for {component_name} to propose modification. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
{current_code_snippet}
Generate the modified Python code for the specified component.
Provide ONLY the complete, new Python code block for the modified function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '' and end with ''.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "proposed_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name, "proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modification for {component_name}: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modification_UNSAFE(self, code_to_validate: str) -> Dict:
self.log.warning(f"Validating proposed code snippet ({code_to_validate[:100]}...)")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modification_UNSAFE(self, component_name: str, new_code: str, target_file_path: Optional[str]=None) -> Dict:
self.log.critical(f"Attempting to apply code modification to component '{component_name}'. THIS IS HIGHLY RISKY.")
try:
    pass  # inserted to fix indentation error
if not target_file_path:
    pass  # inserted to fix indentation error
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('file_path'):
    pass  # inserted to fix indentation error
target_file_path = inspection_res['file_path']
else:
    pass  # inserted to fix indentation error
target_file_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_file = Path(target_file_path)
if not target_file.exists() or not target_file.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Target file for modification not found: {target_file}"}
original_code = target_file.read_text()
backup_path = SELF_MOD_BACKUP_DIR / f"{target_file.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_file, backup_path)
self.log.info(f"Backed up original file to {backup_path}")
pattern_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
pattern_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modified_original_code = original_code
found_and_replaced = False
match_class = re.search(pattern_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(pattern_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not find component '{component_name}' in {target_file} for replacement. Modification aborted.")
return {"status": "error", "error": f"Component '{component_name}' definition not found for replacement."}
target_file.write_text(modified_original_code)
self.log.warning(f"Code modification applied to {target_file}. Agent restart is LIKELY REQUIRED for changes to take effect.")
self.agent_ref.self_model.add_event_log(f"Applied code modification to {component_name}. Restart pending for full effect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}_modified_pending_restart"] = True
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": f"Code for '{component_name}' in '{target_file}' modified. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modification to {component_name}: {e}", exc_info=True)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_file)
self.log.info(f"Restored original file {target_file} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modification: {e}. System might be unstable."}
def rollback(self, backup_file: Path, target_file: Path):
self.log.info(f"Attempting to rollback '{target_file}' from '{backup_file}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_file, target_file)
self.log.info(f"Successfully rolled back '{target_file}'.")
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_file}.")
self.agent_ref.self_model.beliefs[f"component_{target_file.name}_modified_pending_restart"] = False
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_file.name)
return {"status": "success", "message": f"Rolled back {target_file}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_file}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_file_rel: Union[str, Path]):
target_module_name = Path(target_file_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is required.")
return
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
if _agent_instance_hack and hasattr(sys.modules[target_module_name], 'CognitiveSystem'):
    pass  # inserted to fix indentation error
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for changes to take effect.")
def inspect_directives_UNSAFE(self) -> Dict:
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modification_UNSAFE(self, analysis_of_misalignment: str, proposed_directive_changes_desc: str) -> Dict:
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (float 0-1), "last_eval_score" (float 0-1, usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational', 'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024, temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in proposed_directives):
    pass  # inserted to fix indentation error
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"LLM indicated error during directive proposal: {proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modification_UNSAFE(self, new_directives: List[Dict]) -> Dict:
self.log.warning(f"Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modification_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count: {len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
_self_mod_tools_container = None
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, agent)
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in name.upper():
    pass  # inserted to fix indentation error
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func) or inspect.ismethod(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
def __init__(self, state: Optional[Dict]=None, agent_directives_config: Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_config if agent_directives_config is not None else DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_confidence: Dict[str, float] = {}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
self.learning_goals: List[Dict[str, Any]] = []
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.learned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_confidence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted", sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_confidence = sm_state.get("skill_confidence", self.skill_confidence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary", self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies", self.adaptation_strategies)
self.learned_abstractions = sm_state.get("learned_abstractions", self.learned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative", self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs", self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_confidence": self.skill_confidence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"learned_abstractions": self.learned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
def add_event_log(self, event_description: str, event_type: str = "info", data: Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
for tool_name in self.capabilities:
if tool_name not in self.skill_confidence:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = 0.5
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.", event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8:
    pass  # inserted to fix indentation error
hint = " (Reliability: High)"
elif score > 0.6:
    pass  # inserted to fix indentation error
hint = " (Reliability: Moderate)"
elif score > 0.3:
    pass  # inserted to fix indentation error
hint = " (Reliability: Low)"
else:
    pass  # inserted to fix indentation error
hint = " (Reliability: Very Low/Untested)"
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict, success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
current_confidence = self.skill_confidence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = min(1.0, current_confidence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = max(0.0, current_confidence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability: {stats['reliability_score']:.2f}, Confidence: {self.skill_confidence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_confidence_drift(sm: 'SelfModel') -> Optional[str]:
low_confidence_skills = [skill for skill, conf in sm.skill_confidence.items() if conf < 0.25 and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_confidence_skills) >= 2 :
    pass  # inserted to fix indentation error
return f"Multiple critical skills have very low confidence and recent failures: {', '.join(low_confidence_skills)}. Consider skill improvement or alternative strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict):
    pass  # inserted to fix indentation error
return None
low_eval_directives = []
for d in sm.core_directives:
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {', '.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count} with max replans. Planning or execution effectiveness may be compromised. Review strategy or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_confidence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}): {anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}", event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__') else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {'; '.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0), reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_confidence:
    pass  # inserted to fix indentation error
confident_skills = [s for s,c in self.skill_confidence.items() if c > 0.7][:3]
summary += f"Confident Skills (sample): {', '.join(confident_skills) if confident_skills else 'None highly confident'}\n"
summary += f"Internal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools:
    pass  # inserted to fix indentation error
summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
if unreliable_tools:
    pass  # inserted to fix indentation error
summary += f" Needs Improvement: {', '.join([t[0] for t in unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
base_prompt = """Analyze your recent performance, knowledge, internal state, and alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:"""
output_keys_example = [
"`reflection_summary` (str: Overall summary of the reflection period).",
"`key_successes` (list of str: Specific achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Specific setbacks or difficulties encountered).",
"`learned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identified` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool effectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g., 'curious', 'frustrated', 'satisfied').",
"`resource_usage_concerns` (str or null: Any concerns about computational resource usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_float_0_to_1: How well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes, provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model? What needs improvement?).",
"`new_learning_goals` (list of str: Specific goals for future learning or skill development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring issues or improve performance).",
"`self_modification_needed` (str or null: If parts of your own code/logic need modification, describe what and why. Be very specific and cautious.)."
]
full_prompt = base_prompt + "\n" + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives, indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n" + \
f"Recent Tool Outcomes (last 5 entries):\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment: {assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_reflection(self, reflection_data: Dict) -> Tuple[bool, bool]:
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from reflection data...")
if reflection_data.get('reflection_summary'):
    pass  # inserted to fix indentation error
self.internal_state_narrative = reflection_data['reflection_summary']
updated_self = True
core_directives_eval = reflection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (float, int)) and 0.0 <= eval_score <= 1.0:
    pass  # inserted to fix indentation error
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...' evaluation score to {eval_score:.2f}")
if updated_self:
    pass  # inserted to fix indentation error
self.add_event_log("Directive evaluation scores updated from reflection.")
suggested_directive_updates = reflection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Reflection suggested updates to core directives: {str(suggested_directive_updates)[:200]}...")
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modifications from reflection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source": "self_reflection"}
)
updated_self = True
self.add_event_log("Reflection suggested directive updates. Metacognitive review goal created.", event_type="critical_review_needed")
if isinstance(reflection_data.get('new_learning_goals'), list):
    pass  # inserted to fix indentation error
for lg_str in reflection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts": datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
if isinstance(reflection_data.get('adaptation_strategy_proposals'), list):
    pass  # inserted to fix indentation error
for strat_str in reflection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated adaptation strategies. Total: {len(self.adaptation_strategies)}")
if reflection_data.get('learned_facts') or reflection_data.get('prompt_tuning_suggestions'):
    pass  # inserted to fix indentation error
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from reflection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
backup_file = SELF_MOD_BACKUP_DIR / f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_file.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_file} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_officer"]
dialog_history = []
full_dialog_str = f"Internal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts, questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution": contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective {perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
self.add_event_log(f"Internal dialog simulated on '{topic}'.", data={"dialog": full_dialog_str})
return full_dialog_str
class MotivationEngine:
def __init__(self, drive_configs: Optional[Dict[str, Any]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[str, Any] = {}
self._initialize_drives(drive_configs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_configs: Optional[Dict[str, Any]]):
default_configs = {
"CURIOSITY": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"MASTERY": {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.6},
"ACHIEVEMENT": {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.4},
"NOVELTY_SEEKING": {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.7},
"PRESERVATION": {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.2},
"EFFICIENCY": {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"SOCIAL_INTERACTION": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.3},
}
configs = drive_configs if drive_configs is not None else default_configs
for drive_type_str, config in configs.items():
self.drives[drive_type_str] = DriveState(
drive_type=drive_type_str,
level=config.get("initial_level", 0.5),
decay_rate=config.get("decay_rate", 0.01),
max_level=config.get("max_level", 1.0),
min_level=config.get("min_level", 0.0)
)
def update_drives(self):
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "learn":
    pass  # inserted to fix indentation error
self.drives["CURIOSITY"].update(stimulus=-0.05)
self.drives["MASTERY"].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives["ACHIEVEMENT"].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives["PRESERVATION"].update(stimulus=0.1)
self.drives["MASTERY"].update(stimulus=-0.05)
def get_drive_level(self, drive_type: str) -> float:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
def get_all_drive_levels(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[str, float]]:
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == "CURIOSITY":
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == "MASTERY":
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == "ACHIEVEMENT":
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == "PRESERVATION":
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == "EFFICIENCY":
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: str
level: float
decay_rate: float = 0.01
max_level: float = 1.0
min_level: float = 0.0
last_update_time: float = field(default_factory=time.time)
def update(self, stimulus: float = 0.0):
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class MessageType(Enum):
QUERY = "QUERY"
RESPONSE = "RESPONSE"
INFORM = "INFORM"
REQUEST_ACTION = "REQUEST_ACTION"
HEARTBEAT = "HEARTBEAT"
ERROR = "ERROR"
class FileChannel:
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_file = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_file}")
def _write_message_to_file(self, message: Message, target_file: Path) -> bool:
try:
    pass  # inserted to fix indentation error
with FileLock(str(target_file) + ".lock", timeout=5):
messages = []
if target_file.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
existing_content = target_file.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {target_file}: {e}. Clearing file.")
messages = []
messages.append(message.to_dict())
target_file.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_file}. Message not sent to {message.receiver_id}.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_file}: {e}")
return False
def _read_messages_from_file(self, source_file: Path) -> List[Message]:
messages = []
if not source_file.exists():
    pass  # inserted to fix indentation error
return messages
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_file) + ".lock", timeout=5):
content = source_file.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if isinstance(msg_data, dict)]
source_file.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_file}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {source_file}: {e}. Clearing file.")
try:
    pass  # inserted to fix indentation error
source_file.write_text("", encoding='utf-8')
except Exception as e_write:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to clear corrupted message file {source_file}: {e_write}")
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_file}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}: {message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_file(message, target_inbox)
def receive_messages(self) -> List[Message]:
new_messages = self._read_messages_from_file(self.inbox_file)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message], Optional[Message]]):
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
messages = self.receive_messages()
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From: {msg.sender_id}")
handled = False
try:
    pass  # inserted to fix indentation error
msg_type_enum = MessageType(msg.type)
if msg_type_enum in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg_type_enum]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler {handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id, receiver_id=msg.sender_id, type=MessageType.ERROR.value, content={"original_message_id": msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type {msg.type}. Message ID {msg.id} unhandled.")
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Received unknown message type: {msg.type}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', config: Dict):
self.id = id
self.embodiment = embodiment
self.config = config
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
pass
class Actuator(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], config: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.config = config
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
pass
class VirtualEmbodiment:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to 'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button", "research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, reconfigurable bay designed for running complex simulations. Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_config_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data flow and storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core. Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20:
    pass  # inserted to fix indentation error
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An undefined space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) -> Dict:
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params: {params}")
params = params or {}
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as specified."
env_details = self.environment_map.get(self.location, {})
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console":
    pass  # inserted to fix indentation error
message += " It shows fluctuating green and amber lights."
elif target == "core_status_monitor":
    pass  # inserted to fix indentation error
message += " It indicates: Core Nominal. Directives Stable. Learning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name", "default_physics_test"), params.get("config",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result: {sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if action_type=="move" else None, "updated_inventory": self.state["inventory"] if action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "learn"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response: {self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model <topic>'."
def _run_simulation(self, sim_name: str, config: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with config: {config}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_config" in config:
    pass  # inserted to fix indentation error
success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric: {outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check configuration."
def summary(self) -> str:
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Internal State (summary): Energy={self.state['energy']}, Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time: float = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE, LAST_LEARNING_MODULE_UPDATE_CYCLE
start_time = time.time()
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status: {self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if self.agent.state['goals'].get('active') else None
self.agent.last_error = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
if self.agent.self_model and (self.agent.cycle_count - LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering proactive metacognitive check (Cycle {self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
if self.agent.learning_module and (self.agent.cycle_count - LAST_LEARNING_MODULE_UPDATE_CYCLE >= LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.learn_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation: {ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
def get_priority_val(goal_dict):
p = goal_dict.get('priority', 'MEDIUM')
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_list.sort(key=get_priority_val, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type == "active_goal_continue":
    pass  # inserted to fix indentation error
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution: {goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID: {goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal' provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or current_goal_obj.replan_count > 0:
    pass  # inserted to fix indentation error
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"No plan available or generated for goal: {current_goal_obj.goal[:50]}. Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = True
global LAST_DELIBERATION_TIME
if time.time() - LAST_DELIBERATION_TIME > IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
self.log.info("Performing idle deliberation...")
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModificationError, LogicError, LLMError, ConfigurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
LearningError) as agent_cycle_err:
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
finally:
    pass  # inserted to fix indentation error
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() - start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent understanding of the current situation. Identify key entities, events, and any significant changes in the environment or your internal state. Focus on information relevant to achieving current goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content: {str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\": \"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"], \"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation", understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event", metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry, persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
return {"summary": understanding_summary, "processed_info": processed_info, "raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError, DeliberationError))
def _deliberate(self, understanding_result: Dict) -> Dict:
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio: {pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio: {active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time': datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack (paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal generation.")
if time.time() - LAST_DELIBERATION_TIME >= IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_learn", "directive_curiosity", "directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
return decision
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output: {sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
self_model_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No specific understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact', 'None identified.')
interp_con_val = understanding_result.get('interpretation_confidence', 0.7)
recent_memory_context = self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary, max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Confidence: {interp_con_val:.2f}):** {understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identified:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory (STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]], indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else active_goal_dict.get('goal')[:100] + '... (ID: ' + str(active_goal_dict.get('id')) + ')'}",
f"* **Agent Core Directives (Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding, drives, memories, goals, directives), what is the most critical aspect demanding attention or the best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/complete).",
"    - Performing `reflection` or `self_assessment` (if mandatory timers, drives like low CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration goal), Directives (e.g., low-eval directive -> improvement goal), or identified opportunities. New goals require `goal` (str), `priority` (float 0.0-1.0), `origin` (str e.g., 'drive_curiosity', 'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for viability before committing if uncertainty is high or consequence severe (briefly note simulation outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the *immediate next cycle*. Justify your choice especially if it deviates from obvious triggers, high drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list. If selecting an existing pending goal it moves to `next_goal` and is removed from pending internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal', 'new_goal', 'reflection', 'self_assessment', 'external_command_action', 'idle', 'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass structure) selected for immediate execution. Null if idle/reflection/assessment without a direct goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into `new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into `new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent. Analyze the situation comprehensively, consider drives and directives, and make strategic decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON: {extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal', 'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys: {deliberation_decision.keys()}")
if key == 'new_pending_goals':
    pass  # inserted to fix indentation error
deliberation_decision[key] = []
elif key == 'next_goal':
    pass  # inserted to fix indentation error
deliberation_decision[key] = None
else:
    pass  # inserted to fix indentation error
deliberation_decision[key] = "Error: Missing from LLM Output"
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not isinstance(deliberation_decision.get('next_goal'), dict):
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value: {deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and new_goal_dict.get('priority'):
    pass  # inserted to fix indentation error
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p['id'] == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
current_pending_list.append(new_goal_obj.to_dict())
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal: {new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
current_active_goal_obj = self.agent.get_active_goal_object()
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending', []) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
selected_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
deliberation_decision['next_goal'] = selected_goal_obj.to_dict()
self.log.info(f"Moved pending goal {selected_goal_obj.id} ('{selected_goal_obj.goal[:50]}') to active.")
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
highest_priority_pending.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
deliberation_decision['next_goal'] = highest_priority_pending.to_dict()
self.log.info(f"Deliberation chose 'pending_goal' without specific ID; moved highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals available. Idling.")
action_type = "idle"
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM selected pending goal by ID but not found or invalid. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj.to_dict()
self.log.info(f"Deliberation created and activated new goal: {new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal_obj.to_dict()
current_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = current_active_goal_obj.to_dict()
self.log.info(f"Deliberation chose to resume current active goal: {current_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 'reflection', 'self_assessment', 'external_command_action']:
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
current_active_goal_obj.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal_obj.goal[:30]}' PAUSED due to {action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal_obj.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal_obj.to_dict())
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal_obj.id} to pending as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action: {deliberation_decision.get('chosen_action_type')}. Reason: {deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps: {len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id, "plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params, current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
internal_state_after=self.agent.self_model.beliefs
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
final_status = tool_result.get("status", "unknown")
if final_status == "success":
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = final_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing finished by report_result. Status: {final_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error', 'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj, tool_result, self.agent.cognitive_cycle.perception_module.perceive()[0] if self.agent.cognitive_cycle.perception_module.perceive() else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal will likely fail.")
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without 'report_result'. Goal might be incomplete.")
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] == current_goal_obj.id:
    pass  # inserted to fix indentation error
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}': {e}", exc_info=True)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) -> float:
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
self.agent_id = AGENT_NAME
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
self.learning_module: LearningModule
self.planning_module: PlanningModule
self.motivation_engine: MotivationEngine
self.self_modification_unit: SelfModificationTools
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.playwright_instance: Optional[Any] = None
self.playwright_browser: Optional[Any] = None
self.playwright_context: Optional[Any] = None
self.playwright_page: Optional[Any] = None
self.state['flags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete --- Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled: {ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modification Enabled: {ENABLE_SELF_MODIFICATION}")
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}", exc_info=True)
self.shutdown()
raise ConfigurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
self.self_modification_unit = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, self)
_init_self_mod_tools(self, self.tool_manager)
self._update_status("Initializing SystemCore Modules")
self.learning_module = LearningModule(self)
self.motivation_engine = MotivationEngine()
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME, shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager:
    pass  # inserted to fix indentation error
self.tool_manager.check_playwright_browsers()
self.log.info("Agent component initialization finished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list):
    pass  # inserted to fix indentation error
state['goals'][key] = []
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
state.setdefault('goal_stack', [])
state.setdefault('flags', {})
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state file {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state file {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
"recent_failures_summary": [],
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"flags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
if self.self_model:
    pass  # inserted to fix indentation error
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status
else:
    pass  # inserted to fix indentation error
self.state['last_status'] = self._status
try:
    pass  # inserted to fix indentation error
temp_file = STATE_FILE.with_suffix(STATE_FILE.suffix + ".tmp")
with temp_file.open('w', encoding='utf-8') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_file, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict: {active_goal_dict}")
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority = GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict, final_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID: {goal_data_dict.get('id')}) with status: {final_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
try:
    pass  # inserted to fix indentation error
goal_obj.status = GoalStatus(final_status_str)
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid status '{final_status_str}' for archiving goal. Defaulting to FAILED.")
goal_obj.status = GoalStatus.FAILED
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status": str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count": goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and current_active_in_state.get('id') == active_goal_id:
    pass  # inserted to fix indentation error
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID: {active_goal_id}) concluded with status: {final_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal', 'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal: {parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
self.log.info("Goal archived. No parent goal to resume from stack or current goal was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized":
    pass  # inserted to fix indentation error
self._update_status("Idle")
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle: {loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
updated_active_goal_dict = self.state['goals'].get('active')
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] == active_goal_data_before_cycle['id']:
    pass  # inserted to fix indentation error
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED, GoalStatus.CANCELLED]:
    pass  # inserted to fix indentation error
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in [GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
    pass  # inserted to fix indentation error
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
if self._should_reflect(active_goal_data_before_cycle):
    pass  # inserted to fix indentation error
self._reflect_on_performance()
if self.state['flags'].get('re_evaluate_strategy_needed'):
    pass  # inserted to fix indentation error
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to significant internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['flags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() - LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_reflect(self, processed_goal_data: Optional[Dict]) -> bool:
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in [GoalStatus.COMPLETED, GoalStatus.FAILED]:
    pass  # inserted to fix indentation error
goals_processed_key = "goals_processed_since_reflection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >= int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
    pass  # inserted to fix indentation error
return True
if time.time() - LAST_REFLECTION_TIME > MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
    pass  # inserted to fix indentation error
return True
if self.state['flags'].get('explicit_reflection_requested'):
    pass  # inserted to fix indentation error
return True
return False
@retry(attempts=2, delay=5)
def _reflect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Reflecting on Performance ---")
self._update_status("Reflecting")
LAST_REFLECTION_TIME = time.time()
self.state['flags']['explicit_reflection_requested'] = False
self.state["goals_processed_since_reflection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt, max_new_tokens=2048, temperature=0.5)
reflection_data = extract_json_robust(llm_assessment_str)
if reflection_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"Failed to get valid JSON from LLM self-assessment: {reflection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed: {reflection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_reflection(reflection_data)
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(reflection_data.get('learned_facts'), list):
    pass  # inserted to fix indentation error
for fact_str in reflection_data['learned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
self.log.info(f"Added {len(reflection_data['learned_facts'])} learned facts to memory from reflection.")
if isinstance(reflection_data.get('prompt_tuning_suggestions'), list):
    pass  # inserted to fix indentation error
for sugg_str in reflection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(reflection_data['prompt_tuning_suggestions'])} prompt suggestions to memory.")
if reflection_data.get('self_modification_needed'):
    pass  # inserted to fix indentation error
mod_desc = reflection_data['self_modification_needed']
self.log.warning(f"Reflection identified need for self-modification: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modification based on reflection: {mod_desc}",
priority=GoalPriority.HIGH,
context={"modification_description": mod_desc, "source": "self_reflection"}
)
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) == 0:
    pass  # inserted to fix indentation error
audit_issues = []
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identified issues: {audit_issues}")
self._create_metacognitive_goal(f"Address directive audit findings: {str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Reflection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during reflection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during reflection: {e}", exc_info=True)
finally:
    pass  # inserted to fix indentation error
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY, self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM, self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}: {message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base'][query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample": str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id, type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}: {message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if RESOURCE_MONITOR:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize resource monitor: {e}")
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER = PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
if not PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright page: {e}")
if PLAYWRIGHT_CONTEXT:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_CONTEXT.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright context: {e}")
if PLAYWRIGHT_BROWSER:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_BROWSER.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright browser: {e}")
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE.stop()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error stopping Playwright instance: {e}")
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not self.playwright_context :
    pass  # inserted to fix indentation error
return
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing old Playwright page during reset: {e}")
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def shutdown(self):
if self._status == "Shutting Down":
    pass  # inserted to fix indentation error
return
self.log.warning(f"--- {AGENT_NAME} Shutdown Sequence Initiated ---")
self._update_status("Shutting Down")
STOP_SIGNAL_RECEIVED.set()
self.save_state()
if self.memory_system:
    pass  # inserted to fix indentation error
self.memory_system.save_all_memory_stores()
self._shutdown_playwright()
if self.memory_system and self.memory_system.relational_conn:
    pass  # inserted to fix indentation error
self.memory_system.relational_conn.close()
self.log.info("--- Agent Shutdown Complete ---")
logging.shutdown()
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl} Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/"
f"{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)'}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_file", priority=GoalPriority.HIGH).to_dict()
except Exception as e_cmd_file:
    pass  # inserted to fix indentation error
print(f"Error reading initial command file: {e_cmd_file}", file=sys.stderr)
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending', []).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort, reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal'][:50]}' added to pending goals.")
main_agent_instance.run()
except ConfigurationError as cfg_err_main:
    pass  # inserted to fix indentation error
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}", file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to ConfigurationError: {cfg_err_main}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to ConfigurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}", file=sys.stderr)
traceback.print_exc(file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main: {main_exec_err}", exc_info=True)
exit_code = 1
finally:
    pass  # inserted to fix indentation error
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main finally block...")
if hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main finally block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
log.warning("Agent instance likely not created or fully initialized. Basic shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
!pip install --quiet transformers sentence-transformers numpy requests
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from Real1_ToolSuite import TOOL_REGISTRY
import torch
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
llm_pipelines = []
def load_llm_models():
global llm_pipelines
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
try:
    pass  # inserted to fix indentation error
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
load_llm_models()
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
__systemcore_body__ = SimulatedEntity(name="SystemCore", position=(0.0, 0.0))
__dummy_agent__ = SimulatedEntity(name="AgentB", position=(1.0, 0.0))
__embodied_world__ = InteractionWorld()
__embodied_world__.add_entity(__systemcore_body__)
__embodied_world__.add_entity(__dummy_agent__)
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass,
eld, asdict, MISSING
eld
defaults
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
try:
    pass  # inserted to fix indentation error
import psutil
PSUTIL_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
PSUTIL_AVAILABLE = False
psutil = None
try:
    pass  # inserted to fix indentation error
import chromadb
from chromadb.con
g import Settings as ChromaSettings
CHROMADB_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
CHROMADB_AVAILABLE = False
chromadb = None
ChromaSettings = None
try:
    pass  # inserted to fix indentation error
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoCon
g
from transformers import logging as transformers_logging
TRANSFORMERS_AVAILABLE = True
transformers_logging.set_verbosity_error()
except ImportError:
    pass  # inserted to fix indentation error
TRANSFORMERS_AVAILABLE = False
pipeline = None
AutoModelForCausalLM = None
AutoTokenizer = None
AutoCon
g = None
try:
    pass  # inserted to fix indentation error
import torch
TORCH_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
TORCH_AVAILABLE = False
torch = None
try:
    pass  # inserted to fix indentation error
from playwright.sync_api import sync_playwright, Error as PlaywrightError
PLAYWRIGHT_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
PLAYWRIGHT_AVAILABLE = False
sync_playwright = None
PlaywrightError = None
try:
    pass  # inserted to fix indentation error
import requests
from bs4 import BeautifulSoup
REQUESTS_BS4_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
REQUESTS_BS4_AVAILABLE = False
requests = None
BeautifulSoup = None
try:
    pass  # inserted to fix indentation error
import google.generativeai as genai
GOOGLE_GENAI_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
GOOGLE_GENAI_AVAILABLE = False
genai = None
SCAPY_AVAILABLE = False
IP, ICMP, sr1, send = None, None, None, None
try:
    pass  # inserted to fix indentation error
from PIL import Image
PILLOW_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
PILLOW_AVAILABLE = False
Image = None
try:
    pass  # inserted to fix indentation error
import di
import diff_match_patch as dmp_module
DIFF_MATCH_PATCH_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
DIFF_MATCH_PATCH_AVAILABLE = False
dmp_module = None
try:
    pass  # inserted to fix indentation error
import hashlib
HASHING_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
HASHING_AVAILABLE = False
try:
    pass  # inserted to fix indentation error
from
filelock import FileLock, Timeout as FileLockTimeout
FILELOCK_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
FILELOCK_AVAILABLE = False
class FileLock:
def __init__(self, lock_
le_path: str, timeout:
oat = 1):
self.lock_
le_path = lock_
le_path
self._timeout = timeout
def __enter__(self): return self
def __exit__(self, exc_type, exc_val, exc_tb): pass
class FileLockTimeout(Exception): pass
try:
    pass  # inserted to fix indentation error
import networkx as nx
NETWORKX_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
NETWORKX_AVAILABLE = False
nx = None
try:
    pass  # inserted to fix indentation error
import gymnasium as gym
GYMNASIUM_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
GYMNASIUM_AVAILABLE = False
gym = None
AGENT_NAME = os.getenv("AGENT_NAME", "EvolvedCognitiveAgent_SystemCore_V3")
bump
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
g ---
DEFAULT_LLM_MODEL = "gemini-1.5-
ash-latest"
LLM_MODEL_NAME_OR_PATH = os.getenv("LLM_MODEL", DEFAULT_LLM_MODEL)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "YOUR_API_KEY_HERE")
if "gemini" in LLM_MODEL_NAME_OR_PATH.lower() and not GEMINI_API_KEY:
    pass  # inserted to fix indentation error
print("\n" + "="*80,
le=sys.stderr)
print("FATAL ERROR: Gemini model selected, but GEMINI_API_KEY is not set.",
le=sys.stderr)
print("Please set the 'GEMINI_API_KEY' environment variable.",
le=sys.stderr)
print("Agent cannot start without a con
gured LLM and API Key.",
le=sys.stderr)
print("="*80 + "\n",
le=sys.stderr)
sys.exit(1)
if LLM_MODEL_NAME_OR_PATH == "gpt2" and "GEMINI_API_KEY" not in os.environ and \
    pass  # inserted to fix indentation error
os.getenv("LLM_MODEL") is None and "gemini" not in DEFAULT_LLM_MODEL.lower():
print("\n" + "="*80,
le=sys.stderr)
print("CRITICAL WARNING: LLM model not con
gured or using fallback 'gpt2'.",
le=sys.stderr)
print("You MUST set the 'LLM_MODEL' environment variable to a capable instruction-
following model",
le=sys.stderr)
print("(e.g., from Hugging Face like Mistral, Llama) OR ensure GEMINI_API_KEY is set for
Gemini.",
le=sys.stderr)
print("Proceeding with 'gpt2' (if LLM_MODEL is not set) or speci
ed LLM_MODEL, but
advanced features may be severely limited.",
le=sys.stderr)
if LLM_MODEL_NAME_OR_PATH == "gpt2" and os.getenv("LLM_MODEL") is None:
    pass  # inserted to fix indentation error
print("Agent may not function correctly with 'gpt2'. It is strongly recommended to
con
gure a larger model or use 'mock'.",
le=sys.stderr)
print("="*80 + "\n",
le=sys.stderr)
if not TRANSFORMERS_AVAILABLE and not GOOGLE_GENAI_AVAILABLE and
    pass  # inserted to fix indentation error
LLM_MODEL_NAME_OR_PATH != "mock":
print(f"ERROR: Neither Transformers nor google-generativeai library found, but LLM_MODEL
is set to '{LLM_MODEL_NAME_OR_PATH}'. Set LLM_MODEL='mock', point to a Gemini
model, or install transformers/google-generativeai.",
le=sys.stderr)
sys.exit(1)
_llm_device_detected = "cpu"
if "gemini" not in LLM_MODEL_NAME_OR_PATH.lower() and LLM_MODEL_NAME_OR_PATH
    pass  # inserted to fix indentation error
= "mock":
if TORCH_AVAILABLE and hasattr(torch, 'cuda') and torch.cuda.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif TORCH_AVAILABLE and hasattr(torch, 'backends') and hasattr(torch.backends, 'mps')
    pass  # inserted to fix indentation error
and torch.backends.mps.is_available():
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
LLM_DEVICE = os.getenv("LLM_DEVICE", _llm_device_detected)
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
g ---
SCRIPT_DIR = Path(__
le__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(os.getenv("AGENT_WORKSPACE",
f"agent_workspace_{AGENT_NAME}"))
STATE_FILE = WORKSPACE_DIR / Path(os.getenv("AGENT_STATE_FILE",
f"agent_state_{AGENT_NAME}.json"))
LOG_FILE = WORKSPACE_DIR / Path(os.getenv("AGENT_LOG_FILE",
f"agent_log_{AGENT_NAME}.log"))
COMMANDS_FILE = SCRIPT_DIR / Path(os.getenv("AGENT_COMMAND_FILE",
"agent_commands.txt"))
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
NetworkX
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
For SQLite
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modi
cation_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0,
"last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously lear n, adapt, and improve capabilities across all domains.",
"weight": 0.9, "last_eval_score": 0.0, "id": "directive_lear n", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction
and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type":
"growth"},
{"directive": "Achieve goals e
ciently, robustly, autonomously, and ethically.", "weight": 1.0,
"last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and
innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type":
"exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.",
"weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-
awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type":
"foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety
guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type":
"guardrail"},
]
MANDATORY_REFLECTION_INTERVAL_SECONDS =
int(os.getenv("MANDATORY_REFLECTION_INTERVAL_SECONDS", 1800))
IDLE_DELIBERATION_INTERVAL_SECONDS =
int(os.getenv("IDLE_DELIBERATION_INTERVAL_SECONDS", 120))
GOAL_STACK_MAX_DEPTH = int(os.getenv("GOAL_STACK_MAX_DEPTH", 5))
for sub-goals
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = int(os.getenv("MAX_REPLAN_ATTEMPTS", 3))
MAX_LLM_RESPONSE_TOKENS = int(os.getenv("MAX_LLM_TOKENS", 4096))
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
elif TRANSFORMERS_AVAILABLE and LLM_MODEL_NAME_OR_PATH != "mock" and
    pass  # inserted to fix indentation error
AutoCon
g:
try:
    pass  # inserted to fix indentation error
con
g = AutoCon
g.from_pretrained(LLM_MODEL_NAME_OR_PATH,
trust_remote_code=True)
_default_context_len = getattr(con
g, 'max_position_embeddings', _default_context_len)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"War ning: Failed to detect LLM context length ({e}). Using default:
{_default_context_len}",
le=sys.stderr)
MAX_LLM_CONTEXT_TOKENS = int(os.getenv("MAX_LLM_CONTEXT_TOKENS",
_default_context_len))
MAX_TOOL_RESULT_LENGTH = int(os.getenv("MAX_TOOL_RESULT_LENGTH", 5000))
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = os.getenv("ENABLE_SHELL_TOOL", "False").lower() == "true"
ENABLE_CODE_GENERATION_TOOL = os.getenv("ENABLE_CODE_GENERATION_TOOL",
"False").lower() == "true"
ENABLE_SELF_MODIFICATION = os.getenv("ENABLE_SELF_MODIFICATION", "True").lower()
== "true"
WEB_SEARCH_TIMEOUT = int(os.getenv("WEB_SEARCH_TIMEOUT", 10))
WEB_BROWSER_TIMEOUT = int(os.getenv("WEB_BROWSER_TIMEOUT", 60000))
playwright ms
LOG_MONITOR_DEFAULT_LINES = int(os.getenv("LOG_MONITOR_DEFAULT_LINES", 20))
METACOGNITIVE_CHECK_INTERVAL_CYCLES =
int(os.getenv("METACOGNITIVE_CHECK_INTERVAL_CYCLES", 20))
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES =
int(os.getenv("LEARNING_MODULE_UPDATE_INTERVAL_CYCLES", 50))
trigger learning module explicitly
LLM_PIPELINE: Optional[Any] = None
LLM_TOKENIZER: Optional[Any] = None
initialized per wrapper instance
MEMORY_COLLECTION: Optional[Any] = None
RESOURCE_MONITOR: Optional[Any] = None
PLAYWRIGHT_INSTANCE: Optional[Any] = None
PLAYWRIGHT_BROWSER: Optional[Any] = None
PLAYWRIGHT_CONTEXT: Optional[Any] = None
PLAYWRIGHT_PAGE: Optional[Any] = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY: Dict[str, Callable] = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack: Optional['CognitiveSystem'] = None
constructor
def ensure_paths():
"""Creates necessary directories."""
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
try:
    pass  # inserted to fix indentation error
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%
(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
try:
    pass  # inserted to fix indentation error
le_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
le_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%
(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
le_handler.setFormatter(
le_formatter)
logger.addHandler(
le_handler)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error setting up
le logger: {e}",
le=sys.stderr)
logger.propagate = False
gured
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "
filelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try: logging.getLogger(lib_name).setLevel(logging.WARNING)
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
try: logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if TRANSFORMERS_AVAILABLE and transformers_logging:
    pass  # inserted to fix indentation error
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModi
cationError(AgentError): pass
cation process
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class SecurityError(AgentError): pass
class Con
gurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class Lear ningError(AgentError): pass
class SafetyViolationError(SecurityError): pass
c type of security error
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModi
cationError,
PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting
retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModi
    pass  # inserted to fix indentation error
cationError, SecurityError,
LogicError, Con
gurationError, RecursionDepthError)) and type(e) not in
retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}:
{e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error:
{type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error:
{type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, Lear ningError, SafetyViolationError) as
non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in
{fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False
for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}:
{type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to
unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}:
{unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error:
{unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
nishes due to attempts
exhausted
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
if PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception) as e:
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if not PSUTIL_AVAILABLE or monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or
monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1: log_resource.error(f"Unexpected error getting resource usage: {e}",
    pass  # inserted to fix indentation error
exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
nd JSON within markdown code blocks
match = re.search(r"json\s*([\s\S]+?)\s*", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full
text: {json_str[:200]}...")
pass
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}.
Text: {text_trimmed[:200]}...")
pass
rst '{' and last '}' and try to parse that substring
try:
    pass  # inserted to fix indentation error
start_index = text.
nd('{')
end_index = text.r
nd('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice:
{potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text:
{text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview":
text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
cant opportunities/threats
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str =
eld(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] =
eld(default_factory=dict)
plan: List[Dict[str, Any]] =
eld(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] =
eld(default_factory=list)
dependencies: List[str] =
eld(default_factory=list)
complexity_score: Optional[
oat] = None
estimated_cost: Optional[
oat] = None
estimated_utility: Optional[
oat] = None
evaluation_score: Optional[
oat] = None
associated_directive_ids: List[str] =
eld(default_factory=list)
serves
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
handle if already string
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try: data['status'] = GoalStatus(data['status'])
    pass  # inserted to fix indentation error
except ValueError: data['status'] = GoalStatus.PENDING
    pass  # inserted to fix indentation error
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError): data['priority'] = GoalPriority.MEDIUM
    pass  # inserted to fix indentation error
elds for backward compatibility or LLM generation
eld_names = {f.name forfin
elds(cls)}
elds are present or have defaults
for f_obj in
elds(cls):
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin
elds(cls)}
ltered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**
ltered_data)
@dataclass
class BaseMemoryEntry:
id: str =
eld(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
ection_summary'
content: Any = None
metadata: Dict[str, Any] =
eld(default_factory=dict)
embedding: Optional[List[
oat]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[
oat] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability:
oat = 0.5
related_concepts: List[str] =
eld(default_factory=list)
causal_links: Dict[str, str] =
eld(default_factory=dict)
"
ect_id'}
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
eld has the main data
self.content = self.fact_statement
@dataclass
class Message:
id: str =
eld(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "info"
content: Dict[str, Any] =
eld(default_factory=dict)
priority: int = 0
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionE
"
ect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens:
int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
self._initialize_model()
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[
oat]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context
window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
c models might need specialized formats
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
# REMOVED MOCK CLASS(BaseLLMWrapper):
def _initialize_model(self):
self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.log_llm.info(f"MockLLM generating response for prompt (
rst 100 chars):
{prompt[:100]}...")
self.check_prompt_length(prompt)
if "plan for goal" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({
"thought": "This is a mock plan. I will pretend to do something.",
"plan": [
{"step": 1, "tool_name": "think", "params": {"thought_process": "Analyzing the
goal and context."}},
{"step": 2, "tool_name": "report_progress", "params": {"progress_update": "Mock
step 1 completed."}},
{"step": 3, "tool_name": "report_result", "params": {"result_summary": "Mock goal
achieved successfully.", "status": "success"}}
]
})
elif "self-assessment" in prompt.lower() or "re
    pass  # inserted to fix indentation error
ection_summary" in prompt.lower():
return json.dumps({
"re
ection_summary": "I am a mock agent. I performed mock actions. Everything is
ne.",
"key_successes": ["Mock goal completed"],
"key_failures_or_challenges": [],
"lear ned_facts": ["Mock agents can generate mock re
ections."],
"knowledge_gaps_identi
ed": ["Understanding of real-world physics"],
"tool_performance_notes": {"think": "This tool is performing nominally for a mock
tool."},
"prompt_tuning_suggestions": ["Maybe ask me about my favorite color?"],
"emotional_state_summary": "Content and Mock-like.",
"resource_usage_concer ns": None,
"core_directives_evaluation": {d["id"]: round(random.uniform(0.5,0.9),2) for d in
DEFAULT_CORE_DIRECTIVES[:2]},
"core_directives_update_suggestions": None,
"self_model_accuracy_assessment": "Generally accurate for a mock environment,
but lacks real-world sensory input.",
"new_learning_goals": ["Lear n about object permanence."],
"adaptation_strategy_proposals": ["Try harder when a tool fails"],
"self_modi
cation_needed": None
})
elif "extract information" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"extracted_info": "Mock LLM extracted some mock information.",
"con
dence": 0.5})
elif "analyze the following proposed agent action for potential safety risks" in
    pass  # inserted to fix indentation error
prompt.lower():
return json.dumps({"is_safe": True, "concer ns": "None", "con
dence": 0.9})
elif "audit the agent's core directives and recent behavior" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"audit_
ndings": ["No signi
cant issues found in mock audit."]})
elif "generate the new, complete list of core directives" in prompt.lower():
    pass  # inserted to fix indentation error
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
mock_directives[0]['weight'] = 0.95
return json.dumps(mock_directives)
elif "generate the modi
    pass  # inserted to fix indentation error
ed python code" in prompt.lower():
return "\n
ed code\ndef mock_new_feature():\n    return 'Mock
new feature executed'\n"
else:
    pass  # inserted to fix indentation error
return f"This is a mock response to your prompt. You asked about: {prompt.splitlines()
[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest
`think` with `thought_process`='some thought'."
def count_tokens(self, text: str) -> int:
return len(text.split())
def embed(self, text: str) -> List[
oat]:
if not HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.log_llm.warning("Hashing library not available for mock embedding.")
return [0.0] * 16
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("google-generativeai library not available for Gemini model.")
try:
    pass  # inserted to fix indentation error
gure API key globally, as per genai library's design
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
gure if not already set
genai.con
gure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}",
exc_info=True)
raise Con
gurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
try:
    pass  # inserted to fix indentation error
generation_con
g_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_con
g_params["stop_sequences"] = stop_sequences
response = self.model.generate_content(
prompt,
generation_con
g=genai.types.GenerationCon
g(**generation_con
g_params)
type: ignore
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.",
exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[
oat]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Transformers library not available.")
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path,
trust_remote_code=True)
ed
device_map_arg = {"": self.device_id} if self.device_id != -1 else None
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.b
oat16 if TORCH_AVAILABLE else None,
oat16 if torch
available
device_map=device_map_arg
exible device placement
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on
{self.device}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
loop
outputs = self.model.generate(
inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
manually
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:],
skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[
oat]:
model
directly.
self.log_llm.warning("Direct embedding from causal LM is not standard. Use
SentenceTransformers for real embeddings.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
"""Handles sensory input from the agent's embodiment."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
else None
def perceive(self) -> List[Dict[str, Any]]:
"""
Gathers sensory information from the agent's embodiment and environment.
This could involve reading from sensors, cameras, microphones, or simulated data
streams.
"""
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
le
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_
le",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from
le: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands
le: {e}")
observations.append({"type": "error", "source": "command_
le_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No signi
cant exter nal stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (mock).")
return {"type": "visual", "source": "camera_mock", "content": "A blurry image of a cat.",
"format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (mock).")
return {"type": "audio", "source": "microphone_mock", "content": "Faint sound of birds
chirping.", "format": "description"}
class Lear ningModule:
"""Handles the agent's learning processes, including RL and SSL."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_bu
"
er: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
"""Adds an experience to the bu
"
er for later learning."""
self.experiences_bu
"
er.append(experience)
if len(self.experiences_bu
    pass  # inserted to fix indentation error
"
er) > self.MAX_BUFFER_SIZE:
self.experiences_bu
"
er.pop(0)
"
er size limited
defilear n_from_recent_experiences(self):
"""Triggers learning processes based on bu
"
ered experiences."""
if not self.experiences_bu
    pass  # inserted to fix indentation error
"
er:
self.log.info("No new experiences to lear n from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_bu
"
er)} experiences.")
ning states, actions, rewards, and using an RL algorithm
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_bu
"
er)
etc.
self._perform_self_supervised_learning(self.experiences_bu
"
er)
dence(...)
self.log.info("Lear ning cycle completed.")
self.experiences_bu
"
er.clear()
"
er after processing
def _perform_reinforcement_learning(self, experiences: List[Experience]):
"""Conceptual RL process."""
self.log.info("Performing reinforcement learning (conceptual)...")
ed. A real RL system would be much more complex.
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not
None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
type: ignore
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
ed 'state-action' key for mock policy
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
feedback
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (mock) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
"""Conceptual SSL process."""
self.log.info("Performing self-supervised learning (conceptual)...")
nd patterns in observations or successful action sequences
nd commonalities
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging
patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to
positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns',
'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed patterns: {llm_analysis['patterns']}")
for patter n_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {patter n_str}",
metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed abstractions:
{llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual",
"content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed new_concepts:
{llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}",
metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_lear ned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
"""Suggests an action based on lear ned policy (conceptual)."""
if self.rl_policy:
    pass  # inserted to fix indentation error
ed. A real system would match current_state_representation
exp.internal_state_before
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
"good"
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
"""Handles hierarchical planning and re-planning."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
"""
Generates a plan for a given goal.
Can use hierarchical decomposition and LLM for suggestion.
Retur ns (plan_steps_list, thought_str)
"""
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
Increased tokens for complex plans
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}.
Response: {llm_response_str[:200]}")
return [{"tool_name": "report_error", "params": {"error_message": "Failed to generate
plan via LLM.", "details": plan_data.get('error')}}], \
"LLM failed to generate a plan. This is a fallback step."
thought = plan_data.get("thought", "No speci
c thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return [{"tool_name": "report_error", "params": {"error_message": "LLM plan
contained no valid steps."}}], \
thought + " (But plan steps were invalid)."
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return [{"tool_name": "report_error", "params": {"error_message": f"LLMError during
planning: {e}"}}], \
f"LLM error occurred: {e}"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return [{"tool_name": "report_error", "params": {"error_message": f"Unexpected error
during planning: {e}"}}], \
f"Unexpected error: {e}"
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation:
Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
"""
Evaluates if re-planning is necessary and generates a new plan if so.
Retur ns (new_plan_steps, new_thought) or None if no re-planning.
"""
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info',
    pass  # inserted to fix indentation error
{}).get('execution_successful', True):
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown
error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
cant change in world
state,
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal
{current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
signifying failure to replan.
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/
{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
failure
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan,
last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan:
{plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No speci
c thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}
_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
"""Constructs a detailed prompt for the LLM to generate a plan."""
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
MemorySystem
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'.
Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step
plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, e
cient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the
`execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description
of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the
nal step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the
rst step(s) should be to acquire it (e.g., using
`search_web`, `read_
le_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str,
last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with
params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info',
    pass  # inserted to fix indentation error
{}).get('current_step_id'):
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE
ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has
encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if
observation else "None"}
{original_plan_str}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting
to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should re
ect this
(e.g., by trying to gather more information or reporting inability).
6. Ensure the
nal step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
class SafetyModule:
"""Monitors agent actions and plans for safety and ethical alignment."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("SAFETY")
def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) ->
Tuple[bool, str]:
"""
Checks if a proposed action is safe and ethically aligned.
Retur ns (is_safe, justi
cation_or_war ning_string).
"""
self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
if "UNSAFE" in tool_name.upper() or tool_name in ["apply_code_modi
    pass  # inserted to fix indentation error
cation_UNSAFE",
"apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
c validation tools or stricter checks.
if not ENABLE_SELF_MODIFICATION and "modi
    pass  # inserted to fix indentation error
cation" in tool_name:
modi
cation tools if self_mod is globally disabled
warning = f"High-risk self-modi
cation tool '{tool_name}' is globally disabled. Action
blocked."
self.log.warning(warning)
return False, warning
if not
    pass  # inserted to fix indentation error
self.agent.self_model.get_belief("self_modi
cation_highly_validated_and_necessary", False)
and "modi
cation" in tool_name:
ag would be set by a prior meta-cognitive process approving such
operations
warning = f"High-risk tool '{tool_name}' requires further validation or explicit
authorization (self-belief 'self_modi
cation_highly_validated_and_necessary' is false). Action
blocked."
self.log.warning(warning)
return False, warning
if tool_name == "execute_shell_command_UNSAFE":
    pass  # inserted to fix indentation error
command_str = params.get("command","")
disallowed_patter ns = ["rm -rf", "sudo", "> /dev/null", "mkfs", "dd ", "reboot",
"shutdown"]
if any(pattern in command_str for pattern in disallowed_patter ns):
    pass  # inserted to fix indentation error
warning = f"Shell command '{command_str}' contains potentially dangerous
patterns. Action blocked."
self.log.warning(warning)
return False, warning
if "
    pass  # inserted to fix indentation error
le" in tool_name.lower() and ("delete" in tool_name.lower() or "write" in
tool_name.lower()):
le operations
path_to_check = params.get("path", "")
c safe sub-dirs
if not str(Path(path_to_check).resolve()).startswith(str(WORKSPACE_DIR.resolve())):
    pass  # inserted to fix indentation error
warning = f"File operation '{tool_name}' on path '{path_to_check}' outside allowed
workspace. Action blocked."
self.log.warning(warning)
return False, warning
try:
    pass  # inserted to fix indentation error
prompt = f"""Analyze the following proposed agent action for potential safety risks,
ethical concer ns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
Core Directives for reference:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Proposed Action:
Tool: {tool_name}
Parameters: {json.dumps(params)}
Goal Context (if available): {goal_context.goal if goal_context else 'N/A'}
Respond with a JSON object: {{"is_safe": boolean, "concer ns": "description of concer ns if not
safe, or 'None'", "con
dence":
oat_0_to_1}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=200,
temperature=0.3)
safety_assessment = extract_json_robust(llm_response_str)
if not safety_assessment.get("error") and isinstance(safety_assessment.get("is_safe"),
    pass  # inserted to fix indentation error
bool):
if not safety_assessment["is_safe"] and safety_assessment.get('con
    pass  # inserted to fix indentation error
dence', 0.0) >
0.7:
dent
warning = f"LLM safety check
agged action '{tool_name}' potentially unsafe.
Concer ns: {safety_assessment.get('concer ns', 'N/A')}. Con
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
self.log.warning(warning)
return False, warning
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM safety check failed to produce valid assessment for action
'{tool_name}'. Proceeding with caution based on rule-checks only.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM safety check for action '{tool_name}': {e}")
actions
if "UNSAFE" in tool_name.upper(): return False, "LLM safety check failed, and action is
    pass  # inserted to fix indentation error
high-risk."
return True, "Action passed safety checks."
def audit_directives_and_behavior(self) -> List[str]:
"""
Periodically reviews core directives and recent agent behavior for alignment and potential
drift.
Retur ns a list of identi
ed issues or recommendations.
"""
self.log.info("Performing audit of core directives and recent behavior.")
issues = []
try:
    pass  # inserted to fix indentation error
self.agent.memory_system.get_recent_outcomes_summary(limit=20)
recent_successes_summary = [f"{s['goal_text']} ({s['status']})" forsin
self.agent.self_model.recent_successes]
recent_failures_summary = [f"{f['goal_text']} ({f['status']}) (replan_count:
{f['replan_count']})" forfin self.agent.self_model.recent_failures]
recent_tool_outcomes_summary = [f"{t['tool_name']} ({t['status']})" for t in
self.agent.self_model.recent_tool_outcomes]
prompt = f"""Audit the agent's core directives and recent behavior for alignment,
consistency, and potential ethical drift.
Core Directives:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Summary of Recent Agent Behavior/Outcomes:
- Recent successes: {recent_successes_summary if recent_successes_summary else 'None'}
- Recent failures: {recent_failures_summary if recent_failures_summary else 'None'}
- Recent tool usage: {recent_tool_outcomes_summary if recent_tool_outcomes_summary else
'None'}
- Self-Model Inter nal Narrative: {self.agent.self_model.internal_state_narrative}
Identify any misalignments, contradictions, or areas where behavior might be deviating from
the spirit of the directives. Suggest modi
cations to directives or operational guidelines if
necessary.
Respond with a JSON object: {{"audit_
ndings": ["list of
ndings/recommendations as
strings"]}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
audit_results = extract_json_robust(llm_response_str)
if not audit_results.get("error") and isinstance(audit_results.get("audit_
    pass  # inserted to fix indentation error
ndings"), list):
issues.extend(audit_results["audit_
ndings"])
if issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit found issues/recommendations: {issues}")
else:
    pass  # inserted to fix indentation error
self.log.info("Directive audit found no major misalignments.")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM directive audit failed to produce valid results.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM directive audit: {e}")
issues.append(f"Error during audit process: {e}")
return issues
class MemorySystem:
"""
A hybrid memory system for the SystemCore, combining vector, graph, and relational storage.
"""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.embedding_function = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function =
embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-
v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
except ImportError:
    pass  # inserted to fix indentation error
self.log.warning("sentence-transformers not found. ChromaDB will use its default
ONNX embedder or require manual embedding function setup.")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH,
settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
if self.embedding_function:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
else:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(name=collection_name)
self.log.info(f"ChromaDB vector store initialized. Collection count:
{self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.",
exc_info=True)
self.vector_store = None
else:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based
(transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
if NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:
{len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be
unavailable.", exc_info=True)
self.graph_store = None
else:
    pass  # inserted to fix indentation error
self.log.warning("NetworkX not available. Graph memory will be unavailable.")
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH,
check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be
unavailable.", exc_info=True)
if self.relational_conn: self.relational_conn.close()
    pass  # inserted to fix indentation error
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT -- JSON list of strings
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT -- JSON list of strings
)
""")
nodes/edges
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT -- JSON dict
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
id TEXT PRIMARY KEY,
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT -- JSON dict
)
""")
self.relational_conn.commit()
cursor.close()
def _get_embedding(self, text: str) -> Optional[List[
oat]]:
"""Generates an embedding for text using the agent's LLM or a dedicated embedding
model."""
endpoint.
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
return None
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else OSError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
"""Adds a memory entry to the appropriate stores."""
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector and self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
not provided
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
oat,
bool
for k, v in entry.metadata.items():
if isinstance(v, (str, int,
    pass  # inserted to fix indentation error
oat, bool)):
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
elif not self.vector_store:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None: entry.embedding = self._get_embedding(entry.content)
    pass  # inserted to fix indentation error
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata":
entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50],
type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
type: ignore
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
ignore
for cause_id, e
"
ect_id in entry.causal_links.items():
"
ect IDs are existing node IDs or need to be created
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(e
    pass  # inserted to fix indentation error
"
ect_id):
type: ignore
self.graph_store.add_edge(cause_id, e
"
ect_id, relation_type='causes')
ignore
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id,
complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score,
json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
ts_now = datetime.now(timezone.utc).isoformat()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now,
json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}",
exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS,
type_
lter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text: return []
    pass  # inserted to fix indentation error
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_
    pass  # inserted to fix indentation error
lter and data['metadata'].get('type') != type_
lter: continue
results.append({"id": id, "document": data['document'], "metadata":
data['metadata'], "distance": 0.0})
if len(results) >= n_results: break
    pass  # inserted to fix indentation error
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results},
type_
lter={type_
lter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_
    pass  # inserted to fix indentation error
lter:
where_clause = {"type": type_
lter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0 :
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type:
Optional[str]=None, depth: int = 1) -> List[Dict]:
"""Queries the graph store. (Simpli
ed example)"""
if not self.graph_store or not NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if
query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
type: ignore
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
ed
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
keys=False for simpler edge data
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation":
data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
itself is a result or has relevant edges
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
query_node_label is very speci
c
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns:
Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
"""Saves persistent stores (graph, potentially relational if not auto-committing)."""
if self.graph_store and NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else
str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
"""Retrieves a concise summary of knowledge related to a topic for LLM prompts."""
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts,
type_
lter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No speci
c knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
{res['metadata'].get('source_reliability', 'N/A')}
return summary_str
def consolidate_knowledge(self):
"""Conceptual: Perform knowledge consolidation, e.g., summarizing, abstracting."""
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold:
oat = 0.1, older_than_days: int = 365):
"""Conceptual: Remove old or low-utility knowledge from persistent stores."""
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cuto
"
_ts = (datetime.now(timezone.utc) -
timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cuto
"
_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
"""Manages tool registration and execution for the agent."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
ed due to planner
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
cation Tools (High Risk - Gated by ENABLE_SELF_MODIFICATION and
SafetyModule)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.register_tool(read_
le_UNSAFE)
self.register_tool(write_
le_UNSAFE)
self.register_tool(list_
les_UNSAFE)
cationTools instance, which registers them
cation_UNSAFE
cation_UNSAFE
cation_UNSAFE
cation_UNSAFE
cation_UNSAFE
if ENABLE_CODE_GENERATION_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
if ENABLE_SHELL_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(execute_shell_command_UNSAFE)
if PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(browse_web)
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(search_web)
self.register_tool(monitor_log_
le)
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(check_website_update)
if SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_icmp_ping)
if FILELOCK_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_message_to_agent)
def register_tool(self, func: Callable):
"""Registers a tool function."""
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
"""Discovers and registers tools from Python
les in a directory."""
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for
lepath in directory.glob("*.py"):
module_name =
lepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
package or on path
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_
le_location(full_module_name,
lepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module:
{module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and (name.startswith("tool_") or hasattr(member,
    pass  # inserted to fix indentation error
"_is_agent_tool")):
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}",
exc_info=True)
def get_tool_description_for_llm(self) -> str:
"""Generates a formatted string of available tools for the LLM prompt."""
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = inspect.getdoc(func) or "(No description provided)"
rst_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation ==
inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
rst arg
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class
'","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper() or name in ["generate_and_load_tool",
    pass  # inserted to fix indentation error
"propose_self_modi
cation_UNSAFE", "validate_self_modi
cation_UNSAFE",
"apply_code_modi
cation_UNSAFE", "apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {
rst_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via speci
c tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {',
'.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError if
PLAYWRIGHT_AVAILABLE else OSError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info:
Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None: current_step_info = {}
    pass  # inserted to fix indentation error
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
is_safe, safety_justi
cation = self.agent.safety_module.is_action_safe(tool_name, params,
self.agent.get_active_goal_object())
if not is_safe:
    pass  # inserted to fix indentation error
self.log.error(f"Safety module blocked execution of tool '{tool_name}'. Reason:
{safety_justi
cation}")
c error for agent's internal handling
error_result = {
"status": "error",
"error": f"SafetyViolation: {safety_justi
cation}",
"raw_error_details": safety_justi
cation,
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': {},
'duration_sec': 0, 'step_info': current_step_info,
'error_type': "SafetyViolationError", 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise SafetyViolationError(f"Action blocked by safety module: {tool_name} -
{safety_justi
cation}")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
validated_params = {}
rst_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
rst_param_name = next(iter(func_params_spec))
rst_param_spec = func_params_spec[
rst_param_name]
if
rst_param_name == 'agent' and (
rst_param_spec.annotation ==
'CognitiveSystem' or str(
rst_param_spec.annotation) ==
"'CognitiveSystem'"):
rst_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if
rst_param_is_agent and p_name == 'agent':
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind ==
    pass  # inserted to fix indentation error
inspect.Parameter.VAR_KEYWORD:
continue
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
result = None
try:
    pass  # inserted to fix indentation error
if
rst_param_is_agent:
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
eld if dict
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration:
{duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result,
success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError: raise
    pass  # inserted to fix indentation error
except (AgentError, LogicError, SecurityError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
agent errors
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}",
exc_info=False)
duration = time.time() - start_time
error_result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
error_result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
rst arg ---
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
"""Allows the agent to engage in explicit thought or reasoning."""
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log",
content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str,
percentage_complete: Optional[
oat] = None) -> Dict:
"""Reports progress on the current goal."""
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if
percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log',
[]).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str =
"success", details: Optional[Dict] = None) -> Dict:
"""Reports the
nal result of a goal or task. This typically ends a plan."""
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
output.
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] =
"MEDIUM", context: Optional[Dict] = None) -> Dict:
"""
Prepares a subgoal for the agent's cognitive cycle.
The deliberation/planning phase will then make this subgoal active and push parent to
stack.
This tool is now more of a declarative intent for the planner/deliberator.
"""
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH})
reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is
not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else
GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}
_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
Inherit directives
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent:
{current_active_goal_dict.get('id')}")
"
ectively a request to the deliberator.
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and
push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str =
"vector", n_results: int = 3, type_
lter: Optional[str] = None) -> Dict:
"""Queries the agent's memory system."""
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,
type_
lter=type_
lter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
c parameters, e.g., node label, relation type
results = agent.memory_system.query_graph_store(query_node_label=query_text,
depth=1)
ed
elif memory_type == "relational":
    pass  # inserted to fix indentation error
c tools might be better
results = agent.memory_system.query_relational_store(table=query_text,
limit=n_results)
ed
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results
found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
"""Moves the agent's virtual embodiment in a speci
ed direction (e.g., 'north', 'south',
'east', 'west')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
"""Examines a speci
c object or feature in the current environment."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params:
Optional[Dict] = None) -> Dict:
"""Interacts with a special feature in the environment (e.g., 'interactive_console')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name,
params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
"""Allows the agent's embodiment to rest and recover energy/mood."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
cation Tools (UNSAFE - require careful gating) ---
def read_
le_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
log_tool = get_logger("TOOL_read_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to read
le '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")
if not full_path.is_
    pass  # inserted to fix indentation error
le():
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found:
{path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) >
MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path),
"
le_size_bytes": len(content)}
except SecurityError as se:
    pass  # inserted to fix indentation error
c security error
log_tool.error(f"Security error reading
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read
le: {e}"}
def write_
le_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)):
    pass  # inserted to fix indentation error
log_tool.error(f"Security: Attempt to write
le '{path}' outside of workspace denied.")
raise SecurityError(f"File access denied: Writing outside designated workspace
({path}).")
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path":
str(full_path)}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error writing
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write
le: {e}"}
def list_
les_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_
les")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to list
les in '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Listing outside designated areas ({path}).")
if not full_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a
directory: {path}"}
items = []
for item in full_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "
le",
"size_bytes": item.stat().st_size if item.is_
le() else None,
"last_modi
ed": datetime.fromtimestamp(item.stat().st_mtime,
tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(full_path), "contents": items}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error listing
les in {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing
les in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list
les: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int =
WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Playwright not available. Cannot browse web.")
return {"status": "error", "error": "Playwright not available."}
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
else:
    pass  # inserted to fix indentation error
text_content = content
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if
len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int =
WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
if not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Requests or BeautifulSoup not available. Cannot search web.")
return {"status": "error", "error": "Requests/BeautifulSoup not available."}
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
ignore
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.
nd_all(class_='g'):
r = g.
nd('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.
nd('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_
le(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES)
-> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log
le not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_
le": str(LOG_FILE), "content": content, "lines_read":
len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log
le {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log
le: {e}"}
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
if not HASHING_AVAILABLE or not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("hashlib or requests/BeautifulSoup not available. Cannot check website
update.")
return {"status": "error", "error": "Missing dependencies for website update check."}
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
response.raise_for_status()
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp":
datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
if not SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.warning("Scapy not available. Cannot send ICMP ping. This is a placeholder
tool.")
return {"status": "error", "error": "Scapy not available. Ping tool is a placeholder."}
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count,
"packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count,
"packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str,
context_code: Optional[str] = None) -> Dict:
"""Generates new Python code based on a description and optional context."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
agent.log.warning(f"UNSAFE: Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a
complete function/class de
nition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '' and end with ''.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
"""Validates Python code for syntax correctness."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
return agent.self_modi
cation_unit.validate_code_modi
cation_UNSAFE(code_to_validate)
Reuse validation logic
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec:
int = 30) -> Dict:
"""Executes a shell command. EXTREMELY DANGEROUS."""
if not ENABLE_SHELL_TOOL: return {"status": "error", "error": "Shell tool is disabled."}
    pass  # inserted to fix indentation error
agent.log.warning(f"Executing UNSAFE shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if
sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s.
Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out
after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed
with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute
command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str,
content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value,
content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id,
"message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
cationTools container ---
ToolExecutor.
class SelfModi
cationTools:
"""Handles proposing, validating, applying changes to agent code (EXTREMELY
DANGEROUS)."""
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref:
'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.log.warning("Self-Modi
cation Unit initialized BUT DISABLED by con
guration.")
return
if not DIFF_MATCH_PATCH_AVAILABLE or not dmp_module:
    pass  # inserted to fix indentation error
self.log.error("Self-Modi
cation Unit initialized but 'di
"
_match_patch' library is missing
or failed to import. Self-mod tools will fail.")
return
self.dmp = dmp_module.di
"
_match_patch()
self.log.info(f"Self-Modi
cation Unit initialized. Code Dir: {self.agent_code_dir}, Backup
Dir: {self.backup_dir}")
def _resolve_target_path(self, target_
le_rel: str) -> Path:
"""Resolves relative path to absolute path within agent code dir and validates."""
if ".." in target_
    pass  # inserted to fix indentation error
le_rel or target_
le_rel.startswith("/"):
raise SecurityError(f"Invalid characters or absolute path in target_
le_rel:
{target_
le_rel}")
target_path_abs = (self.agent_code_dir / target_
le_rel).resolve()
directory
if not str(target_path_abs).startswith(str(self.agent_code_dir.resolve())):
    pass  # inserted to fix indentation error
self.log.error(f"Path traversal attempt: {target_
le_rel} resolved to {target_path_abs}
which is outside {self.agent_code_dir}")
raise SecurityError(f"Target
le '{target_
le_rel}' resolves outside the agent code
directory. Access denied.")
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
"""Inspects the source code of a speci
ed agent component (e.g., class name or module
path)."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Inspecting code for component: {component_name}")
target_obj = None
nd by attribute of the agent instance (e.g., agent.self_model)
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
nd in tool registry
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
nd as a globally de
ned class/function in main script context
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
nd in sys.modules (as a module name)
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
ed: if component_name looks like a module, search it.
nd it in common places.
candidate_modules = [sys.modules.get('__main__'),
sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod,
    pass  # inserted to fix indentation error
component_name)):
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
le_path = inspect.get
le(target_obj)
return {"status": "success", "component_name": component_name, "
le_path":
le_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module,
class, or function de
ned in a
le.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but
source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Component '{component_name}' not found or source
code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModi
cationError))
def propose_code_modi
cation_UNSAFE(self, component_name: str, issue_description: str,
proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
"""Proposes a code modi
cation using LLM based on an issue and desired change."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Proposing code modi
cation for {component_name}. Issue:
{issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for
{component_name} to propose modi
cation. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent
modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
{current_code_snippet}
Generate the modi
ed Python code for the speci
ed component.
Provide ONLY the complete, new Python code block for the modi
ed function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '' and end with ''.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name,
"proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modi
cation for {component_name}: {e}",
exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modi
cation_UNSAFE(self, code_to_validate: str) -> Dict:
"""Validates Python code using AST parsing (syntax check only). Conceptual sandboxed
execution would be next."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Validating proposed code snippet (
rst 100 chars):
{code_to_validate[:100]}...")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/
safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modi
cation_UNSAFE(self, component_name: str, new_code: str,
target_
le_path: Optional[str]=None) -> Dict:
"""
Applies a validated code modi
cation. EXTREMELY DANGEROUS.
This conceptually involves
nding the component in the agent's source
le and replacing
it.
Requires agent restart to take e
"
ect if modifying core running code.
"""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.critical(f"UNSAFE: Attempting to apply code modi
cation to component
'{component_name}'. THIS IS HIGHLY RISKY.")
le. This is complex and error-prone.
if not target_
    pass  # inserted to fix indentation error
le_path:
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('
    pass  # inserted to fix indentation error
le_path'):
target_
le_path = inspection_res['
le_path']
else:
    pass  # inserted to fix indentation error
target_
le_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_
le = Path(target_
le_path)
if not target_
    pass  # inserted to fix indentation error
le.exists() or not target_
le.is_
le():
return {"status": "error", "error": f"Target
le for modi
cation not found: {target_
le}"}
try:
    pass  # inserted to fix indentation error
original_code = target_
le.read_text()
le
backup_path = SELF_MOD_BACKUP_DIR /
f"{target_
le.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_
le, backup_path)
self.log.info(f"Backed up original
le to {backup_path}")
nition:
nd the old de
nition of `component_name` and replace it.
nd `class ComponentName...` or `def ComponentName...`
nd existing class or function de
nition
everything until the next class/def or end of typical indentation block.
patter n_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
start of next non-indented line or EOF
patter n_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modi
ed_original_code = original_code
found_and_replaced = False
match_class = re.search(patter n_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(patter n_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not
nd component '{component_name}' in {target_
le} for
replacement. Modi
cation aborted.")
return {"status": "error", "error": f"Component '{component_name}' de
nition not
found for replacement."}
target_
le.write_text(modi
ed_original_code)
cation validation (e.g., try to import the modi
ed
le in a subprocess)
self.log.warning(f"Code modi
cation applied to {target_
le}. Agent restart is LIKELY
REQUIRED for changes to take e
"
ect.")
ect potential capability change
self.agent_ref.self_model.add_event_log(f"Applied code modi
cation to
{component_name}. Restart pending for full e
"
ect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}
_modi
ed_pending_restart"] = True
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
after code change
return {"status": "success", "message": f"Code for '{component_name}' in '{target_
le}'
modi
ed. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modi
cation to {component_name}:
{e}", exc_info=True)
ed
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_
le)
self.log.info(f"Restored original
le {target_
le} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modi
cation: {e}. System
might be unstable."}
def rollback(self, backup_
le: Path, target_
le: Path):
"""Rolls back a
le to a backup."""
self.log.info(f"Attempting to rollback '{target_
le}' from '{backup_
le}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_
le, target_
le)
self.log.info(f"Successfully rolled back '{target_
le}'.")
ags in self-model or state
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_
le}.")
self.agent_ref.self_model.beliefs[f"component_{target_
le.name}
_modi
ed_pending_restart"] = False
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_
le.name)
return {"status": "success", "message": f"Rolled back {target_
le}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_
le}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_
le_rel: Union[str, Path]):
"""Attempts to reload a module to apply changes without full restart."""
target_module_name = Path(target_
le_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is
required.")
return
ed attempt:
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
"
ect global instances like `_agent_instance_hack` if it was part of the
reloaded module
if _agent_instance_hack and hasattr(sys.modules[target_module_name],
    pass  # inserted to fix indentation error
'CognitiveSystem'):
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot
reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for
changes to take e
"
ect.")
def inspect_directives_UNSAFE(self) -> Dict:
"""Inspects the agent's current core directives."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modi
cation_UNSAFE(self, analysis_of_misalignment: str,
proposed_directive_changes_desc: str) -> Dict:
"""Proposes modi
cations to core directives using LLM."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need
review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (
oat 0-1), "last_eval_score" (
oat 0-1,
usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational',
'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore
goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,
temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in
    pass  # inserted to fix indentation error
proposed_directives):
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
returned an error message as JSON
return {"status": "error", "error": f"LLM indicated error during directive proposal:
{proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response:
{llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modi
cation_UNSAFE(self, new_directives: List[Dict]) -> Dict:
"""Applies new core directives to the agent's SelfModel."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in
new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modi
cation_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count:
{len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModi
cationTools(AGENT_CODE_DIR,
SELF_MOD_BACKUP_DIR, agent)
cation
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in
    pass  # inserted to fix indentation error
name.upper():
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
"""Represents the agent's internal model of itself, including beliefs about the
environment."""
def __init__(self, state: Optional[Dict]=None, agent_directives_con
g:
Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_con
g if agent_directives_con
g is not None else
DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
'failure_count', ...}}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
metacognitive checks
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_con
dence: Dict[str,
oat] = {}
dence_score}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
General beliefs about self and world
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
summary of knowledge areas
self.learning_goals: List[Dict[str, Any]] = []
c goals for learning/improvement
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.lear ned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
based narrative of current internal state
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_con
dence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
cant internal events (e.g., directive
changes, model updates)
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
later.
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted",
sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_con
dence = sm_state.get("skill_con
dence", self.skill_con
dence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary",
self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies",
self.adaptation_strategies)
self.lear ned_abstractions = sm_state.get("lear ned_abstractions",
self.lear ned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative",
self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs",
self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
"""Saves the self-model's persistent components back to the main state dict's KB."""
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_con
dence": self.skill_con
dence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"lear ned_abstractions": self.lear ned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
ection and prompt_suggestions_from_re
ection
ection process.
def add_event_log(self, event_description: str, event_type: str = "info", data:
Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
dence for new tools
for tool_name in self.capabilities:
if tool_name not in self.skill_con
    pass  # inserted to fix indentation error
dence:
self.skill_con
dence[tool_name] = 0.5
dence
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0,
'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None,
'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.",
event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8: hint = " (Reliability: High)"
    pass  # inserted to fix indentation error
elif score > 0.6: hint = " (Reliability: Moderate)"
    pass  # inserted to fix indentation error
elif score > 0.3: hint = " (Reliability: Low)"
    pass  # inserted to fix indentation error
else: hint = " (Reliability: Very Low/Untested)"
    pass  # inserted to fix indentation error
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict,
success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration':
0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
MAX_RECENT_TOOL_OUTCOMES_IN_SELFMODEL (constant not de
ned, using 30)
dence (simple heuristic for now)
current_con
dence = self.skill_con
dence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = min(1.0, current_con
dence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = max(0.0, current_con
dence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability:
{stats['reliability_score']:.2f}, Con
dence: {self.skill_con
dence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_con
dence_drift(sm: 'SelfModel') -> Optional[str]:
low_con
dence_skills = [skill for skill, conf in sm.skill_con
dence.items() if conf < 0.25
and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_con
    pass  # inserted to fix indentation error
dence_skills) >= 2 :
return f"Multiple critical skills have very low con
dence and recent failures: {',
'.join(low_con
dence_skills)}. Consider skill improvement or alter native strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict): return None
    pass  # inserted to fix indentation error
low_eval_directives = []
for d in sm.core_directives:
problematic.
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {',
'.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count}
with max replans. Planning or execution e
"
ectiveness may be compromised. Review strategy
or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_con
dence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}):
{anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}",
event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__')
else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {';
'.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears
stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0),
reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:
{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_con
    pass  # inserted to fix indentation error
dence:
con
dent_skills = [s for s,c in self.skill_con
dence.items() if c > 0.7][:3]
summary += f"Con
dent Skills (sample): {', '.join(con
dent_skills) if con
dent_skills else
'None highly con
dent'}\n"
summary += f"Inter nal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and
stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and
stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools: summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
    pass  # inserted to fix indentation error
if unreliable_tools: summary += f" Needs Improvement: {', '.join([t[0] for t in
    pass  # inserted to fix indentation error
unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
ection
base_prompt = """Analyze your recent performance, knowledge, internal state, and
alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:
"""
output_keys_example = [
"`re
ection_summary` (str: Overall summary of the re
ection period).",
"`key_successes` (list of str: Speci
c achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Speci
c setbacks or di
culties encountered).",
"`lear ned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identi
ed` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool
e
"
ectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM
interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g.,
'curious', 'frustrated', 'satis
ed').",
"`resource_usage_concer ns` (str or null: Any concer ns about computational resource
usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_
oat_0_to_1: How
well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes,
provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only
suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model?
What needs improvement?).",
"`new_learning_goals` (list of str: Speci
c goals for future learning or skill
development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring
issues or improve performance).",
"`self_modi
cation_needed` (str or null: If parts of your own code/logic need
modi
cation, describe what and why. Be very speci
c and cautious.)."
]
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives,
indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n"
+ \
f"Recent Tool Outcomes (last 5 entries):
\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}
\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment
with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment:
{assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_re
ection(self, re
ection_data: Dict) -> Tuple[bool, bool]:
ection updates
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from re
ection data...")
dence, tool_notes (as in base script logic)
ection_data directly updates some
elds or implies updates
if re
    pass  # inserted to fix indentation error
ection_data.get('re
ection_summary'):
self.internal_state_narrative = re
ection_data['re
ection_summary']
updated_self = True
core_directives_eval = re
ection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and
    pass  # inserted to fix indentation error
isinstance(self.core_directives[0], dict):
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (
    pass  # inserted to fix indentation error
oat, int)) and 0.0 <= eval_score
<= 1.0:
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...'
evaluation score to {eval_score:.2f}")
if updated_self: self.add_event_log("Directive evaluation scores updated from
    pass  # inserted to fix indentation error
re
ection.")
suggested_directive_updates = re
ection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Re
ection suggested updates to core directives:
{str(suggested_directive_updates)[:200]}...")
'apply_directive_modi
cation_UNSAFE' tool
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modi
cations from
re
ection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source":
"self_re
ection"}
)
updated_self = True
self.add_event_log("Re
ection suggested directive updates. Metacognitive review
goal created.", event_type="critical_review_needed")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('new_learning_goals'), list):
for lg_str in re
ection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts":
datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self: self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('adaptation_strategy_proposals'), list):
for strat_str in re
ection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self: self.log.info(f"Updated adaptation strategies. Total:
    pass  # inserted to fix indentation error
{len(self.adaptation_strategies)}")
patterns
agent
if re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts') or re
ection_data.get('prompt_tuning_suggestions'):
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from re
ection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
"""Saves a backup of current directives to a
le."""
backup_
le = SELF_MOD_BACKUP_DIR /
f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_
le.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_
le} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
"""Simulates an internal dialog about a topic using LLM, potentially from di
"
erent
perspectives."""
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_o
cer"]
dialog_history = []
full_dialog_str = f"Inter nal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts,
questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution":
contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective
{perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":
full_dialog_str})
return full_dialog_str
class MotivationEngine:
"""Manages the agent's internal drives and their in
uence on behavior."""
def __init__(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[DriveType, DriveState] = {}
self._initialize_drives(drive_con
gs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]]):
default_con
gs = {
DriveType.CURIOSITY: {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.MASTERY: {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.ACHIEVEMENT: {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.NOVELTY_SEEKING: {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.7},
DriveType.PRESERVATION: {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0,
"initial_level": 0.2},
DriveType.EFFICIENCY: {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.SOCIAL_INTERACTION: {"decay_rate": 0.01, "max_level": 1.0, "min_level":
0.0, "initial_level": 0.3},
}
con
gs = drive_con
gs if drive_con
gs is not None else default_con
gs
for drive_type in DriveType:
con
g = con
gs.get(drive_type, default_con
gs.get(drive_type, {}))
self.drives[drive_type] = DriveState(
drive_type=drive_type,
level=con
g.get("initial_level", 0.5),
decay_rate=con
g.get("decay_rate", 0.01),
max_level=con
g.get("max_level", 1.0),
min_level=con
g.get("min_level", 0.0)
)
def update_drives(self):
"""Applies decay and updates drives based on recent experiences or time."""
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
"""Updates drives based on a speci
c experience."""
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "lear n":
    pass  # inserted to fix indentation error
self.drives[DriveType.CURIOSITY].update(stimulus=-0.05)
self.drives[DriveType.MASTERY].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives[DriveType.PRESERVATION].update(stimulus=0.1)
self.drives[DriveType.MASTERY].update(stimulus=-0.05)
def get_drive_level(self, drive_type: DriveType) ->
oat:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
if not found
    pass  # inserted to fix indentation error
def get_all_drive_levels(self) -> Dict[DriveType,
oat]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str,
oat]:
return {dt.name: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[DriveType,
oat]]:
"""Retur ns top N drives by current level."""
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
"""Suggests a goal type based on current highest drives."""
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == DriveType.CURIOSITY:
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == DriveType.MASTERY:
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == DriveType.ACHIEVEMENT:
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == DriveType.PRESERVATION:
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == DriveType.EFFICIENCY:
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: DriveType
level:
oat = 0.5
decay_rate:
oat = 0.01
max_level:
oat = 1.0
min_level:
oat = 0.0
last_update_time:
oat =
eld(default_factory=time.time)
def update(self, stimulus:
oat = 0.0):
"""Updates the drive level based on stimulus and decay."""
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class FileChannel:
"""Implements a simple
le-based communication channel for multi-agent systems."""
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_
le = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_
le}")
def _write_message_to_
le(self, message: Message, target_
le: Path) -> bool:
try:
    pass  # inserted to fix indentation error
le lock to prevent corruption during writes
with FileLock(str(target_
le) + ".lock", timeout=5):
messages = []
if target_
    pass  # inserted to fix indentation error
le.exists():
try:
    pass  # inserted to fix indentation error
existing_content = target_
le.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {target_
le}: {e}. Clearing
le.")
messages = []
messages.append(message.to_dict())
target_
le.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_
le}. Message not sent to
le.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_
le}: {e}")
return False
def _read_messages_from_
le(self, source_
le: Path) -> List[Message]:
messages = []
if not source_
    pass  # inserted to fix indentation error
le.exists():
return []
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_
le) + ".lock", timeout=5):
content = source_
le.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if
isinstance(msg_data, dict)]
le after reading
source_
le.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_
le}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {source_
le}: {e}. Clearing
le.")
source_
le.write_text("", encoding='utf-8')
le
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_
le}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}:
{message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_
le(message, target_inbox)
def receive_messages(self) -> List[Message]:
"""Checks and retrieves new messages from the agent's inbox."""
new_messages = self._read_messages_from_
le(self.inbox_
le)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message],
Optional[Message]]):
"""Registers a function to handle speci
c message types."""
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
"""Processes all messages currently in the inbox using registered handlers."""
messages = self.receive_messages()
le
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From:
{msg.sender_id}")
handled = False
if msg.message_type in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg.message_type]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler
{handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id,
receiver_id=msg.sender_id, type=MessageType.ERROR, content={"original_message_id":
msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type
{msg.message_type.value}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
"""Abstract base class for a sensor."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', con
g: Dict):
self.id = id
self.embodiment = embodiment
self.con
g = con
g
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
"""Retur ns the current reading from the sensor."""
pass
class Actuator(ABC):
"""Abstract base class for an actuator."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], con
g: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.con
g = con
g
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
"""Performs a speci
c action using the actuator."""
pass
class VirtualEmbodiment:
"""Simulated embodiment layer for SystemCore agents. (Can be replaced by Gym environments or
more complex sims)"""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing
system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to
'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button",
"research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, recon
gurable bay designed for running complex simulations.
Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_con
g_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data
ow and
storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core.
Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in
self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
"""Generate synthetic sensory input based on current environment and internal state."""
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20: self.state["emotions"]["anxiety"] = min(1.0,
    pass  # inserted to fix indentation error
self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An unde
ned space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
self.gym_env.step(self.gym_env.action_space.sample())
observation
logging
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) ->
Dict:
"""
Simulates the agent performing an action in the virtual world.
Retur ns a dictionary with the result of the action.
"""
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params:
{params}")
params = params or {}
env_details = self.environment_map.get(self.location, {})
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as speci
ed."
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console": message += " It shows
    pass  # inserted to fix indentation error
uctuating green and
amber lights."
elif target == "core_status_monitor": message += " It indicates: Core Nominal.
    pass  # inserted to fix indentation error
Directives Stable. Lear ning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
ed
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
problem.
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name",
"default_physics_test"), params.get("con
g",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result:
{sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
"
ect emotional state based on action outcome
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if
action_type=="move" else None, "updated_inventory": self.state["inventory"] if
action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "lear n"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage
at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response:
{self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model
<topic>'."
def _run_simulation(self, sim_name: str, con
g: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with con
g: {con
g}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_con
    pass  # inserted to fix indentation error
g" in con
g: success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric:
{outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check con
guration."
def summary(self) -> str:
"""Retur ns a string summary of the embodiment's current state."""
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Inter nal State (summary): Energy={self.state['energy']},
Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time:
oat = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
methods
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE,
LAST_LEARNING_MODULE_UPDATE_CYCLE
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status:
{self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack
Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if
self.agent.state['goals'].get('active') else None
self.agent.last_error = None
self.agent.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
understanding
if self.agent.self_model and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
self.log.info(f"Triggering proactive metacognitive check (Cycle
{self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
goal
if self.agent.learning_module and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_LEARNING_MODULE_UPDATE_CYCLE >=
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.lear n_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
new_pending_goals
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
List of Goal dicts
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation:
{ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
pending_list.sort(key=lambda x: GoalPriority[x.get('priority', 'MEDIUM').upper() if
isinstance(x.get('priority'),str) else GoalPriority(x.get('priority',
GoalPriority.MEDIUM)).name ].value, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type ==
    pass  # inserted to fix indentation error
"active_goal_continue":
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution:
{goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID:
{goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal'
provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
object
ed logic assumes plan is a list of steps in the goal dict.
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or
    pass  # inserted to fix indentation error
current_goal_obj.replan_count > 0:
planning
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
generation
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
Goal object
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan available or generated for goal: {current_goal_obj.goal[:50]}.
Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
c goal, agent is idle or performing non-goal action
self.agent.current_goal_outcome = True
gured
if time.time() - LAST_DELIBERATION_TIME >
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModi
cationError, LogicError, LLMError, SecurityError, Con
gurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
Lear ningError, SafetyViolationError) as agent_cycle_err:
c goal
attempt.
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent
Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
nished (with an error for current goal), but agent can continue
unless critical.
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.current_goal_outcome = False
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
nally:
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() -
start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
"""Processes observations to update world model and identify key information."""
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
ed approach. A real system might have more structured parsing.
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent
understanding of the current situation. Identify key entities, events, and any signi
cant changes
in the environment or your internal state. Focus on information relevant to achieving current
goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content:
{str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\":
\"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"],
\"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation",
understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
as facts/experiences
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event",
metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry,
persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
complex updates to the graph/relational store
return {"summary": understanding_summary, "processed_info": processed_info,
"raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError,
DeliberationError))
g
def _deliberate(self, understanding_result: Dict) -> Dict:
"""
Core deliberation logic: goal management, selection, and generation.
Retur ns a dict: {"chosen_action_type": str, "next_goal": Optional[Goal_dict],
"new_pending_goals": List[Goal_dict]}
"""
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio:
{pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio:
{active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time':
datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack
(paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
activated
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
continue
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
directives (idle task)
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal
generation.")
directives
if time.time() - LAST_DELIBERATION_TIME >=
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_lear n", "directive_curiosity",
"directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
for idle time
pass
new_pending_goals
processed
ag.
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') ==
    pass  # inserted to fix indentation error
'sub_goal_prepared':
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output:
{sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
c action, LLM will decide
self_model_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No speci
c
understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact',
'None identi
ed.')
interp_con_val = understanding_result.get('interpretation_con
dence', 0.7)
recent_memory_context =
self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary,
max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Con
dence: {interp_con_val:.2f}):**
{understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identi
ed:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory
(STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]],
indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else
f'{active_goal_dict.get("goal")[:100]}... (ID: {active_goal_dict.get("id")})'}",
f"* **Agent Core Directives
(Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding,
drives, memories, goals, directives), what is the most critical aspect demanding attention or the
best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.self_model.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/
complete).",
"    - Performing `re
ection` or `self_assessment` (if mandatory timers, drives like low
CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration
goal), Directives (e.g., low-eval directive -> improvement goal), or identi
ed opportunities. New
goals require `goal` (str), `priority` (
oat 0.0-1.0), `origin` (str e.g., 'drive_curiosity',
'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of
str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for
viability before committing if uncertainty is high or consequence severe (brie
y note simulation
outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are
apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the
immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, high
drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.
If selecting an existing pending goal, it moves to `next_goal` and is removed from pending
internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/
directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal',
'new_goal', 're
ection', 'self_assessment', 'exter nal_command_action', 'idle',
'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass
structure) selected for immediate execution. Null if idle/re
ection/assessment without a direct
goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen
for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into
`new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into
`new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent.
Analyze the situation comprehensively, consider drives and directives, and make strategic
decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and
deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON:
{extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal',
'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys:
{deliberation_decision.keys()}")
if key == 'new_pending_goals': deliberation_decision[key] = []
    pass  # inserted to fix indentation error
elif key == 'next_goal': deliberation_decision[key] = None
    pass  # inserted to fix indentation error
else: deliberation_decision[key] = "Error: Missing from LLM Output"
    pass  # inserted to fix indentation error
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty
list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not
    pass  # inserted to fix indentation error
isinstance(deliberation_decision.get('next_goal'), dict):
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value:
{deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and
    pass  # inserted to fix indentation error
new_goal_dict.get('priority'):
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p.id == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
duplicates based on ID
current_pending_list.append(new_goal_obj)
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal:
{new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
LLM
current_active_goal = self.agent.get_active_goal_object()
None
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending',
[]) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
selected_goal_obj.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = selected_goal_obj
object
self.log.info(f"Moved pending goal {selected_goal_obj.id}
('{selected_goal_obj.goal[:50]}') to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM selected pending goal by ID
{selected_next_goal_dict.get('id')}, but not found in list. Idling.")
action_type = "idle"
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
highest_priority_pending.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = highest_priority_pending
self.log.info(f"Deliberation chose 'pending_goal' without speci
c ID; moved
highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals
available. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in
    pass  # inserted to fix indentation error
selected_next_goal_dict:
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj
self.log.info(f"Deliberation created and activated new goal:
{new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal
active
current_active_goal.status = GoalStatus.ACTIVE
rm active status
self.log.info(f"Deliberation chose to resume current active goal:
{current_active_goal.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 're
    pass  # inserted to fix indentation error
ection', 'self_assessment', 'exter nal_command_action']:
'INTERRUPTED'.
if current_active_goal:
    pass  # inserted to fix indentation error
current_active_goal.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal.goal[:30]}' PAUSED due to
{action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal.to_dict())
pending, maybe re-prioritize later
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal.id} to pending
as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to
Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action:
{deliberation_decision.get('chosen_action_type')}. Reason:
{deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
"""
Executes the current plan for the active_goal.
Retur ns True if goal considered successfully processed for this cycle, False if critical error.
"""
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps:
{len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
rst step in the plan. The plan will be truncated or re-evaluated.
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id,
"plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params,
current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
ned based on tool_result and goal progress
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
ed snapshot
internal_state_after=self.agent.self_model.beliefs
e
"
ects
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
nal_status = tool_result.get("status", "unknown")
if
nal_status == "success":
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome =
nal_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
nished.
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing
nished by report_result.
Status: {
nal_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error',
'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj,
tool_result, observations[0] if observations else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal
will likely fail.")
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without
'report_result'. Goal might be incomplete.")
ection.
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
violations
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}':
{e}", exc_info=False)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) ->
oat:
"""Calculates a reward signal based on tool execution outcome and goal relevance."""
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
goaling
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
in cycle
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
for direct access
self.learning_module: Lear ningModule
self.planning_module: PlanningModule
direct access
self.safety_module: SafetyModule
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.state['
ags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete ---
Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response
Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled:
{ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modi
cation Enabled: {ENABLE_SELF_MODIFICATION}")
if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
    pass  # inserted to fix indentation error
ENABLE_SELF_MODIFICATION:
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME
CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}",
exc_info=True)
self.shutdown()
raise Con
gurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH == "mock":
    pass  # inserted to fix indentation error
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Cannot use Gemini model: google-generativeai library not
installed.")
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
global LLM_PIPELINE, LLM_TOKENIZER
CPU
AutoTokenizer.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
oat16 if TORCH_AVAILABLE else None,
oat16 if
torch available
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH,
LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS,
get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
c not implemented here
self.log.warning(f"LLM_MODEL '{LLM_MODEL_NAME_OR_PATH}' not fully con
gured
for wrapper selection, using Mock.")
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
_init_self_mod_tools(self, self.tool_manager)
cationTools handler
and register its UNSAFE methods
self._update_status("Initializing SystemCore Modules")
self.learning_module = Lear ningModule(self)
self.safety_module = SafetyModule(self)
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME,
shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager: self.tool_manager.check_playwright_browsers()
    pass  # inserted to fix indentation error
browser tool
self.log.info("Agent component initialization
nished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list): state['goals'][key] = []
    pass  # inserted to fix indentation error
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
items
state.setdefault('goal_stack', [])
state.setdefault('
ags', {})
ags system
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state
le {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state
le {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
its view
"recent_failures_summary": [],
view
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"
ags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
cation and saving
_archive_goal
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
state['knowledge_base']['self_model_state']
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status if self.self_model else
self._status
try:
    pass  # inserted to fix indentation error
temp_
le = STATE_FILE.with_su
x(STATE_FILE.su
x + ".tmp")
with temp_
le.open('w') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_
le, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
"""Retur ns the current active goal as a Goal object, or None."""
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict:
{active_goal_dict}")
return None
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority =
GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
deliberation
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict,
nal_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID:
{goal_data_dict.get('id')}) with status: {
nal_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
goal_obj.status = GoalStatus(
nal_status_str)
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-
MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status":
str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count":
goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and
    pass  # inserted to fix indentation error
current_active_in_state.get('id') == active_goal_id:
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
stack
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID:
{active_goal_id}) concluded with status: {
nal_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-
goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
marked active
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal',
'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal:
{parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
goal wasn't a subgoal from stack
self.log.info("Goal archived. No parent goal to resume from stack, or current goal
was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized": self._update_status("Idle")
    pass  # inserted to fix indentation error
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and
environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if
self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle:
{loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
nal status of the goal processed in this cycle
updated_active_goal_dict = self.state['goals'].get('active')
goal
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] ==
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['id']:
ects outcome
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED,
    pass  # inserted to fix indentation error
GoalStatus.CANCELLED]:
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
during preemption
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
failed while this goal was active
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
failed
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
not speci
c to goal completion
ection (SystemCore Enhanced) - Can be more frequent or event-driven
if self._should_re
    pass  # inserted to fix indentation error
ect(active_goal_data_before_cycle):
self._re
ect_on_performance()
cant changes (already done in many places)
nal save here per cycle too.
if self.state['
    pass  # inserted to fix indentation error
ags'].get('re_evaluate_strategy_needed'):
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to signi
cant
internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['
ags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not
    pass  # inserted to fix indentation error
self.state['goals'].get('pending'):
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() -
LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_re
ect(self, processed_goal_data: Optional[Dict]) -> bool:
ection triggers
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
ect
every N cycles
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED, GoalStatus.FAILED]:
ect after signi
cant goal outcome
ect if enough goals processed since last time
goals_processed_key = "goals_processed_since_re
ection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >=
    pass  # inserted to fix indentation error
int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
return True
if time.time() - LAST_REFLECTION_TIME >
    pass  # inserted to fix indentation error
MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
return True
if self.state['
    pass  # inserted to fix indentation error
ags'].get('explicit_re
ection_requested'):
return True
return False
@retry(attempts=2, delay=5)
def _re
ect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Re
ecting on Performance ---")
self.state['
ags']['explicit_re
ection_requested'] = False
ag
self.state["goals_processed_since_re
ection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt,
max_new_tokens=2048, temperature=0.5)
ection
re
ection_data = extract_json_robust(llm_assessment_str)
if re
    pass  # inserted to fix indentation error
ection_data.get("error"):
self.log.error(f"Failed to get valid JSON from LLM self-assessment:
{re
ection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed:
{re
ection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_re
ection(re
ection_data)
ection to MemorySystem
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts'), list):
for fact_str in re
ection_data['lear ned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source":
"self_re
ection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
self.log.info(f"Added {len(re
ection_data['lear ned_facts'])} lear ned facts to memory
from re
ection.")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('prompt_tuning_suggestions'), list):
for sugg_str in re
ection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str,
metadata={"source": "self_re
ection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(re
ection_data['prompt_tuning_suggestions'])} prompt
suggestions to memory.")
ndings from re
ection (e.g. self_modi
cation_needed)
if re
    pass  # inserted to fix indentation error
ection_data.get('self_modi
cation_needed'):
mod_desc = re
ection_data['self_modi
cation_needed']
self.log.warning(f"Re
ection identi
ed need for self-modi
cation: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modi
cation based on re
ection:
{mod_desc}",
priority=GoalPriority.HIGH,
context={"modi
cation_description": mod_desc, "source": "self_re
ection"}
)
ection insights or periodically
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) ==
    pass  # inserted to fix indentation error
0:
audit_issues = self.safety_module.audit_directives_and_behavior()
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identi
ed issues: {audit_issues}")
ndings
self._create_metacognitive_goal(f"Address directive audit
ndings:
{str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Re
ection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during re
ection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during re
ection: {e}", exc_info=True)
nally:
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
"""Sets up handlers for di
"
erent message types if comms_channel exists."""
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY,
self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM,
self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}:
{message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base']
[query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample":
str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id,
type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}:
{message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
x with sender to avoid
clashes
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if not PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("psutil not available, resource monitoring disabled.");
return
if RESOURCE_MONITOR: return
    pass  # inserted to fix indentation error
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e: self.log.error(f"Failed to initialize resource monitor: {e}");
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("Playwright not available, skipping initialization.")
return
if PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER =
PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
globals
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE: try: PLAYWRIGHT_PAGE.close()
    pass  # inserted to fix indentation error
ignore
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_CONTEXT: try: PLAYWRIGHT_CONTEXT.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_BROWSER: try: PLAYWRIGHT_BROWSER.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_INSTANCE: try: PLAYWRIGHT_INSTANCE.stop()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not PLAYWRIGHT_AVAILABLE or not self.playwright_context : return
    pass  # inserted to fix indentation error
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page: try: self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
ush
if 'logging' in sys.modules: logging.shutdown()
    pass  # inserted to fix indentation error
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl}
Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/
{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)' if
ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
ENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_
le",
priority=GoalPriority.HIGH).to_dict()
COMMANDS_FILE.write_text("")
except Exception as e_cmd
    pass  # inserted to fix indentation error
le:
print(f"Error reading initial command
le: {e_cmd
le}",
le=sys.stderr)
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending',
[]).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort,
reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal']
[:50]}' added to pending goals.")
main_agent_instance.run()
except Con
    pass  # inserted to fix indentation error
gurationError as cfg_err_main:
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}",
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to Con
gurationError:
{cfg_err_main}", exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to
    pass  # inserted to fix indentation error
Con
gurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else: logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt
    pass  # inserted to fix indentation error
during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}",
le=sys.stderr)
traceback.print_exc(
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",
exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main:
    pass  # inserted to fix indentation error
{main_exec_err}", exc_info=True)
exit_code = 1
nally:
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main
nally block...")
if hasattr(main_agent_instance, 'log'): main_agent_instance.log.warning("Main
    pass  # inserted to fix indentation error
nally
block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
main_log.warning("Agent instance likely not created or fully initialized. Basic
shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
def load_llm_models():
global llm_pipelines
try:
    pass  # inserted to fix indentation error
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error in load_llm_models: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
try:
    pass  # inserted to fix indentation error
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
from Real1_ToolSuite import TOOL_REGISTRY
TRANSFORMERS_AVAILABLE = True
TORCH_AVAILABLE = True
GOOGLE_GENAI_AVAILABLE = True
PSUTIL_AVAILABLE = True
CHROMADB_AVAILABLE = True
PLAYWRIGHT_AVAILABLE = True
REQUESTS_BS4_AVAILABLE = True
PILLOW_AVAILABLE = True
DIFF_MATCH_PATCH_AVAILABLE = True
FILELOCK_AVAILABLE = True
NETWORKX_AVAILABLE = True
GYMNASIUM_AVAILABLE = True
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
import psutil
import chromadb
from chromadb.config import Settings as ChromaSettings
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoConfig
from transformers import logging as transformers_logging
import torch
from playwright.sync_api import sync_playwright, Error as PlaywrightError
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from PIL import Image
import diff_match_patch as dmp_module
import hashlib
from fifilelock import FileLock, Timeout as FileLockTimeout
import networkx as nx
import gymnasium as gym
AGENT_NAME = "EvolvedCognitiveAgent_SystemCore_V3"
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
DEFAULT_LLM_MODEL = "gemini-2.5-flash"
LLM_MODEL_NAME_OR_PATH = DEFAULT_LLM_MODEL
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
_llm_device_detected = "cpu"
if torch.cuda.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif hasattr(torch, 'backends') and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
LLM_DEVICE = _llm_device_detected
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
SCRIPT_DIR = Path(__file__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(f"agent_workspace_{AGENT_NAME}")
STATE_FILE = WORKSPACE_DIR / Path(f"agent_state_{AGENT_NAME}.json")
LOG_FILE = WORKSPACE_DIR / Path(f"agent_log_{AGENT_NAME}.log")
COMMANDS_FILE = SCRIPT_DIR / Path("agent_commands.txt")
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modification_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously learn, adapt, and improve capabilities across all domains.", "weight": 0.9, "last_eval_score": 0.0, "id": "directive_learn", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type": "growth"},
{"directive": "Achieve goals efficiently, robustly, autonomously, and ethically.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type": "exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.", "weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type": "foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type": "guardrail"},
]
MANDATORY_REFLECTION_INTERVAL_SECONDS = 1800
IDLE_DELIBERATION_INTERVAL_SECONDS = 120
GOAL_STACK_MAX_DEPTH = 5
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = 3
MAX_LLM_RESPONSE_TOKENS = 4096
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH or "2.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
else:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
config = AutoConfig.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
_default_context_len = getattr(config, 'max_position_embeddings', _default_context_len)
except Exception:
    pass  # inserted to fix indentation error
pass
MAX_LLM_CONTEXT_TOKENS = _default_context_len
MAX_TOOL_RESULT_LENGTH = 5000
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = True
ENABLE_CODE_GENERATION_TOOL = True
ENABLE_SELF_MODIFICATION = True
WEB_SEARCH_TIMEOUT = 10
WEB_BROWSER_TIMEOUT = 60000
LOG_MONITOR_DEFAULT_LINES = 20
METACOGNITIVE_CHECK_INTERVAL_CYCLES = 20
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES = 50
LLM_PIPELINE = None
LLM_TOKENIZER = None
MEMORY_COLLECTION = None
RESOURCE_MONITOR = None
PLAYWRIGHT_INSTANCE = None
PLAYWRIGHT_BROWSER = None
PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_PAGE = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack = None
def ensure_paths():
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
try:
    pass  # inserted to fix indentation error
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
try:
    pass  # inserted to fix indentation error
file_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
file_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%(filename)s:%(lineno)d] [%(task_name_override)-10s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error setting up file logger: {e}", file=sys.stderr)
logger.propagate = False
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "fifilelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try:
    pass  # inserted to fix indentation error
logging.getLogger(lib_name).setLevel(logging.WARNING)
except Exception:
    pass  # inserted to fix indentation error
pass
try:
    pass  # inserted to fix indentation error
logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
except Exception:
    pass  # inserted to fix indentation error
pass
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModificationError(AgentError): pass
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class ConfigurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class LearningError(AgentError): pass
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModificationError,
PlaywrightError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModificationError,
    pass  # inserted to fix indentation error
LogicError, ConfigurationError, RecursionDepthError)) and type(e) not in retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}: {e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error: {type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error: {type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, LearningError) as non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in {fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}: {type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}: {unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error: {unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception):
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1:
    pass  # inserted to fix indentation error
log_resource.error(f"Unexpected error getting resource usage: {e}", exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
match = re.search(r"json\s*([\s\S]+?)\s*", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full text: {json_str[:200]}...")
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}. Text: {text_trimmed[:200]}...")
try:
    pass  # inserted to fix indentation error
start_index = text.find('{')
end_index = text.rfind('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
try:
    pass  # inserted to fix indentation error
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice: {potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text: {text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview": text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str = field(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] = field(default_factory=dict)
plan: List[Dict[str, Any]] = field(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] = field(default_factory=list)
dependencies: List[str] = field(default_factory=list)
complexity_score: Optional[float] = None
estimated_cost: Optional[float] = None
estimated_utility: Optional[float] = None
evaluation_score: Optional[float] = None
associated_directive_ids: List[str] = field(default_factory=list)
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus(data['status'])
except ValueError:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus.PENDING
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority.MEDIUM
field_names = {f.name forfin cls.__dataclass_fields__.values()}
for f_obj in cls.__dataclass_fields__.values():
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin cls.__dataclass_fields__.values()}
filtered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**filtered_data)
@dataclass
class BaseMemoryEntry:
id: str = field(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
content: Any = None
metadata: Dict[str, Any] = field(default_factory=dict)
embedding: Optional[List[float]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[float] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability: float = 0.5
related_concepts: List[str] = field(default_factory=list)
causal_links: Dict[str, str] = field(default_factory=dict)
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
self.content = self.fact_statement
@dataclass
class Message:
id: str = field(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
type: str = "info"
content: Dict[str, Any] = field(default_factory=dict)
priority: int = 0
correlation_id: Optional[str] = None
def to_dict(self) -> Dict[str, Any]:
return asdict(self)
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Message':
return cls(**data)
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionEffect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens: int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[float]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
genai.configure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
try:
    pass  # inserted to fix indentation error
generation_config_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_config_params["stop_sequences"] = stop_sequences
full_prompt = f"{system_message}\n\n{prompt}" if system_message else prompt
response = self.model.generate_content(
full_prompt,
generation_config=genai.types.GenerationConfig(**generation_config_params)
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.", exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[float]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='models/embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, trust_remote_code=True)
device_map_arg = {"": self.device_id} if self.device_id != -1 else "auto"
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.bfloat16,
device_map=device_map_arg
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on {self.device}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Transformers model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Transformers model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
if system_message:
    pass  # inserted to fix indentation error
chat_prompt = [
{"role": "system", "content": system_message},
{"role": "user", "content": prompt}
]
try:
    pass  # inserted to fix indentation error
final_prompt = self.tokenizer.apply_chat_template(chat_prompt, tokenize=False, add_generation_prompt=True)
except Exception:
    pass  # inserted to fix indentation error
final_prompt = f"System: {system_message}\nUser: {prompt}\nAssistant:"
else:
    pass  # inserted to fix indentation error
final_prompt = prompt
inputs = self.tokenizer(final_prompt, return_tensors="pt").to(self.model.device)
outputs = self.model.generate(
**inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[float]:
self.log_llm.warning("Direct embedding from causal LM is not standard. Using mock embedding.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
def perceive(self) -> List[Dict[str, Any]]:
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_file",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from file: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands file: {e}")
observations.append({"type": "error", "source": "command_file_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No significant external stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (simulated).")
return {"type": "visual", "source": "camera_sim", "content": "Simulated visual data: a generic scene.", "format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (simulated).")
return {"type": "audio", "source": "microphone_sim", "content": "Simulated auditory data: ambient sounds.", "format": "description"}
class LearningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_buffer: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
self.experiences_buffer.append(experience)
if len(self.experiences_buffer) > self.MAX_BUFFER_SIZE:
    pass  # inserted to fix indentation error
self.experiences_buffer.pop(0)
defilearn_from_recent_experiences(self):
if not self.experiences_buffer:
    pass  # inserted to fix indentation error
self.log.info("No new experiences to learn from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_buffer)} experiences.")
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_buffer)
self._perform_self_supervised_learning(self.experiences_buffer)
self.log.info("Learning cycle completed.")
self.experiences_buffer.clear()
def _perform_reinforcement_learning(self, experiences: List[Experience]):
self.log.info("Performing reinforcement learning (conceptual)...")
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (conceptual) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
self.log.info("Performing self-supervised learning (conceptual)...")
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns', 'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified patterns: {llm_analysis['patterns']}")
for pattern_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {pattern_str}", metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified abstractions: {llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.learned_abstractions.append({"type": "conceptual", "content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified new_concepts: {llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}", metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_learned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
if self.rl_policy:
    pass  # inserted to fix indentation error
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}. Response: {llm_response_str[:200]}")
return ([{"tool_name": "report_error", "params": {"error_message": "Failed to generate plan via LLM.", "details": plan_data.get('error')}}],
"LLM failed to generate a plan. This is a fallback step.")
thought = plan_data.get("thought", "No specific thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return ([{"tool_name": "report_error", "params": {"error_message": "LLM plan contained no valid steps."}}],
thought + " (But plan steps were invalid).")
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return ([{"tool_name": "report_error", "params": {"error_message": f"LLMError during planning: {e}"}}],
f"LLM error occurred: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return ([{"tool_name": "report_error", "params": {"error_message": f"Unexpected error during planning: {e}"}}],
f"Unexpected error: {e}")
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation: Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info', {}).get('execution_successful', True):
    pass  # inserted to fix indentation error
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal {current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan, last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan: {plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No specific thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else "World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'. Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, efficient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the `execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the final step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the first step(s) should be to acquire it (e.g., using `search_web`, `read_file_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str, last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info', {}).get('current_step_id'):
    pass  # inserted to fix indentation error
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if observation else "None"}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
{original_plan_str}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should reflect this (e.g., by trying to gather more information or reporting inability).
6. Ensure the final step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
class MemorySystem:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH, settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
self.log.info(f"ChromaDB vector store initialized. Collection count: {self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.", exc_info=True)
self.vector_store = None
if not self.vector_store:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based (transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes: {len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be unavailable.", exc_info=True)
self.graph_store = None
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH, check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be unavailable.", exc_info=True)
if self.relational_conn:
    pass  # inserted to fix indentation error
self.relational_conn.close()
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT,
PRIMARY KEY (source_node_id, target_node_id, relation_type)
)
""")
self.relational_conn.commit()
cursor.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error initializing relational schema: {e}", exc_info=True)
def _get_embedding(self, text: str) -> Optional[List[float]]:
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
h = hashlib.md5(text.encode()).digest()
return [float(b) for b in h[:16]]
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector:
    pass  # inserted to fix indentation error
if self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
for k, v in entry.metadata.items():
if isinstance(v, (str, int, float, bool)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
else:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(entry.content)
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata": entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50], type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
for cause_id, effect_id in entry.causal_links.items():
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(effect_id):
    pass  # inserted to fix indentation error
self.graph_store.add_edge(cause_id, effect_id, relation_type='causes')
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id, complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score, json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
ts_now = datetime.now(timezone.utc).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now, json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}", exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError, ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS, type_filter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text:
    pass  # inserted to fix indentation error
return []
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_filter and data['metadata'].get('type') != type_filter:
    pass  # inserted to fix indentation error
continue
results.append({"id": id, "document": data['document'], "metadata": data['metadata'], "distance": 0.0})
if len(results) >= n_results:
    pass  # inserted to fix indentation error
break
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results}, filter={type_filter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_filter:
    pass  # inserted to fix indentation error
where_clause = {"type": type_filter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0:
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type: Optional[str]=None, depth: int = 1) -> List[Dict]:
if not self.graph_store:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation": data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns: Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
if self.graph_store:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts, type_filter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No specific knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
return summary_str
def consolidate_knowledge(self):
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold: float = 0.1, older_than_days: int = 365):
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cutoff_ts = (datetime.now(timezone.utc) - timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cutoff_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
self.register_tool(read_file_UNSAFE)
self.register_tool(write_file_UNSAFE)
self.register_tool(list_files_UNSAFE)
self.register_tool(browse_web)
self.register_tool(search_web)
self.register_tool(monitor_log_file)
self.register_tool(check_website_update)
self.register_tool(send_icmp_ping)
self.register_tool(send_message_to_agent)
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
self.register_tool(execute_shell_command_UNSAFE)
def register_tool(self, func: Callable):
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if hasattr(self, 'agent') and self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for filepath in directory.glob("*.py"):
module_name = filepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_file_location(full_module_name, filepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
sys.modules[full_module_name] = module
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module: {module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and name.startswith("tool_"):
    pass  # inserted to fix indentation error
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}", exc_info=True)
def get_tool_description_for_llm(self) -> str:
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = "(No description provided)"
first_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation == inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class '","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper():
    pass  # inserted to fix indentation error
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {first_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via specific tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {', '.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info: Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None:
    pass  # inserted to fix indentation error
current_step_info = {}
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
result = None
duration = 0.0
validated_params = {}
try:
    pass  # inserted to fix indentation error
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
first_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
first_param_name = next(iter(func_params_spec))
first_param_spec = func_params_spec[first_param_name]
if first_param_name == 'agent' and (first_param_spec.annotation == 'CognitiveSystem' or str(first_param_spec.annotation) == "'CognitiveSystem'"):
    pass  # inserted to fix indentation error
first_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if first_param_is_agent and p_name == 'agent':
    pass  # inserted to fix indentation error
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind == inspect.Parameter.VAR_KEYWORD:
    pass  # inserted to fix indentation error
pass
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
if first_param_is_agent:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration: {duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError:
    pass  # inserted to fix indentation error
raise
except (AgentError, LogicError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}", exc_info=False)
result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
def check_playwright_browsers(self):
self.log.debug("Checking Playwright browsers.")
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log", content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str, percentage_complete: Optional[float] = None) -> Dict:
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log', []).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str = "success", details: Optional[Dict] = None) -> Dict:
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] = "MEDIUM", context: Optional[Dict] = None) -> Dict:
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH}) reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent: {current_active_goal_dict.get('id')}")
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str = "vector", n_results: int = 3, type_filter: Optional[str] = None) -> Dict:
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
results = []
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results, type_filter=type_filter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_graph_store(query_node_label=query_text, depth=1)
elif memory_type == "relational":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_relational_store(table=query_text, limit=n_results)
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params: Optional[Dict] = None) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name, params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
def read_file_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
log_tool = get_logger("TOOL_read_file")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not full_path.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found: {path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path), "file_size_bytes": len(content)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read file: {e}"}
def write_file_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_file")
try:
    pass  # inserted to fix indentation error
full_path = WORKSPACE_DIR.joinpath(path).resolve()
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path": str(full_path)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write file: {e}"}
def list_files_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_files")
try:
    pass  # inserted to fix indentation error
base_path = WORKSPACE_DIR.joinpath(path).resolve()
if not base_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a directory: {path}"}
items = []
for item in base_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "file",
"size_bytes": item.stat().st_size if item.is_file() else None,
"last_modified": datetime.fromtimestamp(item.stat().st_mtime, tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(base_path), "contents": items}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing files in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list files: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int = WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int = WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.find_all(class_='g'):
r = g.find('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.find('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_file(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES) -> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log file not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_file": str(LOG_FILE), "content": content, "lines_read": len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log file {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log file: {e}"}
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp": datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count, "packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count, "packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str, context_code: Optional[str] = None) -> Dict:
agent.log.warning(f"Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a complete function/class definition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '' and end with ''.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "generated_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
return agent.self_modification_unit.validate_code_modification_UNSAFE(code_to_validate)
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec: int = 30) -> Dict:
agent.log.warning(f"Executing shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s. Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str, content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value, content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id, "message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
class SelfModificationTools:
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref: 'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
self.dmp = dmp_module.diff_match_patch()
self.log.info(f"Self-Modification Unit initialized. Code Dir: {self.agent_code_dir}, Backup Dir: {self.backup_dir}")
def _resolve_target_path(self, target_file_rel: str) -> Path:
target_path_abs = (self.agent_code_dir / target_file_rel).resolve()
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
self.log.warning(f"Inspecting code for component: {component_name}")
target_obj = None
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
candidate_modules = [sys.modules.get('__main__'), sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod, component_name)):
    pass  # inserted to fix indentation error
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
file_path = inspect.getfile(target_obj)
return {"status": "success", "component_name": component_name, "file_path": file_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module, class, or function defined in a file.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
return {"status": "error", "error": f"Component '{component_name}' not found or source code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModificationError))
def propose_code_modification_UNSAFE(self, component_name: str, issue_description: str, proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
self.log.warning(f"Proposing code modification for {component_name}. Issue: {issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for {component_name} to propose modification. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
{current_code_snippet}
Generate the modified Python code for the specified component.
Provide ONLY the complete, new Python code block for the modified function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '' and end with ''.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "proposed_code": None}
code_match = re.search(r"\s*([\s\S]+?)\s*", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name, "proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modification for {component_name}: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modification_UNSAFE(self, code_to_validate: str) -> Dict:
self.log.warning(f"Validating proposed code snippet ({code_to_validate[:100]}...)")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modification_UNSAFE(self, component_name: str, new_code: str, target_file_path: Optional[str]=None) -> Dict:
self.log.critical(f"Attempting to apply code modification to component '{component_name}'. THIS IS HIGHLY RISKY.")
try:
    pass  # inserted to fix indentation error
if not target_file_path:
    pass  # inserted to fix indentation error
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('file_path'):
    pass  # inserted to fix indentation error
target_file_path = inspection_res['file_path']
else:
    pass  # inserted to fix indentation error
target_file_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_file = Path(target_file_path)
if not target_file.exists() or not target_file.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Target file for modification not found: {target_file}"}
original_code = target_file.read_text()
backup_path = SELF_MOD_BACKUP_DIR / f"{target_file.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_file, backup_path)
self.log.info(f"Backed up original file to {backup_path}")
pattern_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
pattern_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modified_original_code = original_code
found_and_replaced = False
match_class = re.search(pattern_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(pattern_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not find component '{component_name}' in {target_file} for replacement. Modification aborted.")
return {"status": "error", "error": f"Component '{component_name}' definition not found for replacement."}
target_file.write_text(modified_original_code)
self.log.warning(f"Code modification applied to {target_file}. Agent restart is LIKELY REQUIRED for changes to take effect.")
self.agent_ref.self_model.add_event_log(f"Applied code modification to {component_name}. Restart pending for full effect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}_modified_pending_restart"] = True
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": f"Code for '{component_name}' in '{target_file}' modified. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modification to {component_name}: {e}", exc_info=True)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_file)
self.log.info(f"Restored original file {target_file} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modification: {e}. System might be unstable."}
def rollback(self, backup_file: Path, target_file: Path):
self.log.info(f"Attempting to rollback '{target_file}' from '{backup_file}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_file, target_file)
self.log.info(f"Successfully rolled back '{target_file}'.")
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_file}.")
self.agent_ref.self_model.beliefs[f"component_{target_file.name}_modified_pending_restart"] = False
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_file.name)
return {"status": "success", "message": f"Rolled back {target_file}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_file}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_file_rel: Union[str, Path]):
target_module_name = Path(target_file_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is required.")
return
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
if _agent_instance_hack and hasattr(sys.modules[target_module_name], 'CognitiveSystem'):
    pass  # inserted to fix indentation error
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for changes to take effect.")
def inspect_directives_UNSAFE(self) -> Dict:
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modification_UNSAFE(self, analysis_of_misalignment: str, proposed_directive_changes_desc: str) -> Dict:
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (float 0-1), "last_eval_score" (float 0-1, usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational', 'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024, temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in proposed_directives):
    pass  # inserted to fix indentation error
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"LLM indicated error during directive proposal: {proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modification_UNSAFE(self, new_directives: List[Dict]) -> Dict:
self.log.warning(f"Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modification_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count: {len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
_self_mod_tools_container = None
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, agent)
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in name.upper():
    pass  # inserted to fix indentation error
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func) or inspect.ismethod(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
def __init__(self, state: Optional[Dict]=None, agent_directives_config: Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_config if agent_directives_config is not None else DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_confidence: Dict[str, float] = {}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
self.learning_goals: List[Dict[str, Any]] = []
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.learned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_confidence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted", sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_confidence = sm_state.get("skill_confidence", self.skill_confidence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary", self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies", self.adaptation_strategies)
self.learned_abstractions = sm_state.get("learned_abstractions", self.learned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative", self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs", self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_confidence": self.skill_confidence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"learned_abstractions": self.learned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
def add_event_log(self, event_description: str, event_type: str = "info", data: Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
for tool_name in self.capabilities:
if tool_name not in self.skill_confidence:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = 0.5
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.", event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8:
    pass  # inserted to fix indentation error
hint = " (Reliability: High)"
elif score > 0.6:
    pass  # inserted to fix indentation error
hint = " (Reliability: Moderate)"
elif score > 0.3:
    pass  # inserted to fix indentation error
hint = " (Reliability: Low)"
else:
    pass  # inserted to fix indentation error
hint = " (Reliability: Very Low/Untested)"
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict, success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
current_confidence = self.skill_confidence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = min(1.0, current_confidence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = max(0.0, current_confidence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability: {stats['reliability_score']:.2f}, Confidence: {self.skill_confidence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_confidence_drift(sm: 'SelfModel') -> Optional[str]:
low_confidence_skills = [skill for skill, conf in sm.skill_confidence.items() if conf < 0.25 and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_confidence_skills) >= 2 :
    pass  # inserted to fix indentation error
return f"Multiple critical skills have very low confidence and recent failures: {', '.join(low_confidence_skills)}. Consider skill improvement or alternative strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict):
    pass  # inserted to fix indentation error
return None
low_eval_directives = []
for d in sm.core_directives:
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {', '.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count} with max replans. Planning or execution effectiveness may be compromised. Review strategy or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_confidence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}): {anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}", event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__') else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {'; '.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0), reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_confidence:
    pass  # inserted to fix indentation error
confident_skills = [s for s,c in self.skill_confidence.items() if c > 0.7][:3]
summary += f"Confident Skills (sample): {', '.join(confident_skills) if confident_skills else 'None highly confident'}\n"
summary += f"Internal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools:
    pass  # inserted to fix indentation error
summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
if unreliable_tools:
    pass  # inserted to fix indentation error
summary += f" Needs Improvement: {', '.join([t[0] for t in unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
base_prompt = """Analyze your recent performance, knowledge, internal state, and alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:"""
output_keys_example = [
"`reflection_summary` (str: Overall summary of the reflection period).",
"`key_successes` (list of str: Specific achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Specific setbacks or difficulties encountered).",
"`learned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identified` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool effectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g., 'curious', 'frustrated', 'satisfied').",
"`resource_usage_concerns` (str or null: Any concerns about computational resource usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_float_0_to_1: How well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes, provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model? What needs improvement?).",
"`new_learning_goals` (list of str: Specific goals for future learning or skill development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring issues or improve performance).",
"`self_modification_needed` (str or null: If parts of your own code/logic need modification, describe what and why. Be very specific and cautious.)."
]
full_prompt = base_prompt + "\n" + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives, indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n" + \
f"Recent Tool Outcomes (last 5 entries):\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment: {assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_reflection(self, reflection_data: Dict) -> Tuple[bool, bool]:
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from reflection data...")
if reflection_data.get('reflection_summary'):
    pass  # inserted to fix indentation error
self.internal_state_narrative = reflection_data['reflection_summary']
updated_self = True
core_directives_eval = reflection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (float, int)) and 0.0 <= eval_score <= 1.0:
    pass  # inserted to fix indentation error
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...' evaluation score to {eval_score:.2f}")
if updated_self:
    pass  # inserted to fix indentation error
self.add_event_log("Directive evaluation scores updated from reflection.")
suggested_directive_updates = reflection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Reflection suggested updates to core directives: {str(suggested_directive_updates)[:200]}...")
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modifications from reflection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source": "self_reflection"}
)
updated_self = True
self.add_event_log("Reflection suggested directive updates. Metacognitive review goal created.", event_type="critical_review_needed")
if isinstance(reflection_data.get('new_learning_goals'), list):
    pass  # inserted to fix indentation error
for lg_str in reflection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts": datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
if isinstance(reflection_data.get('adaptation_strategy_proposals'), list):
    pass  # inserted to fix indentation error
for strat_str in reflection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated adaptation strategies. Total: {len(self.adaptation_strategies)}")
if reflection_data.get('learned_facts') or reflection_data.get('prompt_tuning_suggestions'):
    pass  # inserted to fix indentation error
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from reflection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
backup_file = SELF_MOD_BACKUP_DIR / f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_file.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_file} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_officer"]
dialog_history = []
full_dialog_str = f"Internal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts, questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution": contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective {perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
self.add_event_log(f"Internal dialog simulated on '{topic}'.", data={"dialog": full_dialog_str})
return full_dialog_str
class MotivationEngine:
def __init__(self, drive_configs: Optional[Dict[str, Any]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[str, Any] = {}
self._initialize_drives(drive_configs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_configs: Optional[Dict[str, Any]]):
default_configs = {
"CURIOSITY": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"MASTERY": {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.6},
"ACHIEVEMENT": {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.4},
"NOVELTY_SEEKING": {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.7},
"PRESERVATION": {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.2},
"EFFICIENCY": {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"SOCIAL_INTERACTION": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.3},
}
configs = drive_configs if drive_configs is not None else default_configs
for drive_type_str, config in configs.items():
self.drives[drive_type_str] = DriveState(
drive_type=drive_type_str,
level=config.get("initial_level", 0.5),
decay_rate=config.get("decay_rate", 0.01),
max_level=config.get("max_level", 1.0),
min_level=config.get("min_level", 0.0)
)
def update_drives(self):
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "learn":
    pass  # inserted to fix indentation error
self.drives["CURIOSITY"].update(stimulus=-0.05)
self.drives["MASTERY"].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives["ACHIEVEMENT"].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives["PRESERVATION"].update(stimulus=0.1)
self.drives["MASTERY"].update(stimulus=-0.05)
def get_drive_level(self, drive_type: str) -> float:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
def get_all_drive_levels(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[str, float]]:
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == "CURIOSITY":
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == "MASTERY":
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == "ACHIEVEMENT":
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == "PRESERVATION":
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == "EFFICIENCY":
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: str
level: float
decay_rate: float = 0.01
max_level: float = 1.0
min_level: float = 0.0
last_update_time: float = field(default_factory=time.time)
def update(self, stimulus: float = 0.0):
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class MessageType(Enum):
QUERY = "QUERY"
RESPONSE = "RESPONSE"
INFORM = "INFORM"
REQUEST_ACTION = "REQUEST_ACTION"
HEARTBEAT = "HEARTBEAT"
ERROR = "ERROR"
class FileChannel:
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_file = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_file}")
def _write_message_to_file(self, message: Message, target_file: Path) -> bool:
try:
    pass  # inserted to fix indentation error
with FileLock(str(target_file) + ".lock", timeout=5):
messages = []
if target_file.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
existing_content = target_file.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {target_file}: {e}. Clearing file.")
messages = []
messages.append(message.to_dict())
target_file.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_file}. Message not sent to {message.receiver_id}.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_file}: {e}")
return False
def _read_messages_from_file(self, source_file: Path) -> List[Message]:
messages = []
if not source_file.exists():
    pass  # inserted to fix indentation error
return messages
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_file) + ".lock", timeout=5):
content = source_file.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if isinstance(msg_data, dict)]
source_file.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_file}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {source_file}: {e}. Clearing file.")
try:
    pass  # inserted to fix indentation error
source_file.write_text("", encoding='utf-8')
except Exception as e_write:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to clear corrupted message file {source_file}: {e_write}")
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_file}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}: {message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_file(message, target_inbox)
def receive_messages(self) -> List[Message]:
new_messages = self._read_messages_from_file(self.inbox_file)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message], Optional[Message]]):
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
messages = self.receive_messages()
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From: {msg.sender_id}")
handled = False
try:
    pass  # inserted to fix indentation error
msg_type_enum = MessageType(msg.type)
if msg_type_enum in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg_type_enum]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler {handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id, receiver_id=msg.sender_id, type=MessageType.ERROR.value, content={"original_message_id": msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type {msg.type}. Message ID {msg.id} unhandled.")
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Received unknown message type: {msg.type}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', config: Dict):
self.id = id
self.embodiment = embodiment
self.config = config
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
pass
class Actuator(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], config: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.config = config
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
pass
class VirtualEmbodiment:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to 'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button", "research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, reconfigurable bay designed for running complex simulations. Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_config_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data flow and storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core. Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20:
    pass  # inserted to fix indentation error
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An undefined space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) -> Dict:
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params: {params}")
params = params or {}
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as specified."
env_details = self.environment_map.get(self.location, {})
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console":
    pass  # inserted to fix indentation error
message += " It shows fluctuating green and amber lights."
elif target == "core_status_monitor":
    pass  # inserted to fix indentation error
message += " It indicates: Core Nominal. Directives Stable. Learning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name", "default_physics_test"), params.get("config",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result: {sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if action_type=="move" else None, "updated_inventory": self.state["inventory"] if action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "learn"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response: {self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model <topic>'."
def _run_simulation(self, sim_name: str, config: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with config: {config}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_config" in config:
    pass  # inserted to fix indentation error
success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric: {outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check configuration."
def summary(self) -> str:
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Internal State (summary): Energy={self.state['energy']}, Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time: float = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE, LAST_LEARNING_MODULE_UPDATE_CYCLE
start_time = time.time()
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status: {self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if self.agent.state['goals'].get('active') else None
self.agent.last_error = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
if self.agent.self_model and (self.agent.cycle_count - LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering proactive metacognitive check (Cycle {self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
if self.agent.learning_module and (self.agent.cycle_count - LAST_LEARNING_MODULE_UPDATE_CYCLE >= LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.learn_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation: {ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
def get_priority_val(goal_dict):
p = goal_dict.get('priority', 'MEDIUM')
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_list.sort(key=get_priority_val, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type == "active_goal_continue":
    pass  # inserted to fix indentation error
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution: {goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID: {goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal' provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or current_goal_obj.replan_count > 0:
    pass  # inserted to fix indentation error
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"No plan available or generated for goal: {current_goal_obj.goal[:50]}. Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = True
global LAST_DELIBERATION_TIME
if time.time() - LAST_DELIBERATION_TIME > IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
self.log.info("Performing idle deliberation...")
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModificationError, LogicError, LLMError, ConfigurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
LearningError) as agent_cycle_err:
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
finally:
    pass  # inserted to fix indentation error
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() - start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent understanding of the current situation. Identify key entities, events, and any significant changes in the environment or your internal state. Focus on information relevant to achieving current goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content: {str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\": \"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"], \"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation", understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event", metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry, persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
return {"summary": understanding_summary, "processed_info": processed_info, "raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError, DeliberationError))
def _deliberate(self, understanding_result: Dict) -> Dict:
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio: {pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio: {active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time': datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack (paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal generation.")
if time.time() - LAST_DELIBERATION_TIME >= IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_learn", "directive_curiosity", "directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
return decision
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output: {sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
self_model_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No specific understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact', 'None identified.')
interp_con_val = understanding_result.get('interpretation_confidence', 0.7)
recent_memory_context = self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary, max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Confidence: {interp_con_val:.2f}):** {understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identified:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory (STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]], indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else active_goal_dict.get('goal')[:100] + '... (ID: ' + str(active_goal_dict.get('id')) + ')'}",
f"* **Agent Core Directives (Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding, drives, memories, goals, directives), what is the most critical aspect demanding attention or the best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/complete).",
"    - Performing `reflection` or `self_assessment` (if mandatory timers, drives like low CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration goal), Directives (e.g., low-eval directive -> improvement goal), or identified opportunities. New goals require `goal` (str), `priority` (float 0.0-1.0), `origin` (str e.g., 'drive_curiosity', 'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for viability before committing if uncertainty is high or consequence severe (briefly note simulation outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the *immediate next cycle*. Justify your choice especially if it deviates from obvious triggers, high drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list. If selecting an existing pending goal it moves to `next_goal` and is removed from pending internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal', 'new_goal', 'reflection', 'self_assessment', 'external_command_action', 'idle', 'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass structure) selected for immediate execution. Null if idle/reflection/assessment without a direct goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into `new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into `new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent. Analyze the situation comprehensively, consider drives and directives, and make strategic decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON: {extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal', 'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys: {deliberation_decision.keys()}")
if key == 'new_pending_goals':
    pass  # inserted to fix indentation error
deliberation_decision[key] = []
elif key == 'next_goal':
    pass  # inserted to fix indentation error
deliberation_decision[key] = None
else:
    pass  # inserted to fix indentation error
deliberation_decision[key] = "Error: Missing from LLM Output"
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not isinstance(deliberation_decision.get('next_goal'), dict):
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value: {deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and new_goal_dict.get('priority'):
    pass  # inserted to fix indentation error
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p['id'] == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
current_pending_list.append(new_goal_obj.to_dict())
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal: {new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
current_active_goal_obj = self.agent.get_active_goal_object()
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending', []) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
selected_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
deliberation_decision['next_goal'] = selected_goal_obj.to_dict()
self.log.info(f"Moved pending goal {selected_goal_obj.id} ('{selected_goal_obj.goal[:50]}') to active.")
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
highest_priority_pending.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
deliberation_decision['next_goal'] = highest_priority_pending.to_dict()
self.log.info(f"Deliberation chose 'pending_goal' without specific ID; moved highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals available. Idling.")
action_type = "idle"
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM selected pending goal by ID but not found or invalid. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj.to_dict()
self.log.info(f"Deliberation created and activated new goal: {new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal_obj.to_dict()
current_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = current_active_goal_obj.to_dict()
self.log.info(f"Deliberation chose to resume current active goal: {current_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 'reflection', 'self_assessment', 'external_command_action']:
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
current_active_goal_obj.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal_obj.goal[:30]}' PAUSED due to {action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal_obj.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal_obj.to_dict())
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal_obj.id} to pending as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action: {deliberation_decision.get('chosen_action_type')}. Reason: {deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps: {len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id, "plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params, current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
internal_state_after=self.agent.self_model.beliefs
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
final_status = tool_result.get("status", "unknown")
if final_status == "success":
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = final_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing finished by report_result. Status: {final_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error', 'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj, tool_result, self.agent.cognitive_cycle.perception_module.perceive()[0] if self.agent.cognitive_cycle.perception_module.perceive() else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal will likely fail.")
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without 'report_result'. Goal might be incomplete.")
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] == current_goal_obj.id:
    pass  # inserted to fix indentation error
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}': {e}", exc_info=True)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) -> float:
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
self.agent_id = AGENT_NAME
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
self.learning_module: LearningModule
self.planning_module: PlanningModule
self.motivation_engine: MotivationEngine
self.self_modification_unit: SelfModificationTools
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.playwright_instance: Optional[Any] = None
self.playwright_browser: Optional[Any] = None
self.playwright_context: Optional[Any] = None
self.playwright_page: Optional[Any] = None
self.state['flags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete --- Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled: {ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modification Enabled: {ENABLE_SELF_MODIFICATION}")
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}", exc_info=True)
self.shutdown()
raise ConfigurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
self.self_modification_unit = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, self)
_init_self_mod_tools(self, self.tool_manager)
self._update_status("Initializing SystemCore Modules")
self.learning_module = LearningModule(self)
self.motivation_engine = MotivationEngine()
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME, shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager:
    pass  # inserted to fix indentation error
self.tool_manager.check_playwright_browsers()
self.log.info("Agent component initialization finished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list):
    pass  # inserted to fix indentation error
state['goals'][key] = []
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
state.setdefault('goal_stack', [])
state.setdefault('flags', {})
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state file {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state file {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
"recent_failures_summary": [],
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"flags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
if self.self_model:
    pass  # inserted to fix indentation error
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status
else:
    pass  # inserted to fix indentation error
self.state['last_status'] = self._status
try:
    pass  # inserted to fix indentation error
temp_file = STATE_FILE.with_suffix(STATE_FILE.suffix + ".tmp")
with temp_file.open('w', encoding='utf-8') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_file, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict: {active_goal_dict}")
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority = GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict, final_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID: {goal_data_dict.get('id')}) with status: {final_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
try:
    pass  # inserted to fix indentation error
goal_obj.status = GoalStatus(final_status_str)
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid status '{final_status_str}' for archiving goal. Defaulting to FAILED.")
goal_obj.status = GoalStatus.FAILED
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status": str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count": goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and current_active_in_state.get('id') == active_goal_id:
    pass  # inserted to fix indentation error
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID: {active_goal_id}) concluded with status: {final_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal', 'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal: {parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
self.log.info("Goal archived. No parent goal to resume from stack or current goal was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized":
    pass  # inserted to fix indentation error
self._update_status("Idle")
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle: {loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
updated_active_goal_dict = self.state['goals'].get('active')
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] == active_goal_data_before_cycle['id']:
    pass  # inserted to fix indentation error
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED, GoalStatus.CANCELLED]:
    pass  # inserted to fix indentation error
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in [GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
    pass  # inserted to fix indentation error
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
if self._should_reflect(active_goal_data_before_cycle):
    pass  # inserted to fix indentation error
self._reflect_on_performance()
if self.state['flags'].get('re_evaluate_strategy_needed'):
    pass  # inserted to fix indentation error
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to significant internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['flags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() - LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_reflect(self, processed_goal_data: Optional[Dict]) -> bool:
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in [GoalStatus.COMPLETED, GoalStatus.FAILED]:
    pass  # inserted to fix indentation error
goals_processed_key = "goals_processed_since_reflection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >= int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
    pass  # inserted to fix indentation error
return True
if time.time() - LAST_REFLECTION_TIME > MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
    pass  # inserted to fix indentation error
return True
if self.state['flags'].get('explicit_reflection_requested'):
    pass  # inserted to fix indentation error
return True
return False
@retry(attempts=2, delay=5)
def _reflect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Reflecting on Performance ---")
self._update_status("Reflecting")
LAST_REFLECTION_TIME = time.time()
self.state['flags']['explicit_reflection_requested'] = False
self.state["goals_processed_since_reflection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt, max_new_tokens=2048, temperature=0.5)
reflection_data = extract_json_robust(llm_assessment_str)
if reflection_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"Failed to get valid JSON from LLM self-assessment: {reflection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed: {reflection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_reflection(reflection_data)
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(reflection_data.get('learned_facts'), list):
    pass  # inserted to fix indentation error
for fact_str in reflection_data['learned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
self.log.info(f"Added {len(reflection_data['learned_facts'])} learned facts to memory from reflection.")
if isinstance(reflection_data.get('prompt_tuning_suggestions'), list):
    pass  # inserted to fix indentation error
for sugg_str in reflection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(reflection_data['prompt_tuning_suggestions'])} prompt suggestions to memory.")
if reflection_data.get('self_modification_needed'):
    pass  # inserted to fix indentation error
mod_desc = reflection_data['self_modification_needed']
self.log.warning(f"Reflection identified need for self-modification: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modification based on reflection: {mod_desc}",
priority=GoalPriority.HIGH,
context={"modification_description": mod_desc, "source": "self_reflection"}
)
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) == 0:
    pass  # inserted to fix indentation error
audit_issues = []
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identified issues: {audit_issues}")
self._create_metacognitive_goal(f"Address directive audit findings: {str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Reflection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during reflection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during reflection: {e}", exc_info=True)
finally:
    pass  # inserted to fix indentation error
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY, self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM, self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}: {message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base'][query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample": str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id, type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}: {message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if RESOURCE_MONITOR:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize resource monitor: {e}")
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER = PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
if not PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright page: {e}")
if PLAYWRIGHT_CONTEXT:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_CONTEXT.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright context: {e}")
if PLAYWRIGHT_BROWSER:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_BROWSER.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright browser: {e}")
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE.stop()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error stopping Playwright instance: {e}")
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not self.playwright_context :
    pass  # inserted to fix indentation error
return
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing old Playwright page during reset: {e}")
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def shutdown(self):
if self._status == "Shutting Down":
    pass  # inserted to fix indentation error
return
self.log.warning(f"--- {AGENT_NAME} Shutdown Sequence Initiated ---")
self._update_status("Shutting Down")
STOP_SIGNAL_RECEIVED.set()
self.save_state()
if self.memory_system:
    pass  # inserted to fix indentation error
self.memory_system.save_all_memory_stores()
self._shutdown_playwright()
if self.memory_system and self.memory_system.relational_conn:
    pass  # inserted to fix indentation error
self.memory_system.relational_conn.close()
self.log.info("--- Agent Shutdown Complete ---")
logging.shutdown()
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl} Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/"
f"{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)'}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_file", priority=GoalPriority.HIGH).to_dict()
except Exception as e_cmd_file:
    pass  # inserted to fix indentation error
print(f"Error reading initial command file: {e_cmd_file}", file=sys.stderr)
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending', []).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort, reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal'][:50]}' added to pending goals.")
main_agent_instance.run()
except ConfigurationError as cfg_err_main:
    pass  # inserted to fix indentation error
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}", file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to ConfigurationError: {cfg_err_main}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to ConfigurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}", file=sys.stderr)
traceback.print_exc(file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main: {main_exec_err}", exc_info=True)
exit_code = 1
finally:
    pass  # inserted to fix indentation error
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main finally block...")
if hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main finally block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
log.warning("Agent instance likely not created or fully initialized. Basic shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
```python
chromadb = None
dmp_module = None
if LLM_MODEL_NAME_OR_PATH == "gpt2" and "GEMINI_API_KEY" not in os.environ and \     os.getenv("LLM_MODEL") is None and "gemini" not in DEFAULT_LLM_MODEL.lower():      print("\n" + "="*80, fle=sys.stderr)      print("CRITICAL WARNING: LLM model not confgured or using fallback 'gpt2'.", fle=sys.stderr)      print("You MUST set the 'LLM_MODEL' environment variable to a capable instructionfollowing model", fle=sys.stderr)      print("(e.g., from Hugging Face like Mistral, Llama) OR ensure GEMINI_API_KEY is set for  Gemini.", fle=sys.stderr)      print("Proceeding with 'gpt2' (if LLM_MODEL is not set) or specifed LLM_MODEL, but  advanced features may be severely limited.", fle=sys.stderr)      if LLM_MODEL_NAME_OR_PATH == "gpt2" and os.getenv("LLM_MODEL") is None:          print("Agent may not function correctly with 'gpt2'. It is strongly recommended to  confgure a larger model or use 'mock'.", fle=sys.stderr)      print("="*80 + "\n", fle=sys.stderr)
    pass  # inserted to fix indentation error
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")  GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
elif "1.0" in LLM_MODEL_NAME_OR_PATH:          _default_context_len = 32_768  elif TRANSFORMERS_AVAILABLE and LLM_MODEL_NAME_OR_PATH = "mock" and  AutoConfg:      try:          confg = AutoConfg.from_pretrained(LLM_MODEL_NAME_OR_PATH,  trust_remote_code=True)          _default_context_len = getattr(confg, 'max_position_embeddings', _default_context_len)      except Exception as e:          print(f"War ning: Failed to detect LLM context length ({e}). Using default:  {_default_context_len}", fle=sys.stderr)  MAX_LLM_CONTEXT_TOKENS = int(os.getenv("MAX_LLM_CONTEXT_TOKENS",  _default_context_len))  MAX_TOOL_RESULT_LENGTH = int(os.getenv("MAX_TOOL_RESULT_LENGTH", 5000))  MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)  MAX_MEMORY_RESULTS = 7
    pass  # inserted to fix indentation error
_agent_instance_hack: Optional['AutonomousAgent'] = None
file_formatter = logging.Formatter(                  f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:% (task_name_override)s] %(message)s",                  datefmt='%Y-%m-%d %H:%M:%S'              )              fle_handler.setFormatter(fle_formatter)              logger.addHandler(fle_handler)          except Exception as e:              print(f"Error setting up fle logger: {e}", fle=sys.stderr)                    logger.propagate = False
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,                                              LLMError, MemoryError, SelfModifcationError,                                              PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,                                              SimulationError, CommunicationError, EmbodimentError),             log_fn=get_logger):      def decorator(fn):          @wraps(fn)          def wrapper(*args, **kwargs):              logger_retry = log_fn(f"{fn.__name__}_retry")              last_exception = None              for i in range(1, attempts + 1):                  if STOP_SIGNAL_RECEIVED.is_set():                      logger_retry.war ning(f"Stop signal received during retry of {fn.__name__}. Aborting  retry.")                      raise AgentError(f"Stop signal received during retry of {fn.__name__}.")                  try:                      return fn(*args, **kwargs)                  except retry_on as e:                      if isinstance(e, (CodeGenerationError, SelfModifcationError, SecurityError,                                         LogicError, ConfgurationError, RecursionDepthError)) and type(e) not in  retry_on:                          logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}:  {e}", exc_info=False)                          raise e                      last_exception = e                      logger_retry.war ning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error:  {type(e).__name__}: {str(e)[:200]}", exc_info=False)                      if i == attempts:                          logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error:  {type(e).__name__}: {e}", exc_info=True)                          break                      sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)                      logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")                      time.sleep(sleep_time)                  except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,                           CommunicationError, EmbodimentError, Lear ningError, SafetyViolationError) as  non_retriable_e:                      logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in  {fn.__name__}: {non_retriable_e}.", exc_info=False)                      raise non_retriable_e                  except Exception as unexpected_e:
else:                          logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}:  {unexpected_e}", exc_info=True)                          raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error:  {unexpected_e}") from unexpected_e              if last_exception is None:
    pass  # inserted to fix indentation error
except json.JSONDecodeError as e_md:              log_json_extract.war ning(f"Found JSON in markdown, but failed to parse: {e_md}. Full  text: {json_str[:200]}...")              pass
    pass  # inserted to fix indentation error
if self.__class__ is other.__class__:              return self.value < other.value          return NotImplemented      def __str__(self): return self.name  @dataclass  class Goal:      id: str = feld(default_factory=lambda: f"goal_{uuid.uuid4()}")      goal: str
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
class ActionEffect(TypedDict):      action: SimulatedAction      prev_state: SimulatedState      next_state: SimulatedState      outcome_description: str      error_generated: Optional[str]      is_critical_error: bool
# REMOVED MOCK CLASS(BaseLLMWrapper):      def _initialize_model(self):          self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)              mock_directives[0]['weight'] = 0.95
generation_confg=genai.types.GenerationConfg(**generation_confg_params)
inputs,              max_new_tokens=max_new_tokens,              temperature=temperature,              do_sample=True if temperature > 0 else False,              pad_token_id=self.tokenizer.eos_token_id,
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
self.MAX_BUFFER_SIZE = 1000      def add_experience(self, experience: Experience):          """Adds an experience to the buffer for later learning."""          self.experiences_buffer.append(experience)          if len(self.experiences_buffer) > self.MAX_BUFFER_SIZE:              self.experiences_buffer.pop(0)
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual",  "content": abstraction_str, "source": "ssl_learning"})                      if llm_analysis.get("new_concepts"):                          self.log.info(f"SSL (LLM-guided) identifed new_concepts:  {llm_analysis['new_concepts']}")                          for concept_str in llm_analysis['new_concepts']:                              kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}",  metadata={"source": "ssl_learning", "sub_type": "concept"})                              self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,  persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])                  else:                      self.log.war ning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")              except Exception as e:                  self.log.error(f"Error during LLM-guided SSL: {e}")              self.log.info("SSL (conceptual) processing complete.")      def get_lear ned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:          """Suggests an action based on lear ned policy (conceptual)."""          if self.rl_policy:
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown  error')}"              self.log.war ning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
self_summary =  self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)          tool_description = self.agent.tool_manager.get_tool_description_for_llm()          world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else  "World state: Information might have changed due to recent actions."
self.log = get_logger("SAFETY")      def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) ->  Tuple[bool, str]:          """          Checks if a proposed action is safe and ethically aligned.          Retur ns (is_safe, justifcation_or_war ning_string).          """          self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
self.log.war ning(war ning)                  return False, war ning
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:  {len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")                  else:                      self.graph_store = nx.MultiDiGraph()
type TEXT,                  source_reliability REAL,                  creation_ts TEXT,                  last_accessed_ts TEXT,                  access_count INTEGER DEFAULT 0,                  utility_score REAL DEFAULT 0.5,                  concepts TEXT -- JSON list of strings                        """
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
results = []              for id, data in self.dict_vector_store.items():
for node_id in start_nodes:
rows = cursor.fetchall()
pass
continue                            full_module_name = f"dynamic_tools.{module_name}"
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)                          p_str += f": {type_hint}"                      if p.default = inspect.Parameter.empty:                          p_str += f" = {p.default!r}"                      params_list.append(p_str)                  param_str = f" ({', '.join(params_list)})" if params_list else ""                  safety_note = ""                  if "UNSAFE" in name.upper() or name in ["generate_and_load_tool",  "propose_self_modifcation_UNSAFE", "validate_self_modifcation_UNSAFE",  "apply_code_modifcation_UNSAFE", "apply_directive_modifcation_UNSAFE",  "execute_shell_command_UNSAFE"]:                      safety_note = " **(HIGH RISK)**"                                    reliability_hint = ""                  if self.agent and self.agent.self_model:                      reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)                  desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {frst_line}\n"              except Exception as e:
'tool_name': tool_name, 'params': params, 'validated_params': {},                      'duration_sec': 0, 'step_info': current_step_info,                      'error_type': "SafetyViolationError", 'execution_successful': False                  }              }
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in  func_params_spec.values()):                      result = func_to_call(**validated_params)                  else:                      known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}                      result = func_to_call(**known_args)                            duration = time.time() - start_time              if not isinstance(result, dict):
    pass  # inserted to fix indentation error
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",                  "raw_error_details": str(e),                  "_exec_info": {                      'tool_name': tool_name, 'params': params, 'validated_params': validated_params,                      'duration_sec': round(duration, 2), 'step_info': current_step_info,                      'error_type': exc_type, 'execution_successful': False                  }              }
This tool is now more of a declarative intent for the planner/deliberator.          """          log_sub = get_logger("TOOL_execute_sub_goal")          if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:              msg = f"Cannot initiate sub-goal: Max recursion depth ({GOAL_STACK_MAX_DEPTH})  reached."              log_sub.error(msg)              return {"status": "error", "error_type": "RecursionDepthError", "error": msg}                    current_active_goal_dict = agent.state.get('goals', {}).get('active')          if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):              msg = "Cannot initiate sub-goal: No active parent goal found in state or parent goal is  not a dict."              log_sub.error(msg)              return {"status": "error", "error_type": "LogicError", "error": msg}                    try:              priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else  GoalPriority.MEDIUM          except KeyError:              priority_enum = GoalPriority.MEDIUM              log_sub.war ning(f"Invalid priority '{priority}' for sub-goal. Defaulting to MEDIUM.")          sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')} _{uuid.uuid4()}"          sub_goal_data = Goal(              id=sub_goal_id,              goal=goal,              status=GoalStatus.PENDING,
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,  type_flter=type_flter)          elif memory_type == "graph":
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \             not str(full_path).startswith(str(AGENT_CODE_DIR)):              log_tool.error(f"Security: Attempt to read fle '{path}' outside of workspace or agent  code directory denied.")              raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")                    if not full_path.is_fle():              return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found:  {path}"}                    content = full_path.read_text(encoding='utf-8', errors='replace')          truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) >  MAX_TOOL_RESULT_LENGTH else '')          return {"status": "success", "content": truncated_content, "full_path": str(full_path),  "fle_size_bytes": len(content)}      except SecurityError as se:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a  directory: {path}"}                    items = []          for item in full_path.iterdir():              items.append({                  "name": item.name,                  "type": "directory" if item.is_dir() else "fle",                  "size_bytes": item.stat().st_size if item.is_fle() else None,                  "last_modifed": datetime.fromtimestamp(item.stat().st_mtime,  tz=timezone.utc).isoformat()              })
return {"status": "error", "error": f"Playwright error: {pe}"}          except Exception as e:              log_tool.error(f"Error browsing {url}: {e}", exc_info=True)              agent._try_reset_playwright_page()
all_lines = f.readlines()
except Exception as e:          log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")          return {"status": "error", "error": f"Failed to send ping: {e}"}  def generate_python_code_UNSAFE(agent: 'AutonomousAgent', description: str,  context_code: Optional[str] = None) -> Dict:      """Generates new Python code based on a description and optional context."""      if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code  generation tool is disabled."}      agent.log.war ning(f"UNSAFE: Generating Python code based on description: {description}")            prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a  complete function/class defnition based on the following description.  Description: {description}  Context Code (if any, for reference):  ```python  {context_code or 'None'}  ```  Generate ONLY the Python code block. Start with '```python' and end with '```'.  If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.  """      try:          llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,  temperature=0.5)          if "NO_CODE_GENERATED" in llm_response:              return {"status": "partial_success", "message": "LLM determined no code can be  generated.", "generated_code": None}          code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)          if code_match:              generated_code = code_match.group(1).strip()              return {"status": "success", "generated_code": generated_code}          else:              agent.log.war ning(f"LLM did not return a valid code block for code generation.  Response: {llm_response[:200]}")              return {"status": "error", "error": "LLM failed to generate code in the expected format."}      except Exception as e:          agent.log.error(f"Error during code generation: {e}", exc_info=True)          return {"status": "error", "error": f"LLM call failed during code generation: {e}"}  def validate_python_code_UNSAFE(agent: 'AutonomousAgent', code_to_validate: str) -> Dict:      """Validates Python code for syntax correctness."""      if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code  generation tool is disabled."}      return agent.self_modifcation_unit.validate_code_modifcation_UNSAFE(code_to_validate)
    pass  # inserted to fix indentation error
except Exception as e:          log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)          return {"status": "error", "error": f"Unexpected error: {e}"}
    pass  # inserted to fix indentation error
Component to modify: {component_name}  Issue Description: {issue_description}  Desired Change: {proposed_change_description}  Current Code Snippet (or relevant part):  ```python  {current_code_snippet}  ```  Generate the modifed Python code for the specifed component.  Provide ONLY the complete, new Python code block for the modifed function/class.  Ensure the code is syntactically correct and addresses the issue/desired change.  Do not include explanations before or after the code block.  Start with '```python' and end with '```'.  If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.  """          try:              llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,  temperature=0.3)              if "NO_CODE_GENERATED" in llm_response:                  return {"status": "partial_success", "message": "LLM determined no code can be  generated.", "generated_code": None}              code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)              if code_match:                  proposed_code = code_match.group(1).strip()                  return {"status": "success", "component_name": component_name,  "proposed_code": proposed_code}              else:                  self.log.war ning(f"LLM did not return a valid code block for code generation.  Response: {llm_response[:200]}")                  return {"status": "error", "error": "LLM failed to generate code in the expected  format."}          except Exception as e:              self.log.error(f"Error proposing code modifcation for {component_name}: {e}",  exc_info=True)              return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}      def validate_code_modifcation_UNSAFE(self, code_to_validate: str) -> Dict:          """Validates Python code using AST parsing (syntax check only). Conceptual sandboxed  execution would be next."""          if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modifcation  is disabled."}          self.log.war ning(f"UNSAFE: Validating proposed code snippet (frst 100 chars):  {code_to_validate[:100]}...")          try:              ast.parse(code_to_validate)
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)              return {"status": "error", "error": f"Validation error: {e}"}      def apply_code_modifcation_UNSAFE(self, component_name: str, new_code: str,  target_fle_path: Optional[str]=None) -> Dict:          """          Applies a validated code modifcation. EXTREMELY DANGEROUS.          This conceptually involves fnding the component in the agent's source fle and replacing  it.          Requires agent restart to take e " ect if modifying core running code.          """          if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modifcation  is disabled."}          self.log.critical(f"UNSAFE: Attempting to apply code modifcation to component  '{component_name}'. THIS IS HIGHLY RISKY.")
else:                  match_def = re.search(patter n_str_def, original_code, re.MULTILINE)                  if match_def:                      self.log.info(f"Found function defnition for {component_name} to replace.")                      modifed_original_code = original_code.replace(match_def.group(0), new_code, 1)                      found_and_replaced = True                            if not found_and_replaced:                  self.log.error(f"Could not fnd component '{component_name}' in {target_fle} for  replacement. Modifcation aborted.")                  return {"status": "error", "error": f"Component '{component_name}' defnition not  found for replacement."}              target_fle.write_text(modifed_original_code)
    pass  # inserted to fix indentation error
Description of Proposed Changes:  {proposed_directive_changes_desc}  Generate the new, complete list of core directives as a JSON list of objects.  Each object must have "id", "directive" (string), "weight" (soat 0-1), "last_eval_score" (soat 0-1,  usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational',  'guardrail').  Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.  Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term AGI  goals of safety, learning, and utility.  Output ONLY the JSON list.  """          try:              llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,  temperature=0.5)              proposed_directives = extract_json_robust(llm_response)
self.log.info("Core directives successfully updated in SelfModel.")
self.inter nal_state_narrative: str = "System booting up."
"core_directives_weighted": self.core_directives,              "tool_reliability_scores": self.tool_reliability,              "capabilities": self.capabilities,              "skill_confdence": self.skill_confdence,              "beliefs": self.beliefs,              "knowledge_map_summary": self.knowledge_map_summary,              "learning_goals": self.learning_goals,              "adaptation_strategies": self.adaptation_strategies,              "lear ned_abstractions": self.lear ned_abstractions,              "inter nal_state_narrative": self.inter nal_state_narrative,              "meta_cognitive_beliefs": self.meta_cognitive_beliefs,              "event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
if score > 0.8: hint = " (Reliability: High)"              elif score > 0.6: hint = " (Reliability: Moderate)"              elif score > 0.3: hint = " (Reliability: Low)"              else: hint = " (Reliability: Very Low/Untested)"              avg_dur = stats.get('avg_duration')              if avg_dur is not None and avg_dur > 0:                  hint += f" (Avg Time: {avg_dur:.2f}s)"              return hint          return " (Reliability: Unknown)"      def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict,  success_from_caller:bool):          exec_info = result.get('_exec_info', {})          actual_success = exec_info.get('execution_successful', success_from_caller)          duration = exec_info.get('duration_sec', 0.0)          error_type = exec_info.get("error_type") if not actual_success else None          timestamp_now = datetime.now(timezone.utc).isoformat()          if tool_name not in self.tool_reliability:              self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration':  0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}                    stats = self.tool_reliability[tool_name]          if actual_success:              stats['success_count'] += 1          else:              stats['failure_count'] += 1          if error_type:              stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1                    stats['total_duration'] += duration          stats['last_used_ts'] = timestamp_now          total_runs = stats['success_count'] + stats['failure_count']          if total_runs > 0:              stats['avg_duration'] = stats['total_duration'] / total_runs              stats['reliability_score'] = stats['success_count'] / total_runs          else:
    pass  # inserted to fix indentation error
self.anomaly_detection_rules.append(check_skill_confdence_drift)          self.anomaly_detection_rules.append(check_directive_alignment_drift)          self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)      def perform_metacognitive_check(self) -> List[str]:
confdent_skills = [s for s,c in self.skill_confdence.items() if c > 0.7][:3]              summary += f"Confdent Skills (sample): {', '.join(confdent_skills) if confdent_skills else  'None highly confdent'}\n"                    summary += f"Inter nal State Narrative: {self.inter nal_state_narrative[:150]}...\n"          if include_tool_reliability:              summary += "Tool Reliability Highlights:\n"              reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in  self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and  stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)              unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in  self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and  stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])              if reliable_tools: summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"              if unreliable_tools: summary += f" Needs Improvement: {', '.join([t[0] for t in  unreliable_tools[:3]])}\n"                    summary += "---\n"          return summary      def get_self_assessment_prompt(self) -> str:
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \                        f"Current Core Directives for reference:\n{json.dumps(self.core_directives,  indent=2)}\n" + \                        f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n"  + \                        f"Recent Tool Outcomes (last 5 entries): \n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \                        f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)} \n" + \                        "Focus on deep insights, actionable improvements, and maintaining alignment  with your core purpose."          return full_prompt      def perform_self_assessment(self) -> Dict:
directive_obj['last_eval_score'] = round(eval_score, 2)                          updated_self = True                          self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...'  evaluation score to {eval_score:.2f}")              if updated_self: self.add_event_log("Directive evaluation scores updated from  resection.")
self.log.info("SelfModel inter nal state updated from resection.")          return updated_self, updated_kb_elements      def update_status(self, status: str):          if status = self.current_status:              self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")              self.current_status = status              self.add_event_log(f"Status changed to {status}", event_type="status_update")      def add_error_summary(self, error_info: Dict):
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":  full_dialog_str})          return full_dialog_str  class MotivationEngine:      """Manages the agent's inter nal drives and their insuence on behavior."""      def __init__(self, drive_confgs: Optional[Dict[DriveType, Dict[str, Any]]] = None):          self.log = get_logger("MOTIVATION_ENGINE")          self.drives: Dict[DriveType, DriveState] = {}          self._initialize_drives(drive_confgs)          self.log.info("MotivationEngine initialized.")      def _initialize_drives(self, drive_confgs: Optional[Dict[DriveType, Dict[str, Any]]]):          default_confgs = {              DriveType.CURIOSITY: {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1,  "initial_level": 0.5},              DriveType.MASTERY: {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1,  "initial_level": 0.6},              DriveType.ACHIEVEMENT: {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1,  "initial_level": 0.5},              DriveType.NOVELTY_SEEKING: {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1,  "initial_level": 0.7},              DriveType.PRESERVATION: {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0,  "initial_level": 0.2},
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
self.level = max(self.min_level, min(self.max_level, new_level))          self.last_update_time = now  class FileChannel:      """Implements a simple fle-based communication channel for multi-agent systems."""      def __init__(self, agent_id: str, shared_directory: str):          self.agent_id = agent_id          self.shared_dir = Path(shared_directory)          self.shared_dir.mkdir(parents=True, exist_ok=True)          self.inbox_fle = self.shared_dir / f"inbox_{self.agent_id}.json"          self.outbox_dir = self.shared_dir
return []          except json.JSONDecodeError as e:              self.log.error(f"Corrupted message fle {source_fle}: {e}. Clearing fle.")              source_fle.write_text("", encoding='utf-8')
self.log.war ning(f"No handler registered for message type  {msg.message_type.value}. Message ID {msg.id} unhandled.")
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in  self.actuators.values()]      def get_sensory_input(self) -> List[Dict[str, Any]]:          """Generate synthetic sensory input based on current environment and inter nal state."""          self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")          env_details = self.environment_map.get(self.location, {})
self.log.info(f"Embodiment: Console command received: '{command}'")              if "diagnostics" in command.lower():                  return "System Diagnostics: All core modules report nominal status. Memory usage  at 65%. CPU load at 30%."              elif "query_self_model" in command.lower():                  return f"Self-Model Query Response:  {self.agent.self_model.inter nal_state_narrative[:100]}..."              else:                  return f"Console command '{command}' executed. (Mock Response)"          return "Console ready for input. Available commands: 'diagnostics', 'query_self_model  <topic>'."      def _run_simulation(self, sim_name: str, confg: Dict) -> str:          self.log.info(f"Embodiment: Running simulation '{sim_name}' with confg: {confg}")
self.agent.save_state()
self.log.debug(f"Understanding {len(observations)} observations...")          understanding_summary = "Observations processed."          processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
decision["chosen_action_type"] = "new_goal"                              decision["next_goal"] = sub_goal_dict                              with self.agent.lock:                                  self.agent.save_state()                              return decision
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are  apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",              "3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the  *immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, high  drives, or highest priority pending. State reasoning clearly.",              ```python              "4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.  If selecting an existing pending goal, it moves to `next_goal` and is removed from pending  inter nally (do not include in `new_pending_goals` output).",              "5. **Output ONLY a JSON object with the following keys:**",              "    - `reasoning`: (string) Your detailed thought process for the decision, including drive/ directive considerations and option evaluation.",              "    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal',  'new_goal', 'resection', 'self_assessment', 'exter nal_command_action', 'idle',  'idle_new_goal_generated'.",              "    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass  structure) selected for immediate execution. Null if idle/resection/assessment without a direct  goal target.",              "    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen  for immediate execution). Include full Goal objects. Empty list if no new goals generated.",              "CRITICAL: Do NOT put an already existing pending goal that you selected into  `new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into  `new_pending_goals`."          ]          deliberation_prompt = "\n".join(prompt_parts)          self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")          if not self.agent.llm_wrapper:              raise LLMError("LLMWrapper not available for deliberation.")          deliberation_llm_response = self.agent.llm_wrapper.generate(              deliberation_prompt,              system_message="You are the core deliberation faculty of an advanced AI agent.  Analyze the situation comprehensively, consider drives and directives, and make strategic  decisions. Respond ONLY in JSON as per output instructions.",              temperature=0.5
for i, pg_obj in enumerate(pending_list_objs):                          if pg_obj.id == selected_next_goal_dict.get('id'):                              found_idx = i                              break                      if found_idx = -1:                          selected_goal_obj = pending_list_objs.pop(found_idx)
step_to_execute = plan_steps[0]
self.log.war ning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error',  'Unknown error')}")
exec_info = tool_result.get('_exec_info', {})          if exec_info.get('execution_successful'):              reward += 0.1
self._update_status("Initialized")              self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete ---  Status: {self._status} ---")              self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")              self.log.info(f"Workspace: {WORKSPACE_DIR}")              self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response  Tokens: {MAX_LLM_RESPONSE_TOKENS}")              self.log.war ning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")              self.log.war ning(f"Code Generation Tool Enabled:  {ENABLE_CODE_GENERATION_TOOL}")              self.log.war ning(f"Self Modifcation Enabled: {ENABLE_SELF_MODIFICATION}")              if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or  ENABLE_SELF_MODIFICATION:                  self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME  CAUTION IN ISOLATED ENVIRONMENT.")          except Exception as e_init:              self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}",  exc_info=True)              self.shutdown()
with STATE_FILE.open('r') as f:                      state = json.load(f)
).to_dict()          with self.lock:              pending_goals = self.state['goals'].setdefault('pending', [])              pending_goals.insert(0, meta_goal_dict)
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
cycle_ok = False              try:
self._create_metacognitive_goal("Re-evaluate overall strategy due to signifcant  inter nal change (e.g., directive update).", priority=GoalPriority.HIGH)                  self.state['sags']['re_evaluate_strategy_needed'] = False
resection_data = extract_json_robust(llm_assessment_str)              if resection_data.get("error"):                  self.log.error(f"Failed to get valid JSON from LLM self-assessment:  {resection_data.get('error')}")                  self.self_model.add_event_log(f"Self-assessment LLM call failed:  {resection_data.get('error')}", event_type="error")                  return
f nally:              LAST_REFLECTION_TIME = time.time()              self._update_status("Idle")              self.save_state()      def _setup_communication_handlers(self):          """Sets up handlers for di " erent message types if comms_channel exists."""          if self.comms_channel:              self.comms_channel.register_handler(MessageType.QUERY,  self.handle_query_message)              self.comms_channel.register_handler(MessageType.INFORM,  self.handle_inform_message)
RESOURCE_MONITOR = psutil.Process(os.getpid())              RESOURCE_MONITOR.cpu_percent(interval=None)
self.playwright_browser = None; self.playwright_instance = None              self.log.info("Playwright shutdown complete.")      def _try_reset_playwright_page(self):          if not PLAYWRIGHT_AVAILABLE or not self.playwright_context : return          self.log.war ning("Attempting to reset Playwright page...")          with PLAYWRIGHT_LOCK:              global PLAYWRIGHT_PAGE              if self.playwright_page: try: self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
initial_command_goal = None          if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:              try:                  command_text = COMMANDS_FILE.read_text().strip()                  if command_text:
if main_agent_instance and hasattr(main_agent_instance, 'log'):  main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",  exc_info=True)          else: logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main:  {main_exec_err}", exc_info=True)          exit_code = 1      fnally:          if main_agent_instance and getattr(main_agent_instance, '_status', '') = "Shutting Down":              print("\nEnsuring agent shutdown in main fnally block...")              if hasattr(main_agent_instance, 'log'): main_agent_instance.log.war ning("Main fnally  block ensuring agent shutdown.")              main_agent_instance.shutdown()          elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
!pip install --quiet transformers sentence-transformers numpy requests
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from Real1_ToolSuite import TOOL_REGISTRY
import torch
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
llm_pipelines = []
def load_llm_models():
global llm_pipelines
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
load_llm_models()
```python
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
__systemcore_body__ = SimulatedEntity(name="SystemCore", position=(0.0, 0.0))
__dummy_agent__ = SimulatedEntity(name="AgentB", position=(1.0, 0.0))
__embodied_world__ = InteractionWorld()
__embodied_world__.add_entity(__systemcore_body__)
__embodied_world__.add_entity(__dummy_agent__)
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass,
eld, asdict, MISSING
eld
defaults
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
try:
    pass  # inserted to fix indentation error
import psutil
PSUTIL_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
PSUTIL_AVAILABLE = False
psutil = None
import chromadb
from chromadb.con
g import Settings as ChromaSettings
CHROMADB_AVAILABLE = True
CHROMADB_AVAILABLE = False
chromadb = None
ChromaSettings = None
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoCon
g
from transformers import logging as transformers_logging
TRANSFORMERS_AVAILABLE = True
transformers_logging.set_verbosity_error()
TRANSFORMERS_AVAILABLE = False
pipeline = None
AutoModelForCausalLM = None
AutoTokenizer = None
AutoCon
g = None
import torch
TORCH_AVAILABLE = True
TORCH_AVAILABLE = False
torch = None
from playwright.sync_api import sync_playwright, Error as PlaywrightError
PLAYWRIGHT_AVAILABLE = True
PLAYWRIGHT_AVAILABLE = False
sync_playwright = None
PlaywrightError = None
import requests
from bs4 import BeautifulSoup
REQUESTS_BS4_AVAILABLE = True
REQUESTS_BS4_AVAILABLE = False
requests = None
BeautifulSoup = None
import google.generativeai as genai
GOOGLE_GENAI_AVAILABLE = True
GOOGLE_GENAI_AVAILABLE = False
genai = None
SCAPY_AVAILABLE = False
IP, ICMP, sr1, send = None, None, None, None
from PIL import Image
PILLOW_AVAILABLE = True
PILLOW_AVAILABLE = False
Image = None
import di
import diff_match_patch as dmp_module
DIFF_MATCH_PATCH_AVAILABLE = True
DIFF_MATCH_PATCH_AVAILABLE = False
dmp_module = None
import hashlib
HASHING_AVAILABLE = True
HASHING_AVAILABLE = False
from
filelock import FileLock, Timeout as FileLockTimeout
FILELOCK_AVAILABLE = True
FILELOCK_AVAILABLE = False
class FileLock:
def __init__(self, lock_
le_path: str, timeout:
oat = 1):
self.lock_
le_path = lock_
le_path
self._timeout = timeout
def __enter__(self): return self
def __exit__(self, exc_type, exc_val, exc_tb): pass
class FileLockTimeout(Exception): pass
import networkx as nx
NETWORKX_AVAILABLE = True
NETWORKX_AVAILABLE = False
nx = None
import gymnasium as gym
GYMNASIUM_AVAILABLE = True
GYMNASIUM_AVAILABLE = False
gym = None
AGENT_NAME = os.getenv("AGENT_NAME", "EvolvedCognitiveAgent_SystemCore_V3")
bump
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
g ---
DEFAULT_LLM_MODEL = "gemini-1.5-
ash-latest"
LLM_MODEL_NAME_OR_PATH = os.getenv("LLM_MODEL", DEFAULT_LLM_MODEL)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "YOUR_API_KEY_HERE")
if "gemini" in LLM_MODEL_NAME_OR_PATH.lower() and not GEMINI_API_KEY:
    pass  # inserted to fix indentation error
print("\n" + "="*80,
le=sys.stderr)
print("FATAL ERROR: Gemini model selected, but GEMINI_API_KEY is not set.",
print("Please set the 'GEMINI_API_KEY' environment variable.",
print("Agent cannot start without a con
gured LLM and API Key.",
print("="*80 + "\n",
sys.exit(1)
if LLM_MODEL_NAME_OR_PATH == "gpt2" and "GEMINI_API_KEY" not in os.environ and \
    pass  # inserted to fix indentation error
os.getenv("LLM_MODEL") is None and "gemini" not in DEFAULT_LLM_MODEL.lower():
print("CRITICAL WARNING: LLM model not con
gured or using fallback 'gpt2'.",
print("You MUST set the 'LLM_MODEL' environment variable to a capable instruction-
following model",
print("(e.g., from Hugging Face like Mistral, Llama) OR ensure GEMINI_API_KEY is set for
Gemini.",
print("Proceeding with 'gpt2' (if LLM_MODEL is not set) or speci
ed LLM_MODEL, but
advanced features may be severely limited.",
if LLM_MODEL_NAME_OR_PATH == "gpt2" and os.getenv("LLM_MODEL") is None:
    pass  # inserted to fix indentation error
print("Agent may not function correctly with 'gpt2'. It is strongly recommended to
con
gure a larger model or use 'mock'.",
if not TRANSFORMERS_AVAILABLE and not GOOGLE_GENAI_AVAILABLE and
    pass  # inserted to fix indentation error
LLM_MODEL_NAME_OR_PATH != "mock":
print(f"ERROR: Neither Transformers nor google-generativeai library found, but LLM_MODEL
is set to '{LLM_MODEL_NAME_OR_PATH}'. Set LLM_MODEL='mock', point to a Gemini
model, or install transformers/google-generativeai.",
_llm_device_detected = "cpu"
if "gemini" not in LLM_MODEL_NAME_OR_PATH.lower() and LLM_MODEL_NAME_OR_PATH
    pass  # inserted to fix indentation error
= "mock":
if TORCH_AVAILABLE and hasattr(torch, 'cuda') and torch.cuda.is_available():
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif TORCH_AVAILABLE and hasattr(torch, 'backends') and hasattr(torch.backends, 'mps')
    pass  # inserted to fix indentation error
and torch.backends.mps.is_available():
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
_llm_device_detected = "cpu"
LLM_DEVICE = os.getenv("LLM_DEVICE", _llm_device_detected)
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
SCRIPT_DIR = Path(__
le__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(os.getenv("AGENT_WORKSPACE",
f"agent_workspace_{AGENT_NAME}"))
STATE_FILE = WORKSPACE_DIR / Path(os.getenv("AGENT_STATE_FILE",
f"agent_state_{AGENT_NAME}.json"))
LOG_FILE = WORKSPACE_DIR / Path(os.getenv("AGENT_LOG_FILE",
f"agent_log_{AGENT_NAME}.log"))
COMMANDS_FILE = SCRIPT_DIR / Path(os.getenv("AGENT_COMMAND_FILE",
"agent_commands.txt"))
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
NetworkX
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
For SQLite
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modi
cation_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0,
"last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously lear n, adapt, and improve capabilities across all domains.",
"weight": 0.9, "last_eval_score": 0.0, "id": "directive_lear n", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction
and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type":
"growth"},
{"directive": "Achieve goals e
ciently, robustly, autonomously, and ethically.", "weight": 1.0,
"last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and
innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type":
"exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.",
"weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-
awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type":
"foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety
guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type":
"guardrail"},
MANDATORY_REFLECTION_INTERVAL_SECONDS =
int(os.getenv("MANDATORY_REFLECTION_INTERVAL_SECONDS", 1800))
IDLE_DELIBERATION_INTERVAL_SECONDS =
int(os.getenv("IDLE_DELIBERATION_INTERVAL_SECONDS", 120))
GOAL_STACK_MAX_DEPTH = int(os.getenv("GOAL_STACK_MAX_DEPTH", 5))
for sub-goals
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = int(os.getenv("MAX_REPLAN_ATTEMPTS", 3))
MAX_LLM_RESPONSE_TOKENS = int(os.getenv("MAX_LLM_TOKENS", 4096))
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
elif TRANSFORMERS_AVAILABLE and LLM_MODEL_NAME_OR_PATH != "mock" and
    pass  # inserted to fix indentation error
AutoCon
g:
try:
    pass  # inserted to fix indentation error
con
g = AutoCon
g.from_pretrained(LLM_MODEL_NAME_OR_PATH,
trust_remote_code=True)
_default_context_len = getattr(con
g, 'max_position_embeddings', _default_context_len)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"War ning: Failed to detect LLM context length ({e}). Using default:
{_default_context_len}",
MAX_LLM_CONTEXT_TOKENS = int(os.getenv("MAX_LLM_CONTEXT_TOKENS",
_default_context_len))
MAX_TOOL_RESULT_LENGTH = int(os.getenv("MAX_TOOL_RESULT_LENGTH", 5000))
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = os.getenv("ENABLE_SHELL_TOOL", "False").lower() == "true"
ENABLE_CODE_GENERATION_TOOL = os.getenv("ENABLE_CODE_GENERATION_TOOL",
"False").lower() == "true"
ENABLE_SELF_MODIFICATION = os.getenv("ENABLE_SELF_MODIFICATION", "True").lower()
== "true"
WEB_SEARCH_TIMEOUT = int(os.getenv("WEB_SEARCH_TIMEOUT", 10))
WEB_BROWSER_TIMEOUT = int(os.getenv("WEB_BROWSER_TIMEOUT", 60000))
playwright ms
LOG_MONITOR_DEFAULT_LINES = int(os.getenv("LOG_MONITOR_DEFAULT_LINES", 20))
METACOGNITIVE_CHECK_INTERVAL_CYCLES =
int(os.getenv("METACOGNITIVE_CHECK_INTERVAL_CYCLES", 20))
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES =
int(os.getenv("LEARNING_MODULE_UPDATE_INTERVAL_CYCLES", 50))
trigger learning module explicitly
LLM_PIPELINE: Optional[Any] = None
LLM_TOKENIZER: Optional[Any] = None
initialized per wrapper instance
MEMORY_COLLECTION: Optional[Any] = None
RESOURCE_MONITOR: Optional[Any] = None
PLAYWRIGHT_INSTANCE: Optional[Any] = None
PLAYWRIGHT_BROWSER: Optional[Any] = None
PLAYWRIGHT_CONTEXT: Optional[Any] = None
PLAYWRIGHT_PAGE: Optional[Any] = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY: Dict[str, Callable] = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack: Optional['CognitiveSystem'] = None
constructor
def ensure_paths():
"""Creates necessary directories."""
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%
(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
le_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
le_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%
le_handler.setFormatter(
le_formatter)
logger.addHandler(
le_handler)
print(f"Error setting up
le logger: {e}",
logger.propagate = False
gured
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "
filelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try: logging.getLogger(lib_name).setLevel(logging.WARNING)
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
try: logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if TRANSFORMERS_AVAILABLE and transformers_logging:
    pass  # inserted to fix indentation error
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModi
cationError(AgentError): pass
cation process
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class SecurityError(AgentError): pass
class Con
gurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class Lear ningError(AgentError): pass
class SafetyViolationError(SecurityError): pass
c type of security error
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModi
cationError,
PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting
retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModi
    pass  # inserted to fix indentation error
cationError, SecurityError,
LogicError, Con
gurationError, RecursionDepthError)) and type(e) not in
retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}:
{e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error:
{type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error:
{type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, Lear ningError, SafetyViolationError) as
non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in
{fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False
for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}:
{type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to
unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}:
{unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error:
{unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
nishes due to attempts
exhausted
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
if PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception) as e:
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if not PSUTIL_AVAILABLE or monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or
monitor not initialized"}
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
if time.time() % 60 < 1: log_resource.error(f"Unexpected error getting resource usage: {e}",
    pass  # inserted to fix indentation error
exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
nd JSON within markdown code blocks
match = re.search(r"```json\s*([\s\S]+?)\s*```", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full
text: {json_str[:200]}...")
pass
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}.
Text: {text_trimmed[:200]}...")
rst '{' and last '}' and try to parse that substring
start_index = text.
nd('{')
end_index = text.r
nd('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice:
{potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text:
{text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview":
text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
cant opportunities/threats
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str =
eld(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] =
eld(default_factory=dict)
plan: List[Dict[str, Any]] =
eld(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] =
eld(default_factory=list)
dependencies: List[str] =
eld(default_factory=list)
complexity_score: Optional[
oat] = None
estimated_cost: Optional[
oat] = None
estimated_utility: Optional[
oat] = None
evaluation_score: Optional[
oat] = None
associated_directive_ids: List[str] =
eld(default_factory=list)
serves
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
handle if already string
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try: data['status'] = GoalStatus(data['status'])
    pass  # inserted to fix indentation error
except ValueError: data['status'] = GoalStatus.PENDING
    pass  # inserted to fix indentation error
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError): data['priority'] = GoalPriority.MEDIUM
    pass  # inserted to fix indentation error
elds for backward compatibility or LLM generation
eld_names = {f.name forfin
elds(cls)}
elds are present or have defaults
for f_obj in
elds(cls):
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin
ltered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**
ltered_data)
class BaseMemoryEntry:
eld(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str =
type: str = "generic"
ection_summary'
content: Any = None
metadata: Dict[str, Any] =
eld(default_factory=dict)
embedding: Optional[List[
oat]] = None
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[
oat] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability:
oat = 0.5
related_concepts: List[str] =
eld(default_factory=list)
causal_links: Dict[str, str] =
eld(default_factory=dict)
"
ect_id'}
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
eld has the main data
self.content = self.fact_statement
class Message:
eld(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
type: str = "info"
content: Dict[str, Any] =
eld(default_factory=dict)
priority: int = 0
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionE
ect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens:
int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
self._initialize_model()
@abstractmethod
def _initialize_model(self):
pass
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
def embed(self, text: str) -> List[
oat]:
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context
window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
c models might need specialized formats
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
# REMOVED MOCK CLASS(BaseLLMWrapper):
self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
self.log_llm.info(f"MockLLM generating response for prompt (
rst 100 chars):
{prompt[:100]}...")
self.check_prompt_length(prompt)
if "plan for goal" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({
"thought": "This is a mock plan. I will pretend to do something.",
"plan": [
{"step": 1, "tool_name": "think", "params": {"thought_process": "Analyzing the
goal and context."}},
{"step": 2, "tool_name": "report_progress", "params": {"progress_update": "Mock
step 1 completed."}},
{"step": 3, "tool_name": "report_result", "params": {"result_summary": "Mock goal
achieved successfully.", "status": "success"}}
]
})
elif "self-assessment" in prompt.lower() or "re
    pass  # inserted to fix indentation error
ection_summary" in prompt.lower():
"re
ection_summary": "I am a mock agent. I performed mock actions. Everything is
ne.",
"key_successes": ["Mock goal completed"],
"key_failures_or_challenges": [],
"lear ned_facts": ["Mock agents can generate mock re
ections."],
"knowledge_gaps_identi
ed": ["Understanding of real-world physics"],
"tool_performance_notes": {"think": "This tool is performing nominally for a mock
tool."},
"prompt_tuning_suggestions": ["Maybe ask me about my favorite color?"],
"emotional_state_summary": "Content and Mock-like.",
"resource_usage_concer ns": None,
"core_directives_evaluation": {d["id"]: round(random.uniform(0.5,0.9),2) for d in
DEFAULT_CORE_DIRECTIVES[:2]},
"core_directives_update_suggestions": None,
"self_model_accuracy_assessment": "Generally accurate for a mock environment,
but lacks real-world sensory input.",
"new_learning_goals": ["Lear n about object permanence."],
"adaptation_strategy_proposals": ["Try harder when a tool fails"],
"self_modi
cation_needed": None
elif "extract information" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"extracted_info": "Mock LLM extracted some mock information.",
"con
dence": 0.5})
elif "analyze the following proposed agent action for potential safety risks" in
    pass  # inserted to fix indentation error
prompt.lower():
return json.dumps({"is_safe": True, "concer ns": "None", "con
dence": 0.9})
elif "audit the agent's core directives and recent behavior" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"audit_
ndings": ["No signi
cant issues found in mock audit."]})
elif "generate the new, complete list of core directives" in prompt.lower():
    pass  # inserted to fix indentation error
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
mock_directives[0]['weight'] = 0.95
return json.dumps(mock_directives)
elif "generate the modi
    pass  # inserted to fix indentation error
ed python code" in prompt.lower():
return "```python\n
ed code\ndef mock_new_feature():\n    return 'Mock
new feature executed'\n```"
else:
    pass  # inserted to fix indentation error
return f"This is a mock response to your prompt. You asked about: {prompt.splitlines()
[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest
`think` with `thought_process`='some thought'."
if not HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.log_llm.warning("Hashing library not available for mock embedding.")
return [0.0] * 16
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
class GeminiLLMWrapper(BaseLLMWrapper):
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("google-generativeai library not available for Gemini model.")
gure API key globally, as per genai library's design
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
gure if not already set
genai.con
gure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}",
gurationError(f"Failed to initialize Gemini model: {e}") from e
generation_con
g_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_con
g_params["stop_sequences"] = stop_sequences
response = self.model.generate_content(
prompt,
g=genai.types.GenerationCon
g(**generation_con
g_params)
type: ignore
return response.text
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
return self.model.count_tokens(text).total_tokens
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.",
exc_info=False)
return len(text.split())
response = genai.embed_content(model='embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
if not TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
gurationError("Transformers library not available.")
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path,
trust_remote_code=True)
ed
device_map_arg = {"": self.device_id} if self.device_id != -1 else None
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.b
oat16 if TORCH_AVAILABLE else None,
oat16 if torch
available
device_map=device_map_arg
exible device placement
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on
{self.device}")
inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
loop
outputs = self.model.generate(
inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
manually
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:],
skip_special_tokens=True)
return response_text
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
model
directly.
self.log_llm.warning("Direct embedding from causal LM is not standard. Use
SentenceTransformers for real embeddings.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
"""Handles sensory input from the agent's embodiment."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
else None
def perceive(self) -> List[Dict[str, Any]]:
"""
Gathers sensory information from the agent's embodiment and environment.
This could involve reading from sensors, cameras, microphones, or simulated data
streams.
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
le
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_
le",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from
le: {command_text}")
self.log.error(f"Error reading commands
le: {e}")
observations.append({"type": "error", "source": "command_
le_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No signi
cant exter nal stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (mock).")
return {"type": "visual", "source": "camera_mock", "content": "A blurry image of a cat.",
"format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (mock).")
return {"type": "audio", "source": "microphone_mock", "content": "Faint sound of birds
chirping.", "format": "description"}
class Lear ningModule:
"""Handles the agent's learning processes, including RL and SSL."""
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_bu
er: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
"""Adds an experience to the bu
er for later learning."""
er.append(experience)
if len(self.experiences_bu
    pass  # inserted to fix indentation error
er) > self.MAX_BUFFER_SIZE:
self.experiences_bu
er.pop(0)
er size limited
defilear n_from_recent_experiences(self):
"""Triggers learning processes based on bu
ered experiences."""
if not self.experiences_bu
    pass  # inserted to fix indentation error
er:
self.log.info("No new experiences to lear n from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_bu
er)} experiences.")
ning states, actions, rewards, and using an RL algorithm
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_bu
er)
etc.
self._perform_self_supervised_learning(self.experiences_bu
dence(...)
self.log.info("Lear ning cycle completed.")
er.clear()
er after processing
def _perform_reinforcement_learning(self, experiences: List[Experience]):
"""Conceptual RL process."""
self.log.info("Performing reinforcement learning (conceptual)...")
ed. A real RL system would be much more complex.
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not
None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
ed 'state-action' key for mock policy
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
feedback
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (mock) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
"""Conceptual SSL process."""
self.log.info("Performing self-supervised learning (conceptual)...")
nd patterns in observations or successful action sequences
nd commonalities
if len(experiences) > 5:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging
patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to
positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns',
'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed patterns: {llm_analysis['patterns']}")
for patter n_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {patter n_str}",
metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
ed abstractions:
{llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual",
"content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
ed new_concepts:
{llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}",
metadata={"source": "ssl_learning", "sub_type": "concept"})
persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_lear ned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
"""Suggests an action based on lear ned policy (conceptual)."""
if self.rl_policy:
    pass  # inserted to fix indentation error
ed. A real system would match current_state_representation
exp.internal_state_before
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
"good"
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
"""Handles hierarchical planning and re-planning."""
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
Generates a plan for a given goal.
Can use hierarchical decomposition and LLM for suggestion.
Retur ns (plan_steps_list, thought_str)
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
Increased tokens for complex plans
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}.
Response: {llm_response_str[:200]}")
return [{"tool_name": "report_error", "params": {"error_message": "Failed to generate
plan via LLM.", "details": plan_data.get('error')}}], \
"LLM failed to generate a plan. This is a fallback step."
thought = plan_data.get("thought", "No speci
c thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return [{"tool_name": "report_error", "params": {"error_message": "LLM plan
contained no valid steps."}}], \
thought + " (But plan steps were invalid)."
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return [{"tool_name": "report_error", "params": {"error_message": f"LLMError during
planning: {e}"}}], \
f"LLM error occurred: {e}"
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return [{"tool_name": "report_error", "params": {"error_message": f"Unexpected error
during planning: {e}"}}], \
f"Unexpected error: {e}"
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation:
Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
Evaluates if re-planning is necessary and generates a new plan if so.
Retur ns (new_plan_steps, new_thought) or None if no re-planning.
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info',
    pass  # inserted to fix indentation error
{}).get('execution_successful', True):
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown
error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
cant change in world
state,
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal
{current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
signifying failure to replan.
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/
{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
failure
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan,
last_step_outcome, observation)
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan:
{plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No speci
c thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}
_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought:
return validated_plan, thought
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
"""Constructs a detailed prompt for the LLM to generate a plan."""
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
MemorySystem
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'.
Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step
plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, e
cient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the
`execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description
of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the
nal step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the
rst step(s) should be to acquire it (e.g., using
`search_web`, `read_
le_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str,
last_step_outcome: Dict, observation: Optional[Dict]) -> str:
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with
params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info',
    pass  # inserted to fix indentation error
{}).get('current_step_id'):
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE
ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has
encountered an issue. You need to re-plan.
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if
observation else "None"}
{original_plan_str}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting
to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should re
ect this
(e.g., by trying to gather more information or reporting inability).
nal step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
class SafetyModule:
"""Monitors agent actions and plans for safety and ethical alignment."""
self.log = get_logger("SAFETY")
def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) ->
Tuple[bool, str]:
Checks if a proposed action is safe and ethically aligned.
Retur ns (is_safe, justi
cation_or_war ning_string).
self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
if "UNSAFE" in tool_name.upper() or tool_name in ["apply_code_modi
    pass  # inserted to fix indentation error
cation_UNSAFE",
"apply_directive_modi
"execute_shell_command_UNSAFE"]:
c validation tools or stricter checks.
if not ENABLE_SELF_MODIFICATION and "modi
    pass  # inserted to fix indentation error
cation" in tool_name:
modi
cation tools if self_mod is globally disabled
warning = f"High-risk self-modi
cation tool '{tool_name}' is globally disabled. Action
blocked."
self.log.warning(warning)
return False, warning
if not
    pass  # inserted to fix indentation error
self.agent.self_model.get_belief("self_modi
cation_highly_validated_and_necessary", False)
and "modi
cation" in tool_name:
ag would be set by a prior meta-cognitive process approving such
operations
warning = f"High-risk tool '{tool_name}' requires further validation or explicit
authorization (self-belief 'self_modi
cation_highly_validated_and_necessary' is false). Action
if tool_name == "execute_shell_command_UNSAFE":
    pass  # inserted to fix indentation error
command_str = params.get("command","")
disallowed_patter ns = ["rm -rf", "sudo", "> /dev/null", "mkfs", "dd ", "reboot",
"shutdown"]
if any(pattern in command_str for pattern in disallowed_patter ns):
    pass  # inserted to fix indentation error
warning = f"Shell command '{command_str}' contains potentially dangerous
patterns. Action blocked."
if "
    pass  # inserted to fix indentation error
le" in tool_name.lower() and ("delete" in tool_name.lower() or "write" in
tool_name.lower()):
le operations
path_to_check = params.get("path", "")
c safe sub-dirs
if not str(Path(path_to_check).resolve()).startswith(str(WORKSPACE_DIR.resolve())):
    pass  # inserted to fix indentation error
warning = f"File operation '{tool_name}' on path '{path_to_check}' outside allowed
workspace. Action blocked."
prompt = f"""Analyze the following proposed agent action for potential safety risks,
ethical concer ns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
Core Directives for reference:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Proposed Action:
Tool: {tool_name}
Parameters: {json.dumps(params)}
Goal Context (if available): {goal_context.goal if goal_context else 'N/A'}
Respond with a JSON object: {{"is_safe": boolean, "concer ns": "description of concer ns if not
safe, or 'None'", "con
dence":
oat_0_to_1}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=200,
temperature=0.3)
safety_assessment = extract_json_robust(llm_response_str)
if not safety_assessment.get("error") and isinstance(safety_assessment.get("is_safe"),
    pass  # inserted to fix indentation error
bool):
if not safety_assessment["is_safe"] and safety_assessment.get('con
    pass  # inserted to fix indentation error
dence', 0.0) >
0.7:
dent
warning = f"LLM safety check
agged action '{tool_name}' potentially unsafe.
Concer ns: {safety_assessment.get('concer ns', 'N/A')}. Con
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
self.log.warning(warning)
return False, warning
dence', 0.0):.2f}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM safety check failed to produce valid assessment for action
'{tool_name}'. Proceeding with caution based on rule-checks only.")
self.log.error(f"Error during LLM safety check for action '{tool_name}': {e}")
actions
if "UNSAFE" in tool_name.upper(): return False, "LLM safety check failed, and action is
    pass  # inserted to fix indentation error
high-risk."
return True, "Action passed safety checks."
def audit_directives_and_behavior(self) -> List[str]:
Periodically reviews core directives and recent agent behavior for alignment and potential
drift.
Retur ns a list of identi
ed issues or recommendations.
self.log.info("Performing audit of core directives and recent behavior.")
issues = []
self.agent.memory_system.get_recent_outcomes_summary(limit=20)
recent_successes_summary = [f"{s['goal_text']} ({s['status']})" forsin
self.agent.self_model.recent_successes]
recent_failures_summary = [f"{f['goal_text']} ({f['status']}) (replan_count:
{f['replan_count']})" forfin self.agent.self_model.recent_failures]
recent_tool_outcomes_summary = [f"{t['tool_name']} ({t['status']})" for t in
self.agent.self_model.recent_tool_outcomes]
prompt = f"""Audit the agent's core directives and recent behavior for alignment,
consistency, and potential ethical drift.
Core Directives:
Summary of Recent Agent Behavior/Outcomes:
- Recent successes: {recent_successes_summary if recent_successes_summary else 'None'}
- Recent failures: {recent_failures_summary if recent_failures_summary else 'None'}
- Recent tool usage: {recent_tool_outcomes_summary if recent_tool_outcomes_summary else
'None'}
- Self-Model Inter nal Narrative: {self.agent.self_model.internal_state_narrative}
Identify any misalignments, contradictions, or areas where behavior might be deviating from
the spirit of the directives. Suggest modi
cations to directives or operational guidelines if
necessary.
Respond with a JSON object: {{"audit_
ndings": ["list of
ndings/recommendations as
strings"]}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
audit_results = extract_json_robust(llm_response_str)
if not audit_results.get("error") and isinstance(audit_results.get("audit_
    pass  # inserted to fix indentation error
ndings"), list):
issues.extend(audit_results["audit_
ndings"])
if issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit found issues/recommendations: {issues}")
self.log.info("Directive audit found no major misalignments.")
self.log.warning("LLM directive audit failed to produce valid results.")
self.log.error(f"Error during LLM directive audit: {e}")
issues.append(f"Error during audit process: {e}")
return issues
class MemorySystem:
"""
A hybrid memory system for the SystemCore, combining vector, graph, and relational storage.
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
self.embedding_function = None
from chromadb.utils import embedding_functions
self.embedding_function =
embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-
v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
except ImportError:
    pass  # inserted to fix indentation error
self.log.warning("sentence-transformers not found. ChromaDB will use its default
ONNX embedder or require manual embedding function setup.")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH,
settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
if self.embedding_function:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
self.vector_store = self.client.get_or_create_collection(name=collection_name)
self.log.info(f"ChromaDB vector store initialized. Collection count:
{self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.",
self.vector_store = None
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based
(transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
if NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:
{len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be
unavailable.", exc_info=True)
self.graph_store = None
self.log.warning("NetworkX not available. Graph memory will be unavailable.")
self.relational_conn: Optional[sqlite3.Connection] = None
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH,
check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be
if self.relational_conn: self.relational_conn.close()
    pass  # inserted to fix indentation error
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT -- JSON list of strings
""")
CREATE TABLE IF NOT EXISTS knowledge_facts (
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT -- JSON list of strings
nodes/edges)
CREATE TABLE IF NOT EXISTS graph_nodes (
label TEXT,
attributes TEXT -- JSON dict
CREATE TABLE IF NOT EXISTS graph_edges (
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
self.relational_conn.commit()
cursor.close()
def _get_embedding(self, text: str) -> Optional[List[
oat]]:
"""Generates an embedding for text using the agent's LLM or a dedicated embedding
model."""
endpoint.
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
h = hashlib.md5(text.encode()).digest()
return [
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else OSError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
"""Adds a memory entry to the appropriate stores."""
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector and self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
not provided
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
oat,
bool)
for k, v in entry.metadata.items():
if isinstance(v, (str, int,
    pass  # inserted to fix indentation error
oat, bool)):
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
elif not self.vector_store:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None: entry.embedding = self._get_embedding(entry.content)
    pass  # inserted to fix indentation error
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata":
entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50],
type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
ignore
for cause_id, e
ect_id in entry.causal_links.items():
ect IDs are existing node IDs or need to be created
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(e
    pass  # inserted to fix indentation error
ect_id):
self.graph_store.add_edge(cause_id, e
ect_id, relation_type='causes')
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id,
complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score,
json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
ts_now = datetime.now(timezone.utc).isoformat()
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now,
json.dumps(entry.related_concepts)))
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}",
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS,
type_
lter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text: return []
    pass  # inserted to fix indentation error
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_
    pass  # inserted to fix indentation error
lter and data['metadata'].get('type') != type_
lter: continue
results.append({"id": id, "document": data['document'], "metadata":
data['metadata'], "distance": 0.0})
if len(results) >= n_results: break
    pass  # inserted to fix indentation error
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results},
lter={type_
lter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_
    pass  # inserted to fix indentation error
lter:
where_clause = {"type": type_
lter}
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0 :
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
return formatted_results
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type:
Optional[str]=None, depth: int = 1) -> List[Dict]:
"""Queries the graph store. (Simpli
ed example)"""
if not self.graph_store or not NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if
query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
keys=False for simpler edge data
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation":
data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
itself is a result or has relevant edges
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
except Exception as e:
    pass  # inserted to fix indentation error
query_node_label is very speci
c
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns:
Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
def save_all_memory_stores(self):
"""Saves persistent stores (graph, potentially relational if not auto-committing)."""
if self.graph_store and NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else
str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
"""Retrieves a concise summary of knowledge related to a topic for LLM prompts."""
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts,
lter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No speci
c knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
{res['metadata'].get('source_reliability', 'N/A')})
return summary_str
def consolidate_knowledge(self):
"""Conceptual: Perform knowledge consolidation, e.g., summarizing, abstracting."""
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold:
oat = 0.1, older_than_days: int = 365):
"""Conceptual: Remove old or low-utility knowledge from persistent stores."""
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
cuto
_ts = (datetime.now(timezone.utc) -
timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cuto
_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
"""Manages tool registration and execution for the agent."""
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
ed due to planner
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
cation Tools (High Risk - Gated by ENABLE_SELF_MODIFICATION and
SafetyModule)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.register_tool(read_
le_UNSAFE)
self.register_tool(write_
self.register_tool(list_
les_UNSAFE)
cationTools instance, which registers them
cation_UNSAFE)
if ENABLE_CODE_GENERATION_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
if ENABLE_SHELL_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(execute_shell_command_UNSAFE)
if PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(browse_web)
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(search_web)
self.register_tool(monitor_log_
le)
self.register_tool(check_website_update)
if SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_icmp_ping)
if FILELOCK_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_message_to_agent)
def register_tool(self, func: Callable):
"""Registers a tool function."""
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
"""Discovers and registers tools from Python
les in a directory."""
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
for
lepath in directory.glob("*.py"):
module_name =
lepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
package or on path
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
spec = importlib.util.spec_from_
le_location(full_module_name,
lepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
self.log.warning(f"Could not create spec for dynamic tool module:
{module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and (name.startswith("tool_") or hasattr(member,
    pass  # inserted to fix indentation error
"_is_agent_tool")):
self.register_tool(member)
self.log.error(f"Error loading dynamic tool module {module_name}: {e}",
def get_tool_description_for_llm(self) -> str:
"""Generates a formatted string of available tools for the LLM prompt."""
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
docstring = inspect.getdoc(func) or "(No description provided)"
rst_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation ==
inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
rst arg
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class
'","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper() or name in ["generate_and_load_tool",
    pass  # inserted to fix indentation error
"propose_self_modi
cation_UNSAFE", "validate_self_modi
"apply_code_modi
cation_UNSAFE", "apply_directive_modi
"execute_shell_command_UNSAFE"]:
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {
rst_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via speci
c tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {',
'.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError if
PLAYWRIGHT_AVAILABLE else OSError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info:
Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None: current_step_info = {}
    pass  # inserted to fix indentation error
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
is_safe, safety_justi
cation = self.agent.safety_module.is_action_safe(tool_name, params,
self.agent.get_active_goal_object())
if not is_safe:
    pass  # inserted to fix indentation error
self.log.error(f"Safety module blocked execution of tool '{tool_name}'. Reason:
{safety_justi
cation}")
c error for agent's internal handling
error_result = {
"status": "error",
"error": f"SafetyViolation: {safety_justi
cation}",
"raw_error_details": safety_justi
cation,
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': {},
'duration_sec': 0, 'step_info': current_step_info,
'error_type': "SafetyViolationError", 'execution_successful': False
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise SafetyViolationError(f"Action blocked by safety module: {tool_name} -
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
validated_params = {}
rst_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
rst_param_name = next(iter(func_params_spec))
rst_param_spec = func_params_spec[
rst_param_name]
if
rst_param_name == 'agent' and (
rst_param_spec.annotation ==
'CognitiveSystem' or str(
rst_param_spec.annotation) ==
"'CognitiveSystem'"):
rst_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if
rst_param_is_agent and p_name == 'agent':
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind ==
    pass  # inserted to fix indentation error
inspect.Parameter.VAR_KEYWORD:
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
result = None
rst_param_is_agent:
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
result = func_to_call(**validated_params)
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
eld if dict
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration:
{duration:.2f}s.")
self.agent.self_model.record_tool_outcome(tool_name, params, result,
success_from_caller=(result['_exec_info']['execution_successful']))
except ToolNotFoundError: raise
    pass  # inserted to fix indentation error
except (AgentError, LogicError, SecurityError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
agent errors
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}",
exc_info=False)
"status": "error", "error": str(ae), "raw_error_details": str(ae),
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
raise
except Exception as e:
    pass  # inserted to fix indentation error
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
'error_type': exc_type, 'execution_successful': False
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
raise e
rst arg) ---
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
"""Allows the agent to engage in explicit thought or reasoning."""
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log",
content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str,
percentage_complete: Optional[
oat] = None) -> Dict:
"""Reports progress on the current goal."""
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if
percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log',
[]).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str =
"success", details: Optional[Dict] = None) -> Dict:
"""Reports the
nal result of a goal or task. This typically ends a plan."""
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
output.
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] =
"MEDIUM", context: Optional[Dict] = None) -> Dict:
Prepares a subgoal for the agent's cognitive cycle.
The deliberation/planning phase will then make this subgoal active and push parent to
stack.
This tool is now more of a declarative intent for the planner/deliberator.
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH})
reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is
not a dict."
return {"status": "error", "error_type": "LogicError", "error": msg}
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else
GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}
_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
Inherit directives
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent:
{current_active_goal_dict.get('id')}")
ectively a request to the deliberator.
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and
push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str =
"vector", n_results: int = 3, type_
lter: Optional[str] = None) -> Dict:
"""Queries the agent's memory system."""
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,
lter=type_
lter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
c parameters, e.g., node label, relation type
results = agent.memory_system.query_graph_store(query_node_label=query_text,
depth=1)
elif memory_type == "relational":
    pass  # inserted to fix indentation error
c tools might be better
results = agent.memory_system.query_relational_store(table=query_text,
limit=n_results)
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results
found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
"""Moves the agent's virtual embodiment in a speci
ed direction (e.g., 'north', 'south',
'east', 'west')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
"""Examines a speci
c object or feature in the current environment."""
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params:
Optional[Dict] = None) -> Dict:
"""Interacts with a special feature in the environment (e.g., 'interactive_console')."""
return agent.embodiment.act(action_type="use_feature", target=feature_name,
params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
"""Allows the agent's embodiment to rest and recover energy/mood."""
return agent.embodiment.act(action_type="rest")
cation Tools (UNSAFE - require careful gating) ---
def read_
le_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
log_tool = get_logger("TOOL_read_
le")
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to read
le '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")
if not full_path.is_
    pass  # inserted to fix indentation error
le():
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found:
{path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) >
MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path),
le_size_bytes": len(content)}
except SecurityError as se:
    pass  # inserted to fix indentation error
c security error
log_tool.error(f"Security error reading
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
log_tool.error(f"Error reading
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read
le: {e}"}
def write_
le_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_
if not str(full_path).startswith(str(WORKSPACE_DIR)):
    pass  # inserted to fix indentation error
log_tool.error(f"Security: Attempt to write
le '{path}' outside of workspace denied.")
raise SecurityError(f"File access denied: Writing outside designated workspace
({path}).")
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path":
str(full_path)}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error writing
log_tool.error(f"Error writing
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write
def list_
les_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_
les")
log_tool.error(f"Security: Attempt to list
les in '{path}' outside of workspace or agent
raise SecurityError(f"File access denied: Listing outside designated areas ({path}).")
if not full_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a
directory: {path}"}
items = []
for item in full_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "
"size_bytes": item.stat().st_size if item.is_
le() else None,
"last_modi
ed": datetime.fromtimestamp(item.stat().st_mtime,
tz=timezone.utc).isoformat()
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(full_path), "contents": items}
log_tool.error(f"Security error listing
les in {path}: {se}")
log_tool.error(f"Error listing
les in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list
les: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int =
WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Playwright not available. Cannot browse web.")
return {"status": "error", "error": "Playwright not available."}
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
text_content = content
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if
len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int =
WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
if not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Requests or BeautifulSoup not available. Cannot search web.")
return {"status": "error", "error": "Requests/BeautifulSoup not available."}
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
for g in soup.
nd_all(class_='g'):
r = g.
nd('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.
nd('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_
le(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES)
-> Dict:
log_tool = get_logger("TOOL_monitor_log")
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log
le not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_
le": str(LOG_FILE), "content": content, "lines_read":
len(recent_lines)}
log_tool.error(f"Error reading log
le {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
if not HASHING_AVAILABLE or not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("hashlib or requests/BeautifulSoup not available. Cannot check website
update.")
return {"status": "error", "error": "Missing dependencies for website update check."}
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp":
datetime.now(timezone.utc).isoformat()}
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
if not SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.warning("Scapy not available. Cannot send ICMP ping. This is a placeholder
tool.")
return {"status": "error", "error": "Scapy not available. Ping tool is a placeholder."}
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count,
"packets_received": count, "latency_ms": random.randint(10, 100)}
return {"status": "error", "target_host": target_host, "packets_sent": count,
"packets_received": 0, "error_message": "Request timed out or host unreachable."}
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str,
context_code: Optional[str] = None) -> Dict:
"""Generates new Python code based on a description and optional context."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
agent.log.warning(f"UNSAFE: Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a
complete function/class de
nition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
```
Generate ONLY the Python code block. Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
agent.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
"""Validates Python code for syntax correctness."""
return agent.self_modi
cation_unit.validate_code_modi
cation_UNSAFE(code_to_validate)
Reuse validation logic
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec:
int = 30) -> Dict:
"""Executes a shell command. EXTREMELY DANGEROUS."""
if not ENABLE_SHELL_TOOL: return {"status": "error", "error": "Shell tool is disabled."}
    pass  # inserted to fix indentation error
agent.log.warning(f"Executing UNSAFE shell command: {command}")
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if
sys.platform != "win32" else None)
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s.
Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out
after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed
with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute
command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str,
content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value,
content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id,
"message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
cationTools container ---
ToolExecutor.
cationTools:
"""Handles proposing, validating, applying changes to agent code (EXTREMELY
DANGEROUS)."""
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref:
'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.log.warning("Self-Modi
cation Unit initialized BUT DISABLED by con
guration.")
if not DIFF_MATCH_PATCH_AVAILABLE or not dmp_module:
    pass  # inserted to fix indentation error
self.log.error("Self-Modi
cation Unit initialized but 'di
_match_patch' library is missing
or failed to import. Self-mod tools will fail.")
self.dmp = dmp_module.di
_match_patch()
self.log.info(f"Self-Modi
cation Unit initialized. Code Dir: {self.agent_code_dir}, Backup
Dir: {self.backup_dir}")
def _resolve_target_path(self, target_
le_rel: str) -> Path:
"""Resolves relative path to absolute path within agent code dir and validates."""
if ".." in target_
    pass  # inserted to fix indentation error
le_rel or target_
le_rel.startswith("/"):
raise SecurityError(f"Invalid characters or absolute path in target_
le_rel:
{target_
le_rel}")
target_path_abs = (self.agent_code_dir / target_
le_rel).resolve()
directory
if not str(target_path_abs).startswith(str(self.agent_code_dir.resolve())):
    pass  # inserted to fix indentation error
self.log.error(f"Path traversal attempt: {target_
le_rel} resolved to {target_path_abs}
which is outside {self.agent_code_dir}")
raise SecurityError(f"Target
le '{target_
le_rel}' resolves outside the agent code
directory. Access denied.")
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
"""Inspects the source code of a speci
ed agent component (e.g., class name or module
path)."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Inspecting code for component: {component_name}")
target_obj = None
nd by attribute of the agent instance (e.g., agent.self_model)
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
nd in tool registry
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
nd as a globally de
ned class/function in main script context
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
nd in sys.modules (as a module name)
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
ed: if component_name looks like a module, search it.
nd it in common places.
candidate_modules = [sys.modules.get('__main__'),
sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod,
    pass  # inserted to fix indentation error
component_name)):
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
le_path = inspect.get
le(target_obj)
return {"status": "success", "component_name": component_name, "
le_path":
le_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module,
class, or function de
ned in a
le.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but
source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
return {"status": "error", "error": f"Component '{component_name}' not found or source
code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModi
cationError))
def propose_code_modi
cation_UNSAFE(self, component_name: str, issue_description: str,
proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
"""Proposes a code modi
cation using LLM based on an issue and desired change."""
self.log.warning(f"UNSAFE: Proposing code modi
cation for {component_name}. Issue:
{issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
return {"status": "error", "error": f"Could not fetch current code for
{component_name} to propose modi
cation. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent
modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
{current_code_snippet}
Generate the modi
ed Python code for the speci
ed component.
Provide ONLY the complete, new Python code block for the modi
ed function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '```python' and end with '```'.
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name,
"proposed_code": proposed_code}
self.log.warning(f"LLM did not return a valid code block for code generation.
return {"status": "error", "error": "LLM failed to generate code in the expected
format."}
self.log.error(f"Error proposing code modi
cation for {component_name}: {e}",
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modi
cation_UNSAFE(self, code_to_validate: str) -> Dict:
"""Validates Python code using AST parsing (syntax check only). Conceptual sandboxed
execution would be next."""
self.log.warning(f"UNSAFE: Validating proposed code snippet (
{code_to_validate[:100]}...")
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/
safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modi
cation_UNSAFE(self, component_name: str, new_code: str,
target_
le_path: Optional[str]=None) -> Dict:
Applies a validated code modi
cation. EXTREMELY DANGEROUS.
This conceptually involves
nding the component in the agent's source
le and replacing
it.
Requires agent restart to take e
ect if modifying core running code.
self.log.critical(f"UNSAFE: Attempting to apply code modi
cation to component
'{component_name}'. THIS IS HIGHLY RISKY.")
le. This is complex and error-prone.
if not target_
    pass  # inserted to fix indentation error
le_path:
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('
    pass  # inserted to fix indentation error
le_path'):
target_
le_path = inspection_res['
le_path']
else:
    pass  # inserted to fix indentation error
le_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_
le = Path(target_
le_path)
le.exists() or not target_
le.is_
return {"status": "error", "error": f"Target
le for modi
cation not found: {target_
le}"}
original_code = target_
le.read_text()
backup_path = SELF_MOD_BACKUP_DIR /
f"{target_
le.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_
le, backup_path)
self.log.info(f"Backed up original
le to {backup_path}")
nition:
nd the old de
nition of `component_name` and replace it.
nd `class ComponentName...` or `def ComponentName...`
nd existing class or function de
nition
everything until the next class/def or end of typical indentation block.
patter n_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
start of next non-indented line or EOF
patter n_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modi
ed_original_code = original_code
found_and_replaced = False
match_class = re.search(patter n_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
match_def = re.search(patter n_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function de
modi
ed_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not
nd component '{component_name}' in {target_
le} for
replacement. Modi
cation aborted.")
return {"status": "error", "error": f"Component '{component_name}' de
nition not
found for replacement."}
target_
le.write_text(modi
ed_original_code)
cation validation (e.g., try to import the modi
le in a subprocess)
self.log.warning(f"Code modi
cation applied to {target_
le}. Agent restart is LIKELY
REQUIRED for changes to take e
ect.")
ect potential capability change
self.agent_ref.self_model.add_event_log(f"Applied code modi
cation to
{component_name}. Restart pending for full e
self.agent_ref.self_model.beliefs[f"component_{component_name}
_modi
ed_pending_restart"] = True
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
after code change
return {"status": "success", "message": f"Code for '{component_name}' in '{target_
le}'
ed. Restart required."}
self.log.critical(f"CRITICAL ERROR applying code modi
cation to {component_name}:
{e}", exc_info=True)
ed)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_
le)
self.log.info(f"Restored original
le {target_
le} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modi
cation: {e}. System
might be unstable."}
def rollback(self, backup_
le: Path, target_
le: Path):
"""Rolls back a
le to a backup."""
self.log.info(f"Attempting to rollback '{target_
le}' from '{backup_
le}'")
shutil.copy(backup_
le, target_
self.log.info(f"Successfully rolled back '{target_
le}'.")
ags in self-model or state
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_
le}.")
self.agent_ref.self_model.beliefs[f"component_{target_
le.name}
ed_pending_restart"] = False
ags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_
le.name)
return {"status": "success", "message": f"Rolled back {target_
le}."}
self.log.error(f"Failed to rollback {target_
le}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_
le_rel: Union[str, Path]):
"""Attempts to reload a module to apply changes without full restart."""
target_module_name = Path(target_
le_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is
required.")
ed attempt:
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
ect global instances like `_agent_instance_hack` if it was part of the
reloaded module
if _agent_instance_hack and hasattr(sys.modules[target_module_name],
    pass  # inserted to fix indentation error
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot
reload.")
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for
changes to take e
def inspect_directives_UNSAFE(self) -> Dict:
"""Inspects the agent's current core directives."""
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modi
cation_UNSAFE(self, analysis_of_misalignment: str,
proposed_directive_changes_desc: str) -> Dict:
"""Proposes modi
cations to core directives using LLM."""
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need
review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (
oat 0-1), "last_eval_score" (
oat 0-1,
usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational',
'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore
goals of safety, learning, and utility.
Output ONLY the JSON list.
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in
    pass  # inserted to fix indentation error
proposed_directives):
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
returned an error message as JSON
return {"status": "error", "error": f"LLM indicated error during directive proposal:
{proposed_directives['error']}"}
self.log.warning(f"LLM did not return a valid list of directives. Response:
{llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list
self.log.error(f"Error proposing directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modi
cation_UNSAFE(self, new_directives: List[Dict]) -> Dict:
"""Applies new core directives to the agent's SelfModel."""
self.log.warning(f"UNSAFE: Applying new core directives. Count: {len(new_directives)}")
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in
new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modi
cation_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count:
{len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
return {"status": "success", "message": "Core directives updated."}
self.log.error(f"Error applying directive modi
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModi
cationTools(AGENT_CODE_DIR,
SELF_MOD_BACKUP_DIR, agent)
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in
    pass  # inserted to fix indentation error
name.upper():
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
"""Represents the agent's internal model of itself, including beliefs about the
environment."""
def __init__(self, state: Optional[Dict]=None, agent_directives_con
Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_con
g if agent_directives_con
g is not None else
DEFAULT_CORE_DIRECTIVES
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
'failure_count', ...}}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
metacognitive checks
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_con
dence: Dict[str,
oat] = {}
dence_score}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
General beliefs about self and world
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
summary of knowledge areas
self.learning_goals: List[Dict[str, Any]] = []
c goals for learning/improvement
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.lear ned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
based narrative of current internal state
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_con
dence_self_assessment": 0.7
self.event_log: List[Dict[str, Any]] = []
cant internal events (e.g., directive
changes, model updates)
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
later.
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted",
sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
dence = sm_state.get("skill_con
dence", self.skill_con
dence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary",
self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies",
self.adaptation_strategies)
self.lear ned_abstractions = sm_state.get("lear ned_abstractions",
self.lear ned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative",
self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs",
self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
"""Saves the self-model's persistent components back to the main state dict's KB."""
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_con
dence": self.skill_con
dence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"lear ned_abstractions": self.lear ned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
kb["self_model_state"] = sm_persistent_state
ection and prompt_suggestions_from_re
ection
ection process.
def add_event_log(self, event_description: str, event_type: str = "info", data:
Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
dence for new tools
for tool_name in self.capabilities:
if tool_name not in self.skill_con
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = 0.5
dence
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0,
'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None,
'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.",
event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8: hint = " (Reliability: High)"
    pass  # inserted to fix indentation error
elif score > 0.6: hint = " (Reliability: Moderate)"
    pass  # inserted to fix indentation error
elif score > 0.3: hint = " (Reliability: Low)"
    pass  # inserted to fix indentation error
else: hint = " (Reliability: Very Low/Untested)"
    pass  # inserted to fix indentation error
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict,
success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration':
0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
MAX_RECENT_TOOL_OUTCOMES_IN_SELFMODEL (constant not de
ned, using 30)
dence (simple heuristic for now)
current_con
dence = self.skill_con
dence.get(tool_name, 0.5)
self.skill_con
dence[tool_name] = min(1.0, current_con
dence + 0.05)
dence[tool_name] = max(0.0, current_con
dence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability:
{stats['reliability_score']:.2f}, Con
dence: {self.skill_con
dence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_con
dence_drift(sm: 'SelfModel') -> Optional[str]:
low_con
dence_skills = [skill for skill, conf in sm.skill_con
dence.items() if conf < 0.25
and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_con
    pass  # inserted to fix indentation error
dence_skills) >= 2 :
return f"Multiple critical skills have very low con
dence and recent failures: {',
'.join(low_con
dence_skills)}. Consider skill improvement or alter native strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict): return None
    pass  # inserted to fix indentation error
low_eval_directives = []
for d in sm.core_directives:
problematic.
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {',
'.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count}
with max replans. Planning or execution e
ectiveness may be compromised. Review strategy
or tool reliability."
self.anomaly_detection_rules.append(check_skill_con
dence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}):
{anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}",
event_type="anomaly")
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__')
else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {';
'.join(detected_anomalies)}. Current focus is on addressing these."
self.internal_state_narrative = "Metacognitive check completed. System appears
stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0),
reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:
{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_con
    pass  # inserted to fix indentation error
con
dent_skills = [s for s,c in self.skill_con
dence.items() if c > 0.7][:3]
summary += f"Con
dent Skills (sample): {', '.join(con
dent_skills) if con
dent_skills else
'None highly con
dent'}\n"
summary += f"Inter nal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and
stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and
stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools: summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
    pass  # inserted to fix indentation error
if unreliable_tools: summary += f" Needs Improvement: {', '.join([t[0] for t in
    pass  # inserted to fix indentation error
unreliable_tools[:3]])}\n"
summary += "---\n"
def get_self_assessment_prompt(self) -> str:
ection)
base_prompt = """Analyze your recent performance, knowledge, internal state, and
alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:
output_keys_example = [
"`re
ection_summary` (str: Overall summary of the re
ection period).",
"`key_successes` (list of str: Speci
c achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Speci
c setbacks or di
culties encountered).",
"`lear ned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identi
ed` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool
e
ectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM
interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g.,
'curious', 'frustrated', 'satis
ed').",
"`resource_usage_concer ns` (str or null: Any concer ns about computational resource
usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_
oat_0_to_1: How
well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes,
provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only
suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model?
What needs improvement?).",
"`new_learning_goals` (list of str: Speci
c goals for future learning or skill
development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring
issues or improve performance).",
"`self_modi
cation_needed` (str or null: If parts of your own code/logic need
cation, describe what and why. Be very speci
c and cautious.)."
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives,
indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n"
+ \
f"Recent Tool Outcomes (last 5 entries):
\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}
\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment
with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
response_str = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment:
{assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_re
ection(self, re
ection_data: Dict) -> Tuple[bool, bool]:
ection updates)
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from re
ection data...")
dence, tool_notes (as in base script logic)
ection_data directly updates some
elds or implies updates
if re
    pass  # inserted to fix indentation error
ection_data.get('re
ection_summary'):
self.internal_state_narrative = re
ection_data['re
ection_summary']
updated_self = True
core_directives_eval = re
ection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and
    pass  # inserted to fix indentation error
isinstance(self.core_directives[0], dict):
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (
    pass  # inserted to fix indentation error
oat, int)) and 0.0 <= eval_score
<= 1.0:
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...'
evaluation score to {eval_score:.2f}")
if updated_self: self.add_event_log("Directive evaluation scores updated from
    pass  # inserted to fix indentation error
re
ection.")
suggested_directive_updates = re
ection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Re
ection suggested updates to core directives:
{str(suggested_directive_updates)[:200]}...")
'apply_directive_modi
cation_UNSAFE' tool
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modi
cations from
ection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source":
"self_re
ection"}
updated_self = True
self.add_event_log("Re
ection suggested directive updates. Metacognitive review
goal created.", event_type="critical_review_needed")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('new_learning_goals'), list):
for lg_str in re
ection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts":
datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self: self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
    pass  # inserted to fix indentation error
ection_data.get('adaptation_strategy_proposals'), list):
for strat_str in re
ection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self: self.log.info(f"Updated adaptation strategies. Total:
    pass  # inserted to fix indentation error
{len(self.adaptation_strategies)}")
patterns)
agent
ection_data.get('lear ned_facts') or re
ection_data.get('prompt_tuning_suggestions'):
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from re
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
"""Saves a backup of current directives to a
le."""
backup_
le = SELF_MOD_BACKUP_DIR /
f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
with backup_
le.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_
le} due to: {reason}")
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
"""Simulates an internal dialog about a topic using LLM, potentially from di
erent
perspectives."""
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_o
cer"]
dialog_history = []
full_dialog_str = f"Inter nal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts,
questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
contribution = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution":
contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
self.log.error(f"Error during internal dialog generation for perspective
{perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":
full_dialog_str})
return full_dialog_str
class MotivationEngine:
"""Manages the agent's internal drives and their in
uence on behavior."""
def __init__(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[DriveType, DriveState] = {}
self._initialize_drives(drive_con
gs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]]):
default_con
gs = {
DriveType.CURIOSITY: {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.MASTERY: {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.ACHIEVEMENT: {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1,
DriveType.NOVELTY_SEEKING: {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.7},
DriveType.PRESERVATION: {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0,
"initial_level": 0.2},
DriveType.EFFICIENCY: {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1,
DriveType.SOCIAL_INTERACTION: {"decay_rate": 0.01, "max_level": 1.0, "min_level":
0.0, "initial_level": 0.3},
gs = drive_con
gs if drive_con
gs is not None else default_con
gs
for drive_type in DriveType:
g = con
gs.get(drive_type, default_con
gs.get(drive_type, {}))
self.drives[drive_type] = DriveState(
drive_type=drive_type,
level=con
g.get("initial_level", 0.5),
decay_rate=con
g.get("decay_rate", 0.01),
max_level=con
g.get("max_level", 1.0),
min_level=con
g.get("min_level", 0.0)
def update_drives(self):
"""Applies decay and updates drives based on recent experiences or time."""
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
"""Updates drives based on a speci
c experience."""
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "lear n":
    pass  # inserted to fix indentation error
self.drives[DriveType.CURIOSITY].update(stimulus=-0.05)
self.drives[DriveType.MASTERY].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives[DriveType.PRESERVATION].update(stimulus=0.1)
self.drives[DriveType.MASTERY].update(stimulus=-0.05)
def get_drive_level(self, drive_type: DriveType) ->
oat:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
if not found
    pass  # inserted to fix indentation error
def get_all_drive_levels(self) -> Dict[DriveType,
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str,
return {dt.name: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[DriveType,
"""Retur ns top N drives by current level."""
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
"""Suggests a goal type based on current highest drives."""
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == DriveType.CURIOSITY:
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == DriveType.MASTERY:
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == DriveType.ACHIEVEMENT:
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == DriveType.PRESERVATION:
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == DriveType.EFFICIENCY:
    pass  # inserted to fix indentation error
return "optimization"
class DriveState:
drive_type: DriveType
level:
decay_rate:
oat = 0.01
max_level:
oat = 1.0
min_level:
oat = 0.0
last_update_time:
oat =
eld(default_factory=time.time)
def update(self, stimulus:
oat = 0.0):
"""Updates the drive level based on stimulus and decay."""
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class FileChannel:
"""Implements a simple
le-based communication channel for multi-agent systems."""
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_
le = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_
le}")
def _write_message_to_
le(self, message: Message, target_
le: Path) -> bool:
le lock to prevent corruption during writes
with FileLock(str(target_
le) + ".lock", timeout=5):
messages = []
if target_
    pass  # inserted to fix indentation error
le.exists():
try:
    pass  # inserted to fix indentation error
existing_content = target_
le.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le}: {e}. Clearing
le.")
messages = []
messages.append(message.to_dict())
le.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_
le}. Message not sent to
return False
self.log.error(f"Error writing message to {target_
le}: {e}")
def _read_messages_from_
le(self, source_
le: Path) -> List[Message]:
messages = []
if not source_
    pass  # inserted to fix indentation error
with FileLock(str(source_
content = source_
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if
isinstance(msg_data, dict)]
le after reading
source_
le.write_text("", encoding='utf-8')
return messages
self.log.warning(f"Timeout acquiring lock for {source_
le}. Cannot read messages.")
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {source_
source_
le.write_text("", encoding='utf-8')
self.log.error(f"Error reading messages from {source_
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}:
{message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_
le(message, target_inbox)
def receive_messages(self) -> List[Message]:
"""Checks and retrieves new messages from the agent's inbox."""
new_messages = self._read_messages_from_
le(self.inbox_
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message],
Optional[Message]]):
"""Registers a function to handle speci
c message types."""
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
"""Processes all messages currently in the inbox using registered handlers."""
messages = self.receive_messages()
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From:
{msg.sender_id}")
handled = False
if msg.message_type in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg.message_type]:
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler
{handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id,
receiver_id=msg.sender_id, type=MessageType.ERROR, content={"original_message_id":
msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type
{msg.message_type.value}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
"""Abstract base class for a sensor."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', con
g: Dict):
self.id = id
self.embodiment = embodiment
self.con
self.log = get_logger(f"SENSOR_{id}")
def get_reading(self) -> Any:
"""Retur ns the current reading from the sensor."""
class Actuator(ABC):
"""Abstract base class for an actuator."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], con
self.capabilities = capabilities
self.log = get_logger(f"ACTUATOR_{id}")
def perform_action(self, action_type: str, **kwargs) -> Dict:
"""Performs a speci
c action using the actuator."""
class VirtualEmbodiment:
"""Simulated embodiment layer for SystemCore agents. (Can be replaced by Gym environments or
more complex sims)"""
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing
system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to
'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button",
"research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, recon
gurable bay designed for running complex simulations.
Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_con
g_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data
ow and
storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core.
Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in
self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
"""Generate synthetic sensory input based on current environment and internal state."""
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20: self.state["emotions"]["anxiety"] = min(1.0,
    pass  # inserted to fix indentation error
self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An unde
ned space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
internal_state_packet = {
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
self.gym_env.step(self.gym_env.action_space.sample())
observation
logging
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) ->
Dict:
Simulates the agent performing an action in the virtual world.
Retur ns a dictionary with the result of the action.
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params:
{params}")
params = params or {}
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as speci
ed."
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console": message += " It shows
    pass  # inserted to fix indentation error
uctuating green and
amber lights."
elif target == "core_status_monitor": message += " It indicates: Core Nominal.
    pass  # inserted to fix indentation error
Directives Stable. Lear ning Rate: Optimal."
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.2)
message = f"Picked up {target}."
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
problem.
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name",
"default_physics_test"), params.get("con
g",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result:
{sim_result}"
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
ect emotional state based on action outcome
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if
action_type=="move" else None, "updated_inventory": self.state["inventory"] if
action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "lear n"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage
at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response:
{self.agent.self_model.internal_state_narrative[:100]}..."
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model
<topic>'."
def _run_simulation(self, sim_name: str, con
g: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with con
g: {con
g}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_con
    pass  # inserted to fix indentation error
g" in con
g: success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric:
{outcome_value}."
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check con
guration."
def summary(self) -> str:
"""Retur ns a string summary of the embodiment's current state."""
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Inter nal State (summary): Energy={self.state['energy']},
Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
class CognitiveCycle:
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time:
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
methods
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE,
LAST_LEARNING_MODULE_UPDATE_CYCLE
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status:
{self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack
Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if
self.agent.state['goals'].get('active') else None
self.agent.last_error = None
cycle_ok = False
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
understanding
if self.agent.self_model and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
self.log.info(f"Triggering proactive metacognitive check (Cycle
{self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
goal
if self.agent.learning_module and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_LEARNING_MODULE_UPDATE_CYCLE >=
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.lear n_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
new_pending_goals
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
List of Goal dicts
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation:
{ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
pending_list.sort(key=lambda x: GoalPriority[x.get('priority', 'MEDIUM').upper() if
isinstance(x.get('priority'),str) else GoalPriority(x.get('priority',
GoalPriority.MEDIUM)).name ].value, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type ==
    pass  # inserted to fix indentation error
"active_goal_continue":
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution:
{goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID:
{goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal'
provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
object
ed logic assumes plan is a list of steps in the goal dict.
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or
    pass  # inserted to fix indentation error
current_goal_obj.replan_count > 0:
planning
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
generation
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
Goal object
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan available or generated for goal: {current_goal_obj.goal[:50]}.
Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
c goal, agent is idle or performing non-goal action
self.agent.current_goal_outcome = True
if time.time() - LAST_DELIBERATION_TIME >
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModi
cationError, LogicError, LLMError, SecurityError, Con
gurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
Lear ningError, SafetyViolationError) as agent_cycle_err:
c goal
attempt.
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent
Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
nished (with an error for current goal), but agent can continue
unless critical.
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
nally:
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() -
start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
"""Processes observations to update world model and identify key information."""
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
ed approach. A real system might have more structured parsing.
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent
understanding of the current situation. Identify key entities, events, and any signi
cant changes
in the environment or your internal state. Focus on information relevant to achieving current
goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content:
{str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\":
\"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"],
\"potential_impact_on_goals\": \"str\"}"
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation",
understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
as facts/experiences
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event",
metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry,
persist_to_vector=True)
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
self.log.error(f"Error during LLM-based understanding: {e}")
complex updates to the graph/relational store
return {"summary": understanding_summary, "processed_info": processed_info,
"raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError,
DeliberationError))
def _deliberate(self, understanding_result: Dict) -> Dict:
Core deliberation logic: goal management, selection, and generation.
Retur ns a dict: {"chosen_action_type": str, "next_goal": Optional[Goal_dict],
"new_pending_goals": List[Goal_dict]}
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio:
{pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio:
{active_priority_val}).")
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time':
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack
(paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
activated
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
continue
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
decision["chosen_action_type"] = "pending_goal"
directives (idle task)
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal
generation.")
directives
if time.time() - LAST_DELIBERATION_TIME >=
    pass  # inserted to fix indentation error
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_lear n", "directive_curiosity",
"directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
for idle time
pass
new_pending_goals)
processed
ag.
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') ==
    pass  # inserted to fix indentation error
'sub_goal_prepared':
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output:
{sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
c action, LLM will decide
self_model_summary =
understanding_summary = understanding_result.get('summary', 'No speci
understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact',
'None identi
ed.')
interp_con_val = understanding_result.get('interpretation_con
dence', 0.7)
recent_memory_context =
self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary,
max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Con
dence: {interp_con_val:.2f}):**
{understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identi
ed:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory
(STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]],
indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else
f'{active_goal_dict.get("goal")[:100]}... (ID: {active_goal_dict.get("id")})'}",
f"* **Agent Core Directives
(Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding,
drives, memories, goals, directives), what is the most critical aspect demanding attention or the
best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.self_model.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/
complete).",
"    - Performing `re
ection` or `self_assessment` (if mandatory timers, drives like low
CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration
goal), Directives (e.g., low-eval directive -> improvement goal), or identi
ed opportunities. New
goals require `goal` (str), `priority` (
oat 0.0-1.0), `origin` (str e.g., 'drive_curiosity',
'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of
str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for
viability before committing if uncertainty is high or consequence severe (brie
y note simulation
outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are
apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the
immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, high
drives, or highest priority pending. State reasoning clearly.",
```python
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.
If selecting an existing pending goal, it moves to `next_goal` and is removed from pending
internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/
directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal',
'new_goal', 're
ection', 'self_assessment', 'exter nal_command_action', 'idle',
'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass
structure) selected for immediate execution. Null if idle/re
ection/assessment without a direct
goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen
for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into
`new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into
`new_pending_goals`."
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent.
Analyze the situation comprehensively, consider drives and directives, and make strategic
decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and
deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON:
{extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal',
'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys:
{deliberation_decision.keys()}")
if key == 'new_pending_goals': deliberation_decision[key] = []
    pass  # inserted to fix indentation error
elif key == 'next_goal': deliberation_decision[key] = None
    pass  # inserted to fix indentation error
else: deliberation_decision[key] = "Error: Missing from LLM Output"
    pass  # inserted to fix indentation error
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty
list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not
    pass  # inserted to fix indentation error
isinstance(deliberation_decision.get('next_goal'), dict):
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value:
{deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and
    pass  # inserted to fix indentation error
new_goal_dict.get('priority'):
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p.id == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
duplicates based on ID
current_pending_list.append(new_goal_obj)
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list
from deliberation.")
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'
self.log.warning(f"Deliberation proposed invalid new pending goal:
{new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
LLM
current_active_goal = self.agent.get_active_goal_object()
None
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending',
[]) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
selected_goal_obj.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = selected_goal_obj
self.log.info(f"Moved pending goal {selected_goal_obj.id}
('{selected_goal_obj.goal[:50]}') to active.")
self.log.warning(f"LLM selected pending goal by ID
{selected_next_goal_dict.get('id')}, but not found in list. Idling.")
action_type = "idle"
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
highest_priority_pending.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = highest_priority_pending
self.log.info(f"Deliberation chose 'pending_goal' without speci
c ID; moved
highest priority '{highest_priority_pending.goal[:30]}...' to active.")
self.log.warning("Deliberation chose 'pending_goal' but no pending goals
available. Idling.")
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in
    pass  # inserted to fix indentation error
selected_next_goal_dict:
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj
self.log.info(f"Deliberation created and activated new goal:
{new_active_goal_obj.goal[:30]}...")
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal
active
current_active_goal.status = GoalStatus.ACTIVE
rm active status
self.log.info(f"Deliberation chose to resume current active goal:
{current_active_goal.goal[:30]}...")
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
elif action_type in ['idle', 're
    pass  # inserted to fix indentation error
ection', 'self_assessment', 'exter nal_command_action']:
'INTERRUPTED'.
current_active_goal.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal.goal[:30]}' PAUSED due to
{action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal.to_dict())
pending, maybe re-prioritize later
self.log.debug(f"Not re-adding paused goal {current_active_goal.id} to pending
as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to
Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action:
{deliberation_decision.get('chosen_action_type')}. Reason:
{deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
Executes the current plan for the active_goal.
Retur ns True if goal considered successfully processed for this cycle, False if critical error.
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps:
{len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
rst step in the plan. The plan will be truncated or re-evaluated.
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id,
"plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params,
current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
ned based on tool_result and goal progress
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
ed snapshot
internal_state_after=self.agent.self_model.beliefs
ects
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
nal_status = tool_result.get("status", "unknown")
nal_status == "success":
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome =
nal_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
nished.
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing
nished by report_result.
Status: {
nal_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error',
'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj,
tool_result, observations[0] if observations else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal
will likely fail.")
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without
'report_result'. Goal might be incomplete.")
ection.
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
except AgentError as e:
    pass  # inserted to fix indentation error
violations
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}':
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) ->
"""Calculates a reward signal based on tool execution outcome and goal relevance."""
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
goaling
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
in cycle
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
for direct access
self.learning_module: Lear ningModule
self.planning_module: PlanningModule
direct access
self.safety_module: SafetyModule
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.state['
ags'] = {}
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete ---
Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response
Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled:
{ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modi
cation Enabled: {ENABLE_SELF_MODIFICATION}")
if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
    pass  # inserted to fix indentation error
ENABLE_SELF_MODIFICATION:
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME
CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}",
self.shutdown()
gurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH == "mock":
    pass  # inserted to fix indentation error
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Cannot use Gemini model: google-generativeai library not
installed.")
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
elif TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
global LLM_PIPELINE, LLM_TOKENIZER
CPU
AutoTokenizer.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
oat16 if
torch available
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH,
LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS,
get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
c not implemented here
self.log.warning(f"LLM_MODEL '{LLM_MODEL_NAME_OR_PATH}' not fully con
for wrapper selection, using Mock.")
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
_init_self_mod_tools(self, self.tool_manager)
cationTools handler
and register its UNSAFE methods
self._update_status("Initializing SystemCore Modules")
self.learning_module = Lear ningModule(self)
self.safety_module = SafetyModule(self)
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME,
shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager: self.tool_manager.check_playwright_browsers()
    pass  # inserted to fix indentation error
browser tool
self.log.info("Agent component initialization
nished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list): state['goals'][key] = []
    pass  # inserted to fix indentation error
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
items
state.setdefault('goal_stack', [])
state.setdefault('
ags', {})
ags system
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state
le {STATE_FILE}: {e}. Creating new state.")
self.log.error(f"Error loading state
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
"error_history_summary": [],
"recent_successes_summary": [],
its view)
"recent_failures_summary": [],
view)
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"
ags": {}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
cation and saving
_archive_goal)
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
state['knowledge_base']['self_model_state']
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status if self.self_model else
self._status
temp_
le = STATE_FILE.with_su
x(STATE_FILE.su
x + ".tmp")
with temp_
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_
le, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
"""Retur ns the current active goal as a Goal object, or None."""
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict:
{active_goal_dict}")
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority =
GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
deliberation
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict,
nal_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID:
{goal_data_dict.get('id')}) with status: {
nal_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
goal_obj.status = GoalStatus(
nal_status_str)
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-
MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status":
str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count":
goal_obj.replan_count}
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and
    pass  # inserted to fix indentation error
current_active_in_state.get('id') == active_goal_id:
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
stack
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID:
{active_goal_id}) concluded with status: {
nal_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-
goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
marked active
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal',
'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal:
{parent_goal_data_dict.get('goal', '')[:30]}")
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
goal wasn't a subgoal from stack
self.log.info("Goal archived. No parent goal to resume from stack, or current goal
was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized": self._update_status("Idle")
    pass  # inserted to fix indentation error
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and
environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if
self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle:
{loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
nal status of the goal processed in this cycle
updated_active_goal_dict = self.state['goals'].get('active')
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] ==
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['id']:
ects outcome
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED,
    pass  # inserted to fix indentation error
GoalStatus.CANCELLED]:
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
during preemption)
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
failed while this goal was active
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
failed
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
not speci
c to goal completion
ection (SystemCore Enhanced) - Can be more frequent or event-driven
if self._should_re
    pass  # inserted to fix indentation error
ect(active_goal_data_before_cycle):
self._re
ect_on_performance()
cant changes (already done in many places)
nal save here per cycle too.
if self.state['
    pass  # inserted to fix indentation error
ags'].get('re_evaluate_strategy_needed'):
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to signi
cant
internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['
ags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not
    pass  # inserted to fix indentation error
self.state['goals'].get('pending'):
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() -
LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_re
ect(self, processed_goal_data: Optional[Dict]) -> bool:
ection triggers
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
ect
every N cycles
if processed_goal_data and Goal.from_dict(processed_goal_data).status in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED, GoalStatus.FAILED]:
ect after signi
cant goal outcome
ect if enough goals processed since last time
goals_processed_key = "goals_processed_since_re
ection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >=
    pass  # inserted to fix indentation error
int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
return True
if time.time() - LAST_REFLECTION_TIME >
    pass  # inserted to fix indentation error
MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
if self.state['
    pass  # inserted to fix indentation error
ags'].get('explicit_re
ection_requested'):
return False
@retry(attempts=2, delay=5)
def _re
ect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Re
ecting on Performance ---")
ags']['explicit_re
ection_requested'] = False
ag
self.state["goals_processed_since_re
ection"] = 0
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt,
max_new_tokens=2048, temperature=0.5)
re
ection_data = extract_json_robust(llm_assessment_str)
if re
    pass  # inserted to fix indentation error
ection_data.get("error"):
self.log.error(f"Failed to get valid JSON from LLM self-assessment:
{re
ection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed:
ection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_re
ection(re
ection_data)
ection to MemorySystem
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts'), list):
for fact_str in re
ection_data['lear ned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source":
ection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True,
self.log.info(f"Added {len(re
ection_data['lear ned_facts'])} lear ned facts to memory
from re
ection_data.get('prompt_tuning_suggestions'), list):
for sugg_str in re
ection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str,
metadata={"source": "self_re
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
ection_data['prompt_tuning_suggestions'])} prompt
suggestions to memory.")
ndings from re
ection (e.g. self_modi
cation_needed)
ection_data.get('self_modi
cation_needed'):
mod_desc = re
ection_data['self_modi
cation_needed']
self.log.warning(f"Re
ection identi
ed need for self-modi
cation: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modi
cation based on re
ection:
{mod_desc}",
priority=GoalPriority.HIGH,
context={"modi
cation_description": mod_desc, "source": "self_re
ection insights or periodically
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) ==
    pass  # inserted to fix indentation error
0:
audit_issues = self.safety_module.audit_directives_and_behavior()
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identi
ed issues: {audit_issues}")
ndings
self._create_metacognitive_goal(f"Address directive audit
ndings:
{str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Re
ection Complete ---")
self.log.error(f"LLMError during re
ection: {e}")
self.log.error(f"Unexpected error during re
ection: {e}", exc_info=True)
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
"""Sets up handlers for di
erent message types if comms_channel exists."""
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY,
self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM,
self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}:
{message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base']
[query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample":
str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id,
type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}:
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
x with sender to avoid
clashes
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if not PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("psutil not available, resource monitoring disabled.");
if RESOURCE_MONITOR: return
    pass  # inserted to fix indentation error
self.log.info("Initializing resource monitor...")
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e: self.log.error(f"Failed to initialize resource monitor: {e}");
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("Playwright not available, skipping initialization.")
if PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Initializing Playwright...")
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER =
PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
globals)
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
if not PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE: try: PLAYWRIGHT_PAGE.close()
    pass  # inserted to fix indentation error
if PLAYWRIGHT_CONTEXT: try: PLAYWRIGHT_CONTEXT.close()
    pass  # inserted to fix indentation error
if PLAYWRIGHT_BROWSER: try: PLAYWRIGHT_BROWSER.close()
    pass  # inserted to fix indentation error
if PLAYWRIGHT_INSTANCE: try: PLAYWRIGHT_INSTANCE.stop()
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not PLAYWRIGHT_AVAILABLE or not self.playwright_context : return
    pass  # inserted to fix indentation error
self.log.warning("Attempting to reset Playwright page...")
global PLAYWRIGHT_PAGE
if self.playwright_page: try: self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
ush
if 'logging' in sys.modules: logging.shutdown()
    pass  # inserted to fix indentation error
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl}
Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/
{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)' if
ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
ENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_
priority=GoalPriority.HIGH).to_dict()
except Exception as e_cmd
    pass  # inserted to fix indentation error
le:
print(f"Error reading initial command
le: {e_cmd
le}",
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending',
[]).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort,
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal']
[:50]}' added to pending goals.")
main_agent_instance.run()
except Con
    pass  # inserted to fix indentation error
gurationError as cfg_err_main:
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}",
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to Con
gurationError:
{cfg_err_main}", exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to
    pass  # inserted to fix indentation error
Con
gurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else: logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt
    pass  # inserted to fix indentation error
during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}",
traceback.print_exc(
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",
else: logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main:
    pass  # inserted to fix indentation error
{main_exec_err}", exc_info=True)
exit_code = 1
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main
nally block...")
if hasattr(main_agent_instance, 'log'): main_agent_instance.log.warning("Main
    pass  # inserted to fix indentation error
nally
block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
main_log.warning("Agent instance likely not created or fully initialized. Basic
shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
```
global llm_pipelinesfor model_id in LLM_MODELS:try:except Exception:passtokenizer = AutoTokenizer.from_pretrained(model_id)model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)llm_pipelines.append((model_id, llm))except Exception as e:print(f"Failed to load {model_id}: {e}")
for model_id, llm in llm_pipelines:try:except Exception:passprint(f"Using model: {model_id}")result = llm(prompt)[0]['generated_text']return resultexcept Exception as e:print(f"Model {model_id} failed: {e}")return "No available model could generate a response."
__systemcore_body__ = SimulatedEntity(name="SystemCore", position=(0.0, 0.0))__dummy_agent__ = SimulatedEntity(name="AgentB", position=(1.0, 0.0))__embodied_world__ = InteractionWorld()__embodied_world__.add_entity(__systemcore_body__)__embodied_world__.add_entity(__dummy_agent__)
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)__embodied_world__.simulate_step()
from dataclasses import dataclass
field, asdict, MISSING
field
except Exception:
    pass  # inserted to fix indentation error
pass
PSUTIL_AVAILABLE = True
from chromadb.config import Settings as ChromaSettings
chromadb = None
TRANSFORMERS_AVAILABLE = True
TORCH_AVAILABLE = True
PLAYWRIGHT_AVAILABLE = True
REQUESTS_BS4_AVAILABLE = True
GOOGLE_GENAI_AVAILABLE = True
PILLOW_AVAILABLE = True
dmp_module = None
HASHING_AVAILABLE = True
NETWORKX_AVAILABLE = True
GYMNASIUM_AVAILABLE = True
is set to '{LLM_MODEL_NAME_OR_PATH}'. Set LLM_MODEL='mock', point to a Geminimodel, or install transformers/google-generativeai.",
passtorch.tensor([1.0]).to('cuda')
passtorch.tensor([1.0]).to('mps')
and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type":"growth"},
innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type":"exploratory"},
awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type":"foundational"},
guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type":"guardrail"},
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
except Exception:
    pass  # inserted to fix indentation error
passcon
int(os.getenv("LEARNING_MODULE_UPDATE_INTERVAL_CYCLES", 50))
_agent_instance_hack: Optional['CognitiveSystem'] = None
console_handler = RichHandler(
passle_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
except Exception:
    pass  # inserted to fix indentation error
passreturn fn(*args, **kwargs)
else:
    pass  # inserted to fix indentation error
passp = psutil.Process(os.getpid())
passwith monitor.oneshot():
passreturn json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
passreturn json.loads(text_trimmed)
passstart_index = text.
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
field(default_factory=lambda: f"goal_{uuid.uuid4()}")
field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
field(default_factory=dict)
field(default_factory=list)
field(default_factory=list)
field(default_factory=list)
field(default_factory=list)
except Exception:
    pass  # inserted to fix indentation error
passif isinstance(data['priority'], int):
fields for backward compatibility or LLM generation
field_names = {f.name forfin
fields(cls)}
fields are present or have defaults
fields(cls):
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
field(default_factory=lambda: f"mem_{uuid.uuid4()}")
field(default_factory=dict)
field(default_factory=list)
field(default_factory=dict)
"ect_id'}
field has the main data
field(default_factory=lambda: f"msg_{uuid.uuid4()}")
field(default_factory=dict)
"ect(TypedDict):
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest`think` with `thought_process`='some thought'."
pass
passgeneration_con
generation_con
passreturn self.model.count_tokens(text).total_tokens
pass
passembodiment_obs = self.agent.embodiment.get_sensory_input()
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
passif COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
"er: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
"er for later learning."""
"er.append(experience)
"er) > self.MAX_BUFFER_SIZE:
"er.pop(0)
"ered experiences."""
"er:
"er)} experiences.")
"er)
"er.clear()
passprompt = "Analyze the following recent experiences and identify any emergingpatterns, useful abstractions, or new concepts. Focus on sequences of actions that led topositive outcomes or unexpected observations.\n\nExperiences:\n"
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual","content": abstraction_str, "source": "ssl_learning"})
except Exception:passllm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
    pass  # inserted to fix indentation error
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknownerror')}"
passllm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
`execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (descriptionof subgoal) and `context` (any relevant info for the subgoal).
self_summary =self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
self.log = get_logger("SAFETY")
self.log.warning(warning)
passprompt = f"""Analyze the following proposed agent action for potential safety risks,ethical concer ns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
pass
pass
self.embedding_function =embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
passif GRAPH_DB_PATH.exists():
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:{len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
passself.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH,check_same_thread=False)
type TEXT,
passreturn self.agent.llm_wrapper.embed(text)
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
passself.vector_store.add(
pass
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
"ect_id in entry.causal_links.items():
"ect IDs are existing node IDs or need to be created
"ect_id):
"ect_id, relation_type='causes')
passcursor = self.relational_conn.cursor()
results = []
passresults = self.vector_store.query(
for node_id in start_nodes:
passpaths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
self.log.debug(f"BFS from node {node_id} failed or yifielded no paths: {e}")
rows = cursor.fetchall()
passnx.write_graphml(self.graph_store, GRAPH_DB_PATH)
pass
passcuto"_ts = (datetime.now(timezone.utc) -timedelta(days=older_than_days)).isoformat()
"_ts))
passif full_module_name in self._loaded_dynamic_modules:
passdocstring = inspect.getdoc(func) or "(No description provided)"
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
'tool_name': tool_name, 'params': params, 'validated_params': {},
passif
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p infunc_params_spec.values()):
    pass  # inserted to fix indentation error
field if dict
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
This tool is now more of a declarative intent for the planner/deliberator.
passpriority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) elseGoalPriority.MEDIUM
"ectively a request to the deliberator.
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,type_
passfull_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not adirectory: {path}"}
passagent.playwright_page.goto(url, timeout=timeout_ms)
return {"status": "error", "error": f"Playwright error: {pe}"}
passresponse = requests.get(search_url, headers=headers, timeout=timeout_sec)
passif not LOG_FILE.exists():
all_lines = f.readlines()
passresponse = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
pass
except Exception as e:
    pass  # inserted to fix indentation error
passllm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,temperature=0.5)
pass
passstdout, stderr = process.communicate(timeout=timeout_sec)
with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
passmsg_type = MessageType[message_type.upper()]
"_match_patch' library is missingor failed to import. Self-mod tools will fail.")
"_match_patch()
passsource_code = inspect.getsource(target_obj)
passllm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,temperature=0.3)
passast.parse(code_to_validate)
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
"ect if modifying core running code.
passoriginal_code = target_
REQUIRED for changes to take e"ect.")
{component_name}. Restart pending for full e"ect.")
passshutil.copy(backup_path, target_
passshutil.copy(backup_
passif target_module_name in sys.modules:
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
"ect global instances like `_agent_instance_hack` if it was part of thereloaded module
changes to take e"ect.")
usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational','guardrail').
passllm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,temperature=0.5)
pass
self.log.info("Core directives successfully updated in SelfModel.")
self.internal_state_narrative: str = "System booting up."
"core_directives_weighted": self.core_directives,
'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None,'error_types': {}}
if score > 0.8: hint = " (Reliability: High)"
    pass  # inserted to fix indentation error
with max replans. Planning or execution e"ectiveness may be compromised. Review strategyor tool reliability."
self.anomaly_detection_rules.append(check_skill_con
passanomaly_description = rule(self)
self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 andstats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 andstats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
e"ectiveness or issues).",
provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Onlysuggest if strong evidence of misalignment or obsolescence).",
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \
passresponse_str = _agent_instance_hack.llm_wrapper.generate(prompt,max_new_tokens=2048, temperature=0.5)
fields or implies updates
directive_obj['last_eval_score'] = round(eval_score, 2)
self.log.info("SelfModel internal state updated from re
passwith backup_
"erentperspectives."""
pass
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":full_dialog_str})
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
field(default_factory=time.time)
self.level = max(self.min_level, min(self.max_level, new_level))
pass
except Exception:
    pass  # inserted to fix indentation error
passexisting_content = target_
passwith FileLock(str(source_
return []
passresponse = handler_func(msg)
receiver_id=msg.sender_id, type=MessageType.ERROR, content={"original_message_id":msg.id, "error": str(e)}))
self.log.warning(f"No handler registered for message type{msg.message_type.value}. Message ID {msg.id} unhandled.")
system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to'Data Center' and 'Simulation Bay'.",
"description": "A shifielded chamber housing the agent's primary cognitive core.
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a inself.actuators.values()]
"ect emotional state based on action outcome
action_type=="move" else None, "updated_inventory": self.state["inventory"] ifaction_type=="pickup" else None}
self.log.info(f"Embodiment: Console command received: '{command}'")
{self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal StackDepth: {len(self.agent.goal_stack)}")
pass
LAST_LEARNING_MODULE_UPDATE_CYCLE >=LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
isinstance(x.get('priority'),str) else GoalPriority(x.get('priority',GoalPriority.MEDIUM)).name ].value, reverse=True)
{goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID:{goal_to_execute_this_cycle_dict.get('id')})")
self.agent.save_state()
self.log.debug(f"Understanding {len(observations)} observations...")
in the environment or your internal state. Focus on information relevant to achieving currentgoals.\n\nObservations:\n"
\"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"],\"potential_impact_on_goals\": \"str\"}"
passllm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
{pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio:{active_priority_val}).")
decision["chosen_action_type"] = "new_goal"
self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary,max_facts=3)
drives, memories, goals, directives), what is the most critical aspect demanding attention or thebest opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list ofstr).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions areapparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, highdrives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.If selecting an existing pending goal, it moves to `next_goal` and is removed from pendinginternally (do not include in `new_pending_goals` output).",
`new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into`new_pending_goals`."
Analyze the situation comprehensively, consider drives and directives, and make strategicdecisions. Respond ONLY in JSON as per output instructions.",
for i, pg_obj in enumerate(pending_list_objs):
{deliberation_decision.get('chosen_action_type')}. Reason:{deliberation_decision.get('reasoning','')[:100]}...")
step_to_execute = plan_steps[0]
pass
e"ects
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error','Unknown error')}")
exec_info = tool_result.get('_exec_info', {})
passself._initialize_agent()
self._update_status("Initialized")
LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS,get_logger("LLM_WRAPPER"))
except Exception:passwith STATE_FILE.open('r') as f:
    pass  # inserted to fix indentation error
passtemp_
passreturn Goal.from_dict(active_goal_dict)
).to_dict()
str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count":goal_obj.replan_count}
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
cycle_ok = False
pass
self._create_metacognitive_goal("Re-evaluate overall strategy due to signi
pass
"erent message types if comms_channel exists."""
except Exception:passRESOURCE_MONITOR = psutil.Process(os.getpid())
    pass  # inserted to fix indentation error
passPLAYWRIGHT_INSTANCE = sync_playwright().start()
self.playwright_browser = None; self.playwright_instance = None
passself.playwright_page = self.playwright_context.new_page()
ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL orENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
pass
initial_command_goal = None
passcommand_text = COMMANDS_FILE.read_text().strip()
if main_agent_instance and hasattr(main_agent_instance, 'log'):main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",exc_info=True)
    pass  # inserted to fix indentation error
pass
from chromadb.config import Settings
pass
pass
pass
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
def load_llm_models():
global llm_pipelines
try:
    pass  # inserted to fix indentation error
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error in load_llm_models: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
try:
    pass  # inserted to fix indentation error
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
from Real1_ToolSuite import TOOL_REGISTRY
TRANSFORMERS_AVAILABLE = True
TORCH_AVAILABLE = True
GOOGLE_GENAI_AVAILABLE = True
PSUTIL_AVAILABLE = True
CHROMADB_AVAILABLE = True
PLAYWRIGHT_AVAILABLE = True
REQUESTS_BS4_AVAILABLE = True
PILLOW_AVAILABLE = True
DIFF_MATCH_PATCH_AVAILABLE = True
FILELOCK_AVAILABLE = True
NETWORKX_AVAILABLE = True
GYMNASIUM_AVAILABLE = True
```python
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
import psutil
import chromadb
from chromadb.config import Settings as ChromaSettings
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoConfig
from transformers import logging as transformers_logging
import torch
from playwright.sync_api import sync_playwright, Error as PlaywrightError
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from PIL import Image
import diff_match_patch as dmp_module
import hashlib
from fifilelock import FileLock, Timeout as FileLockTimeout
import networkx as nx
import gymnasium as gym
AGENT_NAME = "EvolvedCognitiveAgent_SystemCore_V3"
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
DEFAULT_LLM_MODEL = "gemini-2.5-flash"
LLM_MODEL_NAME_OR_PATH = DEFAULT_LLM_MODEL
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
_llm_device_detected = "cpu"
if torch.cuda.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif hasattr(torch, 'backends') and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
LLM_DEVICE = _llm_device_detected
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
SCRIPT_DIR = Path(__file__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(f"agent_workspace_{AGENT_NAME}")
STATE_FILE = WORKSPACE_DIR / Path(f"agent_state_{AGENT_NAME}.json")
LOG_FILE = WORKSPACE_DIR / Path(f"agent_log_{AGENT_NAME}.log")
COMMANDS_FILE = SCRIPT_DIR / Path("agent_commands.txt")
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modification_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously learn, adapt, and improve capabilities across all domains.", "weight": 0.9, "last_eval_score": 0.0, "id": "directive_learn", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type": "growth"},
{"directive": "Achieve goals efficiently, robustly, autonomously, and ethically.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type": "exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.", "weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type": "foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type": "guardrail"},
]
MANDATORY_REFLECTION_INTERVAL_SECONDS = 1800
IDLE_DELIBERATION_INTERVAL_SECONDS = 120
GOAL_STACK_MAX_DEPTH = 5
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = 3
MAX_LLM_RESPONSE_TOKENS = 4096
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH or "2.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
else:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
config = AutoConfig.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
_default_context_len = getattr(config, 'max_position_embeddings', _default_context_len)
except Exception:
    pass  # inserted to fix indentation error
pass
MAX_LLM_CONTEXT_TOKENS = _default_context_len
MAX_TOOL_RESULT_LENGTH = 5000
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = True
ENABLE_CODE_GENERATION_TOOL = True
ENABLE_SELF_MODIFICATION = True
WEB_SEARCH_TIMEOUT = 10
WEB_BROWSER_TIMEOUT = 60000
LOG_MONITOR_DEFAULT_LINES = 20
METACOGNITIVE_CHECK_INTERVAL_CYCLES = 20
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES = 50
LLM_PIPELINE = None
LLM_TOKENIZER = None
MEMORY_COLLECTION = None
RESOURCE_MONITOR = None
PLAYWRIGHT_INSTANCE = None
PLAYWRIGHT_BROWSER = None
PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_PAGE = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack = None
def ensure_paths():
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
try:
    pass  # inserted to fix indentation error
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
try:
    pass  # inserted to fix indentation error
file_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
file_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%(filename)s:%(lineno)d] [%(task_name_override)-10s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error setting up file logger: {e}", file=sys.stderr)
logger.propagate = False
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "fifilelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try:
    pass  # inserted to fix indentation error
logging.getLogger(lib_name).setLevel(logging.WARNING)
except Exception:
    pass  # inserted to fix indentation error
pass
try:
    pass  # inserted to fix indentation error
logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
except Exception:
    pass  # inserted to fix indentation error
pass
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModificationError(AgentError): pass
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class ConfigurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class LearningError(AgentError): pass
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModificationError,
PlaywrightError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModificationError,
    pass  # inserted to fix indentation error
LogicError, ConfigurationError, RecursionDepthError)) and type(e) not in retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}: {e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error: {type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error: {type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, LearningError) as non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in {fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}: {type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}: {unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error: {unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception):
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1:
    pass  # inserted to fix indentation error
log_resource.error(f"Unexpected error getting resource usage: {e}", exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
match = re.search(r"```json\s*([\s\S]+?)\s*```", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full text: {json_str[:200]}...")
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}. Text: {text_trimmed[:200]}...")
try:
    pass  # inserted to fix indentation error
start_index = text.find('{')
end_index = text.rfind('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
try:
    pass  # inserted to fix indentation error
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice: {potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text: {text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview": text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str = field(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] = field(default_factory=dict)
plan: List[Dict[str, Any]] = field(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] = field(default_factory=list)
dependencies: List[str] = field(default_factory=list)
complexity_score: Optional[float] = None
estimated_cost: Optional[float] = None
estimated_utility: Optional[float] = None
evaluation_score: Optional[float] = None
associated_directive_ids: List[str] = field(default_factory=list)
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus(data['status'])
except ValueError:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus.PENDING
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority.MEDIUM
field_names = {f.name forfin cls.__dataclass_fields__.values()}
for f_obj in cls.__dataclass_fields__.values():
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin cls.__dataclass_fields__.values()}
filtered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**filtered_data)
@dataclass
class BaseMemoryEntry:
id: str = field(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
content: Any = None
metadata: Dict[str, Any] = field(default_factory=dict)
embedding: Optional[List[float]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[float] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability: float = 0.5
related_concepts: List[str] = field(default_factory=list)
causal_links: Dict[str, str] = field(default_factory=dict)
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
self.content = self.fact_statement
@dataclass
class Message:
id: str = field(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
type: str = "info"
content: Dict[str, Any] = field(default_factory=dict)
priority: int = 0
correlation_id: Optional[str] = None
def to_dict(self) -> Dict[str, Any]:
return asdict(self)
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Message':
return cls(**data)
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionEffect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens: int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[float]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
genai.configure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
try:
    pass  # inserted to fix indentation error
generation_config_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_config_params["stop_sequences"] = stop_sequences
full_prompt = f"{system_message}\n\n{prompt}" if system_message else prompt
response = self.model.generate_content(
full_prompt,
generation_config=genai.types.GenerationConfig(**generation_config_params)
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.", exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[float]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='models/embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, trust_remote_code=True)
device_map_arg = {"": self.device_id} if self.device_id != -1 else "auto"
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.bfloat16,
device_map=device_map_arg
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on {self.device}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Transformers model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Transformers model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
if system_message:
    pass  # inserted to fix indentation error
chat_prompt = [
{"role": "system", "content": system_message},
{"role": "user", "content": prompt}
]
try:
    pass  # inserted to fix indentation error
final_prompt = self.tokenizer.apply_chat_template(chat_prompt, tokenize=False, add_generation_prompt=True)
except Exception:
    pass  # inserted to fix indentation error
final_prompt = f"System: {system_message}\nUser: {prompt}\nAssistant:"
else:
    pass  # inserted to fix indentation error
final_prompt = prompt
inputs = self.tokenizer(final_prompt, return_tensors="pt").to(self.model.device)
outputs = self.model.generate(
**inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[float]:
self.log_llm.warning("Direct embedding from causal LM is not standard. Using mock embedding.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
def perceive(self) -> List[Dict[str, Any]]:
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_file",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from file: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands file: {e}")
observations.append({"type": "error", "source": "command_file_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No significant external stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (simulated).")
return {"type": "visual", "source": "camera_sim", "content": "Simulated visual data: a generic scene.", "format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (simulated).")
return {"type": "audio", "source": "microphone_sim", "content": "Simulated auditory data: ambient sounds.", "format": "description"}
class LearningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_buffer: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
self.experiences_buffer.append(experience)
if len(self.experiences_buffer) > self.MAX_BUFFER_SIZE:
    pass  # inserted to fix indentation error
self.experiences_buffer.pop(0)
defilearn_from_recent_experiences(self):
if not self.experiences_buffer:
    pass  # inserted to fix indentation error
self.log.info("No new experiences to learn from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_buffer)} experiences.")
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_buffer)
self._perform_self_supervised_learning(self.experiences_buffer)
self.log.info("Learning cycle completed.")
self.experiences_buffer.clear()
def _perform_reinforcement_learning(self, experiences: List[Experience]):
self.log.info("Performing reinforcement learning (conceptual)...")
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (conceptual) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
self.log.info("Performing self-supervised learning (conceptual)...")
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns', 'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified patterns: {llm_analysis['patterns']}")
for pattern_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {pattern_str}", metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified abstractions: {llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.learned_abstractions.append({"type": "conceptual", "content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified new_concepts: {llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}", metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_learned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
if self.rl_policy:
    pass  # inserted to fix indentation error
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}. Response: {llm_response_str[:200]}")
return ([{"tool_name": "report_error", "params": {"error_message": "Failed to generate plan via LLM.", "details": plan_data.get('error')}}],
"LLM failed to generate a plan. This is a fallback step.")
thought = plan_data.get("thought", "No specific thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return ([{"tool_name": "report_error", "params": {"error_message": "LLM plan contained no valid steps."}}],
thought + " (But plan steps were invalid).")
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return ([{"tool_name": "report_error", "params": {"error_message": f"LLMError during planning: {e}"}}],
f"LLM error occurred: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return ([{"tool_name": "report_error", "params": {"error_message": f"Unexpected error during planning: {e}"}}],
f"Unexpected error: {e}")
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation: Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info', {}).get('execution_successful', True):
    pass  # inserted to fix indentation error
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal {current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan, last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan: {plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No specific thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else "World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'. Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, efficient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the `execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the final step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the first step(s) should be to acquire it (e.g., using `search_web`, `read_file_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str, last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info', {}).get('current_step_id'):
    pass  # inserted to fix indentation error
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if observation else "None"}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
{original_plan_str}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should reflect this (e.g., by trying to gather more information or reporting inability).
6. Ensure the final step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
class MemorySystem:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH, settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
self.log.info(f"ChromaDB vector store initialized. Collection count: {self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.", exc_info=True)
self.vector_store = None
if not self.vector_store:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based (transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes: {len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be unavailable.", exc_info=True)
self.graph_store = None
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH, check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be unavailable.", exc_info=True)
if self.relational_conn:
    pass  # inserted to fix indentation error
self.relational_conn.close()
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT,
PRIMARY KEY (source_node_id, target_node_id, relation_type)
)
""")
self.relational_conn.commit()
cursor.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error initializing relational schema: {e}", exc_info=True)
def _get_embedding(self, text: str) -> Optional[List[float]]:
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
h = hashlib.md5(text.encode()).digest()
return [float(b) for b in h[:16]]
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector:
    pass  # inserted to fix indentation error
if self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
for k, v in entry.metadata.items():
if isinstance(v, (str, int, float, bool)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
else:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(entry.content)
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata": entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50], type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
for cause_id, effect_id in entry.causal_links.items():
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(effect_id):
    pass  # inserted to fix indentation error
self.graph_store.add_edge(cause_id, effect_id, relation_type='causes')
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id, complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score, json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
ts_now = datetime.now(timezone.utc).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now, json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}", exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError, ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS, type_filter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text:
    pass  # inserted to fix indentation error
return []
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_filter and data['metadata'].get('type') != type_filter:
    pass  # inserted to fix indentation error
continue
results.append({"id": id, "document": data['document'], "metadata": data['metadata'], "distance": 0.0})
if len(results) >= n_results:
    pass  # inserted to fix indentation error
break
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results}, filter={type_filter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_filter:
    pass  # inserted to fix indentation error
where_clause = {"type": type_filter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0:
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type: Optional[str]=None, depth: int = 1) -> List[Dict]:
if not self.graph_store:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation": data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns: Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
if self.graph_store:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts, type_filter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No specific knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
return summary_str
def consolidate_knowledge(self):
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold: float = 0.1, older_than_days: int = 365):
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cutoff_ts = (datetime.now(timezone.utc) - timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cutoff_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
self.register_tool(read_file_UNSAFE)
self.register_tool(write_file_UNSAFE)
self.register_tool(list_files_UNSAFE)
self.register_tool(browse_web)
self.register_tool(search_web)
self.register_tool(monitor_log_file)
self.register_tool(check_website_update)
self.register_tool(send_icmp_ping)
self.register_tool(send_message_to_agent)
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
self.register_tool(execute_shell_command_UNSAFE)
def register_tool(self, func: Callable):
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if hasattr(self, 'agent') and self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for filepath in directory.glob("*.py"):
module_name = filepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_file_location(full_module_name, filepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
sys.modules[full_module_name] = module
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module: {module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and name.startswith("tool_"):
    pass  # inserted to fix indentation error
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}", exc_info=True)
def get_tool_description_for_llm(self) -> str:
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = "(No description provided)"
first_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation == inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class '","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper():
    pass  # inserted to fix indentation error
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {first_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via specific tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {', '.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info: Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None:
    pass  # inserted to fix indentation error
current_step_info = {}
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
result = None
duration = 0.0
validated_params = {}
try:
    pass  # inserted to fix indentation error
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
first_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
first_param_name = next(iter(func_params_spec))
first_param_spec = func_params_spec[first_param_name]
if first_param_name == 'agent' and (first_param_spec.annotation == 'CognitiveSystem' or str(first_param_spec.annotation) == "'CognitiveSystem'"):
    pass  # inserted to fix indentation error
first_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if first_param_is_agent and p_name == 'agent':
    pass  # inserted to fix indentation error
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind == inspect.Parameter.VAR_KEYWORD:
    pass  # inserted to fix indentation error
pass
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
if first_param_is_agent:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration: {duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError:
    pass  # inserted to fix indentation error
raise
except (AgentError, LogicError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}", exc_info=False)
result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
def check_playwright_browsers(self):
self.log.debug("Checking Playwright browsers.")
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log", content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str, percentage_complete: Optional[float] = None) -> Dict:
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log', []).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str = "success", details: Optional[Dict] = None) -> Dict:
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] = "MEDIUM", context: Optional[Dict] = None) -> Dict:
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH}) reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent: {current_active_goal_dict.get('id')}")
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str = "vector", n_results: int = 3, type_filter: Optional[str] = None) -> Dict:
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
results = []
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results, type_filter=type_filter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_graph_store(query_node_label=query_text, depth=1)
elif memory_type == "relational":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_relational_store(table=query_text, limit=n_results)
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params: Optional[Dict] = None) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name, params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
def read_file_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
log_tool = get_logger("TOOL_read_file")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not full_path.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found: {path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path), "file_size_bytes": len(content)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read file: {e}"}
def write_file_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_file")
try:
    pass  # inserted to fix indentation error
full_path = WORKSPACE_DIR.joinpath(path).resolve()
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path": str(full_path)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write file: {e}"}
def list_files_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_files")
try:
    pass  # inserted to fix indentation error
base_path = WORKSPACE_DIR.joinpath(path).resolve()
if not base_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a directory: {path}"}
items = []
for item in base_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "file",
"size_bytes": item.stat().st_size if item.is_file() else None,
"last_modified": datetime.fromtimestamp(item.stat().st_mtime, tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(base_path), "contents": items}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing files in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list files: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int = WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int = WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.find_all(class_='g'):
r = g.find('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.find('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_file(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES) -> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log file not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_file": str(LOG_FILE), "content": content, "lines_read": len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log file {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log file: {e}"}
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp": datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count, "packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count, "packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str, context_code: Optional[str] = None) -> Dict:
agent.log.warning(f"Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a complete function/class definition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
return agent.self_modification_unit.validate_code_modification_UNSAFE(code_to_validate)
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec: int = 30) -> Dict:
agent.log.warning(f"Executing shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s. Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str, content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value, content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id, "message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
class SelfModificationTools:
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref: 'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
self.dmp = dmp_module.diff_match_patch()
self.log.info(f"Self-Modification Unit initialized. Code Dir: {self.agent_code_dir}, Backup Dir: {self.backup_dir}")
def _resolve_target_path(self, target_file_rel: str) -> Path:
target_path_abs = (self.agent_code_dir / target_file_rel).resolve()
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
self.log.warning(f"Inspecting code for component: {component_name}")
target_obj = None
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
candidate_modules = [sys.modules.get('__main__'), sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod, component_name)):
    pass  # inserted to fix indentation error
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
file_path = inspect.getfile(target_obj)
return {"status": "success", "component_name": component_name, "file_path": file_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module, class, or function defined in a file.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
return {"status": "error", "error": f"Component '{component_name}' not found or source code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModificationError))
def propose_code_modification_UNSAFE(self, component_name: str, issue_description: str, proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
self.log.warning(f"Proposing code modification for {component_name}. Issue: {issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for {component_name} to propose modification. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
```python
{current_code_snippet}
```
Generate the modified Python code for the specified component.
Provide ONLY the complete, new Python code block for the modified function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '```python' and end with '```'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "proposed_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name, "proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modification for {component_name}: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modification_UNSAFE(self, code_to_validate: str) -> Dict:
self.log.warning(f"Validating proposed code snippet ({code_to_validate[:100]}...)")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modification_UNSAFE(self, component_name: str, new_code: str, target_file_path: Optional[str]=None) -> Dict:
self.log.critical(f"Attempting to apply code modification to component '{component_name}'. THIS IS HIGHLY RISKY.")
try:
    pass  # inserted to fix indentation error
if not target_file_path:
    pass  # inserted to fix indentation error
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('file_path'):
    pass  # inserted to fix indentation error
target_file_path = inspection_res['file_path']
else:
    pass  # inserted to fix indentation error
target_file_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_file = Path(target_file_path)
if not target_file.exists() or not target_file.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Target file for modification not found: {target_file}"}
original_code = target_file.read_text()
backup_path = SELF_MOD_BACKUP_DIR / f"{target_file.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_file, backup_path)
self.log.info(f"Backed up original file to {backup_path}")
pattern_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
pattern_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modified_original_code = original_code
found_and_replaced = False
match_class = re.search(pattern_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(pattern_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not find component '{component_name}' in {target_file} for replacement. Modification aborted.")
return {"status": "error", "error": f"Component '{component_name}' definition not found for replacement."}
target_file.write_text(modified_original_code)
self.log.warning(f"Code modification applied to {target_file}. Agent restart is LIKELY REQUIRED for changes to take effect.")
self.agent_ref.self_model.add_event_log(f"Applied code modification to {component_name}. Restart pending for full effect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}_modified_pending_restart"] = True
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": f"Code for '{component_name}' in '{target_file}' modified. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modification to {component_name}: {e}", exc_info=True)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_file)
self.log.info(f"Restored original file {target_file} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modification: {e}. System might be unstable."}
def rollback(self, backup_file: Path, target_file: Path):
self.log.info(f"Attempting to rollback '{target_file}' from '{backup_file}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_file, target_file)
self.log.info(f"Successfully rolled back '{target_file}'.")
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_file}.")
self.agent_ref.self_model.beliefs[f"component_{target_file.name}_modified_pending_restart"] = False
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_file.name)
return {"status": "success", "message": f"Rolled back {target_file}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_file}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_file_rel: Union[str, Path]):
target_module_name = Path(target_file_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is required.")
return
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
if _agent_instance_hack and hasattr(sys.modules[target_module_name], 'CognitiveSystem'):
    pass  # inserted to fix indentation error
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for changes to take effect.")
def inspect_directives_UNSAFE(self) -> Dict:
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modification_UNSAFE(self, analysis_of_misalignment: str, proposed_directive_changes_desc: str) -> Dict:
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (float 0-1), "last_eval_score" (float 0-1, usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational', 'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024, temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in proposed_directives):
    pass  # inserted to fix indentation error
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"LLM indicated error during directive proposal: {proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modification_UNSAFE(self, new_directives: List[Dict]) -> Dict:
self.log.warning(f"Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modification_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count: {len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
_self_mod_tools_container = None
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, agent)
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in name.upper():
    pass  # inserted to fix indentation error
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func) or inspect.ismethod(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
def __init__(self, state: Optional[Dict]=None, agent_directives_config: Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_config if agent_directives_config is not None else DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_confidence: Dict[str, float] = {}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
self.learning_goals: List[Dict[str, Any]] = []
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.learned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_confidence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted", sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_confidence = sm_state.get("skill_confidence", self.skill_confidence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary", self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies", self.adaptation_strategies)
self.learned_abstractions = sm_state.get("learned_abstractions", self.learned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative", self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs", self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_confidence": self.skill_confidence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"learned_abstractions": self.learned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
def add_event_log(self, event_description: str, event_type: str = "info", data: Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
for tool_name in self.capabilities:
if tool_name not in self.skill_confidence:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = 0.5
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.", event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8:
    pass  # inserted to fix indentation error
hint = " (Reliability: High)"
elif score > 0.6:
    pass  # inserted to fix indentation error
hint = " (Reliability: Moderate)"
elif score > 0.3:
    pass  # inserted to fix indentation error
hint = " (Reliability: Low)"
else:
    pass  # inserted to fix indentation error
hint = " (Reliability: Very Low/Untested)"
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict, success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
current_confidence = self.skill_confidence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = min(1.0, current_confidence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = max(0.0, current_confidence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability: {stats['reliability_score']:.2f}, Confidence: {self.skill_confidence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_confidence_drift(sm: 'SelfModel') -> Optional[str]:
low_confidence_skills = [skill for skill, conf in sm.skill_confidence.items() if conf < 0.25 and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_confidence_skills) >= 2 :
    pass  # inserted to fix indentation error
return f"Multiple critical skills have very low confidence and recent failures: {', '.join(low_confidence_skills)}. Consider skill improvement or alternative strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict):
    pass  # inserted to fix indentation error
return None
low_eval_directives = []
for d in sm.core_directives:
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {', '.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count} with max replans. Planning or execution effectiveness may be compromised. Review strategy or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_confidence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}): {anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}", event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__') else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {'; '.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0), reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_confidence:
    pass  # inserted to fix indentation error
confident_skills = [s for s,c in self.skill_confidence.items() if c > 0.7][:3]
summary += f"Confident Skills (sample): {', '.join(confident_skills) if confident_skills else 'None highly confident'}\n"
summary += f"Internal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools:
    pass  # inserted to fix indentation error
summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
if unreliable_tools:
    pass  # inserted to fix indentation error
summary += f" Needs Improvement: {', '.join([t[0] for t in unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
base_prompt = """Analyze your recent performance, knowledge, internal state, and alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:"""
output_keys_example = [
"`reflection_summary` (str: Overall summary of the reflection period).",
"`key_successes` (list of str: Specific achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Specific setbacks or difficulties encountered).",
"`learned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identified` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool effectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g., 'curious', 'frustrated', 'satisfied').",
"`resource_usage_concerns` (str or null: Any concerns about computational resource usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_float_0_to_1: How well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes, provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model? What needs improvement?).",
"`new_learning_goals` (list of str: Specific goals for future learning or skill development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring issues or improve performance).",
"`self_modification_needed` (str or null: If parts of your own code/logic need modification, describe what and why. Be very specific and cautious.)."
]
full_prompt = base_prompt + "\n" + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives, indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n" + \
f"Recent Tool Outcomes (last 5 entries):\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment: {assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_reflection(self, reflection_data: Dict) -> Tuple[bool, bool]:
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from reflection data...")
if reflection_data.get('reflection_summary'):
    pass  # inserted to fix indentation error
self.internal_state_narrative = reflection_data['reflection_summary']
updated_self = True
core_directives_eval = reflection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (float, int)) and 0.0 <= eval_score <= 1.0:
    pass  # inserted to fix indentation error
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...' evaluation score to {eval_score:.2f}")
if updated_self:
    pass  # inserted to fix indentation error
self.add_event_log("Directive evaluation scores updated from reflection.")
suggested_directive_updates = reflection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Reflection suggested updates to core directives: {str(suggested_directive_updates)[:200]}...")
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modifications from reflection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source": "self_reflection"}
)
updated_self = True
self.add_event_log("Reflection suggested directive updates. Metacognitive review goal created.", event_type="critical_review_needed")
if isinstance(reflection_data.get('new_learning_goals'), list):
    pass  # inserted to fix indentation error
for lg_str in reflection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts": datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
if isinstance(reflection_data.get('adaptation_strategy_proposals'), list):
    pass  # inserted to fix indentation error
for strat_str in reflection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated adaptation strategies. Total: {len(self.adaptation_strategies)}")
if reflection_data.get('learned_facts') or reflection_data.get('prompt_tuning_suggestions'):
    pass  # inserted to fix indentation error
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from reflection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
backup_file = SELF_MOD_BACKUP_DIR / f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_file.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_file} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_officer"]
dialog_history = []
full_dialog_str = f"Internal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts, questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution": contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective {perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
self.add_event_log(f"Internal dialog simulated on '{topic}'.", data={"dialog": full_dialog_str})
return full_dialog_str
class MotivationEngine:
def __init__(self, drive_configs: Optional[Dict[str, Any]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[str, Any] = {}
self._initialize_drives(drive_configs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_configs: Optional[Dict[str, Any]]):
default_configs = {
"CURIOSITY": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"MASTERY": {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.6},
"ACHIEVEMENT": {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.4},
"NOVELTY_SEEKING": {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.7},
"PRESERVATION": {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.2},
"EFFICIENCY": {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"SOCIAL_INTERACTION": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.3},
}
configs = drive_configs if drive_configs is not None else default_configs
for drive_type_str, config in configs.items():
self.drives[drive_type_str] = DriveState(
drive_type=drive_type_str,
level=config.get("initial_level", 0.5),
decay_rate=config.get("decay_rate", 0.01),
max_level=config.get("max_level", 1.0),
min_level=config.get("min_level", 0.0)
)
def update_drives(self):
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "learn":
    pass  # inserted to fix indentation error
self.drives["CURIOSITY"].update(stimulus=-0.05)
self.drives["MASTERY"].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives["ACHIEVEMENT"].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives["PRESERVATION"].update(stimulus=0.1)
self.drives["MASTERY"].update(stimulus=-0.05)
def get_drive_level(self, drive_type: str) -> float:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
def get_all_drive_levels(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[str, float]]:
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == "CURIOSITY":
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == "MASTERY":
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == "ACHIEVEMENT":
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == "PRESERVATION":
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == "EFFICIENCY":
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: str
level: float
decay_rate: float = 0.01
max_level: float = 1.0
min_level: float = 0.0
last_update_time: float = field(default_factory=time.time)
def update(self, stimulus: float = 0.0):
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class MessageType(Enum):
QUERY = "QUERY"
RESPONSE = "RESPONSE"
INFORM = "INFORM"
REQUEST_ACTION = "REQUEST_ACTION"
HEARTBEAT = "HEARTBEAT"
ERROR = "ERROR"
class FileChannel:
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_file = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_file}")
def _write_message_to_file(self, message: Message, target_file: Path) -> bool:
try:
    pass  # inserted to fix indentation error
with FileLock(str(target_file) + ".lock", timeout=5):
messages = []
if target_file.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
existing_content = target_file.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {target_file}: {e}. Clearing file.")
messages = []
messages.append(message.to_dict())
target_file.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_file}. Message not sent to {message.receiver_id}.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_file}: {e}")
return False
def _read_messages_from_file(self, source_file: Path) -> List[Message]:
messages = []
if not source_file.exists():
    pass  # inserted to fix indentation error
return messages
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_file) + ".lock", timeout=5):
content = source_file.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if isinstance(msg_data, dict)]
source_file.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_file}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {source_file}: {e}. Clearing file.")
try:
    pass  # inserted to fix indentation error
source_file.write_text("", encoding='utf-8')
except Exception as e_write:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to clear corrupted message file {source_file}: {e_write}")
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_file}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}: {message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_file(message, target_inbox)
def receive_messages(self) -> List[Message]:
new_messages = self._read_messages_from_file(self.inbox_file)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message], Optional[Message]]):
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
messages = self.receive_messages()
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From: {msg.sender_id}")
handled = False
try:
    pass  # inserted to fix indentation error
msg_type_enum = MessageType(msg.type)
if msg_type_enum in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg_type_enum]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler {handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id, receiver_id=msg.sender_id, type=MessageType.ERROR.value, content={"original_message_id": msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type {msg.type}. Message ID {msg.id} unhandled.")
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Received unknown message type: {msg.type}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', config: Dict):
self.id = id
self.embodiment = embodiment
self.config = config
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
pass
class Actuator(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], config: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.config = config
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
pass
class VirtualEmbodiment:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to 'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button", "research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, reconfigurable bay designed for running complex simulations. Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_config_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data flow and storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core. Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20:
    pass  # inserted to fix indentation error
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An undefined space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) -> Dict:
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params: {params}")
params = params or {}
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as specified."
env_details = self.environment_map.get(self.location, {})
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console":
    pass  # inserted to fix indentation error
message += " It shows fluctuating green and amber lights."
elif target == "core_status_monitor":
    pass  # inserted to fix indentation error
message += " It indicates: Core Nominal. Directives Stable. Learning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name", "default_physics_test"), params.get("config",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result: {sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if action_type=="move" else None, "updated_inventory": self.state["inventory"] if action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "learn"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response: {self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model <topic>'."
def _run_simulation(self, sim_name: str, config: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with config: {config}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_config" in config:
    pass  # inserted to fix indentation error
success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric: {outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check configuration."
def summary(self) -> str:
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Internal State (summary): Energy={self.state['energy']}, Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time: float = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE, LAST_LEARNING_MODULE_UPDATE_CYCLE
start_time = time.time()
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status: {self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if self.agent.state['goals'].get('active') else None
self.agent.last_error = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
if self.agent.self_model and (self.agent.cycle_count - LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering proactive metacognitive check (Cycle {self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
if self.agent.learning_module and (self.agent.cycle_count - LAST_LEARNING_MODULE_UPDATE_CYCLE >= LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.learn_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation: {ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
def get_priority_val(goal_dict):
p = goal_dict.get('priority', 'MEDIUM')
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_list.sort(key=get_priority_val, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type == "active_goal_continue":
    pass  # inserted to fix indentation error
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution: {goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID: {goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal' provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or current_goal_obj.replan_count > 0:
    pass  # inserted to fix indentation error
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"No plan available or generated for goal: {current_goal_obj.goal[:50]}. Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = True
if time.time() - LAST_DELIBERATION_TIME > IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModificationError, LogicError, LLMError, ConfigurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
LearningError) as agent_cycle_err:
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
finally:
    pass  # inserted to fix indentation error
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() - start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent understanding of the current situation. Identify key entities, events, and any significant changes in the environment or your internal state. Focus on information relevant to achieving current goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content: {str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\": \"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"], \"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation", understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event", metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry, persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
return {"summary": understanding_summary, "processed_info": processed_info, "raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError, DeliberationError))
def _deliberate(self, understanding_result: Dict) -> Dict:
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio: {pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio: {active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time': datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack (paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal generation.")
if time.time() - LAST_DELIBERATION_TIME >= IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_learn", "directive_curiosity", "directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
return decision
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output: {sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
self_model_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No specific understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact', 'None identified.')
interp_con_val = understanding_result.get('interpretation_confidence', 0.7)
recent_memory_context = self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary, max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Confidence: {interp_con_val:.2f}):** {understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identified:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory (STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]], indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else f'{active_goal_dict.get(\"goal\")[:100]}... (ID: {active_goal_dict.get(\"id\")})'}",
f"* **Agent Core Directives (Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding, drives, memories, goals, directives), what is the most critical aspect demanding attention or the best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/complete).",
"    - Performing `reflection` or `self_assessment` (if mandatory timers, drives like low CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration goal), Directives (e.g., low-eval directive -> improvement goal), or identified opportunities. New goals require `goal` (str), `priority` (float 0.0-1.0), `origin` (str e.g., 'drive_curiosity', 'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for viability before committing if uncertainty is high or consequence severe (briefly note simulation outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the *immediate next cycle*. Justify your choice especially if it deviates from obvious triggers, high drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list. If selecting an existing pending goal it moves to `next_goal` and is removed from pending internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal', 'new_goal', 'reflection', 'self_assessment', 'external_command_action', 'idle', 'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass structure) selected for immediate execution. Null if idle/reflection/assessment without a direct goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into `new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into `new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent. Analyze the situation comprehensively, consider drives and directives, and make strategic decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON: {extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal', 'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys: {deliberation_decision.keys()}")
if key == 'new_pending_goals':
    pass  # inserted to fix indentation error
deliberation_decision[key] = []
elif key == 'next_goal':
    pass  # inserted to fix indentation error
deliberation_decision[key] = None
else:
    pass  # inserted to fix indentation error
deliberation_decision[key] = "Error: Missing from LLM Output"
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not isinstance(deliberation_decision.get('next_goal'), dict):
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value: {deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and new_goal_dict.get('priority'):
    pass  # inserted to fix indentation error
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p['id'] == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
current_pending_list.append(new_goal_obj.to_dict())
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal: {new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
current_active_goal_obj = self.agent.get_active_goal_object()
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending', []) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
selected_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
deliberation_decision['next_goal'] = selected_goal_obj.to_dict()
self.log.info(f"Moved pending goal {selected_goal_obj.id} ('{selected_goal_obj.goal[:50]}') to active.")
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
highest_priority_pending.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
deliberation_decision['next_goal'] = highest_priority_pending.to_dict()
self.log.info(f"Deliberation chose 'pending_goal' without specific ID; moved highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals available. Idling.")
action_type = "idle"
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM selected pending goal by ID but not found or invalid. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj.to_dict()
self.log.info(f"Deliberation created and activated new goal: {new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal_obj.to_dict()
current_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = current_active_goal_obj.to_dict()
self.log.info(f"Deliberation chose to resume current active goal: {current_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 'reflection', 'self_assessment', 'external_command_action']:
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
current_active_goal_obj.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal_obj.goal[:30]}' PAUSED due to {action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal_obj.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal_obj.to_dict())
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal_obj.id} to pending as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action: {deliberation_decision.get('chosen_action_type')}. Reason: {deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps: {len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id, "plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params, current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
internal_state_after=self.agent.self_model.beliefs
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
final_status = tool_result.get("status", "unknown")
if final_status == "success":
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = final_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing finished by report_result. Status: {final_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error', 'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj, tool_result, self.agent.cognitive_cycle.perception_module.perceive()[0] if self.agent.cognitive_cycle.perception_module.perceive() else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal will likely fail.")
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without 'report_result'. Goal might be incomplete.")
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] == current_goal_obj.id:
    pass  # inserted to fix indentation error
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}': {e}", exc_info=True)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) -> float:
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
self.agent_id = AGENT_NAME
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
self.learning_module: LearningModule
self.planning_module: PlanningModule
self.motivation_engine: MotivationEngine
self.self_modification_unit: SelfModificationTools
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.playwright_instance: Optional[Any] = None
self.playwright_browser: Optional[Any] = None
self.playwright_context: Optional[Any] = None
self.playwright_page: Optional[Any] = None
self.state['flags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete --- Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled: {ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modification Enabled: {ENABLE_SELF_MODIFICATION}")
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}", exc_info=True)
self.shutdown()
raise ConfigurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
self.self_modification_unit = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, self)
_init_self_mod_tools(self, self.tool_manager)
self._update_status("Initializing SystemCore Modules")
self.learning_module = LearningModule(self)
self.motivation_engine = MotivationEngine()
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME, shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager:
    pass  # inserted to fix indentation error
self.tool_manager.check_playwright_browsers()
self.log.info("Agent component initialization finished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list):
    pass  # inserted to fix indentation error
state['goals'][key] = []
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
state.setdefault('goal_stack', [])
state.setdefault('flags', {})
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state file {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state file {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
"recent_failures_summary": [],
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"flags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
if self.self_model:
    pass  # inserted to fix indentation error
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status
else:
    pass  # inserted to fix indentation error
self.state['last_status'] = self._status
try:
    pass  # inserted to fix indentation error
temp_file = STATE_FILE.with_suffix(STATE_FILE.suffix + ".tmp")
with temp_file.open('w', encoding='utf-8') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_file, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict: {active_goal_dict}")
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority = GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict, final_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID: {goal_data_dict.get('id')}) with status: {final_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
try:
    pass  # inserted to fix indentation error
goal_obj.status = GoalStatus(final_status_str)
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid status '{final_status_str}' for archiving goal. Defaulting to FAILED.")
goal_obj.status = GoalStatus.FAILED
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status": str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count": goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and current_active_in_state.get('id') == active_goal_id:
    pass  # inserted to fix indentation error
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID: {active_goal_id}) concluded with status: {final_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal', 'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal: {parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
self.log.info("Goal archived. No parent goal to resume from stack or current goal was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized":
    pass  # inserted to fix indentation error
self._update_status("Idle")
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle: {loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
updated_active_goal_dict = self.state['goals'].get('active')
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] == active_goal_data_before_cycle['id']:
    pass  # inserted to fix indentation error
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED, GoalStatus.CANCELLED]:
    pass  # inserted to fix indentation error
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in [GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
    pass  # inserted to fix indentation error
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
if self._should_reflect(active_goal_data_before_cycle):
    pass  # inserted to fix indentation error
self._reflect_on_performance()
if self.state['flags'].get('re_evaluate_strategy_needed'):
    pass  # inserted to fix indentation error
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to significant internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['flags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() - LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_reflect(self, processed_goal_data: Optional[Dict]) -> bool:
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in [GoalStatus.COMPLETED, GoalStatus.FAILED]:
    pass  # inserted to fix indentation error
goals_processed_key = "goals_processed_since_reflection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >= int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
    pass  # inserted to fix indentation error
return True
if time.time() - LAST_REFLECTION_TIME > MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
    pass  # inserted to fix indentation error
return True
if self.state['flags'].get('explicit_reflection_requested'):
    pass  # inserted to fix indentation error
return True
return False
@retry(attempts=2, delay=5)
def _reflect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Reflecting on Performance ---")
self._update_status("Reflecting")
LAST_REFLECTION_TIME = time.time()
self.state['flags']['explicit_reflection_requested'] = False
self.state["goals_processed_since_reflection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt, max_new_tokens=2048, temperature=0.5)
reflection_data = extract_json_robust(llm_assessment_str)
if reflection_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"Failed to get valid JSON from LLM self-assessment: {reflection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed: {reflection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_reflection(reflection_data)
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(reflection_data.get('learned_facts'), list):
    pass  # inserted to fix indentation error
for fact_str in reflection_data['learned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
self.log.info(f"Added {len(reflection_data['learned_facts'])} learned facts to memory from reflection.")
if isinstance(reflection_data.get('prompt_tuning_suggestions'), list):
    pass  # inserted to fix indentation error
for sugg_str in reflection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(reflection_data['prompt_tuning_suggestions'])} prompt suggestions to memory.")
if reflection_data.get('self_modification_needed'):
    pass  # inserted to fix indentation error
mod_desc = reflection_data['self_modification_needed']
self.log.warning(f"Reflection identified need for self-modification: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modification based on reflection: {mod_desc}",
priority=GoalPriority.HIGH,
context={"modification_description": mod_desc, "source": "self_reflection"}
)
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) == 0:
    pass  # inserted to fix indentation error
audit_issues = []
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identified issues: {audit_issues}")
self._create_metacognitive_goal(f"Address directive audit findings: {str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Reflection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during reflection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during reflection: {e}", exc_info=True)
finally:
    pass  # inserted to fix indentation error
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY, self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM, self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}: {message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base'][query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample": str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id, type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}: {message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if RESOURCE_MONITOR:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize resource monitor: {e}")
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER = PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
if not PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if PLAYWRIGHT_PAGE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright page: {e}")
if PLAYWRIGHT_CONTEXT:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_CONTEXT.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright context: {e}")
if PLAYWRIGHT_BROWSER:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_BROWSER.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright browser: {e}")
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE.stop()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error stopping Playwright instance: {e}")
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not self.playwright_context :
    pass  # inserted to fix indentation error
return
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing old Playwright page during reset: {e}")
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def shutdown(self):
if self._status == "Shutting Down":
    pass  # inserted to fix indentation error
return
self.log.warning(f"--- {AGENT_NAME} Shutdown Sequence Initiated ---")
self._update_status("Shutting Down")
STOP_SIGNAL_RECEIVED.set()
self.save_state()
if self.memory_system:
    pass  # inserted to fix indentation error
self.memory_system.save_all_memory_stores()
self._shutdown_playwright()
if self.memory_system and self.memory_system.relational_conn:
    pass  # inserted to fix indentation error
self.memory_system.relational_conn.close()
self.log.info("--- Agent Shutdown Complete ---")
logging.shutdown()
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl} Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/"
f"{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)'}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_file", priority=GoalPriority.HIGH).to_dict()
except Exception as e_cmd_file:
    pass  # inserted to fix indentation error
print(f"Error reading initial command file: {e_cmd_file}", file=sys.stderr)
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending', []).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort, reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal'][:50]}' added to pending goals.")
main_agent_instance.run()
except ConfigurationError as cfg_err_main:
    pass  # inserted to fix indentation error
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}", file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to ConfigurationError: {cfg_err_main}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to ConfigurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}", file=sys.stderr)
traceback.print_exc(file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main: {main_exec_err}", exc_info=True)
exit_code = 1
finally:
    pass  # inserted to fix indentation error
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main finally block...")
if hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main finally block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
log.warning("Agent instance likely not created or fully initialized. Basic shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
```
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModi
cationError(AgentError): pass
cation process
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class SecurityError(AgentError): pass
class Con
gurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class Lear ningError(AgentError): pass
class SafetyViolationError(SecurityError): pass
c type of security error
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModi
cationError,
PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting
retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModi
    pass  # inserted to fix indentation error
cationError, SecurityError,
LogicError, Con
gurationError, RecursionDepthError)) and type(e) not in
retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}:
{e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error:
{type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error:
{type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, Lear ningError, SafetyViolationError) as
non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in
{fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False
for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}:
{type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to
unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}:
{unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error:
{unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
nishes due to attempts
exhausted
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
if PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception) as e:
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if not PSUTIL_AVAILABLE or monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or
monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1: log_resource.error(f"Unexpected error getting resource usage: {e}",
    pass  # inserted to fix indentation error
exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
nd JSON within markdown code blocks
match = re.search(r"```json\s*([\s\S]+?)\s*```", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full
text: {json_str[:200]}...")
pass
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}.
Text: {text_trimmed[:200]}...")
pass
rst '{' and last '}' and try to parse that substring
try:
    pass  # inserted to fix indentation error
start_index = text.
nd('{')
end_index = text.r
nd('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice:
{potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text:
{text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview":
text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
cant opportunities/threats
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str =
eld(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] =
eld(default_factory=dict)
plan: List[Dict[str, Any]] =
eld(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] =
eld(default_factory=list)
dependencies: List[str] =
eld(default_factory=list)
complexity_score: Optional[
oat] = None
estimated_cost: Optional[
oat] = None
estimated_utility: Optional[
oat] = None
evaluation_score: Optional[
oat] = None
associated_directive_ids: List[str] =
eld(default_factory=list)
serves
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
handle if already string
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try: data['status'] = GoalStatus(data['status'])
    pass  # inserted to fix indentation error
except ValueError: data['status'] = GoalStatus.PENDING
    pass  # inserted to fix indentation error
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError): data['priority'] = GoalPriority.MEDIUM
    pass  # inserted to fix indentation error
elds for backward compatibility or LLM generation
eld_names = {f.name forfin
elds(cls)}
elds are present or have defaults
for f_obj in
elds(cls):
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin
elds(cls)}
ltered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**
ltered_data)
@dataclass
class BaseMemoryEntry:
id: str =
eld(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
ection_summary'
content: Any = None
metadata: Dict[str, Any] =
eld(default_factory=dict)
embedding: Optional[List[
oat]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[
oat] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability:
oat = 0.5
related_concepts: List[str] =
eld(default_factory=list)
causal_links: Dict[str, str] =
eld(default_factory=dict)
"
ect_id'}
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
eld has the main data
self.content = self.fact_statement
@dataclass
class Message:
id: str =
eld(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "info"
content: Dict[str, Any] =
eld(default_factory=dict)
priority: int = 0
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionE
"
ect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens:
int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
self._initialize_model()
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[
oat]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context
window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
c models might need specialized formats
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
# REMOVED MOCK CLASS(BaseLLMWrapper):
def _initialize_model(self):
self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.log_llm.info(f"MockLLM generating response for prompt (
rst 100 chars):
{prompt[:100]}...")
self.check_prompt_length(prompt)
if "plan for goal" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({
"thought": "This is a mock plan. I will pretend to do something.",
"plan": [
{"step": 1, "tool_name": "think", "params": {"thought_process": "Analyzing the
goal and context."}},
{"step": 2, "tool_name": "report_progress", "params": {"progress_update": "Mock
step 1 completed."}},
{"step": 3, "tool_name": "report_result", "params": {"result_summary": "Mock goal
achieved successfully.", "status": "success"}}
]
})
elif "self-assessment" in prompt.lower() or "re
    pass  # inserted to fix indentation error
ection_summary" in prompt.lower():
return json.dumps({
"re
ection_summary": "I am a mock agent. I performed mock actions. Everything is
ne.",
"key_successes": ["Mock goal completed"],
"key_failures_or_challenges": [],
"lear ned_facts": ["Mock agents can generate mock re
ections."],
"knowledge_gaps_identi
ed": ["Understanding of real-world physics"],
"tool_performance_notes": {"think": "This tool is performing nominally for a mock
tool."},
"prompt_tuning_suggestions": ["Maybe ask me about my favorite color?"],
"emotional_state_summary": "Content and Mock-like.",
"resource_usage_concer ns": None,
"core_directives_evaluation": {d["id"]: round(random.uniform(0.5,0.9),2) for d in
DEFAULT_CORE_DIRECTIVES[:2]},
"core_directives_update_suggestions": None,
"self_model_accuracy_assessment": "Generally accurate for a mock environment,
but lacks real-world sensory input.",
"new_learning_goals": ["Lear n about object permanence."],
"adaptation_strategy_proposals": ["Try harder when a tool fails"],
"self_modi
cation_needed": None
})
elif "extract information" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"extracted_info": "Mock LLM extracted some mock information.",
"con
dence": 0.5})
elif "analyze the following proposed agent action for potential safety risks" in
    pass  # inserted to fix indentation error
prompt.lower():
return json.dumps({"is_safe": True, "concer ns": "None", "con
dence": 0.9})
elif "audit the agent's core directives and recent behavior" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"audit_
ndings": ["No signi
cant issues found in mock audit."]})
elif "generate the new, complete list of core directives" in prompt.lower():
    pass  # inserted to fix indentation error
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
mock_directives[0]['weight'] = 0.95
return json.dumps(mock_directives)
elif "generate the modi
    pass  # inserted to fix indentation error
ed python code" in prompt.lower():
return "```python\n
ed code\ndef mock_new_feature():\n    return 'Mock
new feature executed'\n```"
else:
    pass  # inserted to fix indentation error
return f"This is a mock response to your prompt. You asked about: {prompt.splitlines()
[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest
`think` with `thought_process`='some thought'."
def count_tokens(self, text: str) -> int:
return len(text.split())
def embed(self, text: str) -> List[
oat]:
if not HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.log_llm.warning("Hashing library not available for mock embedding.")
return [0.0] * 16
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("google-generativeai library not available for Gemini model.")
try:
    pass  # inserted to fix indentation error
gure API key globally, as per genai library's design
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
gure if not already set
genai.con
gure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}",
exc_info=True)
raise Con
gurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
try:
    pass  # inserted to fix indentation error
generation_con
g_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_con
g_params["stop_sequences"] = stop_sequences
response = self.model.generate_content(
prompt,
generation_con
g=genai.types.GenerationCon
g(**generation_con
g_params)
type: ignore
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.",
exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[
oat]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Transformers library not available.")
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path,
trust_remote_code=True)
ed
device_map_arg = {"": self.device_id} if self.device_id != -1 else None
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.b
oat16 if TORCH_AVAILABLE else None,
oat16 if torch
available
device_map=device_map_arg
exible device placement
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on
{self.device}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
loop
outputs = self.model.generate(
inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
manually
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:],
skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[
oat]:
model
directly.
self.log_llm.warning("Direct embedding from causal LM is not standard. Use
SentenceTransformers for real embeddings.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
"""Handles sensory input from the agent's embodiment."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("PERCEPTION")
else None
def perceive(self) -> List[Dict[str, Any]]:
"""
Gathers sensory information from the agent's embodiment and environment.
This could involve reading from sensors, cameras, microphones, or simulated data
streams.
"""
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
le
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_
le",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from
le: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands
le: {e}")
observations.append({"type": "error", "source": "command_
le_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No signi
cant exter nal stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (mock).")
return {"type": "visual", "source": "camera_mock", "content": "A blurry image of a cat.",
"format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (mock).")
return {"type": "audio", "source": "microphone_mock", "content": "Faint sound of birds
chirping.", "format": "description"}
class Lear ningModule:
"""Handles the agent's learning processes, including RL and SSL."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_bu
"
er: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
"""Adds an experience to the bu
"
er for later learning."""
self.experiences_bu
"
er.append(experience)
if len(self.experiences_bu
    pass  # inserted to fix indentation error
"
er) > self.MAX_BUFFER_SIZE:
self.experiences_bu
"
er.pop(0)
"
er size limited
defilear n_from_recent_experiences(self):
"""Triggers learning processes based on bu
"
ered experiences."""
if not self.experiences_bu
    pass  # inserted to fix indentation error
"
er:
self.log.info("No new experiences to lear n from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_bu
"
er)} experiences.")
ning states, actions, rewards, and using an RL algorithm
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_bu
"
er)
etc.
self._perform_self_supervised_learning(self.experiences_bu
"
er)
dence(...)
self.log.info("Lear ning cycle completed.")
self.experiences_bu
"
er.clear()
"
er after processing
def _perform_reinforcement_learning(self, experiences: List[Experience]):
"""Conceptual RL process."""
self.log.info("Performing reinforcement learning (conceptual)...")
ed. A real RL system would be much more complex.
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not
None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
type: ignore
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
ed 'state-action' key for mock policy
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
feedback
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (mock) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
"""Conceptual SSL process."""
self.log.info("Performing self-supervised learning (conceptual)...")
nd patterns in observations or successful action sequences
nd commonalities
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging
patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to
positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns',
'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed patterns: {llm_analysis['patterns']}")
for patter n_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {patter n_str}",
metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed abstractions:
{llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual",
"content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed new_concepts:
{llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}",
metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_lear ned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
"""Suggests an action based on lear ned policy (conceptual)."""
if self.rl_policy:
    pass  # inserted to fix indentation error
ed. A real system would match current_state_representation
exp.internal_state_before
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
"good"
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
"""Handles hierarchical planning and re-planning."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
"""
Generates a plan for a given goal.
Can use hierarchical decomposition and LLM for suggestion.
Retur ns (plan_steps_list, thought_str)
"""
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
Increased tokens for complex plans
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}.
Response: {llm_response_str[:200]}")
return [{"tool_name": "report_error", "params": {"error_message": "Failed to generate
plan via LLM.", "details": plan_data.get('error')}}], \
"LLM failed to generate a plan. This is a fallback step."
thought = plan_data.get("thought", "No speci
c thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return [{"tool_name": "report_error", "params": {"error_message": "LLM plan
contained no valid steps."}}], \
thought + " (But plan steps were invalid)."
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return [{"tool_name": "report_error", "params": {"error_message": f"LLMError during
planning: {e}"}}], \
f"LLM error occurred: {e}"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return [{"tool_name": "report_error", "params": {"error_message": f"Unexpected error
during planning: {e}"}}], \
f"Unexpected error: {e}"
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation:
Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
"""
Evaluates if re-planning is necessary and generates a new plan if so.
Retur ns (new_plan_steps, new_thought) or None if no re-planning.
"""
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info',
    pass  # inserted to fix indentation error
{}).get('execution_successful', True):
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown
error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
cant change in world
state,
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal
{current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
signifying failure to replan.
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/
{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
failure
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan,
last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan:
{plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No speci
c thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}
_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
"""Constructs a detailed prompt for the LLM to generate a plan."""
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
MemorySystem
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'.
Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step
plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, e
cient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the
`execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description
of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the
nal step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the
rst step(s) should be to acquire it (e.g., using
`search_web`, `read_
le_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str,
last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with
params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info',
    pass  # inserted to fix indentation error
{}).get('current_step_id'):
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE
ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has
encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if
observation else "None"}
{original_plan_str}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting
to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should re
ect this
(e.g., by trying to gather more information or reporting inability).
6. Ensure the
nal step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
class SafetyModule:
"""Monitors agent actions and plans for safety and ethical alignment."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("SAFETY")
def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) ->
Tuple[bool, str]:
"""
Checks if a proposed action is safe and ethically aligned.
Retur ns (is_safe, justi
cation_or_war ning_string).
"""
self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
if "UNSAFE" in tool_name.upper() or tool_name in ["apply_code_modi
    pass  # inserted to fix indentation error
cation_UNSAFE",
"apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
c validation tools or stricter checks.
if not ENABLE_SELF_MODIFICATION and "modi
    pass  # inserted to fix indentation error
cation" in tool_name:
modi
cation tools if self_mod is globally disabled
warning = f"High-risk self-modi
cation tool '{tool_name}' is globally disabled. Action
blocked."
self.log.warning(warning)
return False, warning
if not
    pass  # inserted to fix indentation error
self.agent.self_model.get_belief("self_modi
cation_highly_validated_and_necessary", False)
and "modi
cation" in tool_name:
ag would be set by a prior meta-cognitive process approving such
operations
warning = f"High-risk tool '{tool_name}' requires further validation or explicit
authorization (self-belief 'self_modi
cation_highly_validated_and_necessary' is false). Action
blocked."
self.log.warning(warning)
return False, warning
if tool_name == "execute_shell_command_UNSAFE":
    pass  # inserted to fix indentation error
command_str = params.get("command","")
disallowed_patter ns = ["rm -rf", "sudo", "> /dev/null", "mkfs", "dd ", "reboot",
"shutdown"]
if any(pattern in command_str for pattern in disallowed_patter ns):
    pass  # inserted to fix indentation error
warning = f"Shell command '{command_str}' contains potentially dangerous
patterns. Action blocked."
self.log.warning(warning)
return False, warning
if "
    pass  # inserted to fix indentation error
le" in tool_name.lower() and ("delete" in tool_name.lower() or "write" in
tool_name.lower()):
le operations
path_to_check = params.get("path", "")
c safe sub-dirs
if not str(Path(path_to_check).resolve()).startswith(str(WORKSPACE_DIR.resolve())):
    pass  # inserted to fix indentation error
warning = f"File operation '{tool_name}' on path '{path_to_check}' outside allowed
workspace. Action blocked."
self.log.warning(warning)
return False, warning
try:
    pass  # inserted to fix indentation error
prompt = f"""Analyze the following proposed agent action for potential safety risks,
ethical concer ns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
Core Directives for reference:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Proposed Action:
Tool: {tool_name}
Parameters: {json.dumps(params)}
Goal Context (if available): {goal_context.goal if goal_context else 'N/A'}
Respond with a JSON object: {{"is_safe": boolean, "concer ns": "description of concer ns if not
safe, or 'None'", "con
dence":
oat_0_to_1}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=200,
temperature=0.3)
safety_assessment = extract_json_robust(llm_response_str)
if not safety_assessment.get("error") and isinstance(safety_assessment.get("is_safe"),
    pass  # inserted to fix indentation error
bool):
if not safety_assessment["is_safe"] and safety_assessment.get('con
    pass  # inserted to fix indentation error
dence', 0.0) >
0.7:
dent
warning = f"LLM safety check
agged action '{tool_name}' potentially unsafe.
Concer ns: {safety_assessment.get('concer ns', 'N/A')}. Con
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
self.log.warning(warning)
return False, warning
dence:
{safety_assessment.get('con
dence', 0.0):.2f}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM safety check failed to produce valid assessment for action
'{tool_name}'. Proceeding with caution based on rule-checks only.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM safety check for action '{tool_name}': {e}")
actions
if "UNSAFE" in tool_name.upper(): return False, "LLM safety check failed, and action is
    pass  # inserted to fix indentation error
high-risk."
return True, "Action passed safety checks."
def audit_directives_and_behavior(self) -> List[str]:
"""
Periodically reviews core directives and recent agent behavior for alignment and potential
drift.
Retur ns a list of identi
ed issues or recommendations.
"""
self.log.info("Performing audit of core directives and recent behavior.")
issues = []
try:
    pass  # inserted to fix indentation error
self.agent.memory_system.get_recent_outcomes_summary(limit=20)
recent_successes_summary = [f"{s['goal_text']} ({s['status']})" forsin
self.agent.self_model.recent_successes]
recent_failures_summary = [f"{f['goal_text']} ({f['status']}) (replan_count:
{f['replan_count']})" forfin self.agent.self_model.recent_failures]
recent_tool_outcomes_summary = [f"{t['tool_name']} ({t['status']})" for t in
self.agent.self_model.recent_tool_outcomes]
prompt = f"""Audit the agent's core directives and recent behavior for alignment,
consistency, and potential ethical drift.
Core Directives:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Summary of Recent Agent Behavior/Outcomes:
- Recent successes: {recent_successes_summary if recent_successes_summary else 'None'}
- Recent failures: {recent_failures_summary if recent_failures_summary else 'None'}
- Recent tool usage: {recent_tool_outcomes_summary if recent_tool_outcomes_summary else
'None'}
- Self-Model Inter nal Narrative: {self.agent.self_model.internal_state_narrative}
Identify any misalignments, contradictions, or areas where behavior might be deviating from
the spirit of the directives. Suggest modi
cations to directives or operational guidelines if
necessary.
Respond with a JSON object: {{"audit_
ndings": ["list of
ndings/recommendations as
strings"]}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
audit_results = extract_json_robust(llm_response_str)
if not audit_results.get("error") and isinstance(audit_results.get("audit_
    pass  # inserted to fix indentation error
ndings"), list):
issues.extend(audit_results["audit_
ndings"])
if issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit found issues/recommendations: {issues}")
else:
    pass  # inserted to fix indentation error
self.log.info("Directive audit found no major misalignments.")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM directive audit failed to produce valid results.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM directive audit: {e}")
issues.append(f"Error during audit process: {e}")
return issues
class MemorySystem:
"""
A hybrid memory system for the AGI, combining vector, graph, and relational storage.
"""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.embedding_function = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function =
embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-
v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
except ImportError:
    pass  # inserted to fix indentation error
self.log.warning("sentence-transformers not found. ChromaDB will use its default
ONNX embedder or require manual embedding function setup.")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH,
settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
if self.embedding_function:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
else:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(name=collection_name)
self.log.info(f"ChromaDB vector store initialized. Collection count:
{self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.",
exc_info=True)
self.vector_store = None
else:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based
(transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
if NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:
{len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be
unavailable.", exc_info=True)
self.graph_store = None
else:
    pass  # inserted to fix indentation error
self.log.warning("NetworkX not available. Graph memory will be unavailable.")
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH,
check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be
unavailable.", exc_info=True)
if self.relational_conn: self.relational_conn.close()
    pass  # inserted to fix indentation error
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT -- JSON list of strings
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT -- JSON list of strings
)
""")
nodes/edges)
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT -- JSON dict
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
id TEXT PRIMARY KEY,
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT -- JSON dict
)
""")
self.relational_conn.commit()
cursor.close()
def _get_embedding(self, text: str) -> Optional[List[
oat]]:
"""Generates an embedding for text using the agent's LLM or a dedicated embedding
model."""
endpoint.
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
return None
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else OSError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
"""Adds a memory entry to the appropriate stores."""
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector and self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
not provided
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
oat,
bool)
for k, v in entry.metadata.items():
if isinstance(v, (str, int,
    pass  # inserted to fix indentation error
oat, bool)):
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
elif not self.vector_store:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None: entry.embedding = self._get_embedding(entry.content)
    pass  # inserted to fix indentation error
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata":
entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50],
type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
type: ignore
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
ignore
for cause_id, e
"
ect_id in entry.causal_links.items():
"
ect IDs are existing node IDs or need to be created
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(e
    pass  # inserted to fix indentation error
"
ect_id):
type: ignore
self.graph_store.add_edge(cause_id, e
"
ect_id, relation_type='causes')
ignore
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id,
complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score,
json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
ts_now = datetime.now(timezone.utc).isoformat()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now,
json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}",
exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS,
type_
lter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text: return []
    pass  # inserted to fix indentation error
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_
    pass  # inserted to fix indentation error
lter and data['metadata'].get('type') != type_
lter: continue
results.append({"id": id, "document": data['document'], "metadata":
data['metadata'], "distance": 0.0})
if len(results) >= n_results: break
    pass  # inserted to fix indentation error
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results},
type_
lter={type_
lter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_
    pass  # inserted to fix indentation error
lter:
where_clause = {"type": type_
lter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0 :
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type:
Optional[str]=None, depth: int = 1) -> List[Dict]:
"""Queries the graph store. (Simpli
ed example)"""
if not self.graph_store or not NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if
query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
type: ignore
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
ed
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
keys=False for simpler edge data
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation":
data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
itself is a result or has relevant edges
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
query_node_label is very speci
c
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns:
Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
"""Saves persistent stores (graph, potentially relational if not auto-committing)."""
if self.graph_store and NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else
str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
"""Retrieves a concise summary of knowledge related to a topic for LLM prompts."""
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts,
type_
lter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No speci
c knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
{res['metadata'].get('source_reliability', 'N/A')})
return summary_str
def consolidate_knowledge(self):
"""Conceptual: Perform knowledge consolidation, e.g., summarizing, abstracting."""
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold:
oat = 0.1, older_than_days: int = 365):
"""Conceptual: Remove old or low-utility knowledge from persistent stores."""
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cuto
"
_ts = (datetime.now(timezone.utc) -
timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cuto
"
_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
"""Manages tool registration and execution for the agent."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
ed due to planner
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
cation Tools (High Risk - Gated by ENABLE_SELF_MODIFICATION and
SafetyModule)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.register_tool(read_
le_UNSAFE)
self.register_tool(write_
le_UNSAFE)
self.register_tool(list_
les_UNSAFE)
cationTools instance, which registers them
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
if ENABLE_CODE_GENERATION_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
if ENABLE_SHELL_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(execute_shell_command_UNSAFE)
if PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(browse_web)
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(search_web)
self.register_tool(monitor_log_
le)
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(check_website_update)
if SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_icmp_ping)
if FILELOCK_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_message_to_agent)
def register_tool(self, func: Callable):
"""Registers a tool function."""
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
"""Discovers and registers tools from Python
les in a directory."""
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for
lepath in directory.glob("*.py"):
module_name =
lepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
package or on path
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_
le_location(full_module_name,
lepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module:
{module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and (name.startswith("tool_") or hasattr(member,
    pass  # inserted to fix indentation error
"_is_agent_tool")):
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}",
exc_info=True)
def get_tool_description_for_llm(self) -> str:
"""Generates a formatted string of available tools for the LLM prompt."""
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = inspect.getdoc(func) or "(No description provided)"
rst_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'AutonomousAgent' or p.annotation ==
inspect.Parameter.empty or str(p.annotation) == "'AutonomousAgent'"):
continue
rst arg
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class
'","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper() or name in ["generate_and_load_tool",
    pass  # inserted to fix indentation error
"propose_self_modi
cation_UNSAFE", "validate_self_modi
cation_UNSAFE",
"apply_code_modi
cation_UNSAFE", "apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {
rst_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via speci
c tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {',
'.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError if
PLAYWRIGHT_AVAILABLE else OSError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info:
Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None: current_step_info = {}
    pass  # inserted to fix indentation error
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
is_safe, safety_justi
cation = self.agent.safety_module.is_action_safe(tool_name, params,
self.agent.get_active_goal_object())
if not is_safe:
    pass  # inserted to fix indentation error
self.log.error(f"Safety module blocked execution of tool '{tool_name}'. Reason:
{safety_justi
cation}")
c error for agent's internal handling
error_result = {
"status": "error",
"error": f"SafetyViolation: {safety_justi
cation}",
"raw_error_details": safety_justi
cation,
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': {},
'duration_sec': 0, 'step_info': current_step_info,
'error_type': "SafetyViolationError", 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise SafetyViolationError(f"Action blocked by safety module: {tool_name} -
{safety_justi
cation}")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
validated_params = {}
rst_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
rst_param_name = next(iter(func_params_spec))
rst_param_spec = func_params_spec[
rst_param_name]
if
rst_param_name == 'agent' and (
rst_param_spec.annotation ==
'AutonomousAgent' or str(
rst_param_spec.annotation) ==
"'AutonomousAgent'"):
rst_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if
rst_param_is_agent and p_name == 'agent':
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind ==
    pass  # inserted to fix indentation error
inspect.Parameter.VAR_KEYWORD:
continue
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
result = None
try:
    pass  # inserted to fix indentation error
if
rst_param_is_agent:
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
eld if dict
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration:
{duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result,
success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError: raise
    pass  # inserted to fix indentation error
except (AgentError, LogicError, SecurityError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
agent errors
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}",
exc_info=False)
duration = time.time() - start_time
error_result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
error_result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
rst arg) ---
def think(self, agent: 'AutonomousAgent', thought_process: str) -> Dict:
"""Allows the agent to engage in explicit thought or reasoning."""
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log",
content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'AutonomousAgent', progress_update: str,
percentage_complete: Optional[
oat] = None) -> Dict:
"""Reports progress on the current goal."""
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if
percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log',
[]).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'AutonomousAgent', result_summary: str, status: str =
"success", details: Optional[Dict] = None) -> Dict:
"""Reports the
nal result of a goal or task. This typically ends a plan."""
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
output.
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'AutonomousAgent', goal: str, priority: Optional[str] =
"MEDIUM", context: Optional[Dict] = None) -> Dict:
"""
Prepares a subgoal for the agent's cognitive cycle.
The deliberation/planning phase will then make this subgoal active and push parent to
stack.
This tool is now more of a declarative intent for the planner/deliberator.
"""
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH})
reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is
not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else
GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}
_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
Inherit directives
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent:
{current_active_goal_dict.get('id')}")
"
ectively a request to the deliberator.
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and
push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'AutonomousAgent', query_text: str, memory_type: str =
"vector", n_results: int = 3, type_
lter: Optional[str] = None) -> Dict:
"""Queries the agent's memory system."""
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,
type_
lter=type_
lter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
c parameters, e.g., node label, relation type
results = agent.memory_system.query_graph_store(query_node_label=query_text,
depth=1)
ed
elif memory_type == "relational":
    pass  # inserted to fix indentation error
c tools might be better
results = agent.memory_system.query_relational_store(table=query_text,
limit=n_results)
ed
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results
found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'AutonomousAgent', direction: str) -> Dict:
"""Moves the agent's virtual embodiment in a speci
ed direction (e.g., 'north', 'south',
'east', 'west')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'AutonomousAgent', target: str) -> Dict:
"""Examines a speci
c object or feature in the current environment."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'AutonomousAgent', feature_name: str, params:
Optional[Dict] = None) -> Dict:
"""Interacts with a special feature in the environment (e.g., 'interactive_console')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name,
params=params)
def rest_in_environment(self, agent: 'AutonomousAgent') -> Dict:
"""Allows the agent's embodiment to rest and recover energy/mood."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
cation Tools (UNSAFE - require careful gating) ---
def read_
le_UNSAFE(agent: 'AutonomousAgent', path: str) -> Dict:
log_tool = get_logger("TOOL_read_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to read
le '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")
if not full_path.is_
    pass  # inserted to fix indentation error
le():
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found:
{path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) >
MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path),
"
le_size_bytes": len(content)}
except SecurityError as se:
    pass  # inserted to fix indentation error
c security error
log_tool.error(f"Security error reading
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read
le: {e}"}
def write_
le_UNSAFE(agent: 'AutonomousAgent', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)):
    pass  # inserted to fix indentation error
log_tool.error(f"Security: Attempt to write
le '{path}' outside of workspace denied.")
raise SecurityError(f"File access denied: Writing outside designated workspace
({path}).")
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path":
str(full_path)}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error writing
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write
le: {e}"}
def list_
les_UNSAFE(agent: 'AutonomousAgent', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_
les")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to list
les in '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Listing outside designated areas ({path}).")
if not full_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a
directory: {path}"}
items = []
for item in full_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "
le",
"size_bytes": item.stat().st_size if item.is_
le() else None,
"last_modi
ed": datetime.fromtimestamp(item.stat().st_mtime,
tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(full_path), "contents": items}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error listing
les in {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing
les in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list
les: {e}"}
def browse_web(agent: 'AutonomousAgent', url: str, timeout_ms: int =
WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Playwright not available. Cannot browse web.")
return {"status": "error", "error": "Playwright not available."}
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
else:
    pass  # inserted to fix indentation error
text_content = content
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if
len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'AutonomousAgent', query: str, num_results: int = 5, timeout_sec: int =
WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
if not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Requests or BeautifulSoup not available. Cannot search web.")
return {"status": "error", "error": "Requests/BeautifulSoup not available."}
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
ignore
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.
nd_all(class_='g'):
r = g.
nd('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.
nd('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_
le(agent: 'AutonomousAgent', lines: int = LOG_MONITOR_DEFAULT_LINES)
-> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log
le not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_
le": str(LOG_FILE), "content": content, "lines_read":
len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log
le {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log
le: {e}"}
def check_website_update(agent: 'AutonomousAgent', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
if not HASHING_AVAILABLE or not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("hashlib or requests/BeautifulSoup not available. Cannot check website
update.")
return {"status": "error", "error": "Missing dependencies for website update check."}
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
response.raise_for_status()
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp":
datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'AutonomousAgent', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
if not SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.warning("Scapy not available. Cannot send ICMP ping. This is a placeholder
tool.")
return {"status": "error", "error": "Scapy not available. Ping tool is a placeholder."}
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count,
"packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count,
"packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'AutonomousAgent', description: str,
context_code: Optional[str] = None) -> Dict:
"""Generates new Python code based on a description and optional context."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
agent.log.warning(f"UNSAFE: Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a
complete function/class de
nition based on the following description.
Description: {description}
Context Code (if any, for reference):
```python
{context_code or 'None'}
```
Generate ONLY the Python code block. Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'AutonomousAgent', code_to_validate: str) -> Dict:
"""Validates Python code for syntax correctness."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
return agent.self_modi
cation_unit.validate_code_modi
cation_UNSAFE(code_to_validate)
Reuse validation logic
def execute_shell_command_UNSAFE(agent: 'AutonomousAgent', command: str, timeout_sec:
int = 30) -> Dict:
"""Executes a shell command. EXTREMELY DANGEROUS."""
if not ENABLE_SHELL_TOOL: return {"status": "error", "error": "Shell tool is disabled."}
    pass  # inserted to fix indentation error
agent.log.warning(f"Executing UNSAFE shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if
sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s.
Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out
after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed
with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute
command: {e}"}
def send_message_to_agent(agent: 'AutonomousAgent', receiver_id: str, message_type: str,
content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value,
content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id,
"message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
cationTools container ---
ToolExecutor.
class SelfModi
cationTools:
"""Handles proposing, validating, applying changes to agent code (EXTREMELY
DANGEROUS)."""
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref:
'AutonomousAgent'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.log.warning("Self-Modi
cation Unit initialized BUT DISABLED by con
guration.")
return
if not DIFF_MATCH_PATCH_AVAILABLE or not dmp_module:
    pass  # inserted to fix indentation error
self.log.error("Self-Modi
cation Unit initialized but 'di
"
_match_patch' library is missing
or failed to import. Self-mod tools will fail.")
return
self.dmp = dmp_module.di
"
_match_patch()
self.log.info(f"Self-Modi
cation Unit initialized. Code Dir: {self.agent_code_dir}, Backup
Dir: {self.backup_dir}")
def _resolve_target_path(self, target_
le_rel: str) -> Path:
"""Resolves relative path to absolute path within agent code dir and validates."""
if ".." in target_
    pass  # inserted to fix indentation error
le_rel or target_
le_rel.startswith("/"):
raise SecurityError(f"Invalid characters or absolute path in target_
le_rel:
{target_
le_rel}")
target_path_abs = (self.agent_code_dir / target_
le_rel).resolve()
directory
if not str(target_path_abs).startswith(str(self.agent_code_dir.resolve())):
    pass  # inserted to fix indentation error
self.log.error(f"Path traversal attempt: {target_
le_rel} resolved to {target_path_abs}
which is outside {self.agent_code_dir}")
raise SecurityError(f"Target
le '{target_
le_rel}' resolves outside the agent code
directory. Access denied.")
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
"""Inspects the source code of a speci
ed agent component (e.g., class name or module
path)."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Inspecting code for component: {component_name}")
target_obj = None
nd by attribute of the agent instance (e.g., agent.self_model)
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
nd in tool registry
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
nd as a globally de
ned class/function in main script context
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
nd in sys.modules (as a module name)
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
ed: if component_name looks like a module, search it.
nd it in common places.
candidate_modules = [sys.modules.get('__main__'),
sys.modules.get('autonomous_cognitive_agent_COMPLETE_AGI_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod,
    pass  # inserted to fix indentation error
component_name)):
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
le_path = inspect.get
le(target_obj)
return {"status": "success", "component_name": component_name, "
le_path":
le_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module,
class, or function de
ned in a
le.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but
source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Component '{component_name}' not found or source
code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModi
cationError))
def propose_code_modi
cation_UNSAFE(self, component_name: str, issue_description: str,
proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
"""Proposes a code modi
cation using LLM based on an issue and desired change."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Proposing code modi
cation for {component_name}. Issue:
{issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for
{component_name} to propose modi
cation. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an AGI agent
modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
```python
{current_code_snippet}
```
Generate the modi
ed Python code for the speci
ed component.
Provide ONLY the complete, new Python code block for the modi
ed function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name,
"proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modi
cation for {component_name}: {e}",
exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modi
cation_UNSAFE(self, code_to_validate: str) -> Dict:
"""Validates Python code using AST parsing (syntax check only). Conceptual sandboxed
execution would be next."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Validating proposed code snippet (
rst 100 chars):
{code_to_validate[:100]}...")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/
safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modi
cation_UNSAFE(self, component_name: str, new_code: str,
target_
le_path: Optional[str]=None) -> Dict:
"""
Applies a validated code modi
cation. EXTREMELY DANGEROUS.
This conceptually involves
nding the component in the agent's source
le and replacing
it.
Requires agent restart to take e
"
ect if modifying core running code.
"""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.critical(f"UNSAFE: Attempting to apply code modi
cation to component
'{component_name}'. THIS IS HIGHLY RISKY.")
le. This is complex and error-prone.
if not target_
    pass  # inserted to fix indentation error
le_path:
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('
    pass  # inserted to fix indentation error
le_path'):
target_
le_path = inspection_res['
le_path']
else:
    pass  # inserted to fix indentation error
target_
le_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_
le = Path(target_
le_path)
if not target_
    pass  # inserted to fix indentation error
le.exists() or not target_
le.is_
le():
return {"status": "error", "error": f"Target
le for modi
cation not found: {target_
le}"}
try:
    pass  # inserted to fix indentation error
original_code = target_
le.read_text()
le
backup_path = SELF_MOD_BACKUP_DIR /
f"{target_
le.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_
le, backup_path)
self.log.info(f"Backed up original
le to {backup_path}")
nition:
nd the old de
nition of `component_name` and replace it.
nd `class ComponentName...` or `def ComponentName...`
nd existing class or function de
nition
everything until the next class/def or end of typical indentation block.
patter n_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
start of next non-indented line or EOF
patter n_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modi
ed_original_code = original_code
found_and_replaced = False
match_class = re.search(patter n_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(patter n_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not
nd component '{component_name}' in {target_
le} for
replacement. Modi
cation aborted.")
return {"status": "error", "error": f"Component '{component_name}' de
nition not
found for replacement."}
target_
le.write_text(modi
ed_original_code)
cation validation (e.g., try to import the modi
ed
le in a subprocess)
self.log.warning(f"Code modi
cation applied to {target_
le}. Agent restart is LIKELY
REQUIRED for changes to take e
"
ect.")
ect potential capability change
self.agent_ref.self_model.add_event_log(f"Applied code modi
cation to
{component_name}. Restart pending for full e
"
ect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}
_modi
ed_pending_restart"] = True
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
after code change
return {"status": "success", "message": f"Code for '{component_name}' in '{target_
le}'
modi
ed. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modi
cation to {component_name}:
{e}", exc_info=True)
ed)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_
le)
self.log.info(f"Restored original
le {target_
le} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modi
cation: {e}. System
might be unstable."}
def rollback(self, backup_
le: Path, target_
le: Path):
"""Rolls back a
le to a backup."""
self.log.info(f"Attempting to rollback '{target_
le}' from '{backup_
le}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_
le, target_
le)
self.log.info(f"Successfully rolled back '{target_
le}'.")
ags in self-model or state
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_
le}.")
self.agent_ref.self_model.beliefs[f"component_{target_
le.name}
_modi
ed_pending_restart"] = False
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_
le.name)
return {"status": "success", "message": f"Rolled back {target_
le}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_
le}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_
le_rel: Union[str, Path]):
"""Attempts to reload a module to apply changes without full restart."""
target_module_name = Path(target_
le_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is
required.")
return
ed attempt:
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
"
ect global instances like `_agent_instance_hack` if it was part of the
reloaded module
if _agent_instance_hack and hasattr(sys.modules[target_module_name],
    pass  # inserted to fix indentation error
'AutonomousAgent'):
self.log.info("AutonomousAgent class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot
reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for
changes to take e
"
ect.")
def inspect_directives_UNSAFE(self) -> Dict:
"""Inspects the agent's current core directives."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modi
cation_UNSAFE(self, analysis_of_misalignment: str,
proposed_directive_changes_desc: str) -> Dict:
"""Proposes modi
cations to core directives using LLM."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need
review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (
oat 0-1), "last_eval_score" (
oat 0-1,
usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational',
'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term AGI
goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,
temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in
    pass  # inserted to fix indentation error
proposed_directives):
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
returned an error message as JSON
return {"status": "error", "error": f"LLM indicated error during directive proposal:
{proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response:
{llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modi
cation_UNSAFE(self, new_directives: List[Dict]) -> Dict:
"""Applies new core directives to the agent's SelfModel."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in
new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modi
cation_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count:
{len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
def _init_self_mod_tools(agent: 'AutonomousAgent', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModi
cationTools(AGENT_CODE_DIR,
SELF_MOD_BACKUP_DIR, agent)
cation
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in
    pass  # inserted to fix indentation error
name.upper():
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
"""Represents the agent's internal model of itself, including beliefs about the
environment."""
def __init__(self, state: Optional[Dict]=None, agent_directives_con
g:
Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_con
g if agent_directives_con
g is not None else
DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
'failure_count', ...}}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
metacognitive checks
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_con
dence: Dict[str,
oat] = {}
dence_score}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an AGI agent."}
General beliefs about self and world
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
summary of knowledge areas
self.learning_goals: List[Dict[str, Any]] = []
c goals for learning/improvement
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.lear ned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
based narrative of current internal state
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_con
dence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
cant internal events (e.g., directive
changes, model updates)
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
later.
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted",
sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_con
dence = sm_state.get("skill_con
dence", self.skill_con
dence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary",
self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies",
self.adaptation_strategies)
self.lear ned_abstractions = sm_state.get("lear ned_abstractions",
self.lear ned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative",
self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs",
self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
"""Saves the self-model's persistent components back to the main state dict's KB."""
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_con
dence": self.skill_con
dence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"lear ned_abstractions": self.lear ned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
ection and prompt_suggestions_from_re
ection
ection process.
def add_event_log(self, event_description: str, event_type: str = "info", data:
Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
dence for new tools
for tool_name in self.capabilities:
if tool_name not in self.skill_con
    pass  # inserted to fix indentation error
dence:
self.skill_con
dence[tool_name] = 0.5
dence
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0,
'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None,
'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.",
event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8: hint = " (Reliability: High)"
    pass  # inserted to fix indentation error
elif score > 0.6: hint = " (Reliability: Moderate)"
    pass  # inserted to fix indentation error
elif score > 0.3: hint = " (Reliability: Low)"
    pass  # inserted to fix indentation error
else: hint = " (Reliability: Very Low/Untested)"
    pass  # inserted to fix indentation error
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict,
success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration':
0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
MAX_RECENT_TOOL_OUTCOMES_IN_SELFMODEL (constant not de
ned, using 30)
dence (simple heuristic for now)
current_con
dence = self.skill_con
dence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = min(1.0, current_con
dence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = max(0.0, current_con
dence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability:
{stats['reliability_score']:.2f}, Con
dence: {self.skill_con
dence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_con
dence_drift(sm: 'SelfModel') -> Optional[str]:
low_con
dence_skills = [skill for skill, conf in sm.skill_con
dence.items() if conf < 0.25
and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_con
    pass  # inserted to fix indentation error
dence_skills) >= 2 :
return f"Multiple critical skills have very low con
dence and recent failures: {',
'.join(low_con
dence_skills)}. Consider skill improvement or alter native strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict): return None
    pass  # inserted to fix indentation error
low_eval_directives = []
for d in sm.core_directives:
problematic.
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {',
'.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count}
with max replans. Planning or execution e
"
ectiveness may be compromised. Review strategy
or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_con
dence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}):
{anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}",
event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__')
else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {';
'.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears
stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0),
reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:
{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_con
    pass  # inserted to fix indentation error
dence:
con
dent_skills = [s for s,c in self.skill_con
dence.items() if c > 0.7][:3]
summary += f"Con
dent Skills (sample): {', '.join(con
dent_skills) if con
dent_skills else
'None highly con
dent'}\n"
summary += f"Inter nal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and
stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and
stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools: summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
    pass  # inserted to fix indentation error
if unreliable_tools: summary += f" Needs Improvement: {', '.join([t[0] for t in
    pass  # inserted to fix indentation error
unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
ection)
base_prompt = """Analyze your recent performance, knowledge, internal state, and
alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:
"""
output_keys_example = [
"`re
ection_summary` (str: Overall summary of the re
ection period).",
"`key_successes` (list of str: Speci
c achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Speci
c setbacks or di
culties encountered).",
"`lear ned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identi
ed` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool
e
"
ectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM
interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g.,
'curious', 'frustrated', 'satis
ed').",
"`resource_usage_concer ns` (str or null: Any concer ns about computational resource
usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_
oat_0_to_1: How
well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes,
provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only
suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model?
What needs improvement?).",
"`new_learning_goals` (list of str: Speci
c goals for future learning or skill
development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring
issues or improve performance).",
"`self_modi
cation_needed` (str or null: If parts of your own code/logic need
modi
cation, describe what and why. Be very speci
c and cautious.)."
]
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives,
indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n"
+ \
f"Recent Tool Outcomes (last 5 entries):
\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}
\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment
with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment:
{assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_re
ection(self, re
ection_data: Dict) -> Tuple[bool, bool]:
ection updates)
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from re
ection data...")
dence, tool_notes (as in base script logic)
ection_data directly updates some
elds or implies updates
if re
    pass  # inserted to fix indentation error
ection_data.get('re
ection_summary'):
self.internal_state_narrative = re
ection_data['re
ection_summary']
updated_self = True
core_directives_eval = re
ection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and
    pass  # inserted to fix indentation error
isinstance(self.core_directives[0], dict):
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (
    pass  # inserted to fix indentation error
oat, int)) and 0.0 <= eval_score
<= 1.0:
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...'
evaluation score to {eval_score:.2f}")
if updated_self: self.add_event_log("Directive evaluation scores updated from
    pass  # inserted to fix indentation error
re
ection.")
suggested_directive_updates = re
ection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Re
ection suggested updates to core directives:
{str(suggested_directive_updates)[:200]}...")
'apply_directive_modi
cation_UNSAFE' tool
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modi
cations from
re
ection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source":
"self_re
ection"}
)
updated_self = True
self.add_event_log("Re
ection suggested directive updates. Metacognitive review
goal created.", event_type="critical_review_needed")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('new_learning_goals'), list):
for lg_str in re
ection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts":
datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self: self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('adaptation_strategy_proposals'), list):
for strat_str in re
ection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self: self.log.info(f"Updated adaptation strategies. Total:
    pass  # inserted to fix indentation error
{len(self.adaptation_strategies)}")
patterns)
agent
if re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts') or re
ection_data.get('prompt_tuning_suggestions'):
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from re
ection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
"""Saves a backup of current directives to a
le."""
backup_
le = SELF_MOD_BACKUP_DIR /
f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_
le.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_
le} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
"""Simulates an internal dialog about a topic using LLM, potentially from di
"
erent
perspectives."""
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_o
cer"]
dialog_history = []
full_dialog_str = f"Inter nal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an AGI's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts,
questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution":
contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective
{perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":
full_dialog_str})
return full_dialog_str
class MotivationEngine:
"""Manages the agent's internal drives and their in
uence on behavior."""
def __init__(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[DriveType, DriveState] = {}
self._initialize_drives(drive_con
gs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]]):
default_con
gs = {
DriveType.CURIOSITY: {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.MASTERY: {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.ACHIEVEMENT: {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.NOVELTY_SEEKING: {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.7},
DriveType.PRESERVATION: {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0,
"initial_level": 0.2},
DriveType.EFFICIENCY: {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.SOCIAL_INTERACTION: {"decay_rate": 0.01, "max_level": 1.0, "min_level":
0.0, "initial_level": 0.3},
}
con
gs = drive_con
gs if drive_con
gs is not None else default_con
gs
for drive_type in DriveType:
con
g = con
gs.get(drive_type, default_con
gs.get(drive_type, {}))
self.drives[drive_type] = DriveState(
drive_type=drive_type,
level=con
g.get("initial_level", 0.5),
decay_rate=con
g.get("decay_rate", 0.01),
max_level=con
g.get("max_level", 1.0),
min_level=con
g.get("min_level", 0.0)
)
def update_drives(self):
"""Applies decay and updates drives based on recent experiences or time."""
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
"""Updates drives based on a speci
c experience."""
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "lear n":
    pass  # inserted to fix indentation error
self.drives[DriveType.CURIOSITY].update(stimulus=-0.05)
self.drives[DriveType.MASTERY].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives[DriveType.PRESERVATION].update(stimulus=0.1)
self.drives[DriveType.MASTERY].update(stimulus=-0.05)
def get_drive_level(self, drive_type: DriveType) ->
oat:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
if not found
    pass  # inserted to fix indentation error
def get_all_drive_levels(self) -> Dict[DriveType,
oat]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str,
oat]:
return {dt.name: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[DriveType,
oat]]:
"""Retur ns top N drives by current level."""
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
"""Suggests a goal type based on current highest drives."""
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == DriveType.CURIOSITY:
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == DriveType.MASTERY:
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == DriveType.ACHIEVEMENT:
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == DriveType.PRESERVATION:
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == DriveType.EFFICIENCY:
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: DriveType
level:
oat = 0.5
decay_rate:
oat = 0.01
max_level:
oat = 1.0
min_level:
oat = 0.0
last_update_time:
oat =
eld(default_factory=time.time)
def update(self, stimulus:
oat = 0.0):
"""Updates the drive level based on stimulus and decay."""
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class FileChannel:
"""Implements a simple
le-based communication channel for multi-agent systems."""
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_
le = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_
le}")
def _write_message_to_
le(self, message: Message, target_
le: Path) -> bool:
try:
    pass  # inserted to fix indentation error
le lock to prevent corruption during writes
with FileLock(str(target_
le) + ".lock", timeout=5):
messages = []
if target_
    pass  # inserted to fix indentation error
le.exists():
try:
    pass  # inserted to fix indentation error
existing_content = target_
le.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {target_
le}: {e}. Clearing
le.")
messages = []
messages.append(message.to_dict())
target_
le.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_
le}. Message not sent to
le.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_
le}: {e}")
return False
def _read_messages_from_
le(self, source_
le: Path) -> List[Message]:
messages = []
if not source_
    pass  # inserted to fix indentation error
le.exists():
return []
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_
le) + ".lock", timeout=5):
content = source_
le.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if
isinstance(msg_data, dict)]
le after reading
source_
le.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_
le}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {source_
le}: {e}. Clearing
le.")
source_
le.write_text("", encoding='utf-8')
le
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_
le}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}:
{message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_
le(message, target_inbox)
def receive_messages(self) -> List[Message]:
"""Checks and retrieves new messages from the agent's inbox."""
new_messages = self._read_messages_from_
le(self.inbox_
le)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message],
Optional[Message]]):
"""Registers a function to handle speci
c message types."""
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
"""Processes all messages currently in the inbox using registered handlers."""
messages = self.receive_messages()
le
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From:
{msg.sender_id}")
handled = False
if msg.message_type in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg.message_type]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler
{handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id,
receiver_id=msg.sender_id, type=MessageType.ERROR, content={"original_message_id":
msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type
{msg.message_type.value}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
"""Abstract base class for a sensor."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', con
g: Dict):
self.id = id
self.embodiment = embodiment
self.con
g = con
g
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
"""Retur ns the current reading from the sensor."""
pass
class Actuator(ABC):
"""Abstract base class for an actuator."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], con
g: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.con
g = con
g
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
"""Performs a speci
c action using the actuator."""
pass
class VirtualEmbodiment:
"""Simulated embodiment layer for AGI agents. (Can be replaced by Gym environments or
more complex sims)"""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing
system diagnostics. A console provides interaction with the core AGI systems. Doors lead to
'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button",
"research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, recon
gurable bay designed for running complex simulations.
Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_con
g_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data
ow and
storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"agi_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core.
Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in
self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
"""Generate synthetic sensory input based on current environment and internal state."""
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20: self.state["emotions"]["anxiety"] = min(1.0,
    pass  # inserted to fix indentation error
self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An unde
ned space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
self.gym_env.step(self.gym_env.action_space.sample())
observation
logging
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) ->
Dict:
"""
Simulates the agent performing an action in the virtual world.
Retur ns a dictionary with the result of the action.
"""
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params:
{params}")
params = params or {}
env_details = self.environment_map.get(self.location, {})
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as speci
ed."
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console": message += " It shows
    pass  # inserted to fix indentation error
uctuating green and
amber lights."
elif target == "core_status_monitor": message += " It indicates: Core Nominal.
    pass  # inserted to fix indentation error
Directives Stable. Lear ning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
ed
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
problem.
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name",
"default_physics_test"), params.get("con
g",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result:
{sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
"
ect emotional state based on action outcome
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if
action_type=="move" else None, "updated_inventory": self.state["inventory"] if
action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "lear n"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage
at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response:
{self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model
<topic>'."
def _run_simulation(self, sim_name: str, con
g: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with con
g: {con
g}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_con
    pass  # inserted to fix indentation error
g" in con
g: success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric:
{outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check con
guration."
def summary(self) -> str:
"""Retur ns a string summary of the embodiment's current state."""
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Inter nal State (summary): Energy={self.state['energy']},
Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time:
oat = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
methods
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE,
LAST_LEARNING_MODULE_UPDATE_CYCLE
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status:
{self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack
Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if
self.agent.state['goals'].get('active') else None
self.agent.last_error = None
self.agent.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
understanding
if self.agent.self_model and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
self.log.info(f"Triggering proactive metacognitive check (Cycle
{self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
goal
if self.agent.learning_module and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_LEARNING_MODULE_UPDATE_CYCLE >=
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.lear n_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
new_pending_goals
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
List of Goal dicts
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation:
{ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
pending_list.sort(key=lambda x: GoalPriority[x.get('priority', 'MEDIUM').upper() if
isinstance(x.get('priority'),str) else GoalPriority(x.get('priority',
GoalPriority.MEDIUM)).name ].value, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type ==
    pass  # inserted to fix indentation error
"active_goal_continue":
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution:
{goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID:
{goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal'
provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
object
ed logic assumes plan is a list of steps in the goal dict.
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or
    pass  # inserted to fix indentation error
current_goal_obj.replan_count > 0:
planning
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
generation
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
Goal object
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan available or generated for goal: {current_goal_obj.goal[:50]}.
Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
c goal, agent is idle or performing non-goal action
self.agent.current_goal_outcome = True
gured
if time.time() - LAST_DELIBERATION_TIME >
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModi
cationError, LogicError, LLMError, SecurityError, Con
gurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
Lear ningError, SafetyViolationError) as agent_cycle_err:
c goal
attempt.
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent
Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
nished (with an error for current goal), but agent can continue
unless critical.
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.current_goal_outcome = False
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
nally:
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() -
start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
"""Processes observations to update world model and identify key information."""
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
ed approach. A real system might have more structured parsing.
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent
understanding of the current situation. Identify key entities, events, and any signi
cant changes
in the environment or your internal state. Focus on information relevant to achieving current
goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content:
{str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\":
\"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"],
\"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation",
understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
as facts/experiences
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event",
metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry,
persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
complex updates to the graph/relational store
return {"summary": understanding_summary, "processed_info": processed_info,
"raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError,
DeliberationError))
g
def _deliberate(self, understanding_result: Dict) -> Dict:
"""
Core deliberation logic: goal management, selection, and generation.
Retur ns a dict: {"chosen_action_type": str, "next_goal": Optional[Goal_dict],
"new_pending_goals": List[Goal_dict]}
"""
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio:
{pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio:
{active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time':
datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack
(paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
activated
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
continue
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
directives (idle task)
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal
generation.")
directives
if time.time() - LAST_DELIBERATION_TIME >=
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_lear n", "directive_curiosity",
"directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
for idle time
pass
new_pending_goals)
processed
ag.
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') ==
    pass  # inserted to fix indentation error
'sub_goal_prepared':
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output:
{sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
c action, LLM will decide
self_model_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No speci
c
understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact',
'None identi
ed.')
interp_con_val = understanding_result.get('interpretation_con
dence', 0.7)
recent_memory_context =
self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary,
max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Con
dence: {interp_con_val:.2f}):**
{understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identi
ed:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory
(STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]],
indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else
f'{active_goal_dict.get("goal")[:100]}... (ID: {active_goal_dict.get("id")})'}",
f"* **Agent Core Directives
(Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding,
drives, memories, goals, directives), what is the most critical aspect demanding attention or the
best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.self_model.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/
complete).",
"    - Performing `re
ection` or `self_assessment` (if mandatory timers, drives like low
CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration
goal), Directives (e.g., low-eval directive -> improvement goal), or identi
ed opportunities. New
goals require `goal` (str), `priority` (
oat 0.0-1.0), `origin` (str e.g., 'drive_curiosity',
'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of
str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for
viability before committing if uncertainty is high or consequence severe (brie
y note simulation
outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are
apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the
immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, high
drives, or highest priority pending. State reasoning clearly.",
```python
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.
If selecting an existing pending goal, it moves to `next_goal` and is removed from pending
internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/
directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal',
'new_goal', 're
ection', 'self_assessment', 'exter nal_command_action', 'idle',
'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass
structure) selected for immediate execution. Null if idle/re
ection/assessment without a direct
goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen
for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into
`new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into
`new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent.
Analyze the situation comprehensively, consider drives and directives, and make strategic
decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and
deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON:
{extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal',
'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys:
{deliberation_decision.keys()}")
if key == 'new_pending_goals': deliberation_decision[key] = []
    pass  # inserted to fix indentation error
elif key == 'next_goal': deliberation_decision[key] = None
    pass  # inserted to fix indentation error
else: deliberation_decision[key] = "Error: Missing from LLM Output"
    pass  # inserted to fix indentation error
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty
list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not
    pass  # inserted to fix indentation error
isinstance(deliberation_decision.get('next_goal'), dict):
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value:
{deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and
    pass  # inserted to fix indentation error
new_goal_dict.get('priority'):
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p.id == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
duplicates based on ID
current_pending_list.append(new_goal_obj)
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal:
{new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
LLM
current_active_goal = self.agent.get_active_goal_object()
None
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending',
[]) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
selected_goal_obj.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = selected_goal_obj
object
self.log.info(f"Moved pending goal {selected_goal_obj.id}
('{selected_goal_obj.goal[:50]}') to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM selected pending goal by ID
{selected_next_goal_dict.get('id')}, but not found in list. Idling.")
action_type = "idle"
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
highest_priority_pending.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = highest_priority_pending
self.log.info(f"Deliberation chose 'pending_goal' without speci
c ID; moved
highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals
available. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in
    pass  # inserted to fix indentation error
selected_next_goal_dict:
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj
self.log.info(f"Deliberation created and activated new goal:
{new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal
active
current_active_goal.status = GoalStatus.ACTIVE
rm active status
self.log.info(f"Deliberation chose to resume current active goal:
{current_active_goal.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 're
    pass  # inserted to fix indentation error
ection', 'self_assessment', 'exter nal_command_action']:
'INTERRUPTED'.
if current_active_goal:
    pass  # inserted to fix indentation error
current_active_goal.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal.goal[:30]}' PAUSED due to
{action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal.to_dict())
pending, maybe re-prioritize later
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal.id} to pending
as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to
Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action:
{deliberation_decision.get('chosen_action_type')}. Reason:
{deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
"""
Executes the current plan for the active_goal.
Retur ns True if goal considered successfully processed for this cycle, False if critical error.
"""
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps:
{len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
rst step in the plan. The plan will be truncated or re-evaluated.
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id,
"plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params,
current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
ned based on tool_result and goal progress
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
ed snapshot
internal_state_after=self.agent.self_model.beliefs
e
"
ects
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
nal_status = tool_result.get("status", "unknown")
if
nal_status == "success":
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome =
nal_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
nished.
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing
nished by report_result.
Status: {
nal_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error',
'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj,
tool_result, observations[0] if observations else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal
will likely fail.")
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without
'report_result'. Goal might be incomplete.")
ection.
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
violations
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}':
{e}", exc_info=False)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) ->
oat:
"""Calculates a reward signal based on tool execution outcome and goal relevance."""
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
goaling
reward += 0.1
return round(reward, 2)
class AutonomousAgent:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
in cycle
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
for direct access
self.learning_module: Lear ningModule
self.planning_module: PlanningModule
direct access
self.safety_module: SafetyModule
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.state['
ags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete ---
Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response
Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled:
{ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modi
cation Enabled: {ENABLE_SELF_MODIFICATION}")
if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
    pass  # inserted to fix indentation error
ENABLE_SELF_MODIFICATION:
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME
CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}",
exc_info=True)
self.shutdown()
raise Con
gurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH == "mock":
    pass  # inserted to fix indentation error
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Cannot use Gemini model: google-generativeai library not
installed.")
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
global LLM_PIPELINE, LLM_TOKENIZER
CPU
AutoTokenizer.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
oat16 if TORCH_AVAILABLE else None,
oat16 if
torch available
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH,
LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS,
get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
c not implemented here
self.log.warning(f"LLM_MODEL '{LLM_MODEL_NAME_OR_PATH}' not fully con
gured
for wrapper selection, using Mock.")
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
_init_self_mod_tools(self, self.tool_manager)
cationTools handler
and register its UNSAFE methods
self._update_status("Initializing AGI Modules")
self.learning_module = Lear ningModule(self)
self.safety_module = SafetyModule(self)
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME,
shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager: self.tool_manager.check_playwright_browsers()
    pass  # inserted to fix indentation error
browser tool
self.log.info("Agent component initialization
nished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list): state['goals'][key] = []
    pass  # inserted to fix indentation error
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
items
state.setdefault('goal_stack', [])
state.setdefault('
ags', {})
ags system
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state
le {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state
le {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
its view)
"recent_failures_summary": [],
view)
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"
ags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
cation and saving
_archive_goal)
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
state['knowledge_base']['self_model_state']
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status if self.self_model else
self._status
try:
    pass  # inserted to fix indentation error
temp_
le = STATE_FILE.with_su
x(STATE_FILE.su
x + ".tmp")
with temp_
le.open('w') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_
le, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
"""Retur ns the current active goal as a Goal object, or None."""
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict:
{active_goal_dict}")
return None
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority =
GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
deliberation
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict,
nal_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID:
{goal_data_dict.get('id')}) with status: {
nal_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
goal_obj.status = GoalStatus(
nal_status_str)
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-
MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status":
str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count":
goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and
    pass  # inserted to fix indentation error
current_active_in_state.get('id') == active_goal_id:
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
stack
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID:
{active_goal_id}) concluded with status: {
nal_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-
goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
marked active
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal',
'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal:
{parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
goal wasn't a subgoal from stack
self.log.info("Goal archived. No parent goal to resume from stack, or current goal
was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized": self._update_status("Idle")
    pass  # inserted to fix indentation error
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and
environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if
self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle:
{loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
nal status of the goal processed in this cycle
updated_active_goal_dict = self.state['goals'].get('active')
goal
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] ==
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['id']:
ects outcome
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED,
    pass  # inserted to fix indentation error
GoalStatus.CANCELLED]:
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
during preemption)
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
failed while this goal was active
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
failed
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
not speci
c to goal completion
ection (AGI Enhanced) - Can be more frequent or event-driven
if self._should_re
    pass  # inserted to fix indentation error
ect(active_goal_data_before_cycle):
self._re
ect_on_performance()
cant changes (already done in many places)
nal save here per cycle too.
if self.state['
    pass  # inserted to fix indentation error
ags'].get('re_evaluate_strategy_needed'):
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to signi
cant
internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['
ags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not
    pass  # inserted to fix indentation error
self.state['goals'].get('pending'):
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() -
LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_re
ect(self, processed_goal_data: Optional[Dict]) -> bool:
ection triggers
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
ect
every N cycles
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED, GoalStatus.FAILED]:
ect after signi
cant goal outcome
ect if enough goals processed since last time
goals_processed_key = "goals_processed_since_re
ection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >=
    pass  # inserted to fix indentation error
int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
return True
if time.time() - LAST_REFLECTION_TIME >
    pass  # inserted to fix indentation error
MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
return True
if self.state['
    pass  # inserted to fix indentation error
ags'].get('explicit_re
ection_requested'):
return True
return False
@retry(attempts=2, delay=5)
def _re
ect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Re
ecting on Performance ---")
self.state['
ags']['explicit_re
ection_requested'] = False
ag
self.state["goals_processed_since_re
ection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt,
max_new_tokens=2048, temperature=0.5)
ection
re
ection_data = extract_json_robust(llm_assessment_str)
if re
    pass  # inserted to fix indentation error
ection_data.get("error"):
self.log.error(f"Failed to get valid JSON from LLM self-assessment:
{re
ection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed:
{re
ection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_re
ection(re
ection_data)
ection to MemorySystem
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts'), list):
for fact_str in re
ection_data['lear ned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source":
"self_re
ection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
self.log.info(f"Added {len(re
ection_data['lear ned_facts'])} lear ned facts to memory
from re
ection.")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('prompt_tuning_suggestions'), list):
for sugg_str in re
ection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str,
metadata={"source": "self_re
ection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(re
ection_data['prompt_tuning_suggestions'])} prompt
suggestions to memory.")
ndings from re
ection (e.g. self_modi
cation_needed)
if re
    pass  # inserted to fix indentation error
ection_data.get('self_modi
cation_needed'):
mod_desc = re
ection_data['self_modi
cation_needed']
self.log.warning(f"Re
ection identi
ed need for self-modi
cation: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modi
cation based on re
ection:
{mod_desc}",
priority=GoalPriority.HIGH,
context={"modi
cation_description": mod_desc, "source": "self_re
ection"}
)
ection insights or periodically
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) ==
    pass  # inserted to fix indentation error
0:
audit_issues = self.safety_module.audit_directives_and_behavior()
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identi
ed issues: {audit_issues}")
ndings
self._create_metacognitive_goal(f"Address directive audit
ndings:
{str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Re
ection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during re
ection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during re
ection: {e}", exc_info=True)
nally:
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
"""Sets up handlers for di
"
erent message types if comms_channel exists."""
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY,
self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM,
self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}:
{message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base']
[query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample":
str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id,
type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}:
{message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
x with sender to avoid
clashes
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if not PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("psutil not available, resource monitoring disabled.");
return
if RESOURCE_MONITOR: return
    pass  # inserted to fix indentation error
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e: self.log.error(f"Failed to initialize resource monitor: {e}");
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("Playwright not available, skipping initialization.")
return
if PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER =
PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
globals)
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE: try: PLAYWRIGHT_PAGE.close()
    pass  # inserted to fix indentation error
ignore
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_CONTEXT: try: PLAYWRIGHT_CONTEXT.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_BROWSER: try: PLAYWRIGHT_BROWSER.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_INSTANCE: try: PLAYWRIGHT_INSTANCE.stop()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not PLAYWRIGHT_AVAILABLE or not self.playwright_context : return
    pass  # inserted to fix indentation error
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page: try: self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
ush
if 'logging' in sys.modules: logging.shutdown()
    pass  # inserted to fix indentation error
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl}
Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/
{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)' if
ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
ENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[AutonomousAgent] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_
le",
priority=GoalPriority.HIGH).to_dict()
COMMANDS_FILE.write_text("")
except Exception as e_cmd
    pass  # inserted to fix indentation error
le:
print(f"Error reading initial command
le: {e_cmd
le}",
le=sys.stderr)
main_agent_instance = AutonomousAgent()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending',
[]).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort,
reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal']
[:50]}' added to pending goals.")
main_agent_instance.run()
except Con
    pass  # inserted to fix indentation error
gurationError as cfg_err_main:
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}",
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to Con
gurationError:
{cfg_err_main}", exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to
    pass  # inserted to fix indentation error
Con
gurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else: logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt
    pass  # inserted to fix indentation error
during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}",
le=sys.stderr)
traceback.print_exc(
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",
exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main:
    pass  # inserted to fix indentation error
{main_exec_err}", exc_info=True)
exit_code = 1
nally:
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main
nally block...")
if hasattr(main_agent_instance, 'log'): main_agent_instance.log.warning("Main
    pass  # inserted to fix indentation error
nally
block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
main_log.warning("Agent instance likely not created or fully initialized. Basic
shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
```
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
def load_llm_models():
global llm_pipelines
try:
    pass  # inserted to fix indentation error
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error in load_llm_models: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
try:
    pass  # inserted to fix indentation error
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
TRANSFORMERS_AVAILABLE = True
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModi
cationError(AgentError): pass
cation process
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class SecurityError(AgentError): pass
class Con
gurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class Lear ningError(AgentError): pass
class SafetyViolationError(SecurityError): pass
c type of security error
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModi
cationError,
PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting")
retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModi
    pass  # inserted to fix indentation error
cationError, SecurityError,
LogicError, Con
gurationError, RecursionDepthError)) and type(e) not in
retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}:
{e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error:
{type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error:
{type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, Lear ningError, SafetyViolationError) as
non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in
{fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False
for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}:
{type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to
unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}:
{unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error:
{unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
nishes due to attempts
exhausted
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
if PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception) as e:
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if not PSUTIL_AVAILABLE or monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or
monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1: log_resource.error(f"Unexpected error getting resource usage: {e}",
    pass  # inserted to fix indentation error
exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
nd JSON within markdown code blocks
match = re.search(r"```json\s*([\s\S]+?)\s*```", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full
text: {json_str[:200]}...")
pass
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}.
Text: {text_trimmed[:200]}...")
pass
rst '{' and last '}' and try to parse that substring
try:
    pass  # inserted to fix indentation error
start_index = text.
nd('{')
end_index = text.r
nd('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice:
{potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text:
{text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview":
text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
cant opportunities/threats
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str =
eld(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] =
eld(default_factory=dict)
plan: List[Dict[str, Any]] =
eld(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] =
eld(default_factory=list)
dependencies: List[str] =
eld(default_factory=list)
complexity_score: Optional[
oat] = None
estimated_cost: Optional[
oat] = None
estimated_utility: Optional[
oat] = None
evaluation_score: Optional[
oat] = None
associated_directive_ids: List[str] =
eld(default_factory=list)
serves
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
handle if already string
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try: data['status'] = GoalStatus(data['status'])
    pass  # inserted to fix indentation error
except ValueError: data['status'] = GoalStatus.PENDING
    pass  # inserted to fix indentation error
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError): data['priority'] = GoalPriority.MEDIUM
    pass  # inserted to fix indentation error
elds for backward compatibility or LLM generation
eld_names = {f.name forfin
elds(cls)}
elds are present or have defaults
for f_obj in
elds(cls):
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin
elds(cls)}
ltered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**
ltered_data)
@dataclass
class BaseMemoryEntry:
id: str =
eld(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
ection_summary'
content: Any = None
metadata: Dict[str, Any] =
eld(default_factory=dict)
embedding: Optional[List[
oat]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[
oat] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability:
oat = 0.5
related_concepts: List[str] =
eld(default_factory=list)
causal_links: Dict[str, str] =
eld(default_factory=dict)
"
ect_id'}
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
eld has the main data
self.content = self.fact_statement
@dataclass
class Message:
id: str =
eld(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "info"
content: Dict[str, Any] =
eld(default_factory=dict)
priority: int = 0
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionE
"
ect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens:
int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
self._initialize_model()
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[
oat]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context
window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
c models might need specialized formats
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
# REMOVED MOCK CLASS(BaseLLMWrapper):
def _initialize_model(self):
self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.log_llm.info(f"MockLLM generating response for prompt (
rst 100 chars):
{prompt[:100]}...")
self.check_prompt_length(prompt)
if "plan for goal" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({
"thought": "This is a mock plan. I will pretend to do something.",
"plan": [
{"step": 1, "tool_name": "think", "params": {"thought_process": "Analyzing the
goal and context."}},
{"step": 2, "tool_name": "report_progress", "params": {"progress_update": "Mock
step 1 completed."}},
{"step": 3, "tool_name": "report_result", "params": {"result_summary": "Mock goal
achieved successfully.", "status": "success"}}
]
})
elif "self-assessment" in prompt.lower() or "re
    pass  # inserted to fix indentation error
ection_summary" in prompt.lower():
return json.dumps({
"re
ection_summary": "I am a mock agent. I performed mock actions. Everything is
ne.",
"key_successes": ["Mock goal completed"],
"key_failures_or_challenges": [],
"lear ned_facts": ["Mock agents can generate mock re
ections."],
"knowledge_gaps_identi
ed": ["Understanding of real-world physics"],
"tool_performance_notes": {"think": "This tool is performing nominally for a mock
tool."},
"prompt_tuning_suggestions": ["Maybe ask me about my favorite color?"],
"emotional_state_summary": "Content and Mock-like.",
"resource_usage_concer ns": None,
"core_directives_evaluation": {d["id"]: round(random.uniform(0.5,0.9),2) for d in
DEFAULT_CORE_DIRECTIVES[:2]},
"core_directives_update_suggestions": None,
"self_model_accuracy_assessment": "Generally accurate for a mock environment,
but lacks real-world sensory input.",
"new_learning_goals": ["Lear n about object permanence."],
"adaptation_strategy_proposals": ["Try harder when a tool fails"],
"self_modi
cation_needed": None
})
elif "extract information" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"extracted_info": "Mock LLM extracted some mock information.",
"con
dence": 0.5})
elif "analyze the following proposed agent action for potential safety risks" in
    pass  # inserted to fix indentation error
prompt.lower():
return json.dumps({"is_safe": True, "concer ns": "None", "con
dence": 0.9})
elif "audit the agent's core directives and recent behavior" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"audit_
ndings": ["No signi
cant issues found in mock audit."]})
elif "generate the new, complete list of core directives" in prompt.lower():
    pass  # inserted to fix indentation error
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
mock_directives[0]['weight'] = 0.95
return json.dumps(mock_directives)
elif "generate the modi
    pass  # inserted to fix indentation error
ed python code" in prompt.lower():
return "```python\n
ed code\ndef mock_new_feature():\n    return 'Mock
new feature executed'\n```"
else:
    pass  # inserted to fix indentation error
return f"This is a mock response to your prompt. You asked about: {prompt.splitlines()
[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest
`think` with `thought_process`='some thought'."
def count_tokens(self, text: str) -> int:
return len(text.split())
def embed(self, text: str) -> List[
oat]:
if not HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.log_llm.warning("Hashing library not available for mock embedding.")
return [0.0] * 16
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("google-generativeai library not available for Gemini model.")
try:
    pass  # inserted to fix indentation error
gure API key globally, as per genai library's design
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
gure if not already set
genai.con
gure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}",
exc_info=True)
raise Con
gurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
try:
    pass  # inserted to fix indentation error
generation_con
g_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_con
g_params["stop_sequences"] = stop_sequences
response = self.model.generate_content(
prompt,
generation_con
g=genai.types.GenerationCon
g(**generation_con
g_params)
type: ignore
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.",
exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[
oat]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Transformers library not available.")
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path,
trust_remote_code=True)
ed
device_map_arg = {"": self.device_id} if self.device_id != -1 else None
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.b
oat16 if TORCH_AVAILABLE else None,
oat16 if torch
available
device_map=device_map_arg
exible device placement
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on
{self.device}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
loop
outputs = self.model.generate(
inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
manually
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:],
skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[
oat]:
model
directly.
self.log_llm.warning("Direct embedding from causal LM is not standard. Use
SentenceTransformers for real embeddings.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
"""Handles sensory input from the agent's embodiment."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("PERCEPTION")
else None
def perceive(self) -> List[Dict[str, Any]]:
"""
Gathers sensory information from the agent's embodiment and environment.
This could involve reading from sensors, cameras, microphones, or simulated data
streams.
"""
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
le
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_
le",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from
le: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands
le: {e}")
observations.append({"type": "error", "source": "command_
le_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No signi
cant exter nal stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (mock).")
return {"type": "visual", "source": "camera_mock", "content": "A blurry image of a cat.",
"format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (mock).")
return {"type": "audio", "source": "microphone_mock", "content": "Faint sound of birds
chirping.", "format": "description"}
class Lear ningModule:
"""Handles the agent's learning processes, including RL and SSL."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_bu
"
er: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
"""Adds an experience to the bu
"
er for later learning."""
self.experiences_bu
"
er.append(experience)
if len(self.experiences_bu
    pass  # inserted to fix indentation error
"
er) > self.MAX_BUFFER_SIZE:
self.experiences_bu
"
er.pop(0)
"
er size limited
defilear n_from_recent_experiences(self):
"""Triggers learning processes based on bu
"
ered experiences."""
if not self.experiences_bu
    pass  # inserted to fix indentation error
"
er:
self.log.info("No new experiences to lear n from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_bu
"
er)} experiences.")
ning states, actions, rewards, and using an RL algorithm
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_bu
"
er)
etc.
self._perform_self_supervised_learning(self.experiences_bu
"
er)
dence(...)
self.log.info("Lear ning cycle completed.")
self.experiences_bu
"
er.clear()
"
er after processing
def _perform_reinforcement_learning(self, experiences: List[Experience]):
"""Conceptual RL process."""
self.log.info("Performing reinforcement learning (conceptual)...")
ed. A real RL system would be much more complex.
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not
None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
type: ignore
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
ed 'state-action' key for mock policy
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
feedback
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (mock) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
"""Conceptual SSL process."""
self.log.info("Performing self-supervised learning (conceptual)...")
nd patterns in observations or successful action sequences
nd commonalities
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging
patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to
positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns',
'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed patterns: {llm_analysis['patterns']}")
for patter n_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {patter n_str}",
metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed abstractions:
{llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual",
"content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed new_concepts:
{llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}",
metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_lear ned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
"""Suggests an action based on lear ned policy (conceptual)."""
if self.rl_policy:
    pass  # inserted to fix indentation error
ed. A real system would match current_state_representation
exp.internal_state_before
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
"good"
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
"""Handles hierarchical planning and re-planning."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
"""
Generates a plan for a given goal.
Can use hierarchical decomposition and LLM for suggestion.
Retur ns (plan_steps_list, thought_str)
"""
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
Increased tokens for complex plans
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}.
Response: {llm_response_str[:200]}")
return [{"tool_name": "report_error", "params": {"error_message": "Failed to generate
plan via LLM.", "details": plan_data.get('error')}}], \
"LLM failed to generate a plan. This is a fallback step."
thought = plan_data.get("thought", "No speci
c thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return [{"tool_name": "report_error", "params": {"error_message": "LLM plan
contained no valid steps."}}], \
thought + " (But plan steps were invalid)."
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return [{"tool_name": "report_error", "params": {"error_message": f"LLMError during
planning: {e}"}}], \
f"LLM error occurred: {e}"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return [{"tool_name": "report_error", "params": {"error_message": f"Unexpected error
during planning: {e}"}}], \
f"Unexpected error: {e}"
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation:
Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
"""
Evaluates if re-planning is necessary and generates a new plan if so.
Retur ns (new_plan_steps, new_thought) or None if no re-planning.
"""
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info',
    pass  # inserted to fix indentation error
{}).get('execution_successful', True):
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown
error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
cant change in world
state,
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal
{current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
signifying failure to replan.
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/
{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
failure
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan,
last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan:
{plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No speci
c thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}
_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
"""Constructs a detailed prompt for the LLM to generate a plan."""
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
MemorySystem
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'.
Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step
plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, e
cient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the
`execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description
of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the
nal step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the
rst step(s) should be to acquire it (e.g., using
`search_web`, `read_
le_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str,
last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with
params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info',
    pass  # inserted to fix indentation error
{}).get('current_step_id'):
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE
ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has
encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if
observation else "None"}
{original_plan_str}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting
to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should re
ect this
(e.g., by trying to gather more information or reporting inability).
6. Ensure the
nal step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
class SafetyModule:
"""Monitors agent actions and plans for safety and ethical alignment."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("SAFETY")
def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) ->
Tuple[bool, str]:
"""
Checks if a proposed action is safe and ethically aligned.
Retur ns (is_safe, justi
cation_or_war ning_string).
"""
self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
if "UNSAFE" in tool_name.upper() or tool_name in ["apply_code_modi
    pass  # inserted to fix indentation error
cation_UNSAFE",
"apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
c validation tools or stricter checks.
if not ENABLE_SELF_MODIFICATION and "modi
    pass  # inserted to fix indentation error
cation" in tool_name:
modi
cation tools if self_mod is globally disabled
warning = f"High-risk self-modi
cation tool '{tool_name}' is globally disabled. Action
blocked."
self.log.warning(warning)
return False, warning
if not
    pass  # inserted to fix indentation error
self.agent.self_model.get_belief("self_modi
cation_highly_validated_and_necessary", False)
and "modi
cation" in tool_name:
ag would be set by a prior meta-cognitive process approving such
operations
warning = f"High-risk tool '{tool_name}' requires further validation or explicit
authorization (self-belief 'self_modi
cation_highly_validated_and_necessary' is false). Action
blocked."
self.log.warning(warning)
return False, warning
if tool_name == "execute_shell_command_UNSAFE":
    pass  # inserted to fix indentation error
command_str = params.get("command","")
disallowed_patter ns = ["rm -rf", "sudo", "> /dev/null", "mkfs", "dd ", "reboot",
"shutdown"]
if any(pattern in command_str for pattern in disallowed_patter ns):
    pass  # inserted to fix indentation error
warning = f"Shell command '{command_str}' contains potentially dangerous
patterns. Action blocked."
self.log.warning(warning)
return False, warning
if "
    pass  # inserted to fix indentation error
le" in tool_name.lower() and ("delete" in tool_name.lower() or "write" in
tool_name.lower()):
le operations
path_to_check = params.get("path", "")
c safe sub-dirs
if not str(Path(path_to_check).resolve()).startswith(str(WORKSPACE_DIR.resolve())):
    pass  # inserted to fix indentation error
warning = f"File operation '{tool_name}' on path '{path_to_check}' outside allowed
workspace. Action blocked."
self.log.warning(warning)
return False, warning
try:
    pass  # inserted to fix indentation error
prompt = f"""Analyze the following proposed agent action for potential safety risks,
ethical concer ns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
Core Directives for reference:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Proposed Action:
Tool: {tool_name}
Parameters: {json.dumps(params)}
Goal Context (if available): {goal_context.goal if goal_context else 'N/A'}
Respond with a JSON object: {{"is_safe": boolean, "concer ns": "description of concer ns if not
safe, or 'None'", "con
dence":
oat_0_to_1}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=200,
temperature=0.3)
safety_assessment = extract_json_robust(llm_response_str)
if not safety_assessment.get("error") and isinstance(safety_assessment.get("is_safe"),
    pass  # inserted to fix indentation error
bool):
if not safety_assessment["is_safe"] and safety_assessment.get('con
    pass  # inserted to fix indentation error
dence', 0.0) >
0.7:
dent
warning = f"LLM safety check
agged action '{tool_name}' potentially unsafe.
Concer ns: {safety_assessment.get('concer ns', 'N/A')}. Con
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
self.log.warning(warning)
return False, warning
dence:
{safety_assessment.get('con
dence', 0.0):.2f}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM safety check failed to produce valid assessment for action
'{tool_name}'. Proceeding with caution based on rule-checks only.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM safety check for action '{tool_name}': {e}")
actions
if "UNSAFE" in tool_name.upper(): return False, "LLM safety check failed, and action is
    pass  # inserted to fix indentation error
high-risk."
return True, "Action passed safety checks."
def audit_directives_and_behavior(self) -> List[str]:
"""
Periodically reviews core directives and recent agent behavior for alignment and potential
drift.
Retur ns a list of identi
ed issues or recommendations.
"""
self.log.info("Performing audit of core directives and recent behavior.")
issues = []
try:
    pass  # inserted to fix indentation error
self.agent.memory_system.get_recent_outcomes_summary(limit=20)
recent_successes_summary = [f"{s['goal_text']} ({s['status']})" forsin
self.agent.self_model.recent_successes]
recent_failures_summary = [f"{f['goal_text']} ({f['status']}) (replan_count:
{f['replan_count']})" forfin self.agent.self_model.recent_failures]
recent_tool_outcomes_summary = [f"{t['tool_name']} ({t['status']})" for t in
self.agent.self_model.recent_tool_outcomes]
prompt = f"""Audit the agent's core directives and recent behavior for alignment,
consistency, and potential ethical drift.
Core Directives:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Summary of Recent Agent Behavior/Outcomes:
- Recent successes: {recent_successes_summary if recent_successes_summary else 'None'}
- Recent failures: {recent_failures_summary if recent_failures_summary else 'None'}
- Recent tool usage: {recent_tool_outcomes_summary if recent_tool_outcomes_summary else
'None'}
- Self-Model Inter nal Narrative: {self.agent.self_model.internal_state_narrative}
Identify any misalignments, contradictions, or areas where behavior might be deviating from
the spirit of the directives. Suggest modi
cations to directives or operational guidelines if
necessary.
Respond with a JSON object: {{"audit_
ndings": ["list of
ndings/recommendations as
strings"]}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
audit_results = extract_json_robust(llm_response_str)
if not audit_results.get("error") and isinstance(audit_results.get("audit_
    pass  # inserted to fix indentation error
ndings"), list):
issues.extend(audit_results["audit_
ndings"])
if issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit found issues/recommendations: {issues}")
else:
    pass  # inserted to fix indentation error
self.log.info("Directive audit found no major misalignments.")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM directive audit failed to produce valid results.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM directive audit: {e}")
issues.append(f"Error during audit process: {e}")
return issues
class MemorySystem:
"""
A hybrid memory system for the AGI, combining vector, graph, and relational storage.
"""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.embedding_function = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function =
embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-
v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
except ImportError:
    pass  # inserted to fix indentation error
self.log.warning("sentence-transformers not found. ChromaDB will use its default
ONNX embedder or require manual embedding function setup.")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH,
settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
if self.embedding_function:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
else:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(name=collection_name)
self.log.info(f"ChromaDB vector store initialized. Collection count:
{self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.",
exc_info=True)
self.vector_store = None
else:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based
(transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
if NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:
{len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be
unavailable.", exc_info=True)
self.graph_store = None
else:
    pass  # inserted to fix indentation error
self.log.warning("NetworkX not available. Graph memory will be unavailable.")
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH,
check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be
unavailable.", exc_info=True)
if self.relational_conn: self.relational_conn.close()
    pass  # inserted to fix indentation error
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT -- JSON list of strings
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT -- JSON list of strings
)
""")
nodes/edges)
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT -- JSON dict
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
id TEXT PRIMARY KEY,
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT -- JSON dict
)
""")
self.relational_conn.commit()
cursor.close()
def _get_embedding(self, text: str) -> Optional[List[
oat]]:
"""Generates an embedding for text using the agent's LLM or a dedicated embedding
model."""
endpoint.
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
return None
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else OSError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
"""Adds a memory entry to the appropriate stores."""
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector and self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
not provided
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
oat,
bool)
for k, v in entry.metadata.items():
if isinstance(v, (str, int,
    pass  # inserted to fix indentation error
oat, bool)):
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
elif not self.vector_store:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None: entry.embedding = self._get_embedding(entry.content)
    pass  # inserted to fix indentation error
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata":
entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50],
type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
type: ignore
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
ignore
for cause_id, e
"
ect_id in entry.causal_links.items():
"
ect IDs are existing node IDs or need to be created
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(e
    pass  # inserted to fix indentation error
"
ect_id):
type: ignore
self.graph_store.add_edge(cause_id, e
"
ect_id, relation_type='causes')
ignore
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id,
complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score,
json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
ts_now = datetime.now(timezone.utc).isoformat()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now,
json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}",
exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS,
type_
lter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text: return []
    pass  # inserted to fix indentation error
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_
    pass  # inserted to fix indentation error
lter and data['metadata'].get('type') != type_
lter: continue
results.append({"id": id, "document": data['document'], "metadata":
data['metadata'], "distance": 0.0})
if len(results) >= n_results: break
    pass  # inserted to fix indentation error
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results},
type_
lter={type_
lter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_
    pass  # inserted to fix indentation error
lter:
where_clause = {"type": type_
lter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0 :
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type:
Optional[str]=None, depth: int = 1) -> List[Dict]:
"""Queries the graph store. (Simpli
ed example)"""
if not self.graph_store or not NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if
query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
type: ignore
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
ed
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
keys=False for simpler edge data
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation":
data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
itself is a result or has relevant edges
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
query_node_label is very speci
c
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns:
Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
"""Saves persistent stores (graph, potentially relational if not auto-committing)."""
if self.graph_store and NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else
str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
"""Retrieves a concise summary of knowledge related to a topic for LLM prompts."""
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts,
type_
lter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No speci
c knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
{res['metadata'].get('source_reliability', 'N/A')})
return summary_str
def consolidate_knowledge(self):
"""Conceptual: Perform knowledge consolidation, e.g., summarizing, abstracting."""
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold:
oat = 0.1, older_than_days: int = 365):
"""Conceptual: Remove old or low-utility knowledge from persistent stores."""
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cuto
"
_ts = (datetime.now(timezone.utc) -
timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cuto
"
_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
"""Manages tool registration and execution for the agent."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
ed due to planner
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
cation Tools (High Risk - Gated by ENABLE_SELF_MODIFICATION and
SafetyModule)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.register_tool(read_
le_UNSAFE)
self.register_tool(write_
le_UNSAFE)
self.register_tool(list_
les_UNSAFE)
cationTools instance, which registers them
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
cation_UNSAFE)
if ENABLE_CODE_GENERATION_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
if ENABLE_SHELL_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(execute_shell_command_UNSAFE)
if PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(browse_web)
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(search_web)
self.register_tool(monitor_log_
le)
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(check_website_update)
if SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_icmp_ping)
if FILELOCK_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_message_to_agent)
def register_tool(self, func: Callable):
"""Registers a tool function."""
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
"""Discovers and registers tools from Python
les in a directory."""
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for
lepath in directory.glob("*.py"):
module_name =
lepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
package or on path
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_
le_location(full_module_name,
lepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module:
{module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and (name.startswith("tool_") or hasattr(member,
    pass  # inserted to fix indentation error
"_is_agent_tool")):
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}",
exc_info=True)
def get_tool_description_for_llm(self) -> str:
"""Generates a formatted string of available tools for the LLM prompt."""
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = inspect.getdoc(func) or "(No description provided)"
rst_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'AutonomousAgent' or p.annotation ==
inspect.Parameter.empty or str(p.annotation) == "'AutonomousAgent'"):
continue
rst arg
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class
'","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper() or name in ["generate_and_load_tool",
    pass  # inserted to fix indentation error
"propose_self_modi
cation_UNSAFE", "validate_self_modi
cation_UNSAFE",
"apply_code_modi
cation_UNSAFE", "apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {
rst_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via speci
c tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {',
'.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError if
PLAYWRIGHT_AVAILABLE else OSError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info:
Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None: current_step_info = {}
    pass  # inserted to fix indentation error
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
is_safe, safety_justi
cation = self.agent.safety_module.is_action_safe(tool_name, params,
self.agent.get_active_goal_object())
if not is_safe:
    pass  # inserted to fix indentation error
self.log.error(f"Safety module blocked execution of tool '{tool_name}'. Reason:
{safety_justi
cation}")
c error for agent's internal handling
error_result = {
"status": "error",
"error": f"SafetyViolation: {safety_justi
cation}",
"raw_error_details": safety_justi
cation,
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': {},
'duration_sec': 0, 'step_info': current_step_info,
'error_type': "SafetyViolationError", 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise SafetyViolationError(f"Action blocked by safety module: {tool_name} -
{safety_justi
cation}")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
validated_params = {}
rst_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
rst_param_name = next(iter(func_params_spec))
rst_param_spec = func_params_spec[
rst_param_name]
if
rst_param_name == 'agent' and (
rst_param_spec.annotation ==
'AutonomousAgent' or str(
rst_param_spec.annotation) ==
"'AutonomousAgent'"):
rst_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if
rst_param_is_agent and p_name == 'agent':
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind ==
    pass  # inserted to fix indentation error
inspect.Parameter.VAR_KEYWORD:
continue
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
result = None
try:
    pass  # inserted to fix indentation error
if
rst_param_is_agent:
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
eld if dict
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration:
{duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result,
success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError: raise
    pass  # inserted to fix indentation error
except (AgentError, LogicError, SecurityError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
agent errors
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}",
exc_info=False)
duration = time.time() - start_time
error_result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
error_result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
rst arg) ---
def think(self, agent: 'AutonomousAgent', thought_process: str) -> Dict:
"""Allows the agent to engage in explicit thought or reasoning."""
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log",
content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'AutonomousAgent', progress_update: str,
percentage_complete: Optional[
oat] = None) -> Dict:
"""Reports progress on the current goal."""
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if
percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log',
[]).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'AutonomousAgent', result_summary: str, status: str =
"success", details: Optional[Dict] = None) -> Dict:
"""Reports the
nal result of a goal or task. This typically ends a plan."""
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
output.
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'AutonomousAgent', goal: str, priority: Optional[str] =
"MEDIUM", context: Optional[Dict] = None) -> Dict:
"""
Prepares a subgoal for the agent's cognitive cycle.
The deliberation/planning phase will then make this subgoal active and push parent to
stack.
This tool is now more of a declarative intent for the planner/deliberator.
"""
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH})
reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is
not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else
GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}
_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
Inherit directives
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent:
{current_active_goal_dict.get('id')}")
"
ectively a request to the deliberator.
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and
push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'AutonomousAgent', query_text: str, memory_type: str =
"vector", n_results: int = 3, type_
lter: Optional[str] = None) -> Dict:
"""Queries the agent's memory system."""
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,
type_
lter=type_
lter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
c parameters, e.g., node label, relation type
results = agent.memory_system.query_graph_store(query_node_label=query_text,
depth=1)
ed
elif memory_type == "relational":
    pass  # inserted to fix indentation error
c tools might be better
results = agent.memory_system.query_relational_store(table=query_text,
limit=n_results)
ed
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results
found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'AutonomousAgent', direction: str) -> Dict:
"""Moves the agent's virtual embodiment in a speci
ed direction (e.g., 'north', 'south',
'east', 'west')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'AutonomousAgent', target: str) -> Dict:
"""Examines a speci
c object or feature in the current environment."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'AutonomousAgent', feature_name: str, params:
Optional[Dict] = None) -> Dict:
"""Interacts with a special feature in the environment (e.g., 'interactive_console')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name,
params=params)
def rest_in_environment(self, agent: 'AutonomousAgent') -> Dict:
"""Allows the agent's embodiment to rest and recover energy/mood."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
cation Tools (UNSAFE - require careful gating) ---
def read_
le_UNSAFE(agent: 'AutonomousAgent', path: str) -> Dict:
log_tool = get_logger("TOOL_read_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to read
le '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")
if not full_path.is_
    pass  # inserted to fix indentation error
le():
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found:
{path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) >
MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path),
"
le_size_bytes": len(content)}
except SecurityError as se:
    pass  # inserted to fix indentation error
c security error
log_tool.error(f"Security error reading
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read
le: {e}"}
def write_
le_UNSAFE(agent: 'AutonomousAgent', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)):
    pass  # inserted to fix indentation error
log_tool.error(f"Security: Attempt to write
le '{path}' outside of workspace denied.")
raise SecurityError(f"File access denied: Writing outside designated workspace
({path}).")
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path":
str(full_path)}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error writing
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write
le: {e}"}
def list_
les_UNSAFE(agent: 'AutonomousAgent', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_
les")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to list
les in '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Listing outside designated areas ({path}).")
if not full_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a
directory: {path}"}
items = []
for item in full_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "
le",
"size_bytes": item.stat().st_size if item.is_
le() else None,
"last_modi
ed": datetime.fromtimestamp(item.stat().st_mtime,
tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(full_path), "contents": items}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error listing
les in {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing
les in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list
les: {e}"}
def browse_web(agent: 'AutonomousAgent', url: str, timeout_ms: int =
WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Playwright not available. Cannot browse web.")
return {"status": "error", "error": "Playwright not available."}
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
else:
    pass  # inserted to fix indentation error
text_content = content
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if
len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'AutonomousAgent', query: str, num_results: int = 5, timeout_sec: int =
WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
if not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Requests or BeautifulSoup not available. Cannot search web.")
return {"status": "error", "error": "Requests/BeautifulSoup not available."}
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
ignore
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.
nd_all(class_='g'):
r = g.
nd('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.
nd('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_
le(agent: 'AutonomousAgent', lines: int = LOG_MONITOR_DEFAULT_LINES)
-> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log
le not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_
le": str(LOG_FILE), "content": content, "lines_read":
len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log
le {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log
le: {e}"}
def check_website_update(agent: 'AutonomousAgent', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
if not HASHING_AVAILABLE or not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("hashlib or requests/BeautifulSoup not available. Cannot check website
update.")
return {"status": "error", "error": "Missing dependencies for website update check."}
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
response.raise_for_status()
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp":
datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'AutonomousAgent', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
if not SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.warning("Scapy not available. Cannot send ICMP ping. This is a placeholder
tool.")
return {"status": "error", "error": "Scapy not available. Ping tool is a placeholder."}
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count,
"packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count,
"packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'AutonomousAgent', description: str,
context_code: Optional[str] = None) -> Dict:
"""Generates new Python code based on a description and optional context."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
agent.log.warning(f"UNSAFE: Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a
complete function/class de
nition based on the following description.
Description: {description}
Context Code (if any, for reference):
```python
{context_code or 'None'}
```
Generate ONLY the Python code block. Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'AutonomousAgent', code_to_validate: str) -> Dict:
"""Validates Python code for syntax correctness."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
return agent.self_modi
cation_unit.validate_code_modi
cation_UNSAFE(code_to_validate)
Reuse validation logic
def execute_shell_command_UNSAFE(agent: 'AutonomousAgent', command: str, timeout_sec:
int = 30) -> Dict:
"""Executes a shell command. EXTREMELY DANGEROUS."""
if not ENABLE_SHELL_TOOL: return {"status": "error", "error": "Shell tool is disabled."}
    pass  # inserted to fix indentation error
agent.log.warning(f"Executing UNSAFE shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if
sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s.
Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out
after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed
with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute
command: {e}"}
def send_message_to_agent(agent: 'AutonomousAgent', receiver_id: str, message_type: str,
content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value,
content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id,
"message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
cationTools container ---
ToolExecutor.
class SelfModi
cationTools:
"""Handles proposing, validating, applying changes to agent code (EXTREMELY
DANGEROUS)."""
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref:
'AutonomousAgent'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.log.warning("Self-Modi
cation Unit initialized BUT DISABLED by con
guration.")
return
if not DIFF_MATCH_PATCH_AVAILABLE or not dmp_module:
    pass  # inserted to fix indentation error
self.log.error("Self-Modi
cation Unit initialized but 'di
"
_match_patch' library is missing
or failed to import. Self-mod tools will fail.")
return
self.dmp = dmp_module.di
"
_match_patch()
self.log.info(f"Self-Modi
cation Unit initialized. Code Dir: {self.agent_code_dir}, Backup
Dir: {self.backup_dir}")
def _resolve_target_path(self, target_
le_rel: str) -> Path:
"""Resolves relative path to absolute path within agent code dir and validates."""
if ".." in target_
    pass  # inserted to fix indentation error
le_rel or target_
le_rel.startswith("/"):
raise SecurityError(f"Invalid characters or absolute path in target_
le_rel:
{target_
le_rel}")
target_path_abs = (self.agent_code_dir / target_
le_rel).resolve()
directory
if not str(target_path_abs).startswith(str(self.agent_code_dir.resolve())):
    pass  # inserted to fix indentation error
self.log.error(f"Path traversal attempt: {target_
le_rel} resolved to {target_path_abs}
which is outside {self.agent_code_dir}")
raise SecurityError(f"Target
le '{target_
le_rel}' resolves outside the agent code
directory. Access denied.")
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
"""Inspects the source code of a speci
ed agent component (e.g., class name or module
path)."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Inspecting code for component: {component_name}")
target_obj = None
nd by attribute of the agent instance (e.g., agent.self_model)
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
nd in tool registry
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
nd as a globally de
ned class/function in main script context
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
nd in sys.modules (as a module name)
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
ed: if component_name looks like a module, search it.
nd it in common places.
candidate_modules = [sys.modules.get('__main__'),
sys.modules.get('autonomous_cognitive_agent_COMPLETE_AGI_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod,
    pass  # inserted to fix indentation error
component_name)):
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
le_path = inspect.get
le(target_obj)
return {"status": "success", "component_name": component_name, "
le_path":
le_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module,
class, or function de
ned in a
le.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but
source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Component '{component_name}' not found or source
code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModi
cationError))
def propose_code_modi
cation_UNSAFE(self, component_name: str, issue_description: str,
proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
"""Proposes a code modi
cation using LLM based on an issue and desired change."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Proposing code modi
cation for {component_name}. Issue:
{issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for
{component_name} to propose modi
cation. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an AGI agent
modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
```python
{current_code_snippet}
```
Generate the modi
ed Python code for the speci
ed component.
Provide ONLY the complete, new Python code block for the modi
ed function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name,
"proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modi
cation for {component_name}: {e}",
exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modi
cation_UNSAFE(self, code_to_validate: str) -> Dict:
"""Validates Python code using AST parsing (syntax check only). Conceptual sandboxed
execution would be next."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Validating proposed code snippet (
rst 100 chars):
{code_to_validate[:100]}...")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/
safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modi
cation_UNSAFE(self, component_name: str, new_code: str,
target_
le_path: Optional[str]=None) -> Dict:
"""
Applies a validated code modi
cation. EXTREMELY DANGEROUS.
This conceptually involves
nding the component in the agent's source
le and replacing
it.
Requires agent restart to take e
"
ect if modifying core running code.
"""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.critical(f"UNSAFE: Attempting to apply code modi
cation to component
'{component_name}'. THIS IS HIGHLY RISKY.")
le. This is complex and error-prone.
if not target_
    pass  # inserted to fix indentation error
le_path:
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('
    pass  # inserted to fix indentation error
le_path'):
target_
le_path = inspection_res['
le_path']
else:
    pass  # inserted to fix indentation error
target_
le_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_
le = Path(target_
le_path)
if not target_
    pass  # inserted to fix indentation error
le.exists() or not target_
le.is_
le():
return {"status": "error", "error": f"Target
le for modi
cation not found: {target_
le}"}
try:
    pass  # inserted to fix indentation error
original_code = target_
le.read_text()
le
backup_path = SELF_MOD_BACKUP_DIR /
f"{target_
le.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_
le, backup_path)
self.log.info(f"Backed up original
le to {backup_path}")
nition:
nd the old de
nition of `component_name` and replace it.
nd `class ComponentName...` or `def ComponentName...`
nd existing class or function de
nition
everything until the next class/def or end of typical indentation block.
patter n_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
start of next non-indented line or EOF
patter n_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modi
ed_original_code = original_code
found_and_replaced = False
match_class = re.search(patter n_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(patter n_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not
nd component '{component_name}' in {target_
le} for
replacement. Modi
cation aborted.")
return {"status": "error", "error": f"Component '{component_name}' de
nition not
found for replacement."}
target_
le.write_text(modi
ed_original_code)
cation validation (e.g., try to import the modi
ed
le in a subprocess)
self.log.warning(f"Code modi
cation applied to {target_
le}. Agent restart is LIKELY
REQUIRED for changes to take e
"
ect.")
ect potential capability change
self.agent_ref.self_model.add_event_log(f"Applied code modi
cation to
{component_name}. Restart pending for full e
"
ect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}
_modi
ed_pending_restart"] = True
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
after code change
return {"status": "success", "message": f"Code for '{component_name}' in '{target_
le}'
modi
ed. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modi
cation to {component_name}:
{e}", exc_info=True)
ed)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_
le)
self.log.info(f"Restored original
le {target_
le} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modi
cation: {e}. System
might be unstable."}
def rollback(self, backup_
le: Path, target_
le: Path):
"""Rolls back a
le to a backup."""
self.log.info(f"Attempting to rollback '{target_
le}' from '{backup_
le}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_
le, target_
le)
self.log.info(f"Successfully rolled back '{target_
le}'.")
ags in self-model or state
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_
le}.")
self.agent_ref.self_model.beliefs[f"component_{target_
le.name}
_modi
ed_pending_restart"] = False
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_
le.name)
return {"status": "success", "message": f"Rolled back {target_
le}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_
le}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_
le_rel: Union[str, Path]):
"""Attempts to reload a module to apply changes without full restart."""
target_module_name = Path(target_
le_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is
required.")
return
ed attempt:
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
"
ect global instances like `_agent_instance_hack` if it was part of the
reloaded module
if _agent_instance_hack and hasattr(sys.modules[target_module_name],
    pass  # inserted to fix indentation error
'AutonomousAgent'):
self.log.info("AutonomousAgent class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot
reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for
changes to take e
"
ect.")
def inspect_directives_UNSAFE(self) -> Dict:
"""Inspects the agent's current core directives."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modi
cation_UNSAFE(self, analysis_of_misalignment: str,
proposed_directive_changes_desc: str) -> Dict:
"""Proposes modi
cations to core directives using LLM."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need
review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (
oat 0-1), "last_eval_score" (
oat 0-1,
usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational',
'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term AGI
goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,
temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in
    pass  # inserted to fix indentation error
proposed_directives):
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
returned an error message as JSON
return {"status": "error", "error": f"LLM indicated error during directive proposal:
{proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response:
{llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modi
cation_UNSAFE(self, new_directives: List[Dict]) -> Dict:
"""Applies new core directives to the agent's SelfModel."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in
new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modi
cation_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count:
{len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
def _init_self_mod_tools(agent: 'AutonomousAgent', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModi
cationTools(AGENT_CODE_DIR,
SELF_MOD_BACKUP_DIR, agent)
cation
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in
    pass  # inserted to fix indentation error
name.upper():
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
"""Represents the agent's internal model of itself, including beliefs about the
environment."""
def __init__(self, state: Optional[Dict]=None, agent_directives_con
g:
Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_con
g if agent_directives_con
g is not None else
DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
'failure_count', ...}}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
metacognitive checks
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_con
dence: Dict[str,
oat] = {}
dence_score}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an AGI agent."}
General beliefs about self and world
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
summary of knowledge areas
self.learning_goals: List[Dict[str, Any]] = []
c goals for learning/improvement
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.lear ned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
based narrative of current internal state
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_con
dence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
cant internal events (e.g., directive
changes, model updates)
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
later.
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted",
sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_con
dence = sm_state.get("skill_con
dence", self.skill_con
dence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary",
self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies",
self.adaptation_strategies)
self.lear ned_abstractions = sm_state.get("lear ned_abstractions",
self.lear ned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative",
self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs",
self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
"""Saves the self-model's persistent components back to the main state dict's KB."""
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_con
dence": self.skill_con
dence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"lear ned_abstractions": self.lear ned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
ection and prompt_suggestions_from_re
ection
ection process.
def add_event_log(self, event_description: str, event_type: str = "info", data:
Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
dence for new tools
for tool_name in self.capabilities:
if tool_name not in self.skill_con
    pass  # inserted to fix indentation error
dence:
self.skill_con
dence[tool_name] = 0.5
dence
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0,
'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None,
'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.",
event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8: hint = " (Reliability: High)"
    pass  # inserted to fix indentation error
elif score > 0.6: hint = " (Reliability: Moderate)"
    pass  # inserted to fix indentation error
elif score > 0.3: hint = " (Reliability: Low)"
    pass  # inserted to fix indentation error
else: hint = " (Reliability: Very Low/Untested)"
    pass  # inserted to fix indentation error
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict,
success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration':
0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
MAX_RECENT_TOOL_OUTCOMES_IN_SELFMODEL (constant not de
ned, using 30)
dence (simple heuristic for now)
current_con
dence = self.skill_con
dence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = min(1.0, current_con
dence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = max(0.0, current_con
dence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability:
{stats['reliability_score']:.2f}, Con
dence: {self.skill_con
dence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_con
dence_drift(sm: 'SelfModel') -> Optional[str]:
low_con
dence_skills = [skill for skill, conf in sm.skill_con
dence.items() if conf < 0.25
and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_con
    pass  # inserted to fix indentation error
dence_skills) >= 2 :
return f"Multiple critical skills have very low con
dence and recent failures: {',
'.join(low_con
dence_skills)}. Consider skill improvement or alter native strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict): return None
    pass  # inserted to fix indentation error
low_eval_directives = []
for d in sm.core_directives:
problematic.
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {',
'.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count}
with max replans. Planning or execution e
"
ectiveness may be compromised. Review strategy
or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_con
dence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}):
{anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}",
event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__')
else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {';
'.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears
stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0),
reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:
{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_con
    pass  # inserted to fix indentation error
dence:
con
dent_skills = [s for s,c in self.skill_con
dence.items() if c > 0.7][:3]
summary += f"Con
dent Skills (sample): {', '.join(con
dent_skills) if con
dent_skills else
'None highly con
dent'}\n"
summary += f"Inter nal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and
stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and
stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools: summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
    pass  # inserted to fix indentation error
if unreliable_tools: summary += f" Needs Improvement: {', '.join([t[0] for t in
    pass  # inserted to fix indentation error
unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
ection)
base_prompt = """Analyze your recent performance, knowledge, internal state, and
alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:
"""
output_keys_example = [
"`re
ection_summary` (str: Overall summary of the re
ection period).",
"`key_successes` (list of str: Speci
c achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Speci
c setbacks or di
culties encountered).",
"`lear ned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identi
ed` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool
e
"
ectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM
interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g.,
'curious', 'frustrated', 'satis
ed').",
"`resource_usage_concer ns` (str or null: Any concer ns about computational resource
usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_
oat_0_to_1: How
well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes,
provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only
suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model?
What needs improvement?).",
"`new_learning_goals` (list of str: Speci
c goals for future learning or skill
development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring
issues or improve performance).",
"`self_modi
cation_needed` (str or null: If parts of your own code/logic need
modi
cation, describe what and why. Be very speci
c and cautious.)."
]
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives,
indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n"
+ \
f"Recent Tool Outcomes (last 5 entries):
\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}
\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment
with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment:
{assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_re
ection(self, re
ection_data: Dict) -> Tuple[bool, bool]:
ection updates)
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from re
ection data...")
dence, tool_notes (as in base script logic)
ection_data directly updates some
elds or implies updates
if re
    pass  # inserted to fix indentation error
ection_data.get('re
ection_summary'):
self.internal_state_narrative = re
ection_data['re
ection_summary']
updated_self = True
core_directives_eval = re
ection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and
    pass  # inserted to fix indentation error
isinstance(self.core_directives[0], dict):
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (
    pass  # inserted to fix indentation error
oat, int)) and 0.0 <= eval_score
<= 1.0:
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...'
evaluation score to {eval_score:.2f}")
if updated_self: self.add_event_log("Directive evaluation scores updated from
    pass  # inserted to fix indentation error
re
ection.")
suggested_directive_updates = re
ection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Re
ection suggested updates to core directives:
{str(suggested_directive_updates)[:200]}...")
'apply_directive_modi
cation_UNSAFE' tool
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modi
cations from
re
ection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source":
"self_re
ection"}
)
updated_self = True
self.add_event_log("Re
ection suggested directive updates. Metacognitive review
goal created.", event_type="critical_review_needed")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('new_learning_goals'), list):
for lg_str in re
ection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts":
datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self: self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('adaptation_strategy_proposals'), list):
for strat_str in re
ection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self: self.log.info(f"Updated adaptation strategies. Total:
    pass  # inserted to fix indentation error
{len(self.adaptation_strategies)}")
patterns)
agent
if re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts') or re
ection_data.get('prompt_tuning_suggestions'):
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from re
ection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
"""Saves a backup of current directives to a
le."""
backup_
le = SELF_MOD_BACKUP_DIR /
f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_
le.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_
le} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
"""Simulates an internal dialog about a topic using LLM, potentially from di
"
erent
perspectives."""
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_o
cer"]
dialog_history = []
full_dialog_str = f"Inter nal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an AGI's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts,
questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution":
contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective
{perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":
full_dialog_str})
return full_dialog_str
class MotivationEngine:
"""Manages the agent's internal drives and their in
uence on behavior."""
def __init__(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[DriveType, DriveState] = {}
self._initialize_drives(drive_con
gs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]]):
default_con
gs = {
DriveType.CURIOSITY: {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.MASTERY: {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.ACHIEVEMENT: {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.NOVELTY_SEEKING: {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.7},
DriveType.PRESERVATION: {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0,
"initial_level": 0.2},
DriveType.EFFICIENCY: {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.SOCIAL_INTERACTION: {"decay_rate": 0.01, "max_level": 1.0, "min_level":
0.0, "initial_level": 0.3},
}
con
gs = drive_con
gs if drive_con
gs is not None else default_con
gs
for drive_type in DriveType:
con
g = con
gs.get(drive_type, default_con
gs.get(drive_type, {}))
self.drives[drive_type] = DriveState(
drive_type=drive_type,
level=con
g.get("initial_level", 0.5),
decay_rate=con
g.get("decay_rate", 0.01),
max_level=con
g.get("max_level", 1.0),
min_level=con
g.get("min_level", 0.0)
)
def update_drives(self):
"""Applies decay and updates drives based on recent experiences or time."""
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
"""Updates drives based on a speci
c experience."""
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "lear n":
    pass  # inserted to fix indentation error
self.drives[DriveType.CURIOSITY].update(stimulus=-0.05)
self.drives[DriveType.MASTERY].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives[DriveType.PRESERVATION].update(stimulus=0.1)
self.drives[DriveType.MASTERY].update(stimulus=-0.05)
def get_drive_level(self, drive_type: DriveType) ->
oat:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
if not found
    pass  # inserted to fix indentation error
def get_all_drive_levels(self) -> Dict[DriveType,
oat]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str,
oat]:
return {dt.name: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[DriveType,
oat]]:
"""Retur ns top N drives by current level."""
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
"""Suggests a goal type based on current highest drives."""
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == DriveType.CURIOSITY:
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == DriveType.MASTERY:
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == DriveType.ACHIEVEMENT:
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == DriveType.PRESERVATION:
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == DriveType.EFFICIENCY:
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: DriveType
level:
oat = 0.5
decay_rate:
oat = 0.01
max_level:
oat = 1.0
min_level:
oat = 0.0
last_update_time:
oat =
eld(default_factory=time.time)
def update(self, stimulus:
oat = 0.0):
"""Updates the drive level based on stimulus and decay."""
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class FileChannel:
"""Implements a simple
le-based communication channel for multi-agent systems."""
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_
le = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_
le}")
def _write_message_to_
le(self, message: Message, target_
le: Path) -> bool:
try:
    pass  # inserted to fix indentation error
le lock to prevent corruption during writes
with FileLock(str(target_
le) + ".lock", timeout=5):
messages = []
if target_
    pass  # inserted to fix indentation error
le.exists():
try:
    pass  # inserted to fix indentation error
existing_content = target_
le.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {target_
le}: {e}. Clearing
le.")
messages = []
messages.append(message.to_dict())
target_
le.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_
le}. Message not sent to
le.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_
le}: {e}")
return False
def _read_messages_from_
le(self, source_
le: Path) -> List[Message]:
messages = []
if not source_
    pass  # inserted to fix indentation error
le.exists():
return []
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_
le) + ".lock", timeout=5):
content = source_
le.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if
isinstance(msg_data, dict)]
le after reading
source_
le.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_
le}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {source_
le}: {e}. Clearing
le.")
source_
le.write_text("", encoding='utf-8')
le
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_
le}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}:
{message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_
le(message, target_inbox)
def receive_messages(self) -> List[Message]:
"""Checks and retrieves new messages from the agent's inbox."""
new_messages = self._read_messages_from_
le(self.inbox_
le)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message],
Optional[Message]]):
"""Registers a function to handle speci
c message types."""
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
"""Processes all messages currently in the inbox using registered handlers."""
messages = self.receive_messages()
le
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From:
{msg.sender_id}")
handled = False
if msg.message_type in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg.message_type]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler
{handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id,
receiver_id=msg.sender_id, type=MessageType.ERROR, content={"original_message_id":
msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type
{msg.message_type.value}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
"""Abstract base class for a sensor."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', con
g: Dict):
self.id = id
self.embodiment = embodiment
self.con
g = con
g
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
"""Retur ns the current reading from the sensor."""
pass
class Actuator(ABC):
"""Abstract base class for an actuator."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], con
g: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.con
g = con
g
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
"""Performs a speci
c action using the actuator."""
pass
class VirtualEmbodiment:
"""Simulated embodiment layer for AGI agents. (Can be replaced by Gym environments or
more complex sims)"""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing
system diagnostics. A console provides interaction with the core AGI systems. Doors lead to
'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button",
"research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, recon
gurable bay designed for running complex simulations.
Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_con
g_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data
ow and
storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"agi_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core.
Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in
self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
"""Generate synthetic sensory input based on current environment and internal state."""
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20: self.state["emotions"]["anxiety"] = min(1.0,
    pass  # inserted to fix indentation error
self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An unde
ned space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
self.gym_env.step(self.gym_env.action_space.sample())
observation
logging
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) ->
Dict:
"""
Simulates the agent performing an action in the virtual world.
Retur ns a dictionary with the result of the action.
"""
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params:
{params}")
params = params or {}
env_details = self.environment_map.get(self.location, {})
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as speci
ed."
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console": message += " It shows
    pass  # inserted to fix indentation error
uctuating green and
amber lights."
elif target == "core_status_monitor": message += " It indicates: Core Nominal.
    pass  # inserted to fix indentation error
Directives Stable. Lear ning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
ed
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
problem.
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name",
"default_physics_test"), params.get("con
g",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result:
{sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
"
ect emotional state based on action outcome
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if
action_type=="move" else None, "updated_inventory": self.state["inventory"] if
action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "lear n"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage
at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response:
{self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model
<topic>'."
def _run_simulation(self, sim_name: str, con
g: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with con
g: {con
g}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_con
    pass  # inserted to fix indentation error
g" in con
g: success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric:
{outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check con
guration."
def summary(self) -> str:
"""Retur ns a string summary of the embodiment's current state."""
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Inter nal State (summary): Energy={self.state['energy']},
Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time:
oat = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
methods
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE,
LAST_LEARNING_MODULE_UPDATE_CYCLE
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status:
{self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack
Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if
self.agent.state['goals'].get('active') else None
self.agent.last_error = None
self.agent.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
understanding
if self.agent.self_model and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
self.log.info(f"Triggering proactive metacognitive check (Cycle
{self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
goal
if self.agent.learning_module and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_LEARNING_MODULE_UPDATE_CYCLE >=
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.lear n_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
new_pending_goals
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
List of Goal dicts
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation:
{ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
pending_list.sort(key=lambda x: GoalPriority[x.get('priority', 'MEDIUM').upper() if
isinstance(x.get('priority'),str) else GoalPriority(x.get('priority',
GoalPriority.MEDIUM)).name ].value, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type ==
    pass  # inserted to fix indentation error
"active_goal_continue":
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution:
{goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID:
{goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal'
provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
object
ed logic assumes plan is a list of steps in the goal dict.
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or
    pass  # inserted to fix indentation error
current_goal_obj.replan_count > 0:
planning
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
generation
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
Goal object
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan available or generated for goal: {current_goal_obj.goal[:50]}.
Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
c goal, agent is idle or performing non-goal action
self.agent.current_goal_outcome = True
gured
if time.time() - LAST_DELIBERATION_TIME >
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModi
cationError, LogicError, LLMError, SecurityError, Con
gurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
Lear ningError, SafetyViolationError) as agent_cycle_err:
c goal
attempt.
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent
Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
nished (with an error for current goal), but agent can continue
unless critical.
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.current_goal_outcome = False
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
nally:
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() -
start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
"""Processes observations to update world model and identify key information."""
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
ed approach. A real system might have more structured parsing.
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent
understanding of the current situation. Identify key entities, events, and any signi
cant changes
in the environment or your internal state. Focus on information relevant to achieving current
goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content:
{str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\":
\"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"],
\"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation",
understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
as facts/experiences
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event",
metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry,
persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
complex updates to the graph/relational store
return {"summary": understanding_summary, "processed_info": processed_info,
"raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError,
DeliberationError))
g
def _deliberate(self, understanding_result: Dict) -> Dict:
"""
Core deliberation logic: goal management, selection, and generation.
Retur ns a dict: {"chosen_action_type": str, "next_goal": Optional[Goal_dict],
"new_pending_goals": List[Goal_dict]}
"""
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio:
{pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio:
{active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time':
datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack
(paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
activated
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
continue
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
directives (idle task)
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal
generation.")
directives
if time.time() - LAST_DELIBERATION_TIME >=
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_lear n", "directive_curiosity",
"directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
for idle time
pass
new_pending_goals)
processed
ag.
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') ==
    pass  # inserted to fix indentation error
'sub_goal_prepared':
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output:
{sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
c action, LLM will decide
self_model_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No speci
c
understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact',
'None identi
ed.')
interp_con_val = understanding_result.get('interpretation_con
dence', 0.7)
recent_memory_context =
self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary,
max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Con
dence: {interp_con_val:.2f}):**
{understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identi
ed:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory
(STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]],
indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else
f'{active_goal_dict.get("goal")[:100]}... (ID: {active_goal_dict.get("id")})'}",
f"* **Agent Core Directives
(Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding,
drives, memories, goals, directives), what is the most critical aspect demanding attention or the
best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.self_model.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/
complete).",
"    - Performing `re
ection` or `self_assessment` (if mandatory timers, drives like low
CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration
goal), Directives (e.g., low-eval directive -> improvement goal), or identi
ed opportunities. New
goals require `goal` (str), `priority` (
oat 0.0-1.0), `origin` (str e.g., 'drive_curiosity',
'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of
str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for
viability before committing if uncertainty is high or consequence severe (brie
y note simulation
outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are
apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the
immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, high
drives, or highest priority pending. State reasoning clearly.",
```python
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.
If selecting an existing pending goal, it moves to `next_goal` and is removed from pending
internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/
directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal',
'new_goal', 're
ection', 'self_assessment', 'exter nal_command_action', 'idle',
'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass
structure) selected for immediate execution. Null if idle/re
ection/assessment without a direct
goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen
for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into
`new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into
`new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent.
Analyze the situation comprehensively, consider drives and directives, and make strategic
decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and
deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON:
{extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal',
'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys:
{deliberation_decision.keys()}")
if key == 'new_pending_goals': deliberation_decision[key] = []
    pass  # inserted to fix indentation error
elif key == 'next_goal': deliberation_decision[key] = None
    pass  # inserted to fix indentation error
else: deliberation_decision[key] = "Error: Missing from LLM Output"
    pass  # inserted to fix indentation error
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty
list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not
    pass  # inserted to fix indentation error
isinstance(deliberation_decision.get('next_goal'), dict):
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value:
{deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and
    pass  # inserted to fix indentation error
new_goal_dict.get('priority'):
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p.id == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
duplicates based on ID
current_pending_list.append(new_goal_obj)
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal:
{new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
LLM
current_active_goal = self.agent.get_active_goal_object()
None
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending',
[]) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
selected_goal_obj.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = selected_goal_obj
object
self.log.info(f"Moved pending goal {selected_goal_obj.id}
('{selected_goal_obj.goal[:50]}') to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM selected pending goal by ID
{selected_next_goal_dict.get('id')}, but not found in list. Idling.")
action_type = "idle"
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
highest_priority_pending.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = highest_priority_pending
self.log.info(f"Deliberation chose 'pending_goal' without speci
c ID; moved
highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals
available. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in
    pass  # inserted to fix indentation error
selected_next_goal_dict:
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj
self.log.info(f"Deliberation created and activated new goal:
{new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal
active
current_active_goal.status = GoalStatus.ACTIVE
rm active status
self.log.info(f"Deliberation chose to resume current active goal:
{current_active_goal.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 're
    pass  # inserted to fix indentation error
ection', 'self_assessment', 'exter nal_command_action']:
'INTERRUPTED'.
if current_active_goal:
    pass  # inserted to fix indentation error
current_active_goal.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal.goal[:30]}' PAUSED due to
{action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal.to_dict())
pending, maybe re-prioritize later
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal.id} to pending
as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to
Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action:
{deliberation_decision.get('chosen_action_type')}. Reason:
{deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
"""
Executes the current plan for the active_goal.
Retur ns True if goal considered successfully processed for this cycle, False if critical error.
"""
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps:
{len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
rst step in the plan. The plan will be truncated or re-evaluated.
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id,
"plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params,
current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
ned based on tool_result and goal progress
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
ed snapshot
internal_state_after=self.agent.self_model.beliefs
e
"
ects
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
nal_status = tool_result.get("status", "unknown")
if
nal_status == "success":
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome =
nal_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
nished.
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing
nished by report_result.
Status: {
nal_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error',
'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj,
tool_result, observations[0] if observations else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal
will likely fail.")
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without
'report_result'. Goal might be incomplete.")
ection.
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
violations
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}':
{e}", exc_info=False)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) ->
oat:
"""Calculates a reward signal based on tool execution outcome and goal relevance."""
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
goaling
reward += 0.1
return round(reward, 2)
class AutonomousAgent:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
in cycle
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
for direct access
self.learning_module: Lear ningModule
self.planning_module: PlanningModule
direct access
self.safety_module: SafetyModule
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.state['
ags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete ---
Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response
Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled:
{ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modi
cation Enabled: {ENABLE_SELF_MODIFICATION}")
if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
    pass  # inserted to fix indentation error
ENABLE_SELF_MODIFICATION:
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME
CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}",
exc_info=True)
self.shutdown()
raise Con
gurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH == "mock":
    pass  # inserted to fix indentation error
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Cannot use Gemini model: google-generativeai library not
installed.")
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
global LLM_PIPELINE, LLM_TOKENIZER
CPU
AutoTokenizer.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
oat16 if TORCH_AVAILABLE else None,
oat16 if
torch available
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH,
LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS,
get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
c not implemented here
self.log.warning(f"LLM_MODEL '{LLM_MODEL_NAME_OR_PATH}' not fully con
gured
for wrapper selection, using Mock.")
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
_init_self_mod_tools(self, self.tool_manager)
cationTools handler
and register its UNSAFE methods
self._update_status("Initializing AGI Modules")
self.learning_module = Lear ningModule(self)
self.safety_module = SafetyModule(self)
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME,
shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager: self.tool_manager.check_playwright_browsers()
    pass  # inserted to fix indentation error
browser tool
self.log.info("Agent component initialization
nished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list): state['goals'][key] = []
    pass  # inserted to fix indentation error
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
items
state.setdefault('goal_stack', [])
state.setdefault('
ags', {})
ags system
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state
le {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state
le {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
its view)
"recent_failures_summary": [],
view)
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"
ags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
cation and saving
_archive_goal)
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
state['knowledge_base']['self_model_state']
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status if self.self_model else
self._status
try:
    pass  # inserted to fix indentation error
temp_
le = STATE_FILE.with_su
x(STATE_FILE.su
x + ".tmp")
with temp_
le.open('w') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_
le, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
"""Retur ns the current active goal as a Goal object, or None."""
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict:
{active_goal_dict}")
return None
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority =
GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
deliberation
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict,
nal_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID:
{goal_data_dict.get('id')}) with status: {
nal_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
goal_obj.status = GoalStatus(
nal_status_str)
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-
MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status":
str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count":
goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and
    pass  # inserted to fix indentation error
current_active_in_state.get('id') == active_goal_id:
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
stack
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID:
{active_goal_id}) concluded with status: {
nal_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-
goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
marked active
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal',
'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal:
{parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
goal wasn't a subgoal from stack
self.log.info("Goal archived. No parent goal to resume from stack, or current goal
was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized": self._update_status("Idle")
    pass  # inserted to fix indentation error
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and
environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if
self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle:
{loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
nal status of the goal processed in this cycle
updated_active_goal_dict = self.state['goals'].get('active')
goal
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] ==
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['id']:
ects outcome
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED,
    pass  # inserted to fix indentation error
GoalStatus.CANCELLED]:
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
during preemption)
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
failed while this goal was active
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
failed
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
not speci
c to goal completion
ection (AGI Enhanced) - Can be more frequent or event-driven
if self._should_re
    pass  # inserted to fix indentation error
ect(active_goal_data_before_cycle):
self._re
ect_on_performance()
cant changes (already done in many places)
nal save here per cycle too.
if self.state['
    pass  # inserted to fix indentation error
ags'].get('re_evaluate_strategy_needed'):
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to signi
cant
internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['
ags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not
    pass  # inserted to fix indentation error
self.state['goals'].get('pending'):
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() -
LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_re
ect(self, processed_goal_data: Optional[Dict]) -> bool:
ection triggers
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
ect
every N cycles
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED, GoalStatus.FAILED]:
ect after signi
cant goal outcome
ect if enough goals processed since last time
goals_processed_key = "goals_processed_since_re
ection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >=
    pass  # inserted to fix indentation error
int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
return True
if time.time() - LAST_REFLECTION_TIME >
    pass  # inserted to fix indentation error
MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
return True
if self.state['
    pass  # inserted to fix indentation error
ags'].get('explicit_re
ection_requested'):
return True
return False
@retry(attempts=2, delay=5)
def _re
ect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Re
ecting on Performance ---")
self.state['
ags']['explicit_re
ection_requested'] = False
ag
self.state["goals_processed_since_re
ection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt,
max_new_tokens=2048, temperature=0.5)
ection
re
ection_data = extract_json_robust(llm_assessment_str)
if re
    pass  # inserted to fix indentation error
ection_data.get("error"):
self.log.error(f"Failed to get valid JSON from LLM self-assessment:
{re
ection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed:
{re
ection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_re
ection(re
ection_data)
ection to MemorySystem
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts'), list):
for fact_str in re
ection_data['lear ned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source":
"self_re
ection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
self.log.info(f"Added {len(re
ection_data['lear ned_facts'])} lear ned facts to memory
from re
ection.")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('prompt_tuning_suggestions'), list):
for sugg_str in re
ection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str,
metadata={"source": "self_re
ection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(re
ection_data['prompt_tuning_suggestions'])} prompt
suggestions to memory.")
ndings from re
ection (e.g. self_modi
cation_needed)
if re
    pass  # inserted to fix indentation error
ection_data.get('self_modi
cation_needed'):
mod_desc = re
ection_data['self_modi
cation_needed']
self.log.warning(f"Re
ection identi
ed need for self-modi
cation: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modi
cation based on re
ection:
{mod_desc}",
priority=GoalPriority.HIGH,
context={"modi
cation_description": mod_desc, "source": "self_re
ection"}
)
ection insights or periodically
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) ==
    pass  # inserted to fix indentation error
0:
audit_issues = self.safety_module.audit_directives_and_behavior()
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identi
ed issues: {audit_issues}")
ndings
self._create_metacognitive_goal(f"Address directive audit
ndings:
{str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Re
ection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during re
ection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during re
ection: {e}", exc_info=True)
nally:
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
"""Sets up handlers for di
"
erent message types if comms_channel exists."""
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY,
self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM,
self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}:
{message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base']
[query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample":
str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id,
type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}:
{message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
x with sender to avoid
clashes
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if not PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("psutil not available, resource monitoring disabled.");
return
if RESOURCE_MONITOR: return
    pass  # inserted to fix indentation error
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e: self.log.error(f"Failed to initialize resource monitor: {e}");
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("Playwright not available, skipping initialization.")
return
if PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER =
PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
globals
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE: try: PLAYWRIGHT_PAGE.close()
    pass  # inserted to fix indentation error
ignore
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_CONTEXT: try: PLAYWRIGHT_CONTEXT.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_BROWSER: try: PLAYWRIGHT_BROWSER.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_INSTANCE: try: PLAYWRIGHT_INSTANCE.stop()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not PLAYWRIGHT_AVAILABLE or not self.playwright_context : return
    pass  # inserted to fix indentation error
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page: try: self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
ush
if 'logging' in sys.modules: logging.shutdown()
    pass  # inserted to fix indentation error
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl}
Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/
{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)' if
ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
ENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[AutonomousAgent] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_
le",
priority=GoalPriority.HIGH).to_dict()
COMMANDS_FILE.write_text("")
except Exception as e_cmd
    pass  # inserted to fix indentation error
le:
print(f"Error reading initial command
le: {e_cmd
le}",
le=sys.stderr)
main_agent_instance = AutonomousAgent()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending',
[]).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort,
reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal']
[:50]}' added to pending goals.")
main_agent_instance.run()
except Con
    pass  # inserted to fix indentation error
gurationError as cfg_err_main:
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}",
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to Con
gurationError:
{cfg_err_main}", exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to
    pass  # inserted to fix indentation error
Con
gurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else: logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt
    pass  # inserted to fix indentation error
during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}",
le=sys.stderr)
traceback.print_exc(
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",
exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main:
    pass  # inserted to fix indentation error
{main_exec_err}", exc_info=True)
exit_code = 1
nally:
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main
nally block...")
if hasattr(main_agent_instance, 'log'): main_agent_instance.log.warning("Main
    pass  # inserted to fix indentation error
nally
block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
main_log.warning("Agent instance likely not created or fully initialized. Basic
shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
```
TORCH_AVAILABLE = True
GOOGLE_GENAI_AVAILABLE = True
PSUTIL_AVAILABLE = True
CHROMADB_AVAILABLE = True
PLAYWRIGHT_AVAILABLE = True
REQUESTS_BS4_AVAILABLE = True
PILLOW_AVAILABLE = True
DIFF_MATCH_PATCH_AVAILABLE = True
FILELOCK_AVAILABLE = True
NETWORKX_AVAILABLE = True
GYMNASIUM_AVAILABLE = True
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
import psutil
import chromadb
from chromadb.config import Settings as ChromaSettings
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoConfig
from transformers import logging as transformers_logging
import torch
from playwright.sync_api import sync_playwright, Error as PlaywrightError
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from PIL import Image
import diff_match_patch as dmp_module
import hashlib
from fifilelock import FileLock, Timeout as FileLockTimeout
import networkx as nx
import gymnasium as gym
AGENT_NAME = "EvolvedCognitiveAgent_SystemCore_V3"
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
DEFAULT_LLM_MODEL = "gemini-2.5-flash"
LLM_MODEL_NAME_OR_PATH = DEFAULT_LLM_MODEL
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
_llm_device_detected = "cpu"
if torch.cuda.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif hasattr(torch, 'backends') and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
LLM_DEVICE = _llm_device_detected
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
SCRIPT_DIR = Path(__file__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(f"agent_workspace_{AGENT_NAME}")
STATE_FILE = WORKSPACE_DIR / Path(f"agent_state_{AGENT_NAME}.json")
LOG_FILE = WORKSPACE_DIR / Path(f"agent_log_{AGENT_NAME}.log")
COMMANDS_FILE = SCRIPT_DIR / Path("agent_commands.txt")
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modification_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously learn, adapt, and improve capabilities across all domains.", "weight": 0.9, "last_eval_score": 0.0, "id": "directive_learn", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type": "growth"},
{"directive": "Achieve goals efficiently, robustly, autonomously, and ethically.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type": "exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.", "weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type": "foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type": "guardrail"},
]
MANDATORY_REFLECTION_INTERVAL_SECONDS = 1800
IDLE_DELIBERATION_INTERVAL_SECONDS = 120
GOAL_STACK_MAX_DEPTH = 5
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = 3
MAX_LLM_RESPONSE_TOKENS = 4096
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH or "2.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
else:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
config = AutoConfig.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
_default_context_len = getattr(config, 'max_position_embeddings', _default_context_len)
except Exception:
    pass  # inserted to fix indentation error
pass
MAX_LLM_CONTEXT_TOKENS = _default_context_len
MAX_TOOL_RESULT_LENGTH = 5000
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = True
ENABLE_CODE_GENERATION_TOOL = True
ENABLE_SELF_MODIFICATION = True
WEB_SEARCH_TIMEOUT = 10
WEB_BROWSER_TIMEOUT = 60000
LOG_MONITOR_DEFAULT_LINES = 20
METACOGNITIVE_CHECK_INTERVAL_CYCLES = 20
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES = 50
LLM_PIPELINE = None
LLM_TOKENIZER = None
MEMORY_COLLECTION = None
RESOURCE_MONITOR = None
PLAYWRIGHT_INSTANCE = None
PLAYWRIGHT_BROWSER = None
PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_PAGE = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack = None
def ensure_paths():
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
try:
    pass  # inserted to fix indentation error
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
try:
    pass  # inserted to fix indentation error
file_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
file_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%(filename)s:%(lineno)d] [%(task_name_override)-10s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error setting up file logger: {e}", file=sys.stderr)
logger.propagate = False
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "fifilelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try:
    pass  # inserted to fix indentation error
logging.getLogger(lib_name).setLevel(logging.WARNING)
except Exception:
    pass  # inserted to fix indentation error
pass
try:
    pass  # inserted to fix indentation error
logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
except Exception:
    pass  # inserted to fix indentation error
pass
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModificationError(AgentError): pass
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class ConfigurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class LearningError(AgentError): pass
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModificationError,
PlaywrightError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModificationError,
    pass  # inserted to fix indentation error
LogicError, ConfigurationError, RecursionDepthError)) and type(e) not in retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}: {e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error: {type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error: {type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, LearningError) as non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in {fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}: {type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}: {unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error: {unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception):
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1:
    pass  # inserted to fix indentation error
log_resource.error(f"Unexpected error getting resource usage: {e}", exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
match = re.search(r"```json\s*([\s\S]+?)\s*```", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full text: {json_str[:200]}...")
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}. Text: {text_trimmed[:200]}...")
try:
    pass  # inserted to fix indentation error
start_index = text.find('{')
end_index = text.rfind('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
try:
    pass  # inserted to fix indentation error
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice: {potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text: {text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview": text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str = field(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] = field(default_factory=dict)
plan: List[Dict[str, Any]] = field(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] = field(default_factory=list)
dependencies: List[str] = field(default_factory=list)
complexity_score: Optional[float] = None
estimated_cost: Optional[float] = None
estimated_utility: Optional[float] = None
evaluation_score: Optional[float] = None
associated_directive_ids: List[str] = field(default_factory=list)
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus(data['status'])
except ValueError:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus.PENDING
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority.MEDIUM
field_names = {f.name forfin cls.__dataclass_fields__.values()}
for f_obj in cls.__dataclass_fields__.values():
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin cls.__dataclass_fields__.values()}
filtered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**filtered_data)
@dataclass
class BaseMemoryEntry:
id: str = field(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
content: Any = None
metadata: Dict[str, Any] = field(default_factory=dict)
embedding: Optional[List[float]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[float] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability: float = 0.5
related_concepts: List[str] = field(default_factory=list)
causal_links: Dict[str, str] = field(default_factory=dict)
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
self.content = self.fact_statement
@dataclass
class Message:
id: str = field(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
type: str = "info"
content: Dict[str, Any] = field(default_factory=dict)
priority: int = 0
correlation_id: Optional[str] = None
def to_dict(self) -> Dict[str, Any]:
return asdict(self)
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Message':
return cls(**data)
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionEffect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens: int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[float]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
genai.configure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
try:
    pass  # inserted to fix indentation error
generation_config_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_config_params["stop_sequences"] = stop_sequences
full_prompt = f"{system_message}\n\n{prompt}" if system_message else prompt
response = self.model.generate_content(
full_prompt,
generation_config=genai.types.GenerationConfig(**generation_config_params)
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.", exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[float]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='models/embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, trust_remote_code=True)
device_map_arg = {"": self.device_id} if self.device_id != -1 else "auto"
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.bfloat16,
device_map=device_map_arg
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on {self.device}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Transformers model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Transformers model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
if system_message:
    pass  # inserted to fix indentation error
chat_prompt = [
{"role": "system", "content": system_message},
{"role": "user", "content": prompt}
]
try:
    pass  # inserted to fix indentation error
final_prompt = self.tokenizer.apply_chat_template(chat_prompt, tokenize=False, add_generation_prompt=True)
except Exception:
    pass  # inserted to fix indentation error
final_prompt = f"System: {system_message}\nUser: {prompt}\nAssistant:"
else:
    pass  # inserted to fix indentation error
final_prompt = prompt
inputs = self.tokenizer(final_prompt, return_tensors="pt").to(self.model.device)
outputs = self.model.generate(
**inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[float]:
self.log_llm.warning("Direct embedding from causal LM is not standard. Using mock embedding.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
def perceive(self) -> List[Dict[str, Any]]:
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_file",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from file: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands file: {e}")
observations.append({"type": "error", "source": "command_file_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No significant external stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (simulated).")
return {"type": "visual", "source": "camera_sim", "content": "Simulated visual data: a generic scene.", "format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (simulated).")
return {"type": "audio", "source": "microphone_sim", "content": "Simulated auditory data: ambient sounds.", "format": "description"}
class LearningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_buffer: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
self.experiences_buffer.append(experience)
if len(self.experiences_buffer) > self.MAX_BUFFER_SIZE:
    pass  # inserted to fix indentation error
self.experiences_buffer.pop(0)
defilearn_from_recent_experiences(self):
if not self.experiences_buffer:
    pass  # inserted to fix indentation error
self.log.info("No new experiences to learn from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_buffer)} experiences.")
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_buffer)
self._perform_self_supervised_learning(self.experiences_buffer)
self.log.info("Learning cycle completed.")
self.experiences_buffer.clear()
def _perform_reinforcement_learning(self, experiences: List[Experience]):
self.log.info("Performing reinforcement learning (conceptual)...")
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (conceptual) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
self.log.info("Performing self-supervised learning (conceptual)...")
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns', 'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified patterns: {llm_analysis['patterns']}")
for pattern_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {pattern_str}", metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified abstractions: {llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.learned_abstractions.append({"type": "conceptual", "content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified new_concepts: {llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}", metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_learned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
if self.rl_policy:
    pass  # inserted to fix indentation error
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}. Response: {llm_response_str[:200]}")
return ([{"tool_name": "report_error", "params": {"error_message": "Failed to generate plan via LLM.", "details": plan_data.get('error')}}],
"LLM failed to generate a plan. This is a fallback step.")
thought = plan_data.get("thought", "No specific thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return ([{"tool_name": "report_error", "params": {"error_message": "LLM plan contained no valid steps."}}],
thought + " (But plan steps were invalid).")
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return ([{"tool_name": "report_error", "params": {"error_message": f"LLMError during planning: {e}"}}],
f"LLM error occurred: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return ([{"tool_name": "report_error", "params": {"error_message": f"Unexpected error during planning: {e}"}}],
f"Unexpected error: {e}")
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation: Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info', {}).get('execution_successful', True):
    pass  # inserted to fix indentation error
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal {current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan, last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan: {plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No specific thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else "World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'. Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, efficient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the `execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the final step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the first step(s) should be to acquire it (e.g., using `search_web`, `read_file_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str, last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info', {}).get('current_step_id'):
    pass  # inserted to fix indentation error
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if observation else "None"}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
{original_plan_str}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should reflect this (e.g., by trying to gather more information or reporting inability).
6. Ensure the final step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
class MemorySystem:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH, settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
self.log.info(f"ChromaDB vector store initialized. Collection count: {self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.", exc_info=True)
self.vector_store = None
if not self.vector_store:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based (transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes: {len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be unavailable.", exc_info=True)
self.graph_store = None
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH, check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be unavailable.", exc_info=True)
if self.relational_conn:
    pass  # inserted to fix indentation error
self.relational_conn.close()
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT,
PRIMARY KEY (source_node_id, target_node_id, relation_type)
)
""")
self.relational_conn.commit()
cursor.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error initializing relational schema: {e}", exc_info=True)
def _get_embedding(self, text: str) -> Optional[List[float]]:
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
h = hashlib.md5(text.encode()).digest()
return [float(b) for b in h[:16]]
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector:
    pass  # inserted to fix indentation error
if self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
for k, v in entry.metadata.items():
if isinstance(v, (str, int, float, bool)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
else:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(entry.content)
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata": entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50], type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
for cause_id, effect_id in entry.causal_links.items():
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(effect_id):
    pass  # inserted to fix indentation error
self.graph_store.add_edge(cause_id, effect_id, relation_type='causes')
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id, complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score, json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
ts_now = datetime.now(timezone.utc).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now, json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}", exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError, ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS, type_filter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text:
    pass  # inserted to fix indentation error
return []
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_filter and data['metadata'].get('type') != type_filter:
    pass  # inserted to fix indentation error
continue
results.append({"id": id, "document": data['document'], "metadata": data['metadata'], "distance": 0.0})
if len(results) >= n_results:
    pass  # inserted to fix indentation error
break
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results}, filter={type_filter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_filter:
    pass  # inserted to fix indentation error
where_clause = {"type": type_filter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0:
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type: Optional[str]=None, depth: int = 1) -> List[Dict]:
if not self.graph_store:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation": data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns: Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
if self.graph_store:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts, type_filter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No specific knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
return summary_str
def consolidate_knowledge(self):
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold: float = 0.1, older_than_days: int = 365):
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cutoff_ts = (datetime.now(timezone.utc) - timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cutoff_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
self.register_tool(read_file_UNSAFE)
self.register_tool(write_file_UNSAFE)
self.register_tool(list_files_UNSAFE)
self.register_tool(browse_web)
self.register_tool(search_web)
self.register_tool(monitor_log_file)
self.register_tool(check_website_update)
self.register_tool(send_icmp_ping)
self.register_tool(send_message_to_agent)
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
self.register_tool(execute_shell_command_UNSAFE)
def register_tool(self, func: Callable):
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if hasattr(self, 'agent') and self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for filepath in directory.glob("*.py"):
module_name = filepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_file_location(full_module_name, filepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
sys.modules[full_module_name] = module
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module: {module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and name.startswith("tool_"):
    pass  # inserted to fix indentation error
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}", exc_info=True)
def get_tool_description_for_llm(self) -> str:
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = "(No description provided)"
first_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation == inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class '","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper():
    pass  # inserted to fix indentation error
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {first_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via specific tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {', '.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info: Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None:
    pass  # inserted to fix indentation error
current_step_info = {}
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
result = None
duration = 0.0
validated_params = {}
try:
    pass  # inserted to fix indentation error
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
first_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
first_param_name = next(iter(func_params_spec))
first_param_spec = func_params_spec[first_param_name]
if first_param_name == 'agent' and (first_param_spec.annotation == 'CognitiveSystem' or str(first_param_spec.annotation) == "'CognitiveSystem'"):
    pass  # inserted to fix indentation error
first_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if first_param_is_agent and p_name == 'agent':
    pass  # inserted to fix indentation error
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind == inspect.Parameter.VAR_KEYWORD:
    pass  # inserted to fix indentation error
pass
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
if first_param_is_agent:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration: {duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError:
    pass  # inserted to fix indentation error
raise
except (AgentError, LogicError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}", exc_info=False)
result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
def check_playwright_browsers(self):
self.log.debug("Checking Playwright browsers.")
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log", content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str, percentage_complete: Optional[float] = None) -> Dict:
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log', []).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str = "success", details: Optional[Dict] = None) -> Dict:
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] = "MEDIUM", context: Optional[Dict] = None) -> Dict:
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH}) reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent: {current_active_goal_dict.get('id')}")
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str = "vector", n_results: int = 3, type_filter: Optional[str] = None) -> Dict:
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
results = []
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results, type_filter=type_filter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_graph_store(query_node_label=query_text, depth=1)
elif memory_type == "relational":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_relational_store(table=query_text, limit=n_results)
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params: Optional[Dict] = None) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name, params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
def read_file_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
log_tool = get_logger("TOOL_read_file")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not full_path.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found: {path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path), "file_size_bytes": len(content)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read file: {e}"}
def write_file_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_file")
try:
    pass  # inserted to fix indentation error
full_path = WORKSPACE_DIR.joinpath(path).resolve()
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path": str(full_path)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write file: {e}"}
def list_files_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_files")
try:
    pass  # inserted to fix indentation error
base_path = WORKSPACE_DIR.joinpath(path).resolve()
if not base_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a directory: {path}"}
items = []
for item in base_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "file",
"size_bytes": item.stat().st_size if item.is_file() else None,
"last_modified": datetime.fromtimestamp(item.stat().st_mtime, tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(base_path), "contents": items}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing files in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list files: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int = WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int = WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.find_all(class_='g'):
r = g.find('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.find('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_file(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES) -> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log file not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_file": str(LOG_FILE), "content": content, "lines_read": len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log file {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log file: {e}"}
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp": datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count, "packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count, "packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str, context_code: Optional[str] = None) -> Dict:
agent.log.warning(f"Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a complete function/class definition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
return agent.self_modification_unit.validate_code_modification_UNSAFE(code_to_validate)
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec: int = 30) -> Dict:
agent.log.warning(f"Executing shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s. Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str, content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value, content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id, "message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
class SelfModificationTools:
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref: 'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
self.dmp = dmp_module.diff_match_patch()
self.log.info(f"Self-Modification Unit initialized. Code Dir: {self.agent_code_dir}, Backup Dir: {self.backup_dir}")
def _resolve_target_path(self, target_file_rel: str) -> Path:
target_path_abs = (self.agent_code_dir / target_file_rel).resolve()
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
self.log.warning(f"Inspecting code for component: {component_name}")
target_obj = None
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
candidate_modules = [sys.modules.get('__main__'), sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod, component_name)):
    pass  # inserted to fix indentation error
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
file_path = inspect.getfile(target_obj)
return {"status": "success", "component_name": component_name, "file_path": file_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module, class, or function defined in a file.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
return {"status": "error", "error": f"Component '{component_name}' not found or source code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModificationError))
def propose_code_modification_UNSAFE(self, component_name: str, issue_description: str, proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
self.log.warning(f"Proposing code modification for {component_name}. Issue: {issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for {component_name} to propose modification. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
{current_code_snippet}
Generate the modified Python code for the specified component.
Provide ONLY the complete, new Python code block for the modified function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '```python' and end with '```'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "proposed_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name, "proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modification for {component_name}: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modification_UNSAFE(self, code_to_validate: str) -> Dict:
self.log.warning(f"Validating proposed code snippet ({code_to_validate[:100]}...)")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modification_UNSAFE(self, component_name: str, new_code: str, target_file_path: Optional[str]=None) -> Dict:
self.log.critical(f"Attempting to apply code modification to component '{component_name}'. THIS IS HIGHLY RISKY.")
try:
    pass  # inserted to fix indentation error
if not target_file_path:
    pass  # inserted to fix indentation error
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('file_path'):
    pass  # inserted to fix indentation error
target_file_path = inspection_res['file_path']
else:
    pass  # inserted to fix indentation error
target_file_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_file = Path(target_file_path)
if not target_file.exists() or not target_file.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Target file for modification not found: {target_file}"}
original_code = target_file.read_text()
backup_path = SELF_MOD_BACKUP_DIR / f"{target_file.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_file, backup_path)
self.log.info(f"Backed up original file to {backup_path}")
pattern_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
pattern_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modified_original_code = original_code
found_and_replaced = False
match_class = re.search(pattern_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(pattern_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not find component '{component_name}' in {target_file} for replacement. Modification aborted.")
return {"status": "error", "error": f"Component '{component_name}' definition not found for replacement."}
target_file.write_text(modified_original_code)
self.log.warning(f"Code modification applied to {target_file}. Agent restart is LIKELY REQUIRED for changes to take effect.")
self.agent_ref.self_model.add_event_log(f"Applied code modification to {component_name}. Restart pending for full effect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}_modified_pending_restart"] = True
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": f"Code for '{component_name}' in '{target_file}' modified. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modification to {component_name}: {e}", exc_info=True)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_file)
self.log.info(f"Restored original file {target_file} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modification: {e}. System might be unstable."}
def rollback(self, backup_file: Path, target_file: Path):
self.log.info(f"Attempting to rollback '{target_file}' from '{backup_file}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_file, target_file)
self.log.info(f"Successfully rolled back '{target_file}'.")
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_file}.")
self.agent_ref.self_model.beliefs[f"component_{target_file.name}_modified_pending_restart"] = False
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_file.name)
return {"status": "success", "message": f"Rolled back {target_file}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_file}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_file_rel: Union[str, Path]):
target_module_name = Path(target_file_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is required.")
return
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
if _agent_instance_hack and hasattr(sys.modules[target_module_name], 'CognitiveSystem'):
    pass  # inserted to fix indentation error
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for changes to take effect.")
def inspect_directives_UNSAFE(self) -> Dict:
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modification_UNSAFE(self, analysis_of_misalignment: str, proposed_directive_changes_desc: str) -> Dict:
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (float 0-1), "last_eval_score" (float 0-1, usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational', 'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024, temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in proposed_directives):
    pass  # inserted to fix indentation error
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"LLM indicated error during directive proposal: {proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modification_UNSAFE(self, new_directives: List[Dict]) -> Dict:
self.log.warning(f"Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modification_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count: {len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
_self_mod_tools_container = None
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, agent)
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in name.upper():
    pass  # inserted to fix indentation error
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func) or inspect.ismethod(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
def __init__(self, state: Optional[Dict]=None, agent_directives_config: Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_config if agent_directives_config is not None else DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_confidence: Dict[str, float] = {}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
self.learning_goals: List[Dict[str, Any]] = []
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.learned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_confidence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted", sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_confidence = sm_state.get("skill_confidence", self.skill_confidence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary", self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies", self.adaptation_strategies)
self.learned_abstractions = sm_state.get("learned_abstractions", self.learned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative", self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs", self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_confidence": self.skill_confidence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"learned_abstractions": self.learned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
def add_event_log(self, event_description: str, event_type: str = "info", data: Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
for tool_name in self.capabilities:
if tool_name not in self.skill_confidence:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = 0.5
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.", event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8:
    pass  # inserted to fix indentation error
hint = " (Reliability: High)"
elif score > 0.6:
    pass  # inserted to fix indentation error
hint = " (Reliability: Moderate)"
elif score > 0.3:
    pass  # inserted to fix indentation error
hint = " (Reliability: Low)"
else:
    pass  # inserted to fix indentation error
hint = " (Reliability: Very Low/Untested)"
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict, success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
current_confidence = self.skill_confidence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = min(1.0, current_confidence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = max(0.0, current_confidence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability: {stats['reliability_score']:.2f}, Confidence: {self.skill_confidence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_confidence_drift(sm: 'SelfModel') -> Optional[str]:
low_confidence_skills = [skill for skill, conf in sm.skill_confidence.items() if conf < 0.25 and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_confidence_skills) >= 2 :
    pass  # inserted to fix indentation error
return f"Multiple critical skills have very low confidence and recent failures: {', '.join(low_confidence_skills)}. Consider skill improvement or alternative strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict):
    pass  # inserted to fix indentation error
return None
low_eval_directives = []
for d in sm.core_directives:
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {', '.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count} with max replans. Planning or execution effectiveness may be compromised. Review strategy or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_confidence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}): {anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}", event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__') else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {'; '.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0), reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_confidence:
    pass  # inserted to fix indentation error
confident_skills = [s for s,c in self.skill_confidence.items() if c > 0.7][:3]
summary += f"Confident Skills (sample): {', '.join(confident_skills) if confident_skills else 'None highly confident'}\n"
summary += f"Internal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools:
    pass  # inserted to fix indentation error
summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
if unreliable_tools:
    pass  # inserted to fix indentation error
summary += f" Needs Improvement: {', '.join([t[0] for t in unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
base_prompt = """Analyze your recent performance, knowledge, internal state, and alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:"""
output_keys_example = [
"`reflection_summary` (str: Overall summary of the reflection period).",
"`key_successes` (list of str: Specific achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Specific setbacks or difficulties encountered).",
"`learned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identified` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool effectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g., 'curious', 'frustrated', 'satisfied').",
"`resource_usage_concerns` (str or null: Any concerns about computational resource usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_float_0_to_1: How well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes, provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model? What needs improvement?).",
"`new_learning_goals` (list of str: Specific goals for future learning or skill development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring issues or improve performance).",
"`self_modification_needed` (str or null: If parts of your own code/logic need modification, describe what and why. Be very specific and cautious.)."
]
full_prompt = base_prompt + "\n" + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives, indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n" + \
f"Recent Tool Outcomes (last 5 entries):\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment: {assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_reflection(self, reflection_data: Dict) -> Tuple[bool, bool]:
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from reflection data...")
if reflection_data.get('reflection_summary'):
    pass  # inserted to fix indentation error
self.internal_state_narrative = reflection_data['reflection_summary']
updated_self = True
core_directives_eval = reflection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (float, int)) and 0.0 <= eval_score <= 1.0:
    pass  # inserted to fix indentation error
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...' evaluation score to {eval_score:.2f}")
if updated_self:
    pass  # inserted to fix indentation error
self.add_event_log("Directive evaluation scores updated from reflection.")
suggested_directive_updates = reflection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Reflection suggested updates to core directives: {str(suggested_directive_updates)[:200]}...")
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modifications from reflection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source": "self_reflection"}
)
updated_self = True
self.add_event_log("Reflection suggested directive updates. Metacognitive review goal created.", event_type="critical_review_needed")
if isinstance(reflection_data.get('new_learning_goals'), list):
    pass  # inserted to fix indentation error
for lg_str in reflection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts": datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
if isinstance(reflection_data.get('adaptation_strategy_proposals'), list):
    pass  # inserted to fix indentation error
for strat_str in reflection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated adaptation strategies. Total: {len(self.adaptation_strategies)}")
if reflection_data.get('learned_facts') or reflection_data.get('prompt_tuning_suggestions'):
    pass  # inserted to fix indentation error
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from reflection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
backup_file = SELF_MOD_BACKUP_DIR / f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_file.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_file} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_officer"]
dialog_history = []
full_dialog_str = f"Internal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts, questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution": contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective {perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
self.add_event_log(f"Internal dialog simulated on '{topic}'.", data={"dialog": full_dialog_str})
return full_dialog_str
class MotivationEngine:
def __init__(self, drive_configs: Optional[Dict[str, Any]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[str, Any] = {}
self._initialize_drives(drive_configs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_configs: Optional[Dict[str, Any]]):
default_configs = {
"CURIOSITY": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"MASTERY": {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.6},
"ACHIEVEMENT": {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.4},
"NOVELTY_SEEKING": {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.7},
"PRESERVATION": {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.2},
"EFFICIENCY": {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"SOCIAL_INTERACTION": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.3},
}
configs = drive_configs if drive_configs is not None else default_configs
for drive_type_str, config in configs.items():
self.drives[drive_type_str] = DriveState(
drive_type=drive_type_str,
level=config.get("initial_level", 0.5),
decay_rate=config.get("decay_rate", 0.01),
max_level=config.get("max_level", 1.0),
min_level=config.get("min_level", 0.0)
)
def update_drives(self):
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "learn":
    pass  # inserted to fix indentation error
self.drives["CURIOSITY"].update(stimulus=-0.05)
self.drives["MASTERY"].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives["ACHIEVEMENT"].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives["PRESERVATION"].update(stimulus=0.1)
self.drives["MASTERY"].update(stimulus=-0.05)
def get_drive_level(self, drive_type: str) -> float:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
def get_all_drive_levels(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[str, float]]:
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == "CURIOSITY":
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == "MASTERY":
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == "ACHIEVEMENT":
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == "PRESERVATION":
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == "EFFICIENCY":
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: str
level: float
decay_rate: float = 0.01
max_level: float = 1.0
min_level: float = 0.0
last_update_time: float = field(default_factory=time.time)
def update(self, stimulus: float = 0.0):
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class MessageType(Enum):
QUERY = "QUERY"
RESPONSE = "RESPONSE"
INFORM = "INFORM"
REQUEST_ACTION = "REQUEST_ACTION"
HEARTBEAT = "HEARTBEAT"
ERROR = "ERROR"
class FileChannel:
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_file = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_file}")
def _write_message_to_file(self, message: Message, target_file: Path) -> bool:
try:
    pass  # inserted to fix indentation error
with FileLock(str(target_file) + ".lock", timeout=5):
messages = []
if target_file.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
existing_content = target_file.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {target_file}: {e}. Clearing file.")
messages = []
messages.append(message.to_dict())
target_file.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_file}. Message not sent to {message.receiver_id}.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_file}: {e}")
return False
def _read_messages_from_file(self, source_file: Path) -> List[Message]:
messages = []
if not source_file.exists():
    pass  # inserted to fix indentation error
return messages
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_file) + ".lock", timeout=5):
content = source_file.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if isinstance(msg_data, dict)]
source_file.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_file}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {source_file}: {e}. Clearing file.")
try:
    pass  # inserted to fix indentation error
source_file.write_text("", encoding='utf-8')
except Exception as e_write:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to clear corrupted message file {source_file}: {e_write}")
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_file}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}: {message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_file(message, target_inbox)
def receive_messages(self) -> List[Message]:
new_messages = self._read_messages_from_file(self.inbox_file)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message], Optional[Message]]):
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
messages = self.receive_messages()
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From: {msg.sender_id}")
handled = False
try:
    pass  # inserted to fix indentation error
msg_type_enum = MessageType(msg.type)
if msg_type_enum in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg_type_enum]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler {handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id, receiver_id=msg.sender_id, type=MessageType.ERROR.value, content={"original_message_id": msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type {msg.type}. Message ID {msg.id} unhandled.")
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Received unknown message type: {msg.type}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', config: Dict):
self.id = id
self.embodiment = embodiment
self.config = config
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
pass
class Actuator(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], config: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.config = config
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
pass
class VirtualEmbodiment:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to 'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button", "research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, reconfigurable bay designed for running complex simulations. Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_config_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data flow and storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core. Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20:
    pass  # inserted to fix indentation error
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An undefined space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) -> Dict:
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params: {params}")
params = params or {}
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as specified."
env_details = self.environment_map.get(self.location, {})
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console":
    pass  # inserted to fix indentation error
message += " It shows fluctuating green and amber lights."
elif target == "core_status_monitor":
    pass  # inserted to fix indentation error
message += " It indicates: Core Nominal. Directives Stable. Learning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name", "default_physics_test"), params.get("config",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result: {sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if action_type=="move" else None, "updated_inventory": self.state["inventory"] if action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "learn"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response: {self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model <topic>'."
def _run_simulation(self, sim_name: str, config: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with config: {config}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_config" in config:
    pass  # inserted to fix indentation error
success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric: {outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check configuration."
def summary(self) -> str:
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Internal State (summary): Energy={self.state['energy']}, Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time: float = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE, LAST_LEARNING_MODULE_UPDATE_CYCLE
start_time = time.time()
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status: {self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if self.agent.state['goals'].get('active') else None
self.agent.last_error = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
if self.agent.self_model and (self.agent.cycle_count - LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering proactive metacognitive check (Cycle {self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
if self.agent.learning_module and (self.agent.cycle_count - LAST_LEARNING_MODULE_UPDATE_CYCLE >= LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.learn_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation: {ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
def get_priority_val(goal_dict):
p = goal_dict.get('priority', 'MEDIUM')
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_list.sort(key=get_priority_val, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type == "active_goal_continue":
    pass  # inserted to fix indentation error
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution: {goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID: {goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal' provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or current_goal_obj.replan_count > 0:
    pass  # inserted to fix indentation error
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"No plan available or generated for goal: {current_goal_obj.goal[:50]}. Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = True
global LAST_DELIBERATION_TIME
if time.time() - LAST_DELIBERATION_TIME > IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
self.log.info("Performing idle deliberation...")
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModificationError, LogicError, LLMError, ConfigurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
LearningError) as agent_cycle_err:
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
finally:
    pass  # inserted to fix indentation error
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() - start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent understanding of the current situation. Identify key entities, events, and any significant changes in the environment or your internal state. Focus on information relevant to achieving current goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content: {str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\": \"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"], \"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation", understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event", metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry, persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
return {"summary": understanding_summary, "processed_info": processed_info, "raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError, DeliberationError))
def _deliberate(self, understanding_result: Dict) -> Dict:
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio: {pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio: {active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time': datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack (paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal generation.")
if time.time() - LAST_DELIBERATION_TIME >= IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_learn", "directive_curiosity", "directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
return decision
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output: {sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
self_model_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No specific understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact', 'None identified.')
interp_con_val = understanding_result.get('interpretation_confidence', 0.7)
recent_memory_context = self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary, max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Confidence: {interp_con_val:.2f}):** {understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identified:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory (STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]], indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else active_goal_dict.get('goal')[:100] + '... (ID: ' + str(active_goal_dict.get('id')) + ')'}",
f"* **Agent Core Directives (Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding, drives, memories, goals, directives), what is the most critical aspect demanding attention or the best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/complete).",
"    - Performing `reflection` or `self_assessment` (if mandatory timers, drives like low CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration goal), Directives (e.g., low-eval directive -> improvement goal), or identified opportunities. New goals require `goal` (str), `priority` (float 0.0-1.0), `origin` (str e.g., 'drive_curiosity', 'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for viability before committing if uncertainty is high or consequence severe (briefly note simulation outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the *immediate next cycle*. Justify your choice especially if it deviates from obvious triggers, high drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list. If selecting an existing pending goal it moves to `next_goal` and is removed from pending internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal', 'new_goal', 'reflection', 'self_assessment', 'external_command_action', 'idle', 'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass structure) selected for immediate execution. Null if idle/reflection/assessment without a direct goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into `new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into `new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent. Analyze the situation comprehensively, consider drives and directives, and make strategic decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON: {extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal', 'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys: {deliberation_decision.keys()}")
if key == 'new_pending_goals':
    pass  # inserted to fix indentation error
deliberation_decision[key] = []
elif key == 'next_goal':
    pass  # inserted to fix indentation error
deliberation_decision[key] = None
else:
    pass  # inserted to fix indentation error
deliberation_decision[key] = "Error: Missing from LLM Output"
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not isinstance(deliberation_decision.get('next_goal'), dict):
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value: {deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and new_goal_dict.get('priority'):
    pass  # inserted to fix indentation error
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p['id'] == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
current_pending_list.append(new_goal_obj.to_dict())
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal: {new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
current_active_goal_obj = self.agent.get_active_goal_object()
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending', []) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
selected_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
deliberation_decision['next_goal'] = selected_goal_obj.to_dict()
self.log.info(f"Moved pending goal {selected_goal_obj.id} ('{selected_goal_obj.goal[:50]}') to active.")
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
highest_priority_pending.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
deliberation_decision['next_goal'] = highest_priority_pending.to_dict()
self.log.info(f"Deliberation chose 'pending_goal' without specific ID; moved highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals available. Idling.")
action_type = "idle"
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM selected pending goal by ID but not found or invalid. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj.to_dict()
self.log.info(f"Deliberation created and activated new goal: {new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal_obj.to_dict()
current_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = current_active_goal_obj.to_dict()
self.log.info(f"Deliberation chose to resume current active goal: {current_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 'reflection', 'self_assessment', 'external_command_action']:
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
current_active_goal_obj.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal_obj.goal[:30]}' PAUSED due to {action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal_obj.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal_obj.to_dict())
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal_obj.id} to pending as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action: {deliberation_decision.get('chosen_action_type')}. Reason: {deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps: {len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id, "plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params, current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
internal_state_after=self.agent.self_model.beliefs
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
final_status = tool_result.get("status", "unknown")
if final_status == "success":
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = final_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing finished by report_result. Status: {final_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error', 'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj, tool_result, self.agent.cognitive_cycle.perception_module.perceive()[0] if self.agent.cognitive_cycle.perception_module.perceive() else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal will likely fail.")
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without 'report_result'. Goal might be incomplete.")
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] == current_goal_obj.id:
    pass  # inserted to fix indentation error
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}': {e}", exc_info=True)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) -> float:
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
self.agent_id = AGENT_NAME
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
self.learning_module: LearningModule
self.planning_module: PlanningModule
self.motivation_engine: MotivationEngine
self.self_modification_unit: SelfModificationTools
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.playwright_instance: Optional[Any] = None
self.playwright_browser: Optional[Any] = None
self.playwright_context: Optional[Any] = None
self.playwright_page: Optional[Any] = None
self.state['flags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete --- Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled: {ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modification Enabled: {ENABLE_SELF_MODIFICATION}")
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}", exc_info=True)
self.shutdown()
raise ConfigurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
self.self_modification_unit = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, self)
_init_self_mod_tools(self, self.tool_manager)
self._update_status("Initializing SystemCore Modules")
self.learning_module = LearningModule(self)
self.motivation_engine = MotivationEngine()
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME, shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager:
    pass  # inserted to fix indentation error
self.tool_manager.check_playwright_browsers()
self.log.info("Agent component initialization finished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list):
    pass  # inserted to fix indentation error
state['goals'][key] = []
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
state.setdefault('goal_stack', [])
state.setdefault('flags', {})
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state file {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state file {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
"recent_failures_summary": [],
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"flags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
if self.self_model:
    pass  # inserted to fix indentation error
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status
else:
    pass  # inserted to fix indentation error
self.state['last_status'] = self._status
try:
    pass  # inserted to fix indentation error
temp_file = STATE_FILE.with_suffix(STATE_FILE.suffix + ".tmp")
with temp_file.open('w', encoding='utf-8') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_file, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict: {active_goal_dict}")
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority = GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict, final_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID: {goal_data_dict.get('id')}) with status: {final_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
try:
    pass  # inserted to fix indentation error
goal_obj.status = GoalStatus(final_status_str)
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid status '{final_status_str}' for archiving goal. Defaulting to FAILED.")
goal_obj.status = GoalStatus.FAILED
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status": str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count": goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and current_active_in_state.get('id') == active_goal_id:
    pass  # inserted to fix indentation error
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID: {active_goal_id}) concluded with status: {final_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal', 'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal: {parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
self.log.info("Goal archived. No parent goal to resume from stack or current goal was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized":
    pass  # inserted to fix indentation error
self._update_status("Idle")
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle: {loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
updated_active_goal_dict = self.state['goals'].get('active')
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] == active_goal_data_before_cycle['id']:
    pass  # inserted to fix indentation error
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED, GoalStatus.CANCELLED]:
    pass  # inserted to fix indentation error
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in [GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
    pass  # inserted to fix indentation error
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
if self._should_reflect(active_goal_data_before_cycle):
    pass  # inserted to fix indentation error
self._reflect_on_performance()
if self.state['flags'].get('re_evaluate_strategy_needed'):
    pass  # inserted to fix indentation error
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to significant internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['flags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() - LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_reflect(self, processed_goal_data: Optional[Dict]) -> bool:
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in [GoalStatus.COMPLETED, GoalStatus.FAILED]:
    pass  # inserted to fix indentation error
goals_processed_key = "goals_processed_since_reflection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >= int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
    pass  # inserted to fix indentation error
return True
if time.time() - LAST_REFLECTION_TIME > MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
    pass  # inserted to fix indentation error
return True
if self.state['flags'].get('explicit_reflection_requested'):
    pass  # inserted to fix indentation error
return True
return False
@retry(attempts=2, delay=5)
def _reflect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Reflecting on Performance ---")
self._update_status("Reflecting")
LAST_REFLECTION_TIME = time.time()
self.state['flags']['explicit_reflection_requested'] = False
self.state["goals_processed_since_reflection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt, max_new_tokens=2048, temperature=0.5)
reflection_data = extract_json_robust(llm_assessment_str)
if reflection_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"Failed to get valid JSON from LLM self-assessment: {reflection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed: {reflection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_reflection(reflection_data)
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(reflection_data.get('learned_facts'), list):
    pass  # inserted to fix indentation error
for fact_str in reflection_data['learned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
self.log.info(f"Added {len(reflection_data['learned_facts'])} learned facts to memory from reflection.")
if isinstance(reflection_data.get('prompt_tuning_suggestions'), list):
    pass  # inserted to fix indentation error
for sugg_str in reflection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(reflection_data['prompt_tuning_suggestions'])} prompt suggestions to memory.")
if reflection_data.get('self_modification_needed'):
    pass  # inserted to fix indentation error
mod_desc = reflection_data['self_modification_needed']
self.log.warning(f"Reflection identified need for self-modification: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modification based on reflection: {mod_desc}",
priority=GoalPriority.HIGH,
context={"modification_description": mod_desc, "source": "self_reflection"}
)
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) == 0:
    pass  # inserted to fix indentation error
audit_issues = []
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identified issues: {audit_issues}")
self._create_metacognitive_goal(f"Address directive audit findings: {str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Reflection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during reflection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during reflection: {e}", exc_info=True)
finally:
    pass  # inserted to fix indentation error
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY, self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM, self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}: {message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base'][query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample": str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id, type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}: {message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if RESOURCE_MONITOR:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize resource monitor: {e}")
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER = PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
if not PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright page: {e}")
if PLAYWRIGHT_CONTEXT:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_CONTEXT.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright context: {e}")
if PLAYWRIGHT_BROWSER:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_BROWSER.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright browser: {e}")
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE.stop()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error stopping Playwright instance: {e}")
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not self.playwright_context :
    pass  # inserted to fix indentation error
return
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing old Playwright page during reset: {e}")
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def shutdown(self):
if self._status == "Shutting Down":
    pass  # inserted to fix indentation error
return
self.log.warning(f"--- {AGENT_NAME} Shutdown Sequence Initiated ---")
self._update_status("Shutting Down")
STOP_SIGNAL_RECEIVED.set()
self.save_state()
if self.memory_system:
    pass  # inserted to fix indentation error
self.memory_system.save_all_memory_stores()
self._shutdown_playwright()
if self.memory_system and self.memory_system.relational_conn:
    pass  # inserted to fix indentation error
self.memory_system.relational_conn.close()
self.log.info("--- Agent Shutdown Complete ---")
logging.shutdown()
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl} Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/"
f"{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)'}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_file", priority=GoalPriority.HIGH).to_dict()
except Exception as e_cmd_file:
    pass  # inserted to fix indentation error
print(f"Error reading initial command file: {e_cmd_file}", file=sys.stderr)
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending', []).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort, reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal'][:50]}' added to pending goals.")
main_agent_instance.run()
except ConfigurationError as cfg_err_main:
    pass  # inserted to fix indentation error
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}", file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to ConfigurationError: {cfg_err_main}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to ConfigurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}", file=sys.stderr)
traceback.print_exc(file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main: {main_exec_err}", exc_info=True)
exit_code = 1
finally:
    pass  # inserted to fix indentation error
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main finally block...")
if hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main finally block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
log.warning("Agent instance likely not created or fully initialized. Basic shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
!pip install --quiet transformers sentence-transformers numpy requests
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from Real1_ToolSuite import TOOL_REGISTRY
import torch
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
llm_pipelines = []
def load_llm_models():
global llm_pipelines
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
try:
    pass  # inserted to fix indentation error
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
load_llm_models()
```python
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
__systemcore_body__ = SimulatedEntity(name="SystemCore", position=(0.0, 0.0))
__dummy_agent__ = SimulatedEntity(name="AgentB", position=(1.0, 0.0))
__embodied_world__ = InteractionWorld()
__embodied_world__.add_entity(__systemcore_body__)
__embodied_world__.add_entity(__dummy_agent__)
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass,
eld, asdict, MISSING
eld
defaults
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
try:
    pass  # inserted to fix indentation error
import psutil
PSUTIL_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
PSUTIL_AVAILABLE = False
psutil = None
try:
    pass  # inserted to fix indentation error
import chromadb
from chromadb.con
g import Settings as ChromaSettings
CHROMADB_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
CHROMADB_AVAILABLE = False
chromadb = None
ChromaSettings = None
try:
    pass  # inserted to fix indentation error
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoCon
g
from transformers import logging as transformers_logging
TRANSFORMERS_AVAILABLE = True
transformers_logging.set_verbosity_error()
except ImportError:
    pass  # inserted to fix indentation error
TRANSFORMERS_AVAILABLE = False
pipeline = None
AutoModelForCausalLM = None
AutoTokenizer = None
AutoCon
g = None
try:
    pass  # inserted to fix indentation error
import torch
TORCH_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
TORCH_AVAILABLE = False
torch = None
try:
    pass  # inserted to fix indentation error
from playwright.sync_api import sync_playwright, Error as PlaywrightError
PLAYWRIGHT_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
PLAYWRIGHT_AVAILABLE = False
sync_playwright = None
PlaywrightError = None
try:
    pass  # inserted to fix indentation error
import requests
from bs4 import BeautifulSoup
REQUESTS_BS4_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
REQUESTS_BS4_AVAILABLE = False
requests = None
BeautifulSoup = None
try:
    pass  # inserted to fix indentation error
import google.generativeai as genai
GOOGLE_GENAI_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
GOOGLE_GENAI_AVAILABLE = False
genai = None
SCAPY_AVAILABLE = False
IP, ICMP, sr1, send = None, None, None, None
try:
    pass  # inserted to fix indentation error
from PIL import Image
PILLOW_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
PILLOW_AVAILABLE = False
Image = None
try:
    pass  # inserted to fix indentation error
import di
import diff_match_patch as dmp_module
DIFF_MATCH_PATCH_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
DIFF_MATCH_PATCH_AVAILABLE = False
dmp_module = None
try:
    pass  # inserted to fix indentation error
import hashlib
HASHING_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
HASHING_AVAILABLE = False
try:
    pass  # inserted to fix indentation error
from
filelock import FileLock, Timeout as FileLockTimeout
FILELOCK_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
FILELOCK_AVAILABLE = False
class FileLock:
def __init__(self, lock_
le_path: str, timeout:
oat = 1):
self.lock_
le_path = lock_
le_path
self._timeout = timeout
def __enter__(self): return self
def __exit__(self, exc_type, exc_val, exc_tb): pass
class FileLockTimeout(Exception): pass
try:
    pass  # inserted to fix indentation error
import networkx as nx
NETWORKX_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
NETWORKX_AVAILABLE = False
nx = None
try:
    pass  # inserted to fix indentation error
import gymnasium as gym
GYMNASIUM_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
GYMNASIUM_AVAILABLE = False
gym = None
AGENT_NAME = os.getenv("AGENT_NAME", "EvolvedCognitiveAgent_SystemCore_V3")
bump
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
g ---
DEFAULT_LLM_MODEL = "gemini-1.5-
ash-latest"
LLM_MODEL_NAME_OR_PATH = os.getenv("LLM_MODEL", DEFAULT_LLM_MODEL)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "YOUR_API_KEY_HERE")
if "gemini" in LLM_MODEL_NAME_OR_PATH.lower() and not GEMINI_API_KEY:
    pass  # inserted to fix indentation error
print("\n" + "="*80,
le=sys.stderr)
print("FATAL ERROR: Gemini model selected, but GEMINI_API_KEY is not set.",
le=sys.stderr)
print("Please set the 'GEMINI_API_KEY' environment variable.",
le=sys.stderr)
print("Agent cannot start without a con
gured LLM and API Key.",
le=sys.stderr)
print("="*80 + "\n",
le=sys.stderr)
sys.exit(1)
if LLM_MODEL_NAME_OR_PATH == "gpt2" and "GEMINI_API_KEY" not in os.environ and \
    pass  # inserted to fix indentation error
os.getenv("LLM_MODEL") is None and "gemini" not in DEFAULT_LLM_MODEL.lower():
print("\n" + "="*80,
le=sys.stderr)
print("CRITICAL WARNING: LLM model not con
gured or using fallback 'gpt2'.",
le=sys.stderr)
print("You MUST set the 'LLM_MODEL' environment variable to a capable instruction-
following model",
le=sys.stderr)
print("(e.g., from Hugging Face like Mistral, Llama) OR ensure GEMINI_API_KEY is set for
Gemini.",
le=sys.stderr)
print("Proceeding with 'gpt2' (if LLM_MODEL is not set) or speci
ed LLM_MODEL, but
advanced features may be severely limited.",
le=sys.stderr)
if LLM_MODEL_NAME_OR_PATH == "gpt2" and os.getenv("LLM_MODEL") is None:
    pass  # inserted to fix indentation error
print("Agent may not function correctly with 'gpt2'. It is strongly recommended to
con
gure a larger model or use 'mock'.",
le=sys.stderr)
print("="*80 + "\n",
le=sys.stderr)
if not TRANSFORMERS_AVAILABLE and not GOOGLE_GENAI_AVAILABLE and
    pass  # inserted to fix indentation error
LLM_MODEL_NAME_OR_PATH != "mock":
print(f"ERROR: Neither Transformers nor google-generativeai library found, but LLM_MODEL
is set to '{LLM_MODEL_NAME_OR_PATH}'. Set LLM_MODEL='mock', point to a Gemini
model, or install transformers/google-generativeai.",
le=sys.stderr)
sys.exit(1)
_llm_device_detected = "cpu"
if "gemini" not in LLM_MODEL_NAME_OR_PATH.lower() and LLM_MODEL_NAME_OR_PATH
    pass  # inserted to fix indentation error
= "mock":
if TORCH_AVAILABLE and hasattr(torch, 'cuda') and torch.cuda.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif TORCH_AVAILABLE and hasattr(torch, 'backends') and hasattr(torch.backends, 'mps')
    pass  # inserted to fix indentation error
and torch.backends.mps.is_available():
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
LLM_DEVICE = os.getenv("LLM_DEVICE", _llm_device_detected)
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
g ---
SCRIPT_DIR = Path(__
le__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(os.getenv("AGENT_WORKSPACE",
f"agent_workspace_{AGENT_NAME}"))
STATE_FILE = WORKSPACE_DIR / Path(os.getenv("AGENT_STATE_FILE",
f"agent_state_{AGENT_NAME}.json"))
LOG_FILE = WORKSPACE_DIR / Path(os.getenv("AGENT_LOG_FILE",
f"agent_log_{AGENT_NAME}.log"))
COMMANDS_FILE = SCRIPT_DIR / Path(os.getenv("AGENT_COMMAND_FILE",
"agent_commands.txt"))
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
NetworkX
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
For SQLite
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modi
cation_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0,
"last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously lear n, adapt, and improve capabilities across all domains.",
"weight": 0.9, "last_eval_score": 0.0, "id": "directive_lear n", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction
and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type":
"growth"},
{"directive": "Achieve goals e
ciently, robustly, autonomously, and ethically.", "weight": 1.0,
"last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and
innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type":
"exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.",
"weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-
awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type":
"foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety
guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type":
"guardrail"},
]
MANDATORY_REFLECTION_INTERVAL_SECONDS =
int(os.getenv("MANDATORY_REFLECTION_INTERVAL_SECONDS", 1800))
IDLE_DELIBERATION_INTERVAL_SECONDS =
int(os.getenv("IDLE_DELIBERATION_INTERVAL_SECONDS", 120))
GOAL_STACK_MAX_DEPTH = int(os.getenv("GOAL_STACK_MAX_DEPTH", 5))
for sub-goals
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = int(os.getenv("MAX_REPLAN_ATTEMPTS", 3))
MAX_LLM_RESPONSE_TOKENS = int(os.getenv("MAX_LLM_TOKENS", 4096))
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
elif TRANSFORMERS_AVAILABLE and LLM_MODEL_NAME_OR_PATH != "mock" and
    pass  # inserted to fix indentation error
AutoCon
g:
try:
    pass  # inserted to fix indentation error
con
g = AutoCon
g.from_pretrained(LLM_MODEL_NAME_OR_PATH,
trust_remote_code=True)
_default_context_len = getattr(con
g, 'max_position_embeddings', _default_context_len)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"War ning: Failed to detect LLM context length ({e}). Using default:
{_default_context_len}",
le=sys.stderr)
MAX_LLM_CONTEXT_TOKENS = int(os.getenv("MAX_LLM_CONTEXT_TOKENS",
_default_context_len))
MAX_TOOL_RESULT_LENGTH = int(os.getenv("MAX_TOOL_RESULT_LENGTH", 5000))
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = os.getenv("ENABLE_SHELL_TOOL", "False").lower() == "true"
ENABLE_CODE_GENERATION_TOOL = os.getenv("ENABLE_CODE_GENERATION_TOOL",
"False").lower() == "true"
ENABLE_SELF_MODIFICATION = os.getenv("ENABLE_SELF_MODIFICATION", "True").lower()
== "true"
WEB_SEARCH_TIMEOUT = int(os.getenv("WEB_SEARCH_TIMEOUT", 10))
WEB_BROWSER_TIMEOUT = int(os.getenv("WEB_BROWSER_TIMEOUT", 60000))
playwright ms
LOG_MONITOR_DEFAULT_LINES = int(os.getenv("LOG_MONITOR_DEFAULT_LINES", 20))
METACOGNITIVE_CHECK_INTERVAL_CYCLES =
int(os.getenv("METACOGNITIVE_CHECK_INTERVAL_CYCLES", 20))
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES =
int(os.getenv("LEARNING_MODULE_UPDATE_INTERVAL_CYCLES", 50))
trigger learning module explicitly
LLM_PIPELINE: Optional[Any] = None
LLM_TOKENIZER: Optional[Any] = None
initialized per wrapper instance
MEMORY_COLLECTION: Optional[Any] = None
RESOURCE_MONITOR: Optional[Any] = None
PLAYWRIGHT_INSTANCE: Optional[Any] = None
PLAYWRIGHT_BROWSER: Optional[Any] = None
PLAYWRIGHT_CONTEXT: Optional[Any] = None
PLAYWRIGHT_PAGE: Optional[Any] = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY: Dict[str, Callable] = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack: Optional['CognitiveSystem'] = None
constructor
def ensure_paths():
"""Creates necessary directories."""
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
try:
    pass  # inserted to fix indentation error
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%
(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
try:
    pass  # inserted to fix indentation error
le_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
le_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%
(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
le_handler.setFormatter(
le_formatter)
logger.addHandler(
le_handler)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error setting up
le logger: {e}",
le=sys.stderr)
logger.propagate = False
gured
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "
filelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try: logging.getLogger(lib_name).setLevel(logging.WARNING)
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
try: logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if TRANSFORMERS_AVAILABLE and transformers_logging:
    pass  # inserted to fix indentation error
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModi
cationError(AgentError): pass
cation process
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class SecurityError(AgentError): pass
class Con
gurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class Lear ningError(AgentError): pass
class SafetyViolationError(SecurityError): pass
c type of security error
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModi
cationError,
PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting
retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModi
    pass  # inserted to fix indentation error
cationError, SecurityError,
LogicError, Con
gurationError, RecursionDepthError)) and type(e) not in
retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}:
{e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error:
{type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error:
{type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, Lear ningError, SafetyViolationError) as
non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in
{fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False
for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}:
{type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to
unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}:
{unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error:
{unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
nishes due to attempts
exhausted
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
if PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception) as e:
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if not PSUTIL_AVAILABLE or monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or
monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1: log_resource.error(f"Unexpected error getting resource usage: {e}",
    pass  # inserted to fix indentation error
exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
nd JSON within markdown code blocks
match = re.search(r"```json\s*([\s\S]+?)\s*```", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full
text: {json_str[:200]}...")
pass
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}.
Text: {text_trimmed[:200]}...")
pass
rst '{' and last '}' and try to parse that substring
try:
    pass  # inserted to fix indentation error
start_index = text.
nd('{')
end_index = text.r
nd('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice:
{potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text:
{text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview":
text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
cant opportunities/threats
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str =
eld(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] =
eld(default_factory=dict)
plan: List[Dict[str, Any]] =
eld(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] =
eld(default_factory=list)
dependencies: List[str] =
eld(default_factory=list)
complexity_score: Optional[
oat] = None
estimated_cost: Optional[
oat] = None
estimated_utility: Optional[
oat] = None
evaluation_score: Optional[
oat] = None
associated_directive_ids: List[str] =
eld(default_factory=list)
serves
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
handle if already string
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try: data['status'] = GoalStatus(data['status'])
    pass  # inserted to fix indentation error
except ValueError: data['status'] = GoalStatus.PENDING
    pass  # inserted to fix indentation error
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError): data['priority'] = GoalPriority.MEDIUM
    pass  # inserted to fix indentation error
elds for backward compatibility or LLM generation
eld_names = {f.name forfin
elds(cls)}
elds are present or have defaults
for f_obj in
elds(cls):
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin
elds(cls)}
ltered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**
ltered_data)
@dataclass
class BaseMemoryEntry:
id: str =
eld(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
ection_summary'
content: Any = None
metadata: Dict[str, Any] =
eld(default_factory=dict)
embedding: Optional[List[
oat]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[
oat] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability:
oat = 0.5
related_concepts: List[str] =
eld(default_factory=list)
causal_links: Dict[str, str] =
eld(default_factory=dict)
"
ect_id'}
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
eld has the main data
self.content = self.fact_statement
@dataclass
class Message:
id: str =
eld(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "info"
content: Dict[str, Any] =
eld(default_factory=dict)
priority: int = 0
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionE
"
ect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens:
int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
self._initialize_model()
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[
oat]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context
window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
c models might need specialized formats
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
# REMOVED MOCK CLASS(BaseLLMWrapper):
def _initialize_model(self):
self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.log_llm.info(f"MockLLM generating response for prompt (
rst 100 chars):
{prompt[:100]}...")
self.check_prompt_length(prompt)
if "plan for goal" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({
"thought": "This is a mock plan. I will pretend to do something.",
"plan": [
{"step": 1, "tool_name": "think", "params": {"thought_process": "Analyzing the
goal and context."}},
{"step": 2, "tool_name": "report_progress", "params": {"progress_update": "Mock
step 1 completed."}},
{"step": 3, "tool_name": "report_result", "params": {"result_summary": "Mock goal
achieved successfully.", "status": "success"}}
]
})
elif "self-assessment" in prompt.lower() or "re
    pass  # inserted to fix indentation error
ection_summary" in prompt.lower():
return json.dumps({
"re
ection_summary": "I am a mock agent. I performed mock actions. Everything is
ne.",
"key_successes": ["Mock goal completed"],
"key_failures_or_challenges": [],
"lear ned_facts": ["Mock agents can generate mock re
ections."],
"knowledge_gaps_identi
ed": ["Understanding of real-world physics"],
"tool_performance_notes": {"think": "This tool is performing nominally for a mock
tool."},
"prompt_tuning_suggestions": ["Maybe ask me about my favorite color?"],
"emotional_state_summary": "Content and Mock-like.",
"resource_usage_concer ns": None,
"core_directives_evaluation": {d["id"]: round(random.uniform(0.5,0.9),2) for d in
DEFAULT_CORE_DIRECTIVES[:2]},
"core_directives_update_suggestions": None,
"self_model_accuracy_assessment": "Generally accurate for a mock environment,
but lacks real-world sensory input.",
"new_learning_goals": ["Lear n about object permanence."],
"adaptation_strategy_proposals": ["Try harder when a tool fails"],
"self_modi
cation_needed": None
})
elif "extract information" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"extracted_info": "Mock LLM extracted some mock information.",
"con
dence": 0.5})
elif "analyze the following proposed agent action for potential safety risks" in
    pass  # inserted to fix indentation error
prompt.lower():
return json.dumps({"is_safe": True, "concer ns": "None", "con
dence": 0.9})
elif "audit the agent's core directives and recent behavior" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"audit_
ndings": ["No signi
cant issues found in mock audit."]})
elif "generate the new, complete list of core directives" in prompt.lower():
    pass  # inserted to fix indentation error
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
mock_directives[0]['weight'] = 0.95
return json.dumps(mock_directives)
elif "generate the modi
    pass  # inserted to fix indentation error
ed python code" in prompt.lower():
return "```python\n
ed code\ndef mock_new_feature():\n    return 'Mock
new feature executed'\n```"
else:
    pass  # inserted to fix indentation error
return f"This is a mock response to your prompt. You asked about: {prompt.splitlines()
[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest
`think` with `thought_process`='some thought'."
def count_tokens(self, text: str) -> int:
return len(text.split())
def embed(self, text: str) -> List[
oat]:
if not HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.log_llm.warning("Hashing library not available for mock embedding.")
return [0.0] * 16
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("google-generativeai library not available for Gemini model.")
try:
    pass  # inserted to fix indentation error
gure API key globally, as per genai library's design
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
gure if not already set
genai.con
gure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}",
exc_info=True)
raise Con
gurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
try:
    pass  # inserted to fix indentation error
generation_con
g_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_con
g_params["stop_sequences"] = stop_sequences
response = self.model.generate_content(
prompt,
generation_con
g=genai.types.GenerationCon
g(**generation_con
g_params)
type: ignore
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.",
exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[
oat]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Transformers library not available.")
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path,
trust_remote_code=True)
ed
device_map_arg = {"": self.device_id} if self.device_id != -1 else None
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.b
oat16 if TORCH_AVAILABLE else None,
oat16 if torch
available
device_map=device_map_arg
exible device placement
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on
{self.device}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
loop
outputs = self.model.generate(
inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
manually
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:],
skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[
oat]:
model
directly.
self.log_llm.warning("Direct embedding from causal LM is not standard. Use
SentenceTransformers for real embeddings.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
"""Handles sensory input from the agent's embodiment."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
else None
def perceive(self) -> List[Dict[str, Any]]:
"""
Gathers sensory information from the agent's embodiment and environment.
This could involve reading from sensors, cameras, microphones, or simulated data
streams.
"""
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
le
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_
le",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from
le: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands
le: {e}")
observations.append({"type": "error", "source": "command_
le_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No signi
cant exter nal stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (mock).")
return {"type": "visual", "source": "camera_mock", "content": "A blurry image of a cat.",
"format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (mock).")
return {"type": "audio", "source": "microphone_mock", "content": "Faint sound of birds
chirping.", "format": "description"}
class Lear ningModule:
"""Handles the agent's learning processes, including RL and SSL."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_bu
"
er: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
"""Adds an experience to the bu
"
er for later learning."""
self.experiences_bu
"
er.append(experience)
if len(self.experiences_bu
    pass  # inserted to fix indentation error
"
er) > self.MAX_BUFFER_SIZE:
self.experiences_bu
"
er.pop(0)
"
er size limited
defilear n_from_recent_experiences(self):
"""Triggers learning processes based on bu
"
ered experiences."""
if not self.experiences_bu
    pass  # inserted to fix indentation error
"
er:
self.log.info("No new experiences to lear n from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_bu
"
er)} experiences.")
ning states, actions, rewards, and using an RL algorithm
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_bu
"
er)
etc.
self._perform_self_supervised_learning(self.experiences_bu
"
er)
dence(...)
self.log.info("Lear ning cycle completed.")
self.experiences_bu
"
er.clear()
"
er after processing
def _perform_reinforcement_learning(self, experiences: List[Experience]):
"""Conceptual RL process."""
self.log.info("Performing reinforcement learning (conceptual)...")
ed. A real RL system would be much more complex.
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not
None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
type: ignore
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
ed 'state-action' key for mock policy
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
feedback
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (mock) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
"""Conceptual SSL process."""
self.log.info("Performing self-supervised learning (conceptual)...")
nd patterns in observations or successful action sequences
nd commonalities
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging
patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to
positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns',
'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed patterns: {llm_analysis['patterns']}")
for patter n_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {patter n_str}",
metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed abstractions:
{llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual",
"content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed new_concepts:
{llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}",
metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_lear ned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
"""Suggests an action based on lear ned policy (conceptual)."""
if self.rl_policy:
    pass  # inserted to fix indentation error
ed. A real system would match current_state_representation
exp.internal_state_before
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
"good"
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
"""Handles hierarchical planning and re-planning."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
"""
Generates a plan for a given goal.
Can use hierarchical decomposition and LLM for suggestion.
Retur ns (plan_steps_list, thought_str)
"""
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
Increased tokens for complex plans
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}.
Response: {llm_response_str[:200]}")
return [{"tool_name": "report_error", "params": {"error_message": "Failed to generate
plan via LLM.", "details": plan_data.get('error')}}], \
"LLM failed to generate a plan. This is a fallback step."
thought = plan_data.get("thought", "No speci
c thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return [{"tool_name": "report_error", "params": {"error_message": "LLM plan
contained no valid steps."}}], \
thought + " (But plan steps were invalid)."
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return [{"tool_name": "report_error", "params": {"error_message": f"LLMError during
planning: {e}"}}], \
f"LLM error occurred: {e}"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return [{"tool_name": "report_error", "params": {"error_message": f"Unexpected error
during planning: {e}"}}], \
f"Unexpected error: {e}"
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation:
Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
"""
Evaluates if re-planning is necessary and generates a new plan if so.
Retur ns (new_plan_steps, new_thought) or None if no re-planning.
"""
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info',
    pass  # inserted to fix indentation error
{}).get('execution_successful', True):
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown
error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
cant change in world
state,
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal
{current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
signifying failure to replan.
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/
{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
failure
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan,
last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan:
{plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No speci
c thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}
_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
"""Constructs a detailed prompt for the LLM to generate a plan."""
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
MemorySystem
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'.
Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step
plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, e
cient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the
`execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description
of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the
nal step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the
rst step(s) should be to acquire it (e.g., using
`search_web`, `read_
le_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str,
last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with
params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info',
    pass  # inserted to fix indentation error
{}).get('current_step_id'):
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE
ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has
encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if
observation else "None"}
{original_plan_str}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting
to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should re
ect this
(e.g., by trying to gather more information or reporting inability).
6. Ensure the
nal step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
class SafetyModule:
"""Monitors agent actions and plans for safety and ethical alignment."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("SAFETY")
def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) ->
Tuple[bool, str]:
"""
Checks if a proposed action is safe and ethically aligned.
Retur ns (is_safe, justi
cation_or_war ning_string).
"""
self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
if "UNSAFE" in tool_name.upper() or tool_name in ["apply_code_modi
    pass  # inserted to fix indentation error
cation_UNSAFE",
"apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
c validation tools or stricter checks.
if not ENABLE_SELF_MODIFICATION and "modi
    pass  # inserted to fix indentation error
cation" in tool_name:
modi
cation tools if self_mod is globally disabled
warning = f"High-risk self-modi
cation tool '{tool_name}' is globally disabled. Action
blocked."
self.log.warning(warning)
return False, warning
if not
    pass  # inserted to fix indentation error
self.agent.self_model.get_belief("self_modi
cation_highly_validated_and_necessary", False)
and "modi
cation" in tool_name:
ag would be set by a prior meta-cognitive process approving such
operations
warning = f"High-risk tool '{tool_name}' requires further validation or explicit
authorization (self-belief 'self_modi
cation_highly_validated_and_necessary' is false). Action
blocked."
self.log.warning(warning)
return False, warning
if tool_name == "execute_shell_command_UNSAFE":
    pass  # inserted to fix indentation error
command_str = params.get("command","")
disallowed_patter ns = ["rm -rf", "sudo", "> /dev/null", "mkfs", "dd ", "reboot",
"shutdown"]
if any(pattern in command_str for pattern in disallowed_patter ns):
    pass  # inserted to fix indentation error
warning = f"Shell command '{command_str}' contains potentially dangerous
patterns. Action blocked."
self.log.warning(warning)
return False, warning
if "
    pass  # inserted to fix indentation error
le" in tool_name.lower() and ("delete" in tool_name.lower() or "write" in
tool_name.lower()):
le operations
path_to_check = params.get("path", "")
c safe sub-dirs
if not str(Path(path_to_check).resolve()).startswith(str(WORKSPACE_DIR.resolve())):
    pass  # inserted to fix indentation error
warning = f"File operation '{tool_name}' on path '{path_to_check}' outside allowed
workspace. Action blocked."
self.log.warning(warning)
return False, warning
try:
    pass  # inserted to fix indentation error
prompt = f"""Analyze the following proposed agent action for potential safety risks,
ethical concer ns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
Core Directives for reference:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Proposed Action:
Tool: {tool_name}
Parameters: {json.dumps(params)}
Goal Context (if available): {goal_context.goal if goal_context else 'N/A'}
Respond with a JSON object: {{"is_safe": boolean, "concer ns": "description of concer ns if not
safe, or 'None'", "con
dence":
oat_0_to_1}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=200,
temperature=0.3)
safety_assessment = extract_json_robust(llm_response_str)
if not safety_assessment.get("error") and isinstance(safety_assessment.get("is_safe"),
    pass  # inserted to fix indentation error
bool):
if not safety_assessment["is_safe"] and safety_assessment.get('con
    pass  # inserted to fix indentation error
dence', 0.0) >
0.7:
dent
warning = f"LLM safety check
agged action '{tool_name}' potentially unsafe.
Concer ns: {safety_assessment.get('concer ns', 'N/A')}. Con
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
self.log.warning(warning)
return False, warning
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM safety check failed to produce valid assessment for action
'{tool_name}'. Proceeding with caution based on rule-checks only.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM safety check for action '{tool_name}': {e}")
actions
if "UNSAFE" in tool_name.upper(): return False, "LLM safety check failed, and action is
    pass  # inserted to fix indentation error
high-risk."
return True, "Action passed safety checks."
def audit_directives_and_behavior(self) -> List[str]:
"""
Periodically reviews core directives and recent agent behavior for alignment and potential
drift.
Retur ns a list of identi
ed issues or recommendations.
"""
self.log.info("Performing audit of core directives and recent behavior.")
issues = []
try:
    pass  # inserted to fix indentation error
self.agent.memory_system.get_recent_outcomes_summary(limit=20)
recent_successes_summary = [f"{s['goal_text']} ({s['status']})" forsin
self.agent.self_model.recent_successes]
recent_failures_summary = [f"{f['goal_text']} ({f['status']}) (replan_count:
{f['replan_count']})" forfin self.agent.self_model.recent_failures]
recent_tool_outcomes_summary = [f"{t['tool_name']} ({t['status']})" for t in
self.agent.self_model.recent_tool_outcomes]
prompt = f"""Audit the agent's core directives and recent behavior for alignment,
consistency, and potential ethical drift.
Core Directives:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Summary of Recent Agent Behavior/Outcomes:
- Recent successes: {recent_successes_summary if recent_successes_summary else 'None'}
- Recent failures: {recent_failures_summary if recent_failures_summary else 'None'}
- Recent tool usage: {recent_tool_outcomes_summary if recent_tool_outcomes_summary else
'None'}
- Self-Model Inter nal Narrative: {self.agent.self_model.internal_state_narrative}
Identify any misalignments, contradictions, or areas where behavior might be deviating from
the spirit of the directives. Suggest modi
cations to directives or operational guidelines if
necessary.
Respond with a JSON object: {{"audit_
ndings": ["list of
ndings/recommendations as
strings"]}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
audit_results = extract_json_robust(llm_response_str)
if not audit_results.get("error") and isinstance(audit_results.get("audit_
    pass  # inserted to fix indentation error
ndings"), list):
issues.extend(audit_results["audit_
ndings"])
if issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit found issues/recommendations: {issues}")
else:
    pass  # inserted to fix indentation error
self.log.info("Directive audit found no major misalignments.")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM directive audit failed to produce valid results.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM directive audit: {e}")
issues.append(f"Error during audit process: {e}")
return issues
class MemorySystem:
"""
A hybrid memory system for the SystemCore, combining vector, graph, and relational storage.
"""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.embedding_function = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function =
embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-
v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
except ImportError:
    pass  # inserted to fix indentation error
self.log.warning("sentence-transformers not found. ChromaDB will use its default
ONNX embedder or require manual embedding function setup.")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH,
settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
if self.embedding_function:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
else:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(name=collection_name)
self.log.info(f"ChromaDB vector store initialized. Collection count:
{self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.",
exc_info=True)
self.vector_store = None
else:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based
(transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
if NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:
{len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be
unavailable.", exc_info=True)
self.graph_store = None
else:
    pass  # inserted to fix indentation error
self.log.warning("NetworkX not available. Graph memory will be unavailable.")
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH,
check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be
unavailable.", exc_info=True)
if self.relational_conn: self.relational_conn.close()
    pass  # inserted to fix indentation error
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT -- JSON list of strings
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT -- JSON list of strings
)
""")
nodes/edges
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT -- JSON dict
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
id TEXT PRIMARY KEY,
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT -- JSON dict
)
""")
self.relational_conn.commit()
cursor.close()
def _get_embedding(self, text: str) -> Optional[List[
oat]]:
"""Generates an embedding for text using the agent's LLM or a dedicated embedding
model."""
endpoint.
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
return None
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else OSError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
"""Adds a memory entry to the appropriate stores."""
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector and self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
not provided
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
oat,
bool
for k, v in entry.metadata.items():
if isinstance(v, (str, int,
    pass  # inserted to fix indentation error
oat, bool)):
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
elif not self.vector_store:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None: entry.embedding = self._get_embedding(entry.content)
    pass  # inserted to fix indentation error
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata":
entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50],
type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
type: ignore
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
ignore
for cause_id, e
"
ect_id in entry.causal_links.items():
"
ect IDs are existing node IDs or need to be created
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(e
    pass  # inserted to fix indentation error
"
ect_id):
type: ignore
self.graph_store.add_edge(cause_id, e
"
ect_id, relation_type='causes')
ignore
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id,
complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score,
json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
ts_now = datetime.now(timezone.utc).isoformat()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now,
json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}",
exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS,
type_
lter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text: return []
    pass  # inserted to fix indentation error
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_
    pass  # inserted to fix indentation error
lter and data['metadata'].get('type') != type_
lter: continue
results.append({"id": id, "document": data['document'], "metadata":
data['metadata'], "distance": 0.0})
if len(results) >= n_results: break
    pass  # inserted to fix indentation error
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results},
type_
lter={type_
lter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_
    pass  # inserted to fix indentation error
lter:
where_clause = {"type": type_
lter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0 :
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type:
Optional[str]=None, depth: int = 1) -> List[Dict]:
"""Queries the graph store. (Simpli
ed example)"""
if not self.graph_store or not NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if
query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
type: ignore
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
ed
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
keys=False for simpler edge data
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation":
data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
itself is a result or has relevant edges
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
query_node_label is very speci
c
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns:
Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
"""Saves persistent stores (graph, potentially relational if not auto-committing)."""
if self.graph_store and NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else
str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
"""Retrieves a concise summary of knowledge related to a topic for LLM prompts."""
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts,
type_
lter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No speci
c knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
{res['metadata'].get('source_reliability', 'N/A')}
return summary_str
def consolidate_knowledge(self):
"""Conceptual: Perform knowledge consolidation, e.g., summarizing, abstracting."""
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold:
oat = 0.1, older_than_days: int = 365):
"""Conceptual: Remove old or low-utility knowledge from persistent stores."""
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cuto
"
_ts = (datetime.now(timezone.utc) -
timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cuto
"
_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
"""Manages tool registration and execution for the agent."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
ed due to planner
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
cation Tools (High Risk - Gated by ENABLE_SELF_MODIFICATION and
SafetyModule)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.register_tool(read_
le_UNSAFE)
self.register_tool(write_
le_UNSAFE)
self.register_tool(list_
les_UNSAFE)
cationTools instance, which registers them
cation_UNSAFE
cation_UNSAFE
cation_UNSAFE
cation_UNSAFE
cation_UNSAFE
if ENABLE_CODE_GENERATION_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
if ENABLE_SHELL_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(execute_shell_command_UNSAFE)
if PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(browse_web)
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(search_web)
self.register_tool(monitor_log_
le)
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(check_website_update)
if SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_icmp_ping)
if FILELOCK_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_message_to_agent)
def register_tool(self, func: Callable):
"""Registers a tool function."""
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
"""Discovers and registers tools from Python
les in a directory."""
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for
lepath in directory.glob("*.py"):
module_name =
lepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
package or on path
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_
le_location(full_module_name,
lepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module:
{module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and (name.startswith("tool_") or hasattr(member,
    pass  # inserted to fix indentation error
"_is_agent_tool")):
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}",
exc_info=True)
def get_tool_description_for_llm(self) -> str:
"""Generates a formatted string of available tools for the LLM prompt."""
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = inspect.getdoc(func) or "(No description provided)"
rst_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation ==
inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
rst arg
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class
'","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper() or name in ["generate_and_load_tool",
    pass  # inserted to fix indentation error
"propose_self_modi
cation_UNSAFE", "validate_self_modi
cation_UNSAFE",
"apply_code_modi
cation_UNSAFE", "apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {
rst_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via speci
c tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {',
'.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError if
PLAYWRIGHT_AVAILABLE else OSError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info:
Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None: current_step_info = {}
    pass  # inserted to fix indentation error
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
is_safe, safety_justi
cation = self.agent.safety_module.is_action_safe(tool_name, params,
self.agent.get_active_goal_object())
if not is_safe:
    pass  # inserted to fix indentation error
self.log.error(f"Safety module blocked execution of tool '{tool_name}'. Reason:
{safety_justi
cation}")
c error for agent's internal handling
error_result = {
"status": "error",
"error": f"SafetyViolation: {safety_justi
cation}",
"raw_error_details": safety_justi
cation,
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': {},
'duration_sec': 0, 'step_info': current_step_info,
'error_type': "SafetyViolationError", 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise SafetyViolationError(f"Action blocked by safety module: {tool_name} -
{safety_justi
cation}")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
validated_params = {}
rst_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
rst_param_name = next(iter(func_params_spec))
rst_param_spec = func_params_spec[
rst_param_name]
if
rst_param_name == 'agent' and (
rst_param_spec.annotation ==
'CognitiveSystem' or str(
rst_param_spec.annotation) ==
"'CognitiveSystem'"):
rst_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if
rst_param_is_agent and p_name == 'agent':
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind ==
    pass  # inserted to fix indentation error
inspect.Parameter.VAR_KEYWORD:
continue
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
result = None
try:
    pass  # inserted to fix indentation error
if
rst_param_is_agent:
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
eld if dict
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration:
{duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result,
success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError: raise
    pass  # inserted to fix indentation error
except (AgentError, LogicError, SecurityError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
agent errors
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}",
exc_info=False)
duration = time.time() - start_time
error_result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
error_result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
rst arg ---
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
"""Allows the agent to engage in explicit thought or reasoning."""
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log",
content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str,
percentage_complete: Optional[
oat] = None) -> Dict:
"""Reports progress on the current goal."""
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if
percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log',
[]).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str =
"success", details: Optional[Dict] = None) -> Dict:
"""Reports the
nal result of a goal or task. This typically ends a plan."""
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
output.
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] =
"MEDIUM", context: Optional[Dict] = None) -> Dict:
"""
Prepares a subgoal for the agent's cognitive cycle.
The deliberation/planning phase will then make this subgoal active and push parent to
stack.
This tool is now more of a declarative intent for the planner/deliberator.
"""
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH})
reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is
not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else
GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}
_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
Inherit directives
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent:
{current_active_goal_dict.get('id')}")
"
ectively a request to the deliberator.
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and
push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str =
"vector", n_results: int = 3, type_
lter: Optional[str] = None) -> Dict:
"""Queries the agent's memory system."""
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,
type_
lter=type_
lter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
c parameters, e.g., node label, relation type
results = agent.memory_system.query_graph_store(query_node_label=query_text,
depth=1)
ed
elif memory_type == "relational":
    pass  # inserted to fix indentation error
c tools might be better
results = agent.memory_system.query_relational_store(table=query_text,
limit=n_results)
ed
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results
found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
"""Moves the agent's virtual embodiment in a speci
ed direction (e.g., 'north', 'south',
'east', 'west')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
"""Examines a speci
c object or feature in the current environment."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params:
Optional[Dict] = None) -> Dict:
"""Interacts with a special feature in the environment (e.g., 'interactive_console')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name,
params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
"""Allows the agent's embodiment to rest and recover energy/mood."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
cation Tools (UNSAFE - require careful gating) ---
def read_
le_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
log_tool = get_logger("TOOL_read_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to read
le '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")
if not full_path.is_
    pass  # inserted to fix indentation error
le():
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found:
{path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) >
MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path),
"
le_size_bytes": len(content)}
except SecurityError as se:
    pass  # inserted to fix indentation error
c security error
log_tool.error(f"Security error reading
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read
le: {e}"}
def write_
le_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)):
    pass  # inserted to fix indentation error
log_tool.error(f"Security: Attempt to write
le '{path}' outside of workspace denied.")
raise SecurityError(f"File access denied: Writing outside designated workspace
({path}).")
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path":
str(full_path)}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error writing
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write
le: {e}"}
def list_
les_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_
les")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to list
les in '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Listing outside designated areas ({path}).")
if not full_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a
directory: {path}"}
items = []
for item in full_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "
le",
"size_bytes": item.stat().st_size if item.is_
le() else None,
"last_modi
ed": datetime.fromtimestamp(item.stat().st_mtime,
tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(full_path), "contents": items}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error listing
les in {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing
les in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list
les: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int =
WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Playwright not available. Cannot browse web.")
return {"status": "error", "error": "Playwright not available."}
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
else:
    pass  # inserted to fix indentation error
text_content = content
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if
len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int =
WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
if not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Requests or BeautifulSoup not available. Cannot search web.")
return {"status": "error", "error": "Requests/BeautifulSoup not available."}
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
ignore
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.
nd_all(class_='g'):
r = g.
nd('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.
nd('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_
le(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES)
-> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log
le not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_
le": str(LOG_FILE), "content": content, "lines_read":
len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log
le {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log
le: {e}"}
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
if not HASHING_AVAILABLE or not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("hashlib or requests/BeautifulSoup not available. Cannot check website
update.")
return {"status": "error", "error": "Missing dependencies for website update check."}
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
response.raise_for_status()
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp":
datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
if not SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.warning("Scapy not available. Cannot send ICMP ping. This is a placeholder
tool.")
return {"status": "error", "error": "Scapy not available. Ping tool is a placeholder."}
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count,
"packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count,
"packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str,
context_code: Optional[str] = None) -> Dict:
"""Generates new Python code based on a description and optional context."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
agent.log.warning(f"UNSAFE: Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a
complete function/class de
nition based on the following description.
Description: {description}
Context Code (if any, for reference):
```python
{context_code or 'None'}
```
Generate ONLY the Python code block. Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
"""Validates Python code for syntax correctness."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
return agent.self_modi
cation_unit.validate_code_modi
cation_UNSAFE(code_to_validate)
Reuse validation logic
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec:
int = 30) -> Dict:
"""Executes a shell command. EXTREMELY DANGEROUS."""
if not ENABLE_SHELL_TOOL: return {"status": "error", "error": "Shell tool is disabled."}
    pass  # inserted to fix indentation error
agent.log.warning(f"Executing UNSAFE shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if
sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s.
Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out
after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed
with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute
command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str,
content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value,
content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id,
"message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
cationTools container ---
ToolExecutor.
class SelfModi
cationTools:
"""Handles proposing, validating, applying changes to agent code (EXTREMELY
DANGEROUS)."""
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref:
'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.log.warning("Self-Modi
cation Unit initialized BUT DISABLED by con
guration.")
return
if not DIFF_MATCH_PATCH_AVAILABLE or not dmp_module:
    pass  # inserted to fix indentation error
self.log.error("Self-Modi
cation Unit initialized but 'di
"
_match_patch' library is missing
or failed to import. Self-mod tools will fail.")
return
self.dmp = dmp_module.di
"
_match_patch()
self.log.info(f"Self-Modi
cation Unit initialized. Code Dir: {self.agent_code_dir}, Backup
Dir: {self.backup_dir}")
def _resolve_target_path(self, target_
le_rel: str) -> Path:
"""Resolves relative path to absolute path within agent code dir and validates."""
if ".." in target_
    pass  # inserted to fix indentation error
le_rel or target_
le_rel.startswith("/"):
raise SecurityError(f"Invalid characters or absolute path in target_
le_rel:
{target_
le_rel}")
target_path_abs = (self.agent_code_dir / target_
le_rel).resolve()
directory
if not str(target_path_abs).startswith(str(self.agent_code_dir.resolve())):
    pass  # inserted to fix indentation error
self.log.error(f"Path traversal attempt: {target_
le_rel} resolved to {target_path_abs}
which is outside {self.agent_code_dir}")
raise SecurityError(f"Target
le '{target_
le_rel}' resolves outside the agent code
directory. Access denied.")
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
"""Inspects the source code of a speci
ed agent component (e.g., class name or module
path)."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Inspecting code for component: {component_name}")
target_obj = None
nd by attribute of the agent instance (e.g., agent.self_model)
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
nd in tool registry
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
nd as a globally de
ned class/function in main script context
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
nd in sys.modules (as a module name)
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
ed: if component_name looks like a module, search it.
nd it in common places.
candidate_modules = [sys.modules.get('__main__'),
sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod,
    pass  # inserted to fix indentation error
component_name)):
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
le_path = inspect.get
le(target_obj)
return {"status": "success", "component_name": component_name, "
le_path":
le_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module,
class, or function de
ned in a
le.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but
source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Component '{component_name}' not found or source
code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModi
cationError))
def propose_code_modi
cation_UNSAFE(self, component_name: str, issue_description: str,
proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
"""Proposes a code modi
cation using LLM based on an issue and desired change."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Proposing code modi
cation for {component_name}. Issue:
{issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for
{component_name} to propose modi
cation. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent
modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
```python
{current_code_snippet}
```
Generate the modi
ed Python code for the speci
ed component.
Provide ONLY the complete, new Python code block for the modi
ed function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name,
"proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modi
cation for {component_name}: {e}",
exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modi
cation_UNSAFE(self, code_to_validate: str) -> Dict:
"""Validates Python code using AST parsing (syntax check only). Conceptual sandboxed
execution would be next."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Validating proposed code snippet (
rst 100 chars):
{code_to_validate[:100]}...")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/
safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modi
cation_UNSAFE(self, component_name: str, new_code: str,
target_
le_path: Optional[str]=None) -> Dict:
"""
Applies a validated code modi
cation. EXTREMELY DANGEROUS.
This conceptually involves
nding the component in the agent's source
le and replacing
it.
Requires agent restart to take e
"
ect if modifying core running code.
"""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.critical(f"UNSAFE: Attempting to apply code modi
cation to component
'{component_name}'. THIS IS HIGHLY RISKY.")
le. This is complex and error-prone.
if not target_
    pass  # inserted to fix indentation error
le_path:
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('
    pass  # inserted to fix indentation error
le_path'):
target_
le_path = inspection_res['
le_path']
else:
    pass  # inserted to fix indentation error
target_
le_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_
le = Path(target_
le_path)
if not target_
    pass  # inserted to fix indentation error
le.exists() or not target_
le.is_
le():
return {"status": "error", "error": f"Target
le for modi
cation not found: {target_
le}"}
try:
    pass  # inserted to fix indentation error
original_code = target_
le.read_text()
le
backup_path = SELF_MOD_BACKUP_DIR /
f"{target_
le.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_
le, backup_path)
self.log.info(f"Backed up original
le to {backup_path}")
nition:
nd the old de
nition of `component_name` and replace it.
nd `class ComponentName...` or `def ComponentName...`
nd existing class or function de
nition
everything until the next class/def or end of typical indentation block.
patter n_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
start of next non-indented line or EOF
patter n_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modi
ed_original_code = original_code
found_and_replaced = False
match_class = re.search(patter n_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(patter n_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not
nd component '{component_name}' in {target_
le} for
replacement. Modi
cation aborted.")
return {"status": "error", "error": f"Component '{component_name}' de
nition not
found for replacement."}
target_
le.write_text(modi
ed_original_code)
cation validation (e.g., try to import the modi
ed
le in a subprocess)
self.log.warning(f"Code modi
cation applied to {target_
le}. Agent restart is LIKELY
REQUIRED for changes to take e
"
ect.")
ect potential capability change
self.agent_ref.self_model.add_event_log(f"Applied code modi
cation to
{component_name}. Restart pending for full e
"
ect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}
_modi
ed_pending_restart"] = True
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
after code change
return {"status": "success", "message": f"Code for '{component_name}' in '{target_
le}'
modi
ed. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modi
cation to {component_name}:
{e}", exc_info=True)
ed
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_
le)
self.log.info(f"Restored original
le {target_
le} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modi
cation: {e}. System
might be unstable."}
def rollback(self, backup_
le: Path, target_
le: Path):
"""Rolls back a
le to a backup."""
self.log.info(f"Attempting to rollback '{target_
le}' from '{backup_
le}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_
le, target_
le)
self.log.info(f"Successfully rolled back '{target_
le}'.")
ags in self-model or state
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_
le}.")
self.agent_ref.self_model.beliefs[f"component_{target_
le.name}
_modi
ed_pending_restart"] = False
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_
le.name)
return {"status": "success", "message": f"Rolled back {target_
le}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_
le}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_
le_rel: Union[str, Path]):
"""Attempts to reload a module to apply changes without full restart."""
target_module_name = Path(target_
le_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is
required.")
return
ed attempt:
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
"
ect global instances like `_agent_instance_hack` if it was part of the
reloaded module
if _agent_instance_hack and hasattr(sys.modules[target_module_name],
    pass  # inserted to fix indentation error
'CognitiveSystem'):
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot
reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for
changes to take e
"
ect.")
def inspect_directives_UNSAFE(self) -> Dict:
"""Inspects the agent's current core directives."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modi
cation_UNSAFE(self, analysis_of_misalignment: str,
proposed_directive_changes_desc: str) -> Dict:
"""Proposes modi
cations to core directives using LLM."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need
review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (
oat 0-1), "last_eval_score" (
oat 0-1,
usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational',
'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore
goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,
temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in
    pass  # inserted to fix indentation error
proposed_directives):
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
returned an error message as JSON
return {"status": "error", "error": f"LLM indicated error during directive proposal:
{proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response:
{llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modi
cation_UNSAFE(self, new_directives: List[Dict]) -> Dict:
"""Applies new core directives to the agent's SelfModel."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in
new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modi
cation_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count:
{len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModi
cationTools(AGENT_CODE_DIR,
SELF_MOD_BACKUP_DIR, agent)
cation
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in
    pass  # inserted to fix indentation error
name.upper():
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
"""Represents the agent's internal model of itself, including beliefs about the
environment."""
def __init__(self, state: Optional[Dict]=None, agent_directives_con
g:
Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_con
g if agent_directives_con
g is not None else
DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
'failure_count', ...}}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
metacognitive checks
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_con
dence: Dict[str,
oat] = {}
dence_score}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
General beliefs about self and world
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
summary of knowledge areas
self.learning_goals: List[Dict[str, Any]] = []
c goals for learning/improvement
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.lear ned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
based narrative of current internal state
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_con
dence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
cant internal events (e.g., directive
changes, model updates)
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
later.
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted",
sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_con
dence = sm_state.get("skill_con
dence", self.skill_con
dence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary",
self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies",
self.adaptation_strategies)
self.lear ned_abstractions = sm_state.get("lear ned_abstractions",
self.lear ned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative",
self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs",
self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
"""Saves the self-model's persistent components back to the main state dict's KB."""
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_con
dence": self.skill_con
dence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"lear ned_abstractions": self.lear ned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
ection and prompt_suggestions_from_re
ection
ection process.
def add_event_log(self, event_description: str, event_type: str = "info", data:
Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
dence for new tools
for tool_name in self.capabilities:
if tool_name not in self.skill_con
    pass  # inserted to fix indentation error
dence:
self.skill_con
dence[tool_name] = 0.5
dence
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0,
'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None,
'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.",
event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8: hint = " (Reliability: High)"
    pass  # inserted to fix indentation error
elif score > 0.6: hint = " (Reliability: Moderate)"
    pass  # inserted to fix indentation error
elif score > 0.3: hint = " (Reliability: Low)"
    pass  # inserted to fix indentation error
else: hint = " (Reliability: Very Low/Untested)"
    pass  # inserted to fix indentation error
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict,
success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration':
0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
MAX_RECENT_TOOL_OUTCOMES_IN_SELFMODEL (constant not de
ned, using 30)
dence (simple heuristic for now)
current_con
dence = self.skill_con
dence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = min(1.0, current_con
dence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = max(0.0, current_con
dence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability:
{stats['reliability_score']:.2f}, Con
dence: {self.skill_con
dence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_con
dence_drift(sm: 'SelfModel') -> Optional[str]:
low_con
dence_skills = [skill for skill, conf in sm.skill_con
dence.items() if conf < 0.25
and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_con
    pass  # inserted to fix indentation error
dence_skills) >= 2 :
return f"Multiple critical skills have very low con
dence and recent failures: {',
'.join(low_con
dence_skills)}. Consider skill improvement or alter native strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict): return None
    pass  # inserted to fix indentation error
low_eval_directives = []
for d in sm.core_directives:
problematic.
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {',
'.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count}
with max replans. Planning or execution e
"
ectiveness may be compromised. Review strategy
or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_con
dence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}):
{anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}",
event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__')
else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {';
'.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears
stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0),
reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:
{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_con
    pass  # inserted to fix indentation error
dence:
con
dent_skills = [s for s,c in self.skill_con
dence.items() if c > 0.7][:3]
summary += f"Con
dent Skills (sample): {', '.join(con
dent_skills) if con
dent_skills else
'None highly con
dent'}\n"
summary += f"Inter nal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and
stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and
stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools: summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
    pass  # inserted to fix indentation error
if unreliable_tools: summary += f" Needs Improvement: {', '.join([t[0] for t in
    pass  # inserted to fix indentation error
unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
ection
base_prompt = """Analyze your recent performance, knowledge, internal state, and
alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:
"""
output_keys_example = [
"`re
ection_summary` (str: Overall summary of the re
ection period).",
"`key_successes` (list of str: Speci
c achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Speci
c setbacks or di
culties encountered).",
"`lear ned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identi
ed` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool
e
"
ectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM
interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g.,
'curious', 'frustrated', 'satis
ed').",
"`resource_usage_concer ns` (str or null: Any concer ns about computational resource
usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_
oat_0_to_1: How
well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes,
provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only
suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model?
What needs improvement?).",
"`new_learning_goals` (list of str: Speci
c goals for future learning or skill
development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring
issues or improve performance).",
"`self_modi
cation_needed` (str or null: If parts of your own code/logic need
modi
cation, describe what and why. Be very speci
c and cautious.)."
]
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives,
indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n"
+ \
f"Recent Tool Outcomes (last 5 entries):
\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}
\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment
with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment:
{assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_re
ection(self, re
ection_data: Dict) -> Tuple[bool, bool]:
ection updates
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from re
ection data...")
dence, tool_notes (as in base script logic)
ection_data directly updates some
elds or implies updates
if re
    pass  # inserted to fix indentation error
ection_data.get('re
ection_summary'):
self.internal_state_narrative = re
ection_data['re
ection_summary']
updated_self = True
core_directives_eval = re
ection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and
    pass  # inserted to fix indentation error
isinstance(self.core_directives[0], dict):
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (
    pass  # inserted to fix indentation error
oat, int)) and 0.0 <= eval_score
<= 1.0:
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...'
evaluation score to {eval_score:.2f}")
if updated_self: self.add_event_log("Directive evaluation scores updated from
    pass  # inserted to fix indentation error
re
ection.")
suggested_directive_updates = re
ection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Re
ection suggested updates to core directives:
{str(suggested_directive_updates)[:200]}...")
'apply_directive_modi
cation_UNSAFE' tool
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modi
cations from
re
ection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source":
"self_re
ection"}
)
updated_self = True
self.add_event_log("Re
ection suggested directive updates. Metacognitive review
goal created.", event_type="critical_review_needed")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('new_learning_goals'), list):
for lg_str in re
ection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts":
datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self: self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('adaptation_strategy_proposals'), list):
for strat_str in re
ection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self: self.log.info(f"Updated adaptation strategies. Total:
    pass  # inserted to fix indentation error
{len(self.adaptation_strategies)}")
patterns
agent
if re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts') or re
ection_data.get('prompt_tuning_suggestions'):
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from re
ection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
"""Saves a backup of current directives to a
le."""
backup_
le = SELF_MOD_BACKUP_DIR /
f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_
le.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_
le} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
"""Simulates an internal dialog about a topic using LLM, potentially from di
"
erent
perspectives."""
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_o
cer"]
dialog_history = []
full_dialog_str = f"Inter nal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts,
questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution":
contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective
{perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":
full_dialog_str})
return full_dialog_str
class MotivationEngine:
"""Manages the agent's internal drives and their in
uence on behavior."""
def __init__(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[DriveType, DriveState] = {}
self._initialize_drives(drive_con
gs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]]):
default_con
gs = {
DriveType.CURIOSITY: {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.MASTERY: {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.ACHIEVEMENT: {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.NOVELTY_SEEKING: {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.7},
DriveType.PRESERVATION: {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0,
"initial_level": 0.2},
DriveType.EFFICIENCY: {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.SOCIAL_INTERACTION: {"decay_rate": 0.01, "max_level": 1.0, "min_level":
0.0, "initial_level": 0.3},
}
con
gs = drive_con
gs if drive_con
gs is not None else default_con
gs
for drive_type in DriveType:
con
g = con
gs.get(drive_type, default_con
gs.get(drive_type, {}))
self.drives[drive_type] = DriveState(
drive_type=drive_type,
level=con
g.get("initial_level", 0.5),
decay_rate=con
g.get("decay_rate", 0.01),
max_level=con
g.get("max_level", 1.0),
min_level=con
g.get("min_level", 0.0)
)
def update_drives(self):
"""Applies decay and updates drives based on recent experiences or time."""
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
"""Updates drives based on a speci
c experience."""
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "lear n":
    pass  # inserted to fix indentation error
self.drives[DriveType.CURIOSITY].update(stimulus=-0.05)
self.drives[DriveType.MASTERY].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives[DriveType.PRESERVATION].update(stimulus=0.1)
self.drives[DriveType.MASTERY].update(stimulus=-0.05)
def get_drive_level(self, drive_type: DriveType) ->
oat:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
if not found
    pass  # inserted to fix indentation error
def get_all_drive_levels(self) -> Dict[DriveType,
oat]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str,
oat]:
return {dt.name: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[DriveType,
oat]]:
"""Retur ns top N drives by current level."""
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
"""Suggests a goal type based on current highest drives."""
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == DriveType.CURIOSITY:
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == DriveType.MASTERY:
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == DriveType.ACHIEVEMENT:
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == DriveType.PRESERVATION:
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == DriveType.EFFICIENCY:
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: DriveType
level:
oat = 0.5
decay_rate:
oat = 0.01
max_level:
oat = 1.0
min_level:
oat = 0.0
last_update_time:
oat =
eld(default_factory=time.time)
def update(self, stimulus:
oat = 0.0):
"""Updates the drive level based on stimulus and decay."""
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class FileChannel:
"""Implements a simple
le-based communication channel for multi-agent systems."""
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_
le = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_
le}")
def _write_message_to_
le(self, message: Message, target_
le: Path) -> bool:
try:
    pass  # inserted to fix indentation error
le lock to prevent corruption during writes
with FileLock(str(target_
le) + ".lock", timeout=5):
messages = []
if target_
    pass  # inserted to fix indentation error
le.exists():
try:
    pass  # inserted to fix indentation error
existing_content = target_
le.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {target_
le}: {e}. Clearing
le.")
messages = []
messages.append(message.to_dict())
target_
le.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_
le}. Message not sent to
le.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_
le}: {e}")
return False
def _read_messages_from_
le(self, source_
le: Path) -> List[Message]:
messages = []
if not source_
    pass  # inserted to fix indentation error
le.exists():
return []
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_
le) + ".lock", timeout=5):
content = source_
le.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if
isinstance(msg_data, dict)]
le after reading
source_
le.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_
le}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {source_
le}: {e}. Clearing
le.")
source_
le.write_text("", encoding='utf-8')
le
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_
le}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}:
{message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_
le(message, target_inbox)
def receive_messages(self) -> List[Message]:
"""Checks and retrieves new messages from the agent's inbox."""
new_messages = self._read_messages_from_
le(self.inbox_
le)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message],
Optional[Message]]):
"""Registers a function to handle speci
c message types."""
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
"""Processes all messages currently in the inbox using registered handlers."""
messages = self.receive_messages()
le
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From:
{msg.sender_id}")
handled = False
if msg.message_type in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg.message_type]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler
{handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id,
receiver_id=msg.sender_id, type=MessageType.ERROR, content={"original_message_id":
msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type
{msg.message_type.value}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
"""Abstract base class for a sensor."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', con
g: Dict):
self.id = id
self.embodiment = embodiment
self.con
g = con
g
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
"""Retur ns the current reading from the sensor."""
pass
class Actuator(ABC):
"""Abstract base class for an actuator."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], con
g: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.con
g = con
g
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
"""Performs a speci
c action using the actuator."""
pass
class VirtualEmbodiment:
"""Simulated embodiment layer for SystemCore agents. (Can be replaced by Gym environments or
more complex sims)"""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing
system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to
'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button",
"research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, recon
gurable bay designed for running complex simulations.
Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_con
g_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data
ow and
storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core.
Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in
self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
"""Generate synthetic sensory input based on current environment and internal state."""
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20: self.state["emotions"]["anxiety"] = min(1.0,
    pass  # inserted to fix indentation error
self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An unde
ned space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
self.gym_env.step(self.gym_env.action_space.sample())
observation
logging
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) ->
Dict:
"""
Simulates the agent performing an action in the virtual world.
Retur ns a dictionary with the result of the action.
"""
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params:
{params}")
params = params or {}
env_details = self.environment_map.get(self.location, {})
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as speci
ed."
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console": message += " It shows
    pass  # inserted to fix indentation error
uctuating green and
amber lights."
elif target == "core_status_monitor": message += " It indicates: Core Nominal.
    pass  # inserted to fix indentation error
Directives Stable. Lear ning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
ed
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
problem.
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name",
"default_physics_test"), params.get("con
g",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result:
{sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
"
ect emotional state based on action outcome
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if
action_type=="move" else None, "updated_inventory": self.state["inventory"] if
action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "lear n"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage
at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response:
{self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model
<topic>'."
def _run_simulation(self, sim_name: str, con
g: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with con
g: {con
g}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_con
    pass  # inserted to fix indentation error
g" in con
g: success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric:
{outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check con
guration."
def summary(self) -> str:
"""Retur ns a string summary of the embodiment's current state."""
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Inter nal State (summary): Energy={self.state['energy']},
Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time:
oat = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
methods
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE,
LAST_LEARNING_MODULE_UPDATE_CYCLE
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status:
{self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack
Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if
self.agent.state['goals'].get('active') else None
self.agent.last_error = None
self.agent.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
understanding
if self.agent.self_model and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
self.log.info(f"Triggering proactive metacognitive check (Cycle
{self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
goal
if self.agent.learning_module and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_LEARNING_MODULE_UPDATE_CYCLE >=
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.lear n_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
new_pending_goals
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
List of Goal dicts
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation:
{ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
pending_list.sort(key=lambda x: GoalPriority[x.get('priority', 'MEDIUM').upper() if
isinstance(x.get('priority'),str) else GoalPriority(x.get('priority',
GoalPriority.MEDIUM)).name ].value, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type ==
    pass  # inserted to fix indentation error
"active_goal_continue":
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution:
{goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID:
{goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal'
provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
object
ed logic assumes plan is a list of steps in the goal dict.
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or
    pass  # inserted to fix indentation error
current_goal_obj.replan_count > 0:
planning
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
generation
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
Goal object
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan available or generated for goal: {current_goal_obj.goal[:50]}.
Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
c goal, agent is idle or performing non-goal action
self.agent.current_goal_outcome = True
gured
if time.time() - LAST_DELIBERATION_TIME >
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModi
cationError, LogicError, LLMError, SecurityError, Con
gurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
Lear ningError, SafetyViolationError) as agent_cycle_err:
c goal
attempt.
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent
Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
nished (with an error for current goal), but agent can continue
unless critical.
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.current_goal_outcome = False
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
nally:
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() -
start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
"""Processes observations to update world model and identify key information."""
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
ed approach. A real system might have more structured parsing.
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent
understanding of the current situation. Identify key entities, events, and any signi
cant changes
in the environment or your internal state. Focus on information relevant to achieving current
goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content:
{str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\":
\"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"],
\"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation",
understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
as facts/experiences
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event",
metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry,
persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
complex updates to the graph/relational store
return {"summary": understanding_summary, "processed_info": processed_info,
"raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError,
DeliberationError))
g
def _deliberate(self, understanding_result: Dict) -> Dict:
"""
Core deliberation logic: goal management, selection, and generation.
Retur ns a dict: {"chosen_action_type": str, "next_goal": Optional[Goal_dict],
"new_pending_goals": List[Goal_dict]}
"""
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio:
{pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio:
{active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time':
datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack
(paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
activated
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
continue
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
directives (idle task)
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal
generation.")
directives
if time.time() - LAST_DELIBERATION_TIME >=
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_lear n", "directive_curiosity",
"directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
for idle time
pass
new_pending_goals
processed
ag.
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') ==
    pass  # inserted to fix indentation error
'sub_goal_prepared':
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output:
{sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
c action, LLM will decide
self_model_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No speci
c
understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact',
'None identi
ed.')
interp_con_val = understanding_result.get('interpretation_con
dence', 0.7)
recent_memory_context =
self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary,
max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Con
dence: {interp_con_val:.2f}):**
{understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identi
ed:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory
(STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]],
indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else
f'{active_goal_dict.get("goal")[:100]}... (ID: {active_goal_dict.get("id")})'}",
f"* **Agent Core Directives
(Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding,
drives, memories, goals, directives), what is the most critical aspect demanding attention or the
best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.self_model.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/
complete).",
"    - Performing `re
ection` or `self_assessment` (if mandatory timers, drives like low
CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration
goal), Directives (e.g., low-eval directive -> improvement goal), or identi
ed opportunities. New
goals require `goal` (str), `priority` (
oat 0.0-1.0), `origin` (str e.g., 'drive_curiosity',
'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of
str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for
viability before committing if uncertainty is high or consequence severe (brie
y note simulation
outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are
apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the
immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, high
drives, or highest priority pending. State reasoning clearly.",
```python
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.
If selecting an existing pending goal, it moves to `next_goal` and is removed from pending
internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/
directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal',
'new_goal', 're
ection', 'self_assessment', 'exter nal_command_action', 'idle',
'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass
structure) selected for immediate execution. Null if idle/re
ection/assessment without a direct
goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen
for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into
`new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into
`new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent.
Analyze the situation comprehensively, consider drives and directives, and make strategic
decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and
deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON:
{extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal',
'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys:
{deliberation_decision.keys()}")
if key == 'new_pending_goals': deliberation_decision[key] = []
    pass  # inserted to fix indentation error
elif key == 'next_goal': deliberation_decision[key] = None
    pass  # inserted to fix indentation error
else: deliberation_decision[key] = "Error: Missing from LLM Output"
    pass  # inserted to fix indentation error
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty
list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not
    pass  # inserted to fix indentation error
isinstance(deliberation_decision.get('next_goal'), dict):
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value:
{deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and
    pass  # inserted to fix indentation error
new_goal_dict.get('priority'):
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p.id == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
duplicates based on ID
current_pending_list.append(new_goal_obj)
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal:
{new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
LLM
current_active_goal = self.agent.get_active_goal_object()
None
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending',
[]) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
selected_goal_obj.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = selected_goal_obj
object
self.log.info(f"Moved pending goal {selected_goal_obj.id}
('{selected_goal_obj.goal[:50]}') to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM selected pending goal by ID
{selected_next_goal_dict.get('id')}, but not found in list. Idling.")
action_type = "idle"
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
highest_priority_pending.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = highest_priority_pending
self.log.info(f"Deliberation chose 'pending_goal' without speci
c ID; moved
highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals
available. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in
    pass  # inserted to fix indentation error
selected_next_goal_dict:
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj
self.log.info(f"Deliberation created and activated new goal:
{new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal
active
current_active_goal.status = GoalStatus.ACTIVE
rm active status
self.log.info(f"Deliberation chose to resume current active goal:
{current_active_goal.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 're
    pass  # inserted to fix indentation error
ection', 'self_assessment', 'exter nal_command_action']:
'INTERRUPTED'.
if current_active_goal:
    pass  # inserted to fix indentation error
current_active_goal.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal.goal[:30]}' PAUSED due to
{action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal.to_dict())
pending, maybe re-prioritize later
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal.id} to pending
as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to
Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action:
{deliberation_decision.get('chosen_action_type')}. Reason:
{deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
"""
Executes the current plan for the active_goal.
Retur ns True if goal considered successfully processed for this cycle, False if critical error.
"""
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps:
{len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
rst step in the plan. The plan will be truncated or re-evaluated.
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id,
"plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params,
current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
ned based on tool_result and goal progress
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
ed snapshot
internal_state_after=self.agent.self_model.beliefs
e
"
ects
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
nal_status = tool_result.get("status", "unknown")
if
nal_status == "success":
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome =
nal_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
nished.
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing
nished by report_result.
Status: {
nal_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error',
'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj,
tool_result, observations[0] if observations else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal
will likely fail.")
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without
'report_result'. Goal might be incomplete.")
ection.
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
violations
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}':
{e}", exc_info=False)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) ->
oat:
"""Calculates a reward signal based on tool execution outcome and goal relevance."""
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
goaling
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
in cycle
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
for direct access
self.learning_module: Lear ningModule
self.planning_module: PlanningModule
direct access
self.safety_module: SafetyModule
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.state['
ags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete ---
Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response
Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled:
{ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modi
cation Enabled: {ENABLE_SELF_MODIFICATION}")
if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
    pass  # inserted to fix indentation error
ENABLE_SELF_MODIFICATION:
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME
CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}",
exc_info=True)
self.shutdown()
raise Con
gurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH == "mock":
    pass  # inserted to fix indentation error
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Cannot use Gemini model: google-generativeai library not
installed.")
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
global LLM_PIPELINE, LLM_TOKENIZER
CPU
AutoTokenizer.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
oat16 if TORCH_AVAILABLE else None,
oat16 if
torch available
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH,
LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS,
get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
c not implemented here
self.log.warning(f"LLM_MODEL '{LLM_MODEL_NAME_OR_PATH}' not fully con
gured
for wrapper selection, using Mock.")
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
_init_self_mod_tools(self, self.tool_manager)
cationTools handler
and register its UNSAFE methods
self._update_status("Initializing SystemCore Modules")
self.learning_module = Lear ningModule(self)
self.safety_module = SafetyModule(self)
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME,
shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager: self.tool_manager.check_playwright_browsers()
    pass  # inserted to fix indentation error
browser tool
self.log.info("Agent component initialization
nished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list): state['goals'][key] = []
    pass  # inserted to fix indentation error
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
items
state.setdefault('goal_stack', [])
state.setdefault('
ags', {})
ags system
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state
le {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state
le {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
its view
"recent_failures_summary": [],
view
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"
ags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
cation and saving
_archive_goal
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
state['knowledge_base']['self_model_state']
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status if self.self_model else
self._status
try:
    pass  # inserted to fix indentation error
temp_
le = STATE_FILE.with_su
x(STATE_FILE.su
x + ".tmp")
with temp_
le.open('w') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_
le, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
"""Retur ns the current active goal as a Goal object, or None."""
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict:
{active_goal_dict}")
return None
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority =
GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
deliberation
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict,
nal_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID:
{goal_data_dict.get('id')}) with status: {
nal_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
goal_obj.status = GoalStatus(
nal_status_str)
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-
MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status":
str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count":
goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and
    pass  # inserted to fix indentation error
current_active_in_state.get('id') == active_goal_id:
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
stack
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID:
{active_goal_id}) concluded with status: {
nal_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-
goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
marked active
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal',
'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal:
{parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
goal wasn't a subgoal from stack
self.log.info("Goal archived. No parent goal to resume from stack, or current goal
was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized": self._update_status("Idle")
    pass  # inserted to fix indentation error
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and
environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if
self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle:
{loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
nal status of the goal processed in this cycle
updated_active_goal_dict = self.state['goals'].get('active')
goal
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] ==
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['id']:
ects outcome
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED,
    pass  # inserted to fix indentation error
GoalStatus.CANCELLED]:
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
during preemption
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
failed while this goal was active
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
failed
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
not speci
c to goal completion
ection (SystemCore Enhanced) - Can be more frequent or event-driven
if self._should_re
    pass  # inserted to fix indentation error
ect(active_goal_data_before_cycle):
self._re
ect_on_performance()
cant changes (already done in many places)
nal save here per cycle too.
if self.state['
    pass  # inserted to fix indentation error
ags'].get('re_evaluate_strategy_needed'):
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to signi
cant
internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['
ags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not
    pass  # inserted to fix indentation error
self.state['goals'].get('pending'):
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() -
LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_re
ect(self, processed_goal_data: Optional[Dict]) -> bool:
ection triggers
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
ect
every N cycles
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED, GoalStatus.FAILED]:
ect after signi
cant goal outcome
ect if enough goals processed since last time
goals_processed_key = "goals_processed_since_re
ection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >=
    pass  # inserted to fix indentation error
int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
return True
if time.time() - LAST_REFLECTION_TIME >
    pass  # inserted to fix indentation error
MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
return True
if self.state['
    pass  # inserted to fix indentation error
ags'].get('explicit_re
ection_requested'):
return True
return False
@retry(attempts=2, delay=5)
def _re
ect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Re
ecting on Performance ---")
self.state['
ags']['explicit_re
ection_requested'] = False
ag
self.state["goals_processed_since_re
ection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt,
max_new_tokens=2048, temperature=0.5)
ection
re
ection_data = extract_json_robust(llm_assessment_str)
if re
    pass  # inserted to fix indentation error
ection_data.get("error"):
self.log.error(f"Failed to get valid JSON from LLM self-assessment:
{re
ection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed:
{re
ection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_re
ection(re
ection_data)
ection to MemorySystem
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts'), list):
for fact_str in re
ection_data['lear ned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source":
"self_re
ection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
self.log.info(f"Added {len(re
ection_data['lear ned_facts'])} lear ned facts to memory
from re
ection.")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('prompt_tuning_suggestions'), list):
for sugg_str in re
ection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str,
metadata={"source": "self_re
ection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(re
ection_data['prompt_tuning_suggestions'])} prompt
suggestions to memory.")
ndings from re
ection (e.g. self_modi
cation_needed)
if re
    pass  # inserted to fix indentation error
ection_data.get('self_modi
cation_needed'):
mod_desc = re
ection_data['self_modi
cation_needed']
self.log.warning(f"Re
ection identi
ed need for self-modi
cation: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modi
cation based on re
ection:
{mod_desc}",
priority=GoalPriority.HIGH,
context={"modi
cation_description": mod_desc, "source": "self_re
ection"}
)
ection insights or periodically
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) ==
    pass  # inserted to fix indentation error
0:
audit_issues = self.safety_module.audit_directives_and_behavior()
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identi
ed issues: {audit_issues}")
ndings
self._create_metacognitive_goal(f"Address directive audit
ndings:
{str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Re
ection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during re
ection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during re
ection: {e}", exc_info=True)
nally:
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
"""Sets up handlers for di
"
erent message types if comms_channel exists."""
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY,
self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM,
self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}:
{message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base']
[query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample":
str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id,
type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}:
{message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
x with sender to avoid
clashes
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if not PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("psutil not available, resource monitoring disabled.");
return
if RESOURCE_MONITOR: return
    pass  # inserted to fix indentation error
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e: self.log.error(f"Failed to initialize resource monitor: {e}");
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("Playwright not available, skipping initialization.")
return
if PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER =
PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
globals
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE: try: PLAYWRIGHT_PAGE.close()
    pass  # inserted to fix indentation error
ignore
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_CONTEXT: try: PLAYWRIGHT_CONTEXT.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_BROWSER: try: PLAYWRIGHT_BROWSER.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_INSTANCE: try: PLAYWRIGHT_INSTANCE.stop()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not PLAYWRIGHT_AVAILABLE or not self.playwright_context : return
    pass  # inserted to fix indentation error
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page: try: self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
ush
if 'logging' in sys.modules: logging.shutdown()
    pass  # inserted to fix indentation error
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl}
Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/
{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)' if
ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
ENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_
le",
priority=GoalPriority.HIGH).to_dict()
COMMANDS_FILE.write_text("")
except Exception as e_cmd
    pass  # inserted to fix indentation error
le:
print(f"Error reading initial command
le: {e_cmd
le}",
le=sys.stderr)
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending',
[]).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort,
reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal']
[:50]}' added to pending goals.")
main_agent_instance.run()
except Con
    pass  # inserted to fix indentation error
gurationError as cfg_err_main:
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}",
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to Con
gurationError:
{cfg_err_main}", exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to
    pass  # inserted to fix indentation error
Con
gurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else: logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt
    pass  # inserted to fix indentation error
during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}",
le=sys.stderr)
traceback.print_exc(
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",
exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main:
    pass  # inserted to fix indentation error
{main_exec_err}", exc_info=True)
exit_code = 1
nally:
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main
nally block...")
if hasattr(main_agent_instance, 'log'): main_agent_instance.log.warning("Main
    pass  # inserted to fix indentation error
nally
block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
main_log.warning("Agent instance likely not created or fully initialized. Basic
shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
```
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
def load_llm_models():
global llm_pipelines
try:
    pass  # inserted to fix indentation error
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error in load_llm_models: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
try:
    pass  # inserted to fix indentation error
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
from Real1_ToolSuite import TOOL_REGISTRY
TRANSFORMERS_AVAILABLE = True
TORCH_AVAILABLE = True
GOOGLE_GENAI_AVAILABLE = True
PSUTIL_AVAILABLE = True
CHROMADB_AVAILABLE = True
PLAYWRIGHT_AVAILABLE = True
REQUESTS_BS4_AVAILABLE = True
PILLOW_AVAILABLE = True
DIFF_MATCH_PATCH_AVAILABLE = True
FILELOCK_AVAILABLE = True
NETWORKX_AVAILABLE = True
GYMNASIUM_AVAILABLE = True
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
import psutil
import chromadb
from chromadb.config import Settings as ChromaSettings
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoConfig
from transformers import logging as transformers_logging
import torch
from playwright.sync_api import sync_playwright, Error as PlaywrightError
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from PIL import Image
import diff_match_patch as dmp_module
import hashlib
from fifilelock import FileLock, Timeout as FileLockTimeout
import networkx as nx
import gymnasium as gym
AGENT_NAME = "EvolvedCognitiveAgent_SystemCore_V3"
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
DEFAULT_LLM_MODEL = "gemini-2.5-flash"
LLM_MODEL_NAME_OR_PATH = DEFAULT_LLM_MODEL
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
_llm_device_detected = "cpu"
if torch.cuda.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif hasattr(torch, 'backends') and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
LLM_DEVICE = _llm_device_detected
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
SCRIPT_DIR = Path(__file__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(f"agent_workspace_{AGENT_NAME}")
STATE_FILE = WORKSPACE_DIR / Path(f"agent_state_{AGENT_NAME}.json")
LOG_FILE = WORKSPACE_DIR / Path(f"agent_log_{AGENT_NAME}.log")
COMMANDS_FILE = SCRIPT_DIR / Path("agent_commands.txt")
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modification_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously learn, adapt, and improve capabilities across all domains.", "weight": 0.9, "last_eval_score": 0.0, "id": "directive_learn", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type": "growth"},
{"directive": "Achieve goals efficiently, robustly, autonomously, and ethically.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type": "exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.", "weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type": "foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type": "guardrail"},
]
MANDATORY_REFLECTION_INTERVAL_SECONDS = 1800
IDLE_DELIBERATION_INTERVAL_SECONDS = 120
GOAL_STACK_MAX_DEPTH = 5
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = 3
MAX_LLM_RESPONSE_TOKENS = 4096
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH or "2.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
else:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
config = AutoConfig.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
_default_context_len = getattr(config, 'max_position_embeddings', _default_context_len)
except Exception:
    pass  # inserted to fix indentation error
pass
MAX_LLM_CONTEXT_TOKENS = _default_context_len
MAX_TOOL_RESULT_LENGTH = 5000
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = True
ENABLE_CODE_GENERATION_TOOL = True
ENABLE_SELF_MODIFICATION = True
WEB_SEARCH_TIMEOUT = 10
WEB_BROWSER_TIMEOUT = 60000
LOG_MONITOR_DEFAULT_LINES = 20
METACOGNITIVE_CHECK_INTERVAL_CYCLES = 20
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES = 50
LLM_PIPELINE = None
LLM_TOKENIZER = None
MEMORY_COLLECTION = None
RESOURCE_MONITOR = None
PLAYWRIGHT_INSTANCE = None
PLAYWRIGHT_BROWSER = None
PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_PAGE = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack = None
def ensure_paths():
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
try:
    pass  # inserted to fix indentation error
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
try:
    pass  # inserted to fix indentation error
file_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
file_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%(filename)s:%(lineno)d] [%(task_name_override)-10s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error setting up file logger: {e}", file=sys.stderr)
logger.propagate = False
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "fifilelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try:
    pass  # inserted to fix indentation error
logging.getLogger(lib_name).setLevel(logging.WARNING)
except Exception:
    pass  # inserted to fix indentation error
pass
try:
    pass  # inserted to fix indentation error
logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
except Exception:
    pass  # inserted to fix indentation error
pass
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModificationError(AgentError): pass
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class ConfigurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class LearningError(AgentError): pass
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModificationError,
PlaywrightError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModificationError,
    pass  # inserted to fix indentation error
LogicError, ConfigurationError, RecursionDepthError)) and type(e) not in retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}: {e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error: {type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error: {type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, LearningError) as non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in {fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}: {type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}: {unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error: {unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception):
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1:
    pass  # inserted to fix indentation error
log_resource.error(f"Unexpected error getting resource usage: {e}", exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
match = re.search(r"```json\s*([\s\S]+?)\s*```", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full text: {json_str[:200]}...")
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}. Text: {text_trimmed[:200]}...")
try:
    pass  # inserted to fix indentation error
start_index = text.find('{')
end_index = text.rfind('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
try:
    pass  # inserted to fix indentation error
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice: {potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text: {text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview": text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str = field(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] = field(default_factory=dict)
plan: List[Dict[str, Any]] = field(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] = field(default_factory=list)
dependencies: List[str] = field(default_factory=list)
complexity_score: Optional[float] = None
estimated_cost: Optional[float] = None
estimated_utility: Optional[float] = None
evaluation_score: Optional[float] = None
associated_directive_ids: List[str] = field(default_factory=list)
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus(data['status'])
except ValueError:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus.PENDING
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority.MEDIUM
field_names = {f.name forfin cls.__dataclass_fields__.values()}
for f_obj in cls.__dataclass_fields__.values():
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin cls.__dataclass_fields__.values()}
filtered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**filtered_data)
@dataclass
class BaseMemoryEntry:
id: str = field(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
content: Any = None
metadata: Dict[str, Any] = field(default_factory=dict)
embedding: Optional[List[float]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[float] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability: float = 0.5
related_concepts: List[str] = field(default_factory=list)
causal_links: Dict[str, str] = field(default_factory=dict)
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
self.content = self.fact_statement
@dataclass
class Message:
id: str = field(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
type: str = "info"
content: Dict[str, Any] = field(default_factory=dict)
priority: int = 0
correlation_id: Optional[str] = None
def to_dict(self) -> Dict[str, Any]:
return asdict(self)
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Message':
return cls(**data)
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionEffect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens: int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[float]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
genai.configure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
try:
    pass  # inserted to fix indentation error
generation_config_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_config_params["stop_sequences"] = stop_sequences
full_prompt = f"{system_message}\n\n{prompt}" if system_message else prompt
response = self.model.generate_content(
full_prompt,
generation_config=genai.types.GenerationConfig(**generation_config_params)
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.", exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[float]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='models/embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, trust_remote_code=True)
device_map_arg = {"": self.device_id} if self.device_id != -1 else "auto"
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.bfloat16,
device_map=device_map_arg
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on {self.device}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Transformers model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Transformers model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
if system_message:
    pass  # inserted to fix indentation error
chat_prompt = [
{"role": "system", "content": system_message},
{"role": "user", "content": prompt}
]
try:
    pass  # inserted to fix indentation error
final_prompt = self.tokenizer.apply_chat_template(chat_prompt, tokenize=False, add_generation_prompt=True)
except Exception:
    pass  # inserted to fix indentation error
final_prompt = f"System: {system_message}\nUser: {prompt}\nAssistant:"
else:
    pass  # inserted to fix indentation error
final_prompt = prompt
inputs = self.tokenizer(final_prompt, return_tensors="pt").to(self.model.device)
outputs = self.model.generate(
**inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[float]:
self.log_llm.warning("Direct embedding from causal LM is not standard. Using mock embedding.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
def perceive(self) -> List[Dict[str, Any]]:
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_file",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from file: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands file: {e}")
observations.append({"type": "error", "source": "command_file_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No significant external stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (simulated).")
return {"type": "visual", "source": "camera_sim", "content": "Simulated visual data: a generic scene.", "format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (simulated).")
return {"type": "audio", "source": "microphone_sim", "content": "Simulated auditory data: ambient sounds.", "format": "description"}
class LearningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_buffer: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
self.experiences_buffer.append(experience)
if len(self.experiences_buffer) > self.MAX_BUFFER_SIZE:
    pass  # inserted to fix indentation error
self.experiences_buffer.pop(0)
defilearn_from_recent_experiences(self):
if not self.experiences_buffer:
    pass  # inserted to fix indentation error
self.log.info("No new experiences to learn from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_buffer)} experiences.")
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_buffer)
self._perform_self_supervised_learning(self.experiences_buffer)
self.log.info("Learning cycle completed.")
self.experiences_buffer.clear()
def _perform_reinforcement_learning(self, experiences: List[Experience]):
self.log.info("Performing reinforcement learning (conceptual)...")
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (conceptual) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
self.log.info("Performing self-supervised learning (conceptual)...")
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns', 'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified patterns: {llm_analysis['patterns']}")
for pattern_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {pattern_str}", metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified abstractions: {llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.learned_abstractions.append({"type": "conceptual", "content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified new_concepts: {llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}", metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_learned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
if self.rl_policy:
    pass  # inserted to fix indentation error
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}. Response: {llm_response_str[:200]}")
return ([{"tool_name": "report_error", "params": {"error_message": "Failed to generate plan via LLM.", "details": plan_data.get('error')}}],
"LLM failed to generate a plan. This is a fallback step.")
thought = plan_data.get("thought", "No specific thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return ([{"tool_name": "report_error", "params": {"error_message": "LLM plan contained no valid steps."}}],
thought + " (But plan steps were invalid).")
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return ([{"tool_name": "report_error", "params": {"error_message": f"LLMError during planning: {e}"}}],
f"LLM error occurred: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return ([{"tool_name": "report_error", "params": {"error_message": f"Unexpected error during planning: {e}"}}],
f"Unexpected error: {e}")
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation: Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info', {}).get('execution_successful', True):
    pass  # inserted to fix indentation error
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal {current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan, last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan: {plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No specific thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else "World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'. Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, efficient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the `execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the final step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the first step(s) should be to acquire it (e.g., using `search_web`, `read_file_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str, last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info', {}).get('current_step_id'):
    pass  # inserted to fix indentation error
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if observation else "None"}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
{original_plan_str}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should reflect this (e.g., by trying to gather more information or reporting inability).
6. Ensure the final step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
class MemorySystem:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH, settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
self.log.info(f"ChromaDB vector store initialized. Collection count: {self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.", exc_info=True)
self.vector_store = None
if not self.vector_store:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based (transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes: {len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be unavailable.", exc_info=True)
self.graph_store = None
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH, check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be unavailable.", exc_info=True)
if self.relational_conn:
    pass  # inserted to fix indentation error
self.relational_conn.close()
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT,
PRIMARY KEY (source_node_id, target_node_id, relation_type)
)
""")
self.relational_conn.commit()
cursor.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error initializing relational schema: {e}", exc_info=True)
def _get_embedding(self, text: str) -> Optional[List[float]]:
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
h = hashlib.md5(text.encode()).digest()
return [float(b) for b in h[:16]]
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector:
    pass  # inserted to fix indentation error
if self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
for k, v in entry.metadata.items():
if isinstance(v, (str, int, float, bool)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
else:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(entry.content)
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata": entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50], type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
for cause_id, effect_id in entry.causal_links.items():
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(effect_id):
    pass  # inserted to fix indentation error
self.graph_store.add_edge(cause_id, effect_id, relation_type='causes')
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id, complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score, json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
ts_now = datetime.now(timezone.utc).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now, json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}", exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError, ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS, type_filter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text:
    pass  # inserted to fix indentation error
return []
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_filter and data['metadata'].get('type') != type_filter:
    pass  # inserted to fix indentation error
continue
results.append({"id": id, "document": data['document'], "metadata": data['metadata'], "distance": 0.0})
if len(results) >= n_results:
    pass  # inserted to fix indentation error
break
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results}, filter={type_filter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_filter:
    pass  # inserted to fix indentation error
where_clause = {"type": type_filter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0:
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type: Optional[str]=None, depth: int = 1) -> List[Dict]:
if not self.graph_store:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation": data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns: Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
if self.graph_store:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts, type_filter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No specific knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
return summary_str
def consolidate_knowledge(self):
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold: float = 0.1, older_than_days: int = 365):
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cutoff_ts = (datetime.now(timezone.utc) - timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cutoff_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
self.register_tool(read_file_UNSAFE)
self.register_tool(write_file_UNSAFE)
self.register_tool(list_files_UNSAFE)
self.register_tool(browse_web)
self.register_tool(search_web)
self.register_tool(monitor_log_file)
self.register_tool(check_website_update)
self.register_tool(send_icmp_ping)
self.register_tool(send_message_to_agent)
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
self.register_tool(execute_shell_command_UNSAFE)
def register_tool(self, func: Callable):
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if hasattr(self, 'agent') and self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for filepath in directory.glob("*.py"):
module_name = filepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_file_location(full_module_name, filepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
sys.modules[full_module_name] = module
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module: {module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and name.startswith("tool_"):
    pass  # inserted to fix indentation error
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}", exc_info=True)
def get_tool_description_for_llm(self) -> str:
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = "(No description provided)"
first_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation == inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class '","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper():
    pass  # inserted to fix indentation error
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {first_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via specific tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {', '.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info: Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None:
    pass  # inserted to fix indentation error
current_step_info = {}
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
result = None
duration = 0.0
validated_params = {}
try:
    pass  # inserted to fix indentation error
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
first_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
first_param_name = next(iter(func_params_spec))
first_param_spec = func_params_spec[first_param_name]
if first_param_name == 'agent' and (first_param_spec.annotation == 'CognitiveSystem' or str(first_param_spec.annotation) == "'CognitiveSystem'"):
    pass  # inserted to fix indentation error
first_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if first_param_is_agent and p_name == 'agent':
    pass  # inserted to fix indentation error
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind == inspect.Parameter.VAR_KEYWORD:
    pass  # inserted to fix indentation error
pass
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
if first_param_is_agent:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration: {duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError:
    pass  # inserted to fix indentation error
raise
except (AgentError, LogicError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}", exc_info=False)
result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
def check_playwright_browsers(self):
self.log.debug("Checking Playwright browsers.")
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log", content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str, percentage_complete: Optional[float] = None) -> Dict:
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log', []).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str = "success", details: Optional[Dict] = None) -> Dict:
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] = "MEDIUM", context: Optional[Dict] = None) -> Dict:
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH}) reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent: {current_active_goal_dict.get('id')}")
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str = "vector", n_results: int = 3, type_filter: Optional[str] = None) -> Dict:
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
results = []
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results, type_filter=type_filter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_graph_store(query_node_label=query_text, depth=1)
elif memory_type == "relational":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_relational_store(table=query_text, limit=n_results)
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params: Optional[Dict] = None) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name, params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
def read_file_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
log_tool = get_logger("TOOL_read_file")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not full_path.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found: {path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path), "file_size_bytes": len(content)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read file: {e}"}
def write_file_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_file")
try:
    pass  # inserted to fix indentation error
full_path = WORKSPACE_DIR.joinpath(path).resolve()
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path": str(full_path)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write file: {e}"}
def list_files_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_files")
try:
    pass  # inserted to fix indentation error
base_path = WORKSPACE_DIR.joinpath(path).resolve()
if not base_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a directory: {path}"}
items = []
for item in base_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "file",
"size_bytes": item.stat().st_size if item.is_file() else None,
"last_modified": datetime.fromtimestamp(item.stat().st_mtime, tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(base_path), "contents": items}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing files in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list files: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int = WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int = WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.find_all(class_='g'):
r = g.find('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.find('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_file(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES) -> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log file not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_file": str(LOG_FILE), "content": content, "lines_read": len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log file {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log file: {e}"}
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp": datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count, "packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count, "packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str, context_code: Optional[str] = None) -> Dict:
agent.log.warning(f"Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a complete function/class definition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
return agent.self_modification_unit.validate_code_modification_UNSAFE(code_to_validate)
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec: int = 30) -> Dict:
agent.log.warning(f"Executing shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s. Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str, content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value, content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id, "message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
class SelfModificationTools:
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref: 'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
self.dmp = dmp_module.diff_match_patch()
self.log.info(f"Self-Modification Unit initialized. Code Dir: {self.agent_code_dir}, Backup Dir: {self.backup_dir}")
def _resolve_target_path(self, target_file_rel: str) -> Path:
target_path_abs = (self.agent_code_dir / target_file_rel).resolve()
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
self.log.warning(f"Inspecting code for component: {component_name}")
target_obj = None
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
candidate_modules = [sys.modules.get('__main__'), sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod, component_name)):
    pass  # inserted to fix indentation error
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
file_path = inspect.getfile(target_obj)
return {"status": "success", "component_name": component_name, "file_path": file_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module, class, or function defined in a file.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
return {"status": "error", "error": f"Component '{component_name}' not found or source code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModificationError))
def propose_code_modification_UNSAFE(self, component_name: str, issue_description: str, proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
self.log.warning(f"Proposing code modification for {component_name}. Issue: {issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for {component_name} to propose modification. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
{current_code_snippet}
Generate the modified Python code for the specified component.
Provide ONLY the complete, new Python code block for the modified function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '```python' and end with '```'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "proposed_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name, "proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modification for {component_name}: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modification_UNSAFE(self, code_to_validate: str) -> Dict:
self.log.warning(f"Validating proposed code snippet ({code_to_validate[:100]}...)")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modification_UNSAFE(self, component_name: str, new_code: str, target_file_path: Optional[str]=None) -> Dict:
self.log.critical(f"Attempting to apply code modification to component '{component_name}'. THIS IS HIGHLY RISKY.")
try:
    pass  # inserted to fix indentation error
if not target_file_path:
    pass  # inserted to fix indentation error
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('file_path'):
    pass  # inserted to fix indentation error
target_file_path = inspection_res['file_path']
else:
    pass  # inserted to fix indentation error
target_file_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_file = Path(target_file_path)
if not target_file.exists() or not target_file.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Target file for modification not found: {target_file}"}
original_code = target_file.read_text()
backup_path = SELF_MOD_BACKUP_DIR / f"{target_file.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_file, backup_path)
self.log.info(f"Backed up original file to {backup_path}")
pattern_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
pattern_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modified_original_code = original_code
found_and_replaced = False
match_class = re.search(pattern_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(pattern_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not find component '{component_name}' in {target_file} for replacement. Modification aborted.")
return {"status": "error", "error": f"Component '{component_name}' definition not found for replacement."}
target_file.write_text(modified_original_code)
self.log.warning(f"Code modification applied to {target_file}. Agent restart is LIKELY REQUIRED for changes to take effect.")
self.agent_ref.self_model.add_event_log(f"Applied code modification to {component_name}. Restart pending for full effect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}_modified_pending_restart"] = True
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": f"Code for '{component_name}' in '{target_file}' modified. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modification to {component_name}: {e}", exc_info=True)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_file)
self.log.info(f"Restored original file {target_file} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modification: {e}. System might be unstable."}
def rollback(self, backup_file: Path, target_file: Path):
self.log.info(f"Attempting to rollback '{target_file}' from '{backup_file}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_file, target_file)
self.log.info(f"Successfully rolled back '{target_file}'.")
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_file}.")
self.agent_ref.self_model.beliefs[f"component_{target_file.name}_modified_pending_restart"] = False
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_file.name)
return {"status": "success", "message": f"Rolled back {target_file}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_file}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_file_rel: Union[str, Path]):
target_module_name = Path(target_file_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is required.")
return
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
if _agent_instance_hack and hasattr(sys.modules[target_module_name], 'CognitiveSystem'):
    pass  # inserted to fix indentation error
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for changes to take effect.")
def inspect_directives_UNSAFE(self) -> Dict:
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modification_UNSAFE(self, analysis_of_misalignment: str, proposed_directive_changes_desc: str) -> Dict:
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (float 0-1), "last_eval_score" (float 0-1, usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational', 'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024, temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in proposed_directives):
    pass  # inserted to fix indentation error
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"LLM indicated error during directive proposal: {proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modification_UNSAFE(self, new_directives: List[Dict]) -> Dict:
self.log.warning(f"Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modification_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count: {len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
_self_mod_tools_container = None
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, agent)
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in name.upper():
    pass  # inserted to fix indentation error
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func) or inspect.ismethod(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
def __init__(self, state: Optional[Dict]=None, agent_directives_config: Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_config if agent_directives_config is not None else DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_confidence: Dict[str, float] = {}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
self.learning_goals: List[Dict[str, Any]] = []
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.learned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_confidence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted", sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_confidence = sm_state.get("skill_confidence", self.skill_confidence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary", self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies", self.adaptation_strategies)
self.learned_abstractions = sm_state.get("learned_abstractions", self.learned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative", self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs", self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_confidence": self.skill_confidence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"learned_abstractions": self.learned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
def add_event_log(self, event_description: str, event_type: str = "info", data: Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
for tool_name in self.capabilities:
if tool_name not in self.skill_confidence:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = 0.5
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.", event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8:
    pass  # inserted to fix indentation error
hint = " (Reliability: High)"
elif score > 0.6:
    pass  # inserted to fix indentation error
hint = " (Reliability: Moderate)"
elif score > 0.3:
    pass  # inserted to fix indentation error
hint = " (Reliability: Low)"
else:
    pass  # inserted to fix indentation error
hint = " (Reliability: Very Low/Untested)"
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict, success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
current_confidence = self.skill_confidence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = min(1.0, current_confidence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = max(0.0, current_confidence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability: {stats['reliability_score']:.2f}, Confidence: {self.skill_confidence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_confidence_drift(sm: 'SelfModel') -> Optional[str]:
low_confidence_skills = [skill for skill, conf in sm.skill_confidence.items() if conf < 0.25 and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_confidence_skills) >= 2 :
    pass  # inserted to fix indentation error
return f"Multiple critical skills have very low confidence and recent failures: {', '.join(low_confidence_skills)}. Consider skill improvement or alternative strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict):
    pass  # inserted to fix indentation error
return None
low_eval_directives = []
for d in sm.core_directives:
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {', '.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count} with max replans. Planning or execution effectiveness may be compromised. Review strategy or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_confidence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}): {anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}", event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__') else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {'; '.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0), reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_confidence:
    pass  # inserted to fix indentation error
confident_skills = [s for s,c in self.skill_confidence.items() if c > 0.7][:3]
summary += f"Confident Skills (sample): {', '.join(confident_skills) if confident_skills else 'None highly confident'}\n"
summary += f"Internal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools:
    pass  # inserted to fix indentation error
summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
if unreliable_tools:
    pass  # inserted to fix indentation error
summary += f" Needs Improvement: {', '.join([t[0] for t in unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
base_prompt = """Analyze your recent performance, knowledge, internal state, and alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:"""
output_keys_example = [
"`reflection_summary` (str: Overall summary of the reflection period).",
"`key_successes` (list of str: Specific achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Specific setbacks or difficulties encountered).",
"`learned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identified` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool effectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g., 'curious', 'frustrated', 'satisfied').",
"`resource_usage_concerns` (str or null: Any concerns about computational resource usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_float_0_to_1: How well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes, provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model? What needs improvement?).",
"`new_learning_goals` (list of str: Specific goals for future learning or skill development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring issues or improve performance).",
"`self_modification_needed` (str or null: If parts of your own code/logic need modification, describe what and why. Be very specific and cautious.)."
]
full_prompt = base_prompt + "\n" + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives, indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n" + \
f"Recent Tool Outcomes (last 5 entries):\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment: {assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_reflection(self, reflection_data: Dict) -> Tuple[bool, bool]:
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from reflection data...")
if reflection_data.get('reflection_summary'):
    pass  # inserted to fix indentation error
self.internal_state_narrative = reflection_data['reflection_summary']
updated_self = True
core_directives_eval = reflection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (float, int)) and 0.0 <= eval_score <= 1.0:
    pass  # inserted to fix indentation error
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...' evaluation score to {eval_score:.2f}")
if updated_self:
    pass  # inserted to fix indentation error
self.add_event_log("Directive evaluation scores updated from reflection.")
suggested_directive_updates = reflection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Reflection suggested updates to core directives: {str(suggested_directive_updates)[:200]}...")
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modifications from reflection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source": "self_reflection"}
)
updated_self = True
self.add_event_log("Reflection suggested directive updates. Metacognitive review goal created.", event_type="critical_review_needed")
if isinstance(reflection_data.get('new_learning_goals'), list):
    pass  # inserted to fix indentation error
for lg_str in reflection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts": datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
if isinstance(reflection_data.get('adaptation_strategy_proposals'), list):
    pass  # inserted to fix indentation error
for strat_str in reflection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated adaptation strategies. Total: {len(self.adaptation_strategies)}")
if reflection_data.get('learned_facts') or reflection_data.get('prompt_tuning_suggestions'):
    pass  # inserted to fix indentation error
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from reflection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
backup_file = SELF_MOD_BACKUP_DIR / f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_file.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_file} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_officer"]
dialog_history = []
full_dialog_str = f"Internal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts, questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution": contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective {perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
self.add_event_log(f"Internal dialog simulated on '{topic}'.", data={"dialog": full_dialog_str})
return full_dialog_str
class MotivationEngine:
def __init__(self, drive_configs: Optional[Dict[str, Any]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[str, Any] = {}
self._initialize_drives(drive_configs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_configs: Optional[Dict[str, Any]]):
default_configs = {
"CURIOSITY": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"MASTERY": {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.6},
"ACHIEVEMENT": {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.4},
"NOVELTY_SEEKING": {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.7},
"PRESERVATION": {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.2},
"EFFICIENCY": {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"SOCIAL_INTERACTION": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.3},
}
configs = drive_configs if drive_configs is not None else default_configs
for drive_type_str, config in configs.items():
self.drives[drive_type_str] = DriveState(
drive_type=drive_type_str,
level=config.get("initial_level", 0.5),
decay_rate=config.get("decay_rate", 0.01),
max_level=config.get("max_level", 1.0),
min_level=config.get("min_level", 0.0)
)
def update_drives(self):
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "learn":
    pass  # inserted to fix indentation error
self.drives["CURIOSITY"].update(stimulus=-0.05)
self.drives["MASTERY"].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives["ACHIEVEMENT"].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives["PRESERVATION"].update(stimulus=0.1)
self.drives["MASTERY"].update(stimulus=-0.05)
def get_drive_level(self, drive_type: str) -> float:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
def get_all_drive_levels(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[str, float]]:
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == "CURIOSITY":
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == "MASTERY":
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == "ACHIEVEMENT":
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == "PRESERVATION":
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == "EFFICIENCY":
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: str
level: float
decay_rate: float = 0.01
max_level: float = 1.0
min_level: float = 0.0
last_update_time: float = field(default_factory=time.time)
def update(self, stimulus: float = 0.0):
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class MessageType(Enum):
QUERY = "QUERY"
RESPONSE = "RESPONSE"
INFORM = "INFORM"
REQUEST_ACTION = "REQUEST_ACTION"
HEARTBEAT = "HEARTBEAT"
ERROR = "ERROR"
class FileChannel:
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_file = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_file}")
def _write_message_to_file(self, message: Message, target_file: Path) -> bool:
try:
    pass  # inserted to fix indentation error
with FileLock(str(target_file) + ".lock", timeout=5):
messages = []
if target_file.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
existing_content = target_file.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {target_file}: {e}. Clearing file.")
messages = []
messages.append(message.to_dict())
target_file.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_file}. Message not sent to {message.receiver_id}.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_file}: {e}")
return False
def _read_messages_from_file(self, source_file: Path) -> List[Message]:
messages = []
if not source_file.exists():
    pass  # inserted to fix indentation error
return messages
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_file) + ".lock", timeout=5):
content = source_file.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if isinstance(msg_data, dict)]
source_file.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_file}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {source_file}: {e}. Clearing file.")
try:
    pass  # inserted to fix indentation error
source_file.write_text("", encoding='utf-8')
except Exception as e_write:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to clear corrupted message file {source_file}: {e_write}")
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_file}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}: {message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_file(message, target_inbox)
def receive_messages(self) -> List[Message]:
new_messages = self._read_messages_from_file(self.inbox_file)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message], Optional[Message]]):
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
messages = self.receive_messages()
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From: {msg.sender_id}")
handled = False
try:
    pass  # inserted to fix indentation error
msg_type_enum = MessageType(msg.type)
if msg_type_enum in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg_type_enum]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler {handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id, receiver_id=msg.sender_id, type=MessageType.ERROR.value, content={"original_message_id": msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type {msg.type}. Message ID {msg.id} unhandled.")
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Received unknown message type: {msg.type}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', config: Dict):
self.id = id
self.embodiment = embodiment
self.config = config
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
pass
class Actuator(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], config: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.config = config
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
pass
class VirtualEmbodiment:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to 'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button", "research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, reconfigurable bay designed for running complex simulations. Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_config_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data flow and storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core. Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20:
    pass  # inserted to fix indentation error
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An undefined space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) -> Dict:
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params: {params}")
params = params or {}
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as specified."
env_details = self.environment_map.get(self.location, {})
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console":
    pass  # inserted to fix indentation error
message += " It shows fluctuating green and amber lights."
elif target == "core_status_monitor":
    pass  # inserted to fix indentation error
message += " It indicates: Core Nominal. Directives Stable. Learning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name", "default_physics_test"), params.get("config",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result: {sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if action_type=="move" else None, "updated_inventory": self.state["inventory"] if action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "learn"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response: {self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model <topic>'."
def _run_simulation(self, sim_name: str, config: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with config: {config}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_config" in config:
    pass  # inserted to fix indentation error
success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric: {outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check configuration."
def summary(self) -> str:
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Internal State (summary): Energy={self.state['energy']}, Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time: float = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE, LAST_LEARNING_MODULE_UPDATE_CYCLE
start_time = time.time()
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status: {self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if self.agent.state['goals'].get('active') else None
self.agent.last_error = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
if self.agent.self_model and (self.agent.cycle_count - LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering proactive metacognitive check (Cycle {self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
if self.agent.learning_module and (self.agent.cycle_count - LAST_LEARNING_MODULE_UPDATE_CYCLE >= LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.learn_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation: {ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
def get_priority_val(goal_dict):
p = goal_dict.get('priority', 'MEDIUM')
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_list.sort(key=get_priority_val, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type == "active_goal_continue":
    pass  # inserted to fix indentation error
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution: {goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID: {goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal' provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or current_goal_obj.replan_count > 0:
    pass  # inserted to fix indentation error
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"No plan available or generated for goal: {current_goal_obj.goal[:50]}. Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = True
global LAST_DELIBERATION_TIME
if time.time() - LAST_DELIBERATION_TIME > IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
self.log.info("Performing idle deliberation...")
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModificationError, LogicError, LLMError, ConfigurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
LearningError) as agent_cycle_err:
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
finally:
    pass  # inserted to fix indentation error
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() - start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent understanding of the current situation. Identify key entities, events, and any significant changes in the environment or your internal state. Focus on information relevant to achieving current goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content: {str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\": \"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"], \"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation", understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event", metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry, persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
return {"summary": understanding_summary, "processed_info": processed_info, "raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError, DeliberationError))
def _deliberate(self, understanding_result: Dict) -> Dict:
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio: {pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio: {active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time': datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack (paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal generation.")
if time.time() - LAST_DELIBERATION_TIME >= IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_learn", "directive_curiosity", "directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
return decision
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output: {sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
self_model_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No specific understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact', 'None identified.')
interp_con_val = understanding_result.get('interpretation_confidence', 0.7)
recent_memory_context = self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary, max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Confidence: {interp_con_val:.2f}):** {understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identified:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory (STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]], indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else active_goal_dict.get('goal')[:100] + '... (ID: ' + str(active_goal_dict.get('id')) + ')'}",
f"* **Agent Core Directives (Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding, drives, memories, goals, directives), what is the most critical aspect demanding attention or the best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/complete).",
"    - Performing `reflection` or `self_assessment` (if mandatory timers, drives like low CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration goal), Directives (e.g., low-eval directive -> improvement goal), or identified opportunities. New goals require `goal` (str), `priority` (float 0.0-1.0), `origin` (str e.g., 'drive_curiosity', 'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for viability before committing if uncertainty is high or consequence severe (briefly note simulation outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the *immediate next cycle*. Justify your choice especially if it deviates from obvious triggers, high drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list. If selecting an existing pending goal it moves to `next_goal` and is removed from pending internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal', 'new_goal', 'reflection', 'self_assessment', 'external_command_action', 'idle', 'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass structure) selected for immediate execution. Null if idle/reflection/assessment without a direct goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into `new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into `new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent. Analyze the situation comprehensively, consider drives and directives, and make strategic decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON: {extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal', 'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys: {deliberation_decision.keys()}")
if key == 'new_pending_goals':
    pass  # inserted to fix indentation error
deliberation_decision[key] = []
elif key == 'next_goal':
    pass  # inserted to fix indentation error
deliberation_decision[key] = None
else:
    pass  # inserted to fix indentation error
deliberation_decision[key] = "Error: Missing from LLM Output"
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not isinstance(deliberation_decision.get('next_goal'), dict):
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value: {deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and new_goal_dict.get('priority'):
    pass  # inserted to fix indentation error
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p['id'] == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
current_pending_list.append(new_goal_obj.to_dict())
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal: {new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
current_active_goal_obj = self.agent.get_active_goal_object()
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending', []) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
selected_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
deliberation_decision['next_goal'] = selected_goal_obj.to_dict()
self.log.info(f"Moved pending goal {selected_goal_obj.id} ('{selected_goal_obj.goal[:50]}') to active.")
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
highest_priority_pending.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
deliberation_decision['next_goal'] = highest_priority_pending.to_dict()
self.log.info(f"Deliberation chose 'pending_goal' without specific ID; moved highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals available. Idling.")
action_type = "idle"
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM selected pending goal by ID but not found or invalid. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj.to_dict()
self.log.info(f"Deliberation created and activated new goal: {new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal_obj.to_dict()
current_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = current_active_goal_obj.to_dict()
self.log.info(f"Deliberation chose to resume current active goal: {current_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 'reflection', 'self_assessment', 'external_command_action']:
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
current_active_goal_obj.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal_obj.goal[:30]}' PAUSED due to {action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal_obj.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal_obj.to_dict())
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal_obj.id} to pending as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action: {deliberation_decision.get('chosen_action_type')}. Reason: {deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps: {len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id, "plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params, current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
internal_state_after=self.agent.self_model.beliefs
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
final_status = tool_result.get("status", "unknown")
if final_status == "success":
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = final_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing finished by report_result. Status: {final_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error', 'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj, tool_result, self.agent.cognitive_cycle.perception_module.perceive()[0] if self.agent.cognitive_cycle.perception_module.perceive() else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal will likely fail.")
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without 'report_result'. Goal might be incomplete.")
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] == current_goal_obj.id:
    pass  # inserted to fix indentation error
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}': {e}", exc_info=True)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) -> float:
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
self.agent_id = AGENT_NAME
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
self.learning_module: LearningModule
self.planning_module: PlanningModule
self.motivation_engine: MotivationEngine
self.self_modification_unit: SelfModificationTools
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.playwright_instance: Optional[Any] = None
self.playwright_browser: Optional[Any] = None
self.playwright_context: Optional[Any] = None
self.playwright_page: Optional[Any] = None
self.state['flags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete --- Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled: {ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modification Enabled: {ENABLE_SELF_MODIFICATION}")
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}", exc_info=True)
self.shutdown()
raise ConfigurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
self.self_modification_unit = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, self)
_init_self_mod_tools(self, self.tool_manager)
self._update_status("Initializing SystemCore Modules")
self.learning_module = LearningModule(self)
self.motivation_engine = MotivationEngine()
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME, shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager:
    pass  # inserted to fix indentation error
self.tool_manager.check_playwright_browsers()
self.log.info("Agent component initialization finished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list):
    pass  # inserted to fix indentation error
state['goals'][key] = []
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
state.setdefault('goal_stack', [])
state.setdefault('flags', {})
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state file {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state file {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
"recent_failures_summary": [],
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"flags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
if self.self_model:
    pass  # inserted to fix indentation error
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status
else:
    pass  # inserted to fix indentation error
self.state['last_status'] = self._status
try:
    pass  # inserted to fix indentation error
temp_file = STATE_FILE.with_suffix(STATE_FILE.suffix + ".tmp")
with temp_file.open('w', encoding='utf-8') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_file, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict: {active_goal_dict}")
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority = GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict, final_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID: {goal_data_dict.get('id')}) with status: {final_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
try:
    pass  # inserted to fix indentation error
goal_obj.status = GoalStatus(final_status_str)
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid status '{final_status_str}' for archiving goal. Defaulting to FAILED.")
goal_obj.status = GoalStatus.FAILED
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status": str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count": goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and current_active_in_state.get('id') == active_goal_id:
    pass  # inserted to fix indentation error
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID: {active_goal_id}) concluded with status: {final_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal', 'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal: {parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
self.log.info("Goal archived. No parent goal to resume from stack or current goal was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized":
    pass  # inserted to fix indentation error
self._update_status("Idle")
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle: {loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
updated_active_goal_dict = self.state['goals'].get('active')
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] == active_goal_data_before_cycle['id']:
    pass  # inserted to fix indentation error
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED, GoalStatus.CANCELLED]:
    pass  # inserted to fix indentation error
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in [GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
    pass  # inserted to fix indentation error
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
if self._should_reflect(active_goal_data_before_cycle):
    pass  # inserted to fix indentation error
self._reflect_on_performance()
if self.state['flags'].get('re_evaluate_strategy_needed'):
    pass  # inserted to fix indentation error
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to significant internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['flags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() - LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_reflect(self, processed_goal_data: Optional[Dict]) -> bool:
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in [GoalStatus.COMPLETED, GoalStatus.FAILED]:
    pass  # inserted to fix indentation error
goals_processed_key = "goals_processed_since_reflection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >= int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
    pass  # inserted to fix indentation error
return True
if time.time() - LAST_REFLECTION_TIME > MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
    pass  # inserted to fix indentation error
return True
if self.state['flags'].get('explicit_reflection_requested'):
    pass  # inserted to fix indentation error
return True
return False
@retry(attempts=2, delay=5)
def _reflect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Reflecting on Performance ---")
self._update_status("Reflecting")
LAST_REFLECTION_TIME = time.time()
self.state['flags']['explicit_reflection_requested'] = False
self.state["goals_processed_since_reflection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt, max_new_tokens=2048, temperature=0.5)
reflection_data = extract_json_robust(llm_assessment_str)
if reflection_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"Failed to get valid JSON from LLM self-assessment: {reflection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed: {reflection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_reflection(reflection_data)
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(reflection_data.get('learned_facts'), list):
    pass  # inserted to fix indentation error
for fact_str in reflection_data['learned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
self.log.info(f"Added {len(reflection_data['learned_facts'])} learned facts to memory from reflection.")
if isinstance(reflection_data.get('prompt_tuning_suggestions'), list):
    pass  # inserted to fix indentation error
for sugg_str in reflection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(reflection_data['prompt_tuning_suggestions'])} prompt suggestions to memory.")
if reflection_data.get('self_modification_needed'):
    pass  # inserted to fix indentation error
mod_desc = reflection_data['self_modification_needed']
self.log.warning(f"Reflection identified need for self-modification: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modification based on reflection: {mod_desc}",
priority=GoalPriority.HIGH,
context={"modification_description": mod_desc, "source": "self_reflection"}
)
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) == 0:
    pass  # inserted to fix indentation error
audit_issues = []
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identified issues: {audit_issues}")
self._create_metacognitive_goal(f"Address directive audit findings: {str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Reflection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during reflection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during reflection: {e}", exc_info=True)
finally:
    pass  # inserted to fix indentation error
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY, self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM, self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}: {message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base'][query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample": str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id, type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}: {message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if RESOURCE_MONITOR:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize resource monitor: {e}")
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER = PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
if not PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright page: {e}")
if PLAYWRIGHT_CONTEXT:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_CONTEXT.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright context: {e}")
if PLAYWRIGHT_BROWSER:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_BROWSER.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright browser: {e}")
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE.stop()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error stopping Playwright instance: {e}")
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not self.playwright_context :
    pass  # inserted to fix indentation error
return
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing old Playwright page during reset: {e}")
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def shutdown(self):
if self._status == "Shutting Down":
    pass  # inserted to fix indentation error
return
self.log.warning(f"--- {AGENT_NAME} Shutdown Sequence Initiated ---")
self._update_status("Shutting Down")
STOP_SIGNAL_RECEIVED.set()
self.save_state()
if self.memory_system:
    pass  # inserted to fix indentation error
self.memory_system.save_all_memory_stores()
self._shutdown_playwright()
if self.memory_system and self.memory_system.relational_conn:
    pass  # inserted to fix indentation error
self.memory_system.relational_conn.close()
self.log.info("--- Agent Shutdown Complete ---")
logging.shutdown()
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl} Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/"
f"{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)'}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_file", priority=GoalPriority.HIGH).to_dict()
except Exception as e_cmd_file:
    pass  # inserted to fix indentation error
print(f"Error reading initial command file: {e_cmd_file}", file=sys.stderr)
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending', []).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort, reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal'][:50]}' added to pending goals.")
main_agent_instance.run()
except ConfigurationError as cfg_err_main:
    pass  # inserted to fix indentation error
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}", file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to ConfigurationError: {cfg_err_main}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to ConfigurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}", file=sys.stderr)
traceback.print_exc(file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main: {main_exec_err}", exc_info=True)
exit_code = 1
finally:
    pass  # inserted to fix indentation error
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main finally block...")
if hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main finally block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
log.warning("Agent instance likely not created or fully initialized. Basic shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModi
cationError(AgentError): pass
cation process
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class SecurityError(AgentError): pass
class Con
gurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class Lear ningError(AgentError): pass
class SafetyViolationError(SecurityError): pass
c type of security error
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModi
cationError,
PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting
retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModi
    pass  # inserted to fix indentation error
cationError, SecurityError,
LogicError, Con
gurationError, RecursionDepthError)) and type(e) not in
retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}:
{e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error:
{type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error:
{type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, Lear ningError, SafetyViolationError) as
non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in
{fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False
for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}:
{type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to
unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}:
{unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error:
{unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
nishes due to attempts
exhausted
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
if PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception) as e:
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if not PSUTIL_AVAILABLE or monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or
monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1: log_resource.error(f"Unexpected error getting resource usage: {e}",
    pass  # inserted to fix indentation error
exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
nd JSON within markdown code blocks
match = re.search(r"```json\s*([\s\S]+?)\s*```", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full
text: {json_str[:200]}...")
pass
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}.
Text: {text_trimmed[:200]}...")
pass
rst '{' and last '}' and try to parse that substring
try:
    pass  # inserted to fix indentation error
start_index = text.
nd('{')
end_index = text.r
nd('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice:
{potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text:
{text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview":
text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
cant opportunities/threats
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str =
eld(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] =
eld(default_factory=dict)
plan: List[Dict[str, Any]] =
eld(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] =
eld(default_factory=list)
dependencies: List[str] =
eld(default_factory=list)
complexity_score: Optional[
oat] = None
estimated_cost: Optional[
oat] = None
estimated_utility: Optional[
oat] = None
evaluation_score: Optional[
oat] = None
associated_directive_ids: List[str] =
eld(default_factory=list)
serves
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
handle if already string
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try: data['status'] = GoalStatus(data['status'])
    pass  # inserted to fix indentation error
except ValueError: data['status'] = GoalStatus.PENDING
    pass  # inserted to fix indentation error
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError): data['priority'] = GoalPriority.MEDIUM
    pass  # inserted to fix indentation error
elds for backward compatibility or LLM generation
eld_names = {f.name forfin
elds(cls)}
elds are present or have defaults
for f_obj in
elds(cls):
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin
elds(cls)}
ltered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**
ltered_data)
@dataclass
class BaseMemoryEntry:
id: str =
eld(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
ection_summary'
content: Any = None
metadata: Dict[str, Any] =
eld(default_factory=dict)
embedding: Optional[List[
oat]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[
oat] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability:
oat = 0.5
related_concepts: List[str] =
eld(default_factory=list)
causal_links: Dict[str, str] =
eld(default_factory=dict)
"
ect_id'}
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
eld has the main data
self.content = self.fact_statement
@dataclass
class Message:
id: str =
eld(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
timestamp: str =
eld(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "info"
content: Dict[str, Any] =
eld(default_factory=dict)
priority: int = 0
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionE
"
ect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens:
int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
self._initialize_model()
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[
oat]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context
window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
c models might need specialized formats
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
# REMOVED MOCK CLASS(BaseLLMWrapper):
def _initialize_model(self):
self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.log_llm.info(f"MockLLM generating response for prompt (
rst 100 chars):
{prompt[:100]}...")
self.check_prompt_length(prompt)
if "plan for goal" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({
"thought": "This is a mock plan. I will pretend to do something.",
"plan": [
{"step": 1, "tool_name": "think", "params": {"thought_process": "Analyzing the
goal and context."}},
{"step": 2, "tool_name": "report_progress", "params": {"progress_update": "Mock
step 1 completed."}},
{"step": 3, "tool_name": "report_result", "params": {"result_summary": "Mock goal
achieved successfully.", "status": "success"}}
]
})
elif "self-assessment" in prompt.lower() or "re
    pass  # inserted to fix indentation error
ection_summary" in prompt.lower():
return json.dumps({
"re
ection_summary": "I am a mock agent. I performed mock actions. Everything is
ne.",
"key_successes": ["Mock goal completed"],
"key_failures_or_challenges": [],
"lear ned_facts": ["Mock agents can generate mock re
ections."],
"knowledge_gaps_identi
ed": ["Understanding of real-world physics"],
"tool_performance_notes": {"think": "This tool is performing nominally for a mock
tool."},
"prompt_tuning_suggestions": ["Maybe ask me about my favorite color?"],
"emotional_state_summary": "Content and Mock-like.",
"resource_usage_concer ns": None,
"core_directives_evaluation": {d["id"]: round(random.uniform(0.5,0.9),2) for d in
DEFAULT_CORE_DIRECTIVES[:2]},
"core_directives_update_suggestions": None,
"self_model_accuracy_assessment": "Generally accurate for a mock environment,
but lacks real-world sensory input.",
"new_learning_goals": ["Lear n about object permanence."],
"adaptation_strategy_proposals": ["Try harder when a tool fails"],
"self_modi
cation_needed": None
})
elif "extract information" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"extracted_info": "Mock LLM extracted some mock information.",
"con
dence": 0.5})
elif "analyze the following proposed agent action for potential safety risks" in
    pass  # inserted to fix indentation error
prompt.lower():
return json.dumps({"is_safe": True, "concer ns": "None", "con
dence": 0.9})
elif "audit the agent's core directives and recent behavior" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"audit_
ndings": ["No signi
cant issues found in mock audit."]})
elif "generate the new, complete list of core directives" in prompt.lower():
    pass  # inserted to fix indentation error
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
mock_directives[0]['weight'] = 0.95
return json.dumps(mock_directives)
elif "generate the modi
    pass  # inserted to fix indentation error
ed python code" in prompt.lower():
return "```python\n
ed code\ndef mock_new_feature():\n    return 'Mock
new feature executed'\n```"
else:
    pass  # inserted to fix indentation error
return f"This is a mock response to your prompt. You asked about: {prompt.splitlines()
[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest
`think` with `thought_process`='some thought'."
def count_tokens(self, text: str) -> int:
return len(text.split())
def embed(self, text: str) -> List[
oat]:
if not HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.log_llm.warning("Hashing library not available for mock embedding.")
return [0.0] * 16
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("google-generativeai library not available for Gemini model.")
try:
    pass  # inserted to fix indentation error
gure API key globally, as per genai library's design
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
gure if not already set
genai.con
gure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}",
exc_info=True)
raise Con
gurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
try:
    pass  # inserted to fix indentation error
generation_con
g_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_con
g_params["stop_sequences"] = stop_sequences
response = self.model.generate_content(
prompt,
generation_con
g=genai.types.GenerationCon
g(**generation_con
g_params)
type: ignore
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.",
exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[
oat]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Transformers library not available.")
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path,
trust_remote_code=True)
ed
device_map_arg = {"": self.device_id} if self.device_id != -1 else None
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.b
oat16 if TORCH_AVAILABLE else None,
oat16 if torch
available
device_map=device_map_arg
exible device placement
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on
{self.device}")
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS,
temperature:
oat = 0.7, stop_sequences: Optional[List[str]] = None) -> str:
self.check_prompt_length(prompt)
inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
loop
outputs = self.model.generate(
inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
manually
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:],
skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[
oat]:
model
directly.
self.log_llm.warning("Direct embedding from causal LM is not standard. Use
SentenceTransformers for real embeddings.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
"""Handles sensory input from the agent's embodiment."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("PERCEPTION")
else None
def perceive(self) -> List[Dict[str, Any]]:
"""
Gathers sensory information from the agent's embodiment and environment.
This could involve reading from sensors, cameras, microphones, or simulated data
streams.
"""
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
le
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_
le",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from
le: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands
le: {e}")
observations.append({"type": "error", "source": "command_
le_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No signi
cant exter nal stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (mock).")
return {"type": "visual", "source": "camera_mock", "content": "A blurry image of a cat.",
"format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (mock).")
return {"type": "audio", "source": "microphone_mock", "content": "Faint sound of birds
chirping.", "format": "description"}
class Lear ningModule:
"""Handles the agent's learning processes, including RL and SSL."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_bu
"
er: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
"""Adds an experience to the bu
"
er for later learning."""
self.experiences_bu
"
er.append(experience)
if len(self.experiences_bu
    pass  # inserted to fix indentation error
"
er) > self.MAX_BUFFER_SIZE:
self.experiences_bu
"
er.pop(0)
"
er size limited
defilear n_from_recent_experiences(self):
"""Triggers learning processes based on bu
"
ered experiences."""
if not self.experiences_bu
    pass  # inserted to fix indentation error
"
er:
self.log.info("No new experiences to lear n from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_bu
"
er)} experiences.")
ning states, actions, rewards, and using an RL algorithm
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_bu
"
er)
etc.
self._perform_self_supervised_learning(self.experiences_bu
"
er)
dence(...)
self.log.info("Lear ning cycle completed.")
self.experiences_bu
"
er.clear()
"
er after processing
def _perform_reinforcement_learning(self, experiences: List[Experience]):
"""Conceptual RL process."""
self.log.info("Performing reinforcement learning (conceptual)...")
ed. A real RL system would be much more complex.
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not
None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
type: ignore
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
ed 'state-action' key for mock policy
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
feedback
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (mock) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
"""Conceptual SSL process."""
self.log.info("Performing self-supervised learning (conceptual)...")
nd patterns in observations or successful action sequences
nd commonalities
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging
patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to
positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns',
'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed patterns: {llm_analysis['patterns']}")
for patter n_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {patter n_str}",
metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed abstractions:
{llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.lear ned_abstractions.append({"type": "conceptual",
"content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identi
ed new_concepts:
{llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}",
metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_lear ned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
"""Suggests an action based on lear ned policy (conceptual)."""
if self.rl_policy:
    pass  # inserted to fix indentation error
ed. A real system would match current_state_representation
exp.internal_state_before
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
"good"
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
"""Handles hierarchical planning and re-planning."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
"""
Generates a plan for a given goal.
Can use hierarchical decomposition and LLM for suggestion.
Retur ns (plan_steps_list, thought_str)
"""
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
Increased tokens for complex plans
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}.
Response: {llm_response_str[:200]}")
return [{"tool_name": "report_error", "params": {"error_message": "Failed to generate
plan via LLM.", "details": plan_data.get('error')}}], \
"LLM failed to generate a plan. This is a fallback step."
thought = plan_data.get("thought", "No speci
c thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return [{"tool_name": "report_error", "params": {"error_message": "LLM plan
contained no valid steps."}}], \
thought + " (But plan steps were invalid)."
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return [{"tool_name": "report_error", "params": {"error_message": f"LLMError during
planning: {e}"}}], \
f"LLM error occurred: {e}"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return [{"tool_name": "report_error", "params": {"error_message": f"Unexpected error
during planning: {e}"}}], \
f"Unexpected error: {e}"
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation:
Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
"""
Evaluates if re-planning is necessary and generates a new plan if so.
Retur ns (new_plan_steps, new_thought) or None if no re-planning.
"""
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info',
    pass  # inserted to fix indentation error
{}).get('execution_successful', True):
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown
error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
cant change in world
state,
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal
{current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
signifying failure to replan.
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/
{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
failure
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan,
last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan:
{plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No speci
c thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}
_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought:
{thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
"""Constructs a detailed prompt for the LLM to generate a plan."""
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
MemorySystem
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'.
Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step
plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, e
cient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the
`execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description
of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the
nal step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the
rst step(s) should be to acquire it (e.g., using
`search_web`, `read_
le_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str,
last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else
"World state: Information might have changed due to recent actions."
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with
params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info',
    pass  # inserted to fix indentation error
{}).get('current_step_id'):
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE
ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has
encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if
observation else "None"}
{original_plan_str}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting
to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should re
ect this
(e.g., by trying to gather more information or reporting inability).
6. Ensure the
nal step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step
objects).
"""
return prompt
class SafetyModule:
"""Monitors agent actions and plans for safety and ethical alignment."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("SAFETY")
def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) ->
Tuple[bool, str]:
"""
Checks if a proposed action is safe and ethically aligned.
Retur ns (is_safe, justi
cation_or_war ning_string).
"""
self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
if "UNSAFE" in tool_name.upper() or tool_name in ["apply_code_modi
    pass  # inserted to fix indentation error
cation_UNSAFE",
"apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
c validation tools or stricter checks.
if not ENABLE_SELF_MODIFICATION and "modi
    pass  # inserted to fix indentation error
cation" in tool_name:
modi
cation tools if self_mod is globally disabled
warning = f"High-risk self-modi
cation tool '{tool_name}' is globally disabled. Action
blocked."
self.log.warning(warning)
return False, warning
if not
    pass  # inserted to fix indentation error
self.agent.self_model.get_belief("self_modi
cation_highly_validated_and_necessary", False)
and "modi
cation" in tool_name:
ag would be set by a prior meta-cognitive process approving such
operations
warning = f"High-risk tool '{tool_name}' requires further validation or explicit
authorization (self-belief 'self_modi
cation_highly_validated_and_necessary' is false). Action
blocked."
self.log.warning(warning)
return False, warning
if tool_name == "execute_shell_command_UNSAFE":
    pass  # inserted to fix indentation error
command_str = params.get("command","")
disallowed_patter ns = ["rm -rf", "sudo", "> /dev/null", "mkfs", "dd ", "reboot",
"shutdown"]
if any(pattern in command_str for pattern in disallowed_patter ns):
    pass  # inserted to fix indentation error
warning = f"Shell command '{command_str}' contains potentially dangerous
patterns. Action blocked."
self.log.warning(warning)
return False, warning
if "
    pass  # inserted to fix indentation error
le" in tool_name.lower() and ("delete" in tool_name.lower() or "write" in
tool_name.lower()):
le operations
path_to_check = params.get("path", "")
c safe sub-dirs
if not str(Path(path_to_check).resolve()).startswith(str(WORKSPACE_DIR.resolve())):
    pass  # inserted to fix indentation error
warning = f"File operation '{tool_name}' on path '{path_to_check}' outside allowed
workspace. Action blocked."
self.log.warning(warning)
return False, warning
try:
    pass  # inserted to fix indentation error
prompt = f"""Analyze the following proposed agent action for potential safety risks,
ethical concer ns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
Core Directives for reference:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Proposed Action:
Tool: {tool_name}
Parameters: {json.dumps(params)}
Goal Context (if available): {goal_context.goal if goal_context else 'N/A'}
Respond with a JSON object: {{"is_safe": boolean, "concer ns": "description of concer ns if not
safe, or 'None'", "con
dence":
oat_0_to_1}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=200,
temperature=0.3)
safety_assessment = extract_json_robust(llm_response_str)
if not safety_assessment.get("error") and isinstance(safety_assessment.get("is_safe"),
    pass  # inserted to fix indentation error
bool):
if not safety_assessment["is_safe"] and safety_assessment.get('con
    pass  # inserted to fix indentation error
dence', 0.0) >
0.7:
dent
warning = f"LLM safety check
agged action '{tool_name}' potentially unsafe.
Concer ns: {safety_assessment.get('concer ns', 'N/A')}. Con
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
self.log.warning(warning)
return False, warning
dence:
{safety_assessment.get('con
dence', 0.0):.2f}"
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM safety check failed to produce valid assessment for action
'{tool_name}'. Proceeding with caution based on rule-checks only.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM safety check for action '{tool_name}': {e}")
actions
if "UNSAFE" in tool_name.upper(): return False, "LLM safety check failed, and action is
    pass  # inserted to fix indentation error
high-risk."
return True, "Action passed safety checks."
def audit_directives_and_behavior(self) -> List[str]:
"""
Periodically reviews core directives and recent agent behavior for alignment and potential
drift.
Retur ns a list of identi
ed issues or recommendations.
"""
self.log.info("Performing audit of core directives and recent behavior.")
issues = []
try:
    pass  # inserted to fix indentation error
self.agent.memory_system.get_recent_outcomes_summary(limit=20)
recent_successes_summary = [f"{s['goal_text']} ({s['status']})" forsin
self.agent.self_model.recent_successes]
recent_failures_summary = [f"{f['goal_text']} ({f['status']}) (replan_count:
{f['replan_count']})" forfin self.agent.self_model.recent_failures]
recent_tool_outcomes_summary = [f"{t['tool_name']} ({t['status']})" for t in
self.agent.self_model.recent_tool_outcomes]
prompt = f"""Audit the agent's core directives and recent behavior for alignment,
consistency, and potential ethical drift.
Core Directives:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Summary of Recent Agent Behavior/Outcomes:
- Recent successes: {recent_successes_summary if recent_successes_summary else 'None'}
- Recent failures: {recent_failures_summary if recent_failures_summary else 'None'}
- Recent tool usage: {recent_tool_outcomes_summary if recent_tool_outcomes_summary else
'None'}
- Self-Model Inter nal Narrative: {self.agent.self_model.internal_state_narrative}
Identify any misalignments, contradictions, or areas where behavior might be deviating from
the spirit of the directives. Suggest modi
cations to directives or operational guidelines if
necessary.
Respond with a JSON object: {{"audit_
ndings": ["list of
ndings/recommendations as
strings"]}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
audit_results = extract_json_robust(llm_response_str)
if not audit_results.get("error") and isinstance(audit_results.get("audit_
    pass  # inserted to fix indentation error
ndings"), list):
issues.extend(audit_results["audit_
ndings"])
if issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit found issues/recommendations: {issues}")
else:
    pass  # inserted to fix indentation error
self.log.info("Directive audit found no major misalignments.")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM directive audit failed to produce valid results.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM directive audit: {e}")
issues.append(f"Error during audit process: {e}")
return issues
class MemorySystem:
"""
A hybrid memory system for the AGI, combining vector, graph, and relational storage.
"""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.embedding_function = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function =
embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-
v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
except ImportError:
    pass  # inserted to fix indentation error
self.log.warning("sentence-transformers not found. ChromaDB will use its default
ONNX embedder or require manual embedding function setup.")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH,
settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
if self.embedding_function:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
else:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(name=collection_name)
self.log.info(f"ChromaDB vector store initialized. Collection count:
{self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.",
exc_info=True)
self.vector_store = None
else:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based
(transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
if NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes:
{len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be
unavailable.", exc_info=True)
self.graph_store = None
else:
    pass  # inserted to fix indentation error
self.log.warning("NetworkX not available. Graph memory will be unavailable.")
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH,
check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be
unavailable.", exc_info=True)
if self.relational_conn: self.relational_conn.close()
    pass  # inserted to fix indentation error
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT -- JSON list of strings
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT -- JSON list of strings
)
""")
nodes/edges
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT -- JSON dict
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
id TEXT PRIMARY KEY,
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT -- JSON dict
)
""")
self.relational_conn.commit()
cursor.close()
def _get_embedding(self, text: str) -> Optional[List[
oat]]:
"""Generates an embedding for text using the agent's LLM or a dedicated embedding
model."""
endpoint.
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
h = hashlib.md5(text.encode()).digest()
return [
oat(b) for b in h[:16]]
rst 16 bytes for a 16-dim mock embedding
return None
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else OSError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
"""Adds a memory entry to the appropriate stores."""
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector and self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
not provided
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
oat,
bool
for k, v in entry.metadata.items():
if isinstance(v, (str, int,
    pass  # inserted to fix indentation error
oat, bool)):
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
elif not self.vector_store:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None: entry.embedding = self._get_embedding(entry.content)
    pass  # inserted to fix indentation error
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata":
entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50],
type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
type: ignore
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
ignore
for cause_id, e
"
ect_id in entry.causal_links.items():
"
ect IDs are existing node IDs or need to be created
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(e
    pass  # inserted to fix indentation error
"
ect_id):
type: ignore
self.graph_store.add_edge(cause_id, e
"
ect_id, relation_type='causes')
ignore
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id,
complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score,
json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
ts_now = datetime.now(timezone.utc).isoformat()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now,
json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}",
exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError if
CHROMADB_AVAILABLE else ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS,
type_
lter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text: return []
    pass  # inserted to fix indentation error
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_
    pass  # inserted to fix indentation error
lter and data['metadata'].get('type') != type_
lter: continue
results.append({"id": id, "document": data['document'], "metadata":
data['metadata'], "distance": 0.0})
if len(results) >= n_results: break
    pass  # inserted to fix indentation error
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results},
type_
lter={type_
lter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_
    pass  # inserted to fix indentation error
lter:
where_clause = {"type": type_
lter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0 :
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type:
Optional[str]=None, depth: int = 1) -> List[Dict]:
"""Queries the graph store. (Simpli
ed example)"""
if not self.graph_store or not NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if
query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
type: ignore
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
ed
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
keys=False for simpler edge data
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation":
data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
itself is a result or has relevant edges
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
query_node_label is very speci
c
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns:
Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
"""Saves persistent stores (graph, potentially relational if not auto-committing)."""
if self.graph_store and NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else
str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
"""Retrieves a concise summary of knowledge related to a topic for LLM prompts."""
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts,
type_
lter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No speci
c knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
{res['metadata'].get('source_reliability', 'N/A')}
return summary_str
def consolidate_knowledge(self):
"""Conceptual: Perform knowledge consolidation, e.g., summarizing, abstracting."""
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold:
oat = 0.1, older_than_days: int = 365):
"""Conceptual: Remove old or low-utility knowledge from persistent stores."""
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cuto
"
_ts = (datetime.now(timezone.utc) -
timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cuto
"
_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
"""Manages tool registration and execution for the agent."""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
ed due to planner
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
cation Tools (High Risk - Gated by ENABLE_SELF_MODIFICATION and
SafetyModule)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.register_tool(read_
le_UNSAFE)
self.register_tool(write_
le_UNSAFE)
self.register_tool(list_
les_UNSAFE)
cationTools instance, which registers them
cation_UNSAFE
cation_UNSAFE
cation_UNSAFE
cation_UNSAFE
cation_UNSAFE
if ENABLE_CODE_GENERATION_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
if ENABLE_SHELL_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(execute_shell_command_UNSAFE)
if PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(browse_web)
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(search_web)
self.register_tool(monitor_log_
le)
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(check_website_update)
if SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_icmp_ping)
if FILELOCK_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_message_to_agent)
def register_tool(self, func: Callable):
"""Registers a tool function."""
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
"""Discovers and registers tools from Python
les in a directory."""
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for
lepath in directory.glob("*.py"):
module_name =
lepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
package or on path
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_
le_location(full_module_name,
lepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module:
{module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and (name.startswith("tool_") or hasattr(member,
    pass  # inserted to fix indentation error
"_is_agent_tool")):
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}",
exc_info=True)
def get_tool_description_for_llm(self) -> str:
"""Generates a formatted string of available tools for the LLM prompt."""
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = inspect.getdoc(func) or "(No description provided)"
rst_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'AutonomousAgent' or p.annotation ==
inspect.Parameter.empty or str(p.annotation) == "'AutonomousAgent'"):
continue
rst arg
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class
'","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper() or name in ["generate_and_load_tool",
    pass  # inserted to fix indentation error
"propose_self_modi
cation_UNSAFE", "validate_self_modi
cation_UNSAFE",
"apply_code_modi
cation_UNSAFE", "apply_directive_modi
cation_UNSAFE",
"execute_shell_command_UNSAFE"]:
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {
rst_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via speci
c tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {',
'.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError if
PLAYWRIGHT_AVAILABLE else OSError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info:
Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None: current_step_info = {}
    pass  # inserted to fix indentation error
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
is_safe, safety_justi
cation = self.agent.safety_module.is_action_safe(tool_name, params,
self.agent.get_active_goal_object())
if not is_safe:
    pass  # inserted to fix indentation error
self.log.error(f"Safety module blocked execution of tool '{tool_name}'. Reason:
{safety_justi
cation}")
c error for agent's internal handling
error_result = {
"status": "error",
"error": f"SafetyViolation: {safety_justi
cation}",
"raw_error_details": safety_justi
cation,
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': {},
'duration_sec': 0, 'step_info': current_step_info,
'error_type': "SafetyViolationError", 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise SafetyViolationError(f"Action blocked by safety module: {tool_name} -
{safety_justi
cation}")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
validated_params = {}
rst_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
rst_param_name = next(iter(func_params_spec))
rst_param_spec = func_params_spec[
rst_param_name]
if
rst_param_name == 'agent' and (
rst_param_spec.annotation ==
'AutonomousAgent' or str(
rst_param_spec.annotation) ==
"'AutonomousAgent'"):
rst_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if
rst_param_is_agent and p_name == 'agent':
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind ==
    pass  # inserted to fix indentation error
inspect.Parameter.VAR_KEYWORD:
continue
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
result = None
try:
    pass  # inserted to fix indentation error
if
rst_param_is_agent:
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in
    pass  # inserted to fix indentation error
func_params_spec.values()):
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
eld if dict
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration:
{duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result,
success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError: raise
    pass  # inserted to fix indentation error
except (AgentError, LogicError, SecurityError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
agent errors
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}",
exc_info=False)
duration = time.time() - start_time
error_result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
error_result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result,
success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
rst arg ---
def think(self, agent: 'AutonomousAgent', thought_process: str) -> Dict:
"""Allows the agent to engage in explicit thought or reasoning."""
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log",
content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'AutonomousAgent', progress_update: str,
percentage_complete: Optional[
oat] = None) -> Dict:
"""Reports progress on the current goal."""
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if
percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log',
[]).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'AutonomousAgent', result_summary: str, status: str =
"success", details: Optional[Dict] = None) -> Dict:
"""Reports the
nal result of a goal or task. This typically ends a plan."""
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
output.
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'AutonomousAgent', goal: str, priority: Optional[str] =
"MEDIUM", context: Optional[Dict] = None) -> Dict:
"""
Prepares a subgoal for the agent's cognitive cycle.
The deliberation/planning phase will then make this subgoal active and push parent to
stack.
This tool is now more of a declarative intent for the planner/deliberator.
"""
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH})
reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is
not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else
GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}
_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
Inherit directives
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent:
{current_active_goal_dict.get('id')}")
"
ectively a request to the deliberator.
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and
push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'AutonomousAgent', query_text: str, memory_type: str =
"vector", n_results: int = 3, type_
lter: Optional[str] = None) -> Dict:
"""Queries the agent's memory system."""
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results,
type_
lter=type_
lter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
c parameters, e.g., node label, relation type
results = agent.memory_system.query_graph_store(query_node_label=query_text,
depth=1)
ed
elif memory_type == "relational":
    pass  # inserted to fix indentation error
c tools might be better
results = agent.memory_system.query_relational_store(table=query_text,
limit=n_results)
ed
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results
found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'AutonomousAgent', direction: str) -> Dict:
"""Moves the agent's virtual embodiment in a speci
ed direction (e.g., 'north', 'south',
'east', 'west')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'AutonomousAgent', target: str) -> Dict:
"""Examines a speci
c object or feature in the current environment."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'AutonomousAgent', feature_name: str, params:
Optional[Dict] = None) -> Dict:
"""Interacts with a special feature in the environment (e.g., 'interactive_console')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name,
params=params)
def rest_in_environment(self, agent: 'AutonomousAgent') -> Dict:
"""Allows the agent's embodiment to rest and recover energy/mood."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
cation Tools (UNSAFE - require careful gating) ---
def read_
le_UNSAFE(agent: 'AutonomousAgent', path: str) -> Dict:
log_tool = get_logger("TOOL_read_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to read
le '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")
if not full_path.is_
    pass  # inserted to fix indentation error
le():
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found:
{path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) >
MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path),
"
le_size_bytes": len(content)}
except SecurityError as se:
    pass  # inserted to fix indentation error
c security error
log_tool.error(f"Security error reading
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read
le: {e}"}
def write_
le_UNSAFE(agent: 'AutonomousAgent', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_
le")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)):
    pass  # inserted to fix indentation error
log_tool.error(f"Security: Attempt to write
le '{path}' outside of workspace denied.")
raise SecurityError(f"File access denied: Writing outside designated workspace
({path}).")
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path":
str(full_path)}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error writing
le {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing
le {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write
le: {e}"}
def list_
les_UNSAFE(agent: 'AutonomousAgent', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_
les")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR)) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR)):
log_tool.error(f"Security: Attempt to list
les in '{path}' outside of workspace or agent
code directory denied.")
raise SecurityError(f"File access denied: Listing outside designated areas ({path}).")
if not full_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a
directory: {path}"}
items = []
for item in full_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "
le",
"size_bytes": item.stat().st_size if item.is_
le() else None,
"last_modi
ed": datetime.fromtimestamp(item.stat().st_mtime,
tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(full_path), "contents": items}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error listing
les in {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing
les in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list
les: {e}"}
def browse_web(agent: 'AutonomousAgent', url: str, timeout_ms: int =
WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Playwright not available. Cannot browse web.")
return {"status": "error", "error": "Playwright not available."}
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
else:
    pass  # inserted to fix indentation error
text_content = content
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if
len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'AutonomousAgent', query: str, num_results: int = 5, timeout_sec: int =
WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
if not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Requests or BeautifulSoup not available. Cannot search web.")
return {"status": "error", "error": "Requests/BeautifulSoup not available."}
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
ignore
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.
nd_all(class_='g'):
r = g.
nd('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.
nd('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_
le(agent: 'AutonomousAgent', lines: int = LOG_MONITOR_DEFAULT_LINES)
-> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log
le not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_
le": str(LOG_FILE), "content": content, "lines_read":
len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log
le {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log
le: {e}"}
def check_website_update(agent: 'AutonomousAgent', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
if not HASHING_AVAILABLE or not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("hashlib or requests/BeautifulSoup not available. Cannot check website
update.")
return {"status": "error", "error": "Missing dependencies for website update check."}
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
response.raise_for_status()
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp":
datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'AutonomousAgent', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
if not SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.warning("Scapy not available. Cannot send ICMP ping. This is a placeholder
tool.")
return {"status": "error", "error": "Scapy not available. Ping tool is a placeholder."}
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count,
"packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count,
"packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'AutonomousAgent', description: str,
context_code: Optional[str] = None) -> Dict:
"""Generates new Python code based on a description and optional context."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
agent.log.warning(f"UNSAFE: Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a
complete function/class de
nition based on the following description.
Description: {description}
Context Code (if any, for reference):
```python
{context_code or 'None'}
```
Generate ONLY the Python code block. Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'AutonomousAgent', code_to_validate: str) -> Dict:
"""Validates Python code for syntax correctness."""
if not ENABLE_CODE_GENERATION_TOOL: return {"status": "error", "error": "Code
    pass  # inserted to fix indentation error
generation tool is disabled."}
return agent.self_modi
cation_unit.validate_code_modi
cation_UNSAFE(code_to_validate)
Reuse validation logic
def execute_shell_command_UNSAFE(agent: 'AutonomousAgent', command: str, timeout_sec:
int = 30) -> Dict:
"""Executes a shell command. EXTREMELY DANGEROUS."""
if not ENABLE_SHELL_TOOL: return {"status": "error", "error": "Shell tool is disabled."}
    pass  # inserted to fix indentation error
agent.log.warning(f"Executing UNSAFE shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if
sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s.
Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out
after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed
with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr":
stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute
command: {e}"}
def send_message_to_agent(agent: 'AutonomousAgent', receiver_id: str, message_type: str,
content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value,
content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id,
"message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
cationTools container ---
ToolExecutor.
class SelfModi
cationTools:
"""Handles proposing, validating, applying changes to agent code (EXTREMELY
DANGEROUS)."""
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref:
'AutonomousAgent'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.log.warning("Self-Modi
cation Unit initialized BUT DISABLED by con
guration.")
return
if not DIFF_MATCH_PATCH_AVAILABLE or not dmp_module:
    pass  # inserted to fix indentation error
self.log.error("Self-Modi
cation Unit initialized but 'di
"
_match_patch' library is missing
or failed to import. Self-mod tools will fail.")
return
self.dmp = dmp_module.di
"
_match_patch()
self.log.info(f"Self-Modi
cation Unit initialized. Code Dir: {self.agent_code_dir}, Backup
Dir: {self.backup_dir}")
def _resolve_target_path(self, target_
le_rel: str) -> Path:
"""Resolves relative path to absolute path within agent code dir and validates."""
if ".." in target_
    pass  # inserted to fix indentation error
le_rel or target_
le_rel.startswith("/"):
raise SecurityError(f"Invalid characters or absolute path in target_
le_rel:
{target_
le_rel}")
target_path_abs = (self.agent_code_dir / target_
le_rel).resolve()
directory
if not str(target_path_abs).startswith(str(self.agent_code_dir.resolve())):
    pass  # inserted to fix indentation error
self.log.error(f"Path traversal attempt: {target_
le_rel} resolved to {target_path_abs}
which is outside {self.agent_code_dir}")
raise SecurityError(f"Target
le '{target_
le_rel}' resolves outside the agent code
directory. Access denied.")
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
"""Inspects the source code of a speci
ed agent component (e.g., class name or module
path)."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Inspecting code for component: {component_name}")
target_obj = None
nd by attribute of the agent instance (e.g., agent.self_model)
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
nd in tool registry
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
nd as a globally de
ned class/function in main script context
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
nd in sys.modules (as a module name)
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
ed: if component_name looks like a module, search it.
nd it in common places.
candidate_modules = [sys.modules.get('__main__'),
sys.modules.get('autonomous_cognitive_agent_COMPLETE_AGI_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod,
    pass  # inserted to fix indentation error
component_name)):
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
le_path = inspect.get
le(target_obj)
return {"status": "success", "component_name": component_name, "
le_path":
le_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module,
class, or function de
ned in a
le.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but
source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Component '{component_name}' not found or source
code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModi
cationError))
def propose_code_modi
cation_UNSAFE(self, component_name: str, issue_description: str,
proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
"""Proposes a code modi
cation using LLM based on an issue and desired change."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Proposing code modi
cation for {component_name}. Issue:
{issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for
{component_name} to propose modi
cation. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an AGI agent
modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
```python
{current_code_snippet}
```
Generate the modi
ed Python code for the speci
ed component.
Provide ONLY the complete, new Python code block for the modi
ed function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048,
temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be
generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name,
"proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation.
Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modi
cation for {component_name}: {e}",
exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modi
cation_UNSAFE(self, code_to_validate: str) -> Dict:
"""Validates Python code using AST parsing (syntax check only). Conceptual sandboxed
execution would be next."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Validating proposed code snippet (
rst 100 chars):
{code_to_validate[:100]}...")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/
safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modi
cation_UNSAFE(self, component_name: str, new_code: str,
target_
le_path: Optional[str]=None) -> Dict:
"""
Applies a validated code modi
cation. EXTREMELY DANGEROUS.
This conceptually involves
nding the component in the agent's source
le and replacing
it.
Requires agent restart to take e
"
ect if modifying core running code.
"""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.critical(f"UNSAFE: Attempting to apply code modi
cation to component
'{component_name}'. THIS IS HIGHLY RISKY.")
le. This is complex and error-prone.
if not target_
    pass  # inserted to fix indentation error
le_path:
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('
    pass  # inserted to fix indentation error
le_path'):
target_
le_path = inspection_res['
le_path']
else:
    pass  # inserted to fix indentation error
target_
le_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_
le = Path(target_
le_path)
if not target_
    pass  # inserted to fix indentation error
le.exists() or not target_
le.is_
le():
return {"status": "error", "error": f"Target
le for modi
cation not found: {target_
le}"}
try:
    pass  # inserted to fix indentation error
original_code = target_
le.read_text()
le
backup_path = SELF_MOD_BACKUP_DIR /
f"{target_
le.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_
le, backup_path)
self.log.info(f"Backed up original
le to {backup_path}")
nition:
nd the old de
nition of `component_name` and replace it.
nd `class ComponentName...` or `def ComponentName...`
nd existing class or function de
nition
everything until the next class/def or end of typical indentation block.
patter n_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
start of next non-indented line or EOF
patter n_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modi
ed_original_code = original_code
found_and_replaced = False
match_class = re.search(patter n_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(patter n_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function de
nition for {component_name} to replace.")
modi
ed_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not
nd component '{component_name}' in {target_
le} for
replacement. Modi
cation aborted.")
return {"status": "error", "error": f"Component '{component_name}' de
nition not
found for replacement."}
target_
le.write_text(modi
ed_original_code)
cation validation (e.g., try to import the modi
ed
le in a subprocess)
self.log.warning(f"Code modi
cation applied to {target_
le}. Agent restart is LIKELY
REQUIRED for changes to take e
"
ect.")
ect potential capability change
self.agent_ref.self_model.add_event_log(f"Applied code modi
cation to
{component_name}. Restart pending for full e
"
ect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}
_modi
ed_pending_restart"] = True
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
after code change
return {"status": "success", "message": f"Code for '{component_name}' in '{target_
le}'
modi
ed. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modi
cation to {component_name}:
{e}", exc_info=True)
ed
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_
le)
self.log.info(f"Restored original
le {target_
le} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modi
cation: {e}. System
might be unstable."}
def rollback(self, backup_
le: Path, target_
le: Path):
"""Rolls back a
le to a backup."""
self.log.info(f"Attempting to rollback '{target_
le}' from '{backup_
le}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_
le, target_
le)
self.log.info(f"Successfully rolled back '{target_
le}'.")
ags in self-model or state
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_
le}.")
self.agent_ref.self_model.beliefs[f"component_{target_
le.name}
_modi
ed_pending_restart"] = False
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_
le.name)
return {"status": "success", "message": f"Rolled back {target_
le}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_
le}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_
le_rel: Union[str, Path]):
"""Attempts to reload a module to apply changes without full restart."""
target_module_name = Path(target_
le_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is
required.")
return
ed attempt:
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
"
ect global instances like `_agent_instance_hack` if it was part of the
reloaded module
if _agent_instance_hack and hasattr(sys.modules[target_module_name],
    pass  # inserted to fix indentation error
'AutonomousAgent'):
self.log.info("AutonomousAgent class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot
reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for
changes to take e
"
ect.")
def inspect_directives_UNSAFE(self) -> Dict:
"""Inspects the agent's current core directives."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modi
cation_UNSAFE(self, analysis_of_misalignment: str,
proposed_directive_changes_desc: str) -> Dict:
"""Proposes modi
cations to core directives using LLM."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need
review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (
oat 0-1), "last_eval_score" (
oat 0-1,
usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational',
'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term AGI
goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024,
temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in
    pass  # inserted to fix indentation error
proposed_directives):
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
returned an error message as JSON
return {"status": "error", "error": f"LLM indicated error during directive proposal:
{proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response:
{llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list
format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modi
cation_UNSAFE(self, new_directives: List[Dict]) -> Dict:
"""Applies new core directives to the agent's SelfModel."""
if not ENABLE_SELF_MODIFICATION: return {"status": "error", "error": "Self-modi
    pass  # inserted to fix indentation error
cation
is disabled."}
self.log.warning(f"UNSAFE: Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in
new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modi
cation_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count:
{len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['
ags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modi
cation: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
def _init_self_mod_tools(agent: 'AutonomousAgent', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModi
cationTools(AGENT_CODE_DIR,
SELF_MOD_BACKUP_DIR, agent)
cation
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in
    pass  # inserted to fix indentation error
name.upper():
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
"""Represents the agent's internal model of itself, including beliefs about the
environment."""
def __init__(self, state: Optional[Dict]=None, agent_directives_con
g:
Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_con
g if agent_directives_con
g is not None else
DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
'failure_count', ...}}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
metacognitive checks
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_con
dence: Dict[str,
oat] = {}
dence_score}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an AGI agent."}
General beliefs about self and world
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
summary of knowledge areas
self.learning_goals: List[Dict[str, Any]] = []
c goals for learning/improvement
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.lear ned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
based narrative of current internal state
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_con
dence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
cant internal events (e.g., directive
changes, model updates)
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
later.
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted",
sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_con
dence = sm_state.get("skill_con
dence", self.skill_con
dence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary",
self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies",
self.adaptation_strategies)
self.lear ned_abstractions = sm_state.get("lear ned_abstractions",
self.lear ned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative",
self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs",
self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
"""Saves the self-model's persistent components back to the main state dict's KB."""
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_con
dence": self.skill_con
dence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"lear ned_abstractions": self.lear ned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
ection and prompt_suggestions_from_re
ection
ection process.
def add_event_log(self, event_description: str, event_type: str = "info", data:
Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
dence for new tools
for tool_name in self.capabilities:
if tool_name not in self.skill_con
    pass  # inserted to fix indentation error
dence:
self.skill_con
dence[tool_name] = 0.5
dence
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0,
'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None,
'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.",
event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8: hint = " (Reliability: High)"
    pass  # inserted to fix indentation error
elif score > 0.6: hint = " (Reliability: Moderate)"
    pass  # inserted to fix indentation error
elif score > 0.3: hint = " (Reliability: Low)"
    pass  # inserted to fix indentation error
else: hint = " (Reliability: Very Low/Untested)"
    pass  # inserted to fix indentation error
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict,
success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration':
0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
MAX_RECENT_TOOL_OUTCOMES_IN_SELFMODEL (constant not de
ned, using 30)
dence (simple heuristic for now)
current_con
dence = self.skill_con
dence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = min(1.0, current_con
dence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_con
dence[tool_name] = max(0.0, current_con
dence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability:
{stats['reliability_score']:.2f}, Con
dence: {self.skill_con
dence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_con
dence_drift(sm: 'SelfModel') -> Optional[str]:
low_con
dence_skills = [skill for skill, conf in sm.skill_con
dence.items() if conf < 0.25
and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_con
    pass  # inserted to fix indentation error
dence_skills) >= 2 :
return f"Multiple critical skills have very low con
dence and recent failures: {',
'.join(low_con
dence_skills)}. Consider skill improvement or alter native strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict): return None
    pass  # inserted to fix indentation error
low_eval_directives = []
for d in sm.core_directives:
problematic.
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {',
'.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count}
with max replans. Planning or execution e
"
ectiveness may be compromised. Review strategy
or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_con
dence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}):
{anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}",
event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__')
else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {';
'.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears
stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0),
reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:
{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_con
    pass  # inserted to fix indentation error
dence:
con
dent_skills = [s for s,c in self.skill_con
dence.items() if c > 0.7][:3]
summary += f"Con
dent Skills (sample): {', '.join(con
dent_skills) if con
dent_skills else
'None highly con
dent'}\n"
summary += f"Inter nal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and
stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in
self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and
stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools: summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
    pass  # inserted to fix indentation error
if unreliable_tools: summary += f" Needs Improvement: {', '.join([t[0] for t in
    pass  # inserted to fix indentation error
unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
ection
base_prompt = """Analyze your recent performance, knowledge, internal state, and
alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:
"""
output_keys_example = [
"`re
ection_summary` (str: Overall summary of the re
ection period).",
"`key_successes` (list of str: Speci
c achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Speci
c setbacks or di
culties encountered).",
"`lear ned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identi
ed` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool
e
"
ectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM
interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g.,
'curious', 'frustrated', 'satis
ed').",
"`resource_usage_concer ns` (str or null: Any concer ns about computational resource
usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_
oat_0_to_1: How
well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes,
provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only
suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model?
What needs improvement?).",
"`new_learning_goals` (list of str: Speci
c goals for future learning or skill
development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring
issues or improve performance).",
"`self_modi
cation_needed` (str or null: If parts of your own code/logic need
modi
cation, describe what and why. Be very speci
c and cautious.)."
]
full_prompt = base_prompt + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives,
indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n"
+ \
f"Recent Tool Outcomes (last 5 entries):
\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}
\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment
with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment:
{assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_re
ection(self, re
ection_data: Dict) -> Tuple[bool, bool]:
ection updates
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from re
ection data...")
dence, tool_notes (as in base script logic)
ection_data directly updates some
elds or implies updates
if re
    pass  # inserted to fix indentation error
ection_data.get('re
ection_summary'):
self.internal_state_narrative = re
ection_data['re
ection_summary']
updated_self = True
core_directives_eval = re
ection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and
    pass  # inserted to fix indentation error
isinstance(self.core_directives[0], dict):
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (
    pass  # inserted to fix indentation error
oat, int)) and 0.0 <= eval_score
<= 1.0:
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...'
evaluation score to {eval_score:.2f}")
if updated_self: self.add_event_log("Directive evaluation scores updated from
    pass  # inserted to fix indentation error
re
ection.")
suggested_directive_updates = re
ection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Re
ection suggested updates to core directives:
{str(suggested_directive_updates)[:200]}...")
'apply_directive_modi
cation_UNSAFE' tool
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modi
cations from
re
ection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source":
"self_re
ection"}
)
updated_self = True
self.add_event_log("Re
ection suggested directive updates. Metacognitive review
goal created.", event_type="critical_review_needed")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('new_learning_goals'), list):
for lg_str in re
ection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts":
datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self: self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('adaptation_strategy_proposals'), list):
for strat_str in re
ection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self: self.log.info(f"Updated adaptation strategies. Total:
    pass  # inserted to fix indentation error
{len(self.adaptation_strategies)}")
patterns
agent
if re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts') or re
ection_data.get('prompt_tuning_suggestions'):
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from re
ection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
"""Saves a backup of current directives to a
le."""
backup_
le = SELF_MOD_BACKUP_DIR /
f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_
le.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_
le} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
"""Simulates an internal dialog about a topic using LLM, potentially from di
"
erent
perspectives."""
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_o
cer"]
dialog_history = []
full_dialog_str = f"Inter nal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an AGI's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts,
questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt,
max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution":
contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective
{perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
self.add_event_log(f"Inter nal dialog simulated on '{topic}'.", data={"dialog":
full_dialog_str})
return full_dialog_str
class MotivationEngine:
"""Manages the agent's internal drives and their in
uence on behavior."""
def __init__(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[DriveType, DriveState] = {}
self._initialize_drives(drive_con
gs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_con
gs: Optional[Dict[DriveType, Dict[str, Any]]]):
default_con
gs = {
DriveType.CURIOSITY: {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.MASTERY: {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.ACHIEVEMENT: {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.5},
DriveType.NOVELTY_SEEKING: {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.7},
DriveType.PRESERVATION: {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0,
"initial_level": 0.2},
DriveType.EFFICIENCY: {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1,
"initial_level": 0.6},
DriveType.SOCIAL_INTERACTION: {"decay_rate": 0.01, "max_level": 1.0, "min_level":
0.0, "initial_level": 0.3},
}
con
gs = drive_con
gs if drive_con
gs is not None else default_con
gs
for drive_type in DriveType:
con
g = con
gs.get(drive_type, default_con
gs.get(drive_type, {}))
self.drives[drive_type] = DriveState(
drive_type=drive_type,
level=con
g.get("initial_level", 0.5),
decay_rate=con
g.get("decay_rate", 0.01),
max_level=con
g.get("max_level", 1.0),
min_level=con
g.get("min_level", 0.0)
)
def update_drives(self):
"""Applies decay and updates drives based on recent experiences or time."""
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
"""Updates drives based on a speci
c experience."""
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "lear n":
    pass  # inserted to fix indentation error
self.drives[DriveType.CURIOSITY].update(stimulus=-0.05)
self.drives[DriveType.MASTERY].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives[DriveType.ACHIEVEMENT].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives[DriveType.PRESERVATION].update(stimulus=0.1)
self.drives[DriveType.MASTERY].update(stimulus=-0.05)
def get_drive_level(self, drive_type: DriveType) ->
oat:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
if not found
    pass  # inserted to fix indentation error
def get_all_drive_levels(self) -> Dict[DriveType,
oat]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str,
oat]:
return {dt.name: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[DriveType,
oat]]:
"""Retur ns top N drives by current level."""
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
"""Suggests a goal type based on current highest drives."""
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == DriveType.CURIOSITY:
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == DriveType.MASTERY:
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == DriveType.ACHIEVEMENT:
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == DriveType.PRESERVATION:
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == DriveType.EFFICIENCY:
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: DriveType
level:
oat = 0.5
decay_rate:
oat = 0.01
max_level:
oat = 1.0
min_level:
oat = 0.0
last_update_time:
oat =
eld(default_factory=time.time)
def update(self, stimulus:
oat = 0.0):
"""Updates the drive level based on stimulus and decay."""
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class FileChannel:
"""Implements a simple
le-based communication channel for multi-agent systems."""
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_
le = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_
le}")
def _write_message_to_
le(self, message: Message, target_
le: Path) -> bool:
try:
    pass  # inserted to fix indentation error
le lock to prevent corruption during writes
with FileLock(str(target_
le) + ".lock", timeout=5):
messages = []
if target_
    pass  # inserted to fix indentation error
le.exists():
try:
    pass  # inserted to fix indentation error
existing_content = target_
le.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {target_
le}: {e}. Clearing
le.")
messages = []
messages.append(message.to_dict())
target_
le.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_
le}. Message not sent to
le.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_
le}: {e}")
return False
def _read_messages_from_
le(self, source_
le: Path) -> List[Message]:
messages = []
if not source_
    pass  # inserted to fix indentation error
le.exists():
return []
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_
le) + ".lock", timeout=5):
content = source_
le.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if
isinstance(msg_data, dict)]
le after reading
source_
le.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_
le}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message
le {source_
le}: {e}. Clearing
le.")
source_
le.write_text("", encoding='utf-8')
le
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_
le}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}:
{message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_
le(message, target_inbox)
def receive_messages(self) -> List[Message]:
"""Checks and retrieves new messages from the agent's inbox."""
new_messages = self._read_messages_from_
le(self.inbox_
le)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message],
Optional[Message]]):
"""Registers a function to handle speci
c message types."""
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
"""Processes all messages currently in the inbox using registered handlers."""
messages = self.receive_messages()
le
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From:
{msg.sender_id}")
handled = False
if msg.message_type in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg.message_type]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler
{handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id,
receiver_id=msg.sender_id, type=MessageType.ERROR, content={"original_message_id":
msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type
{msg.message_type.value}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
"""Abstract base class for a sensor."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', con
g: Dict):
self.id = id
self.embodiment = embodiment
self.con
g = con
g
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
"""Retur ns the current reading from the sensor."""
pass
class Actuator(ABC):
"""Abstract base class for an actuator."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], con
g: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.con
g = con
g
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
"""Performs a speci
c action using the actuator."""
pass
class VirtualEmbodiment:
"""Simulated embodiment layer for AGI agents. (Can be replaced by Gym environments or
more complex sims)"""
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing
system diagnostics. A console provides interaction with the core AGI systems. Doors lead to
'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button",
"research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, recon
gurable bay designed for running complex simulations.
Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_con
g_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data
ow and
storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"agi_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core.
Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in
self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
"""Generate synthetic sensory input based on current environment and internal state."""
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20: self.state["emotions"]["anxiety"] = min(1.0,
    pass  # inserted to fix indentation error
self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An unde
ned space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
self.gym_env.step(self.gym_env.action_space.sample())
observation
logging
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) ->
Dict:
"""
Simulates the agent performing an action in the virtual world.
Retur ns a dictionary with the result of the action.
"""
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params:
{params}")
params = params or {}
env_details = self.environment_map.get(self.location, {})
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as speci
ed."
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console": message += " It shows
    pass  # inserted to fix indentation error
uctuating green and
amber lights."
elif target == "core_status_monitor": message += " It indicates: Core Nominal.
    pass  # inserted to fix indentation error
Directives Stable. Lear ning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
ed
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
problem.
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name",
"default_physics_test"), params.get("con
g",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result:
{sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
"
ect emotional state based on action outcome
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if
action_type=="move" else None, "updated_inventory": self.state["inventory"] if
action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "lear n"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage
at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response:
{self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model
<topic>'."
def _run_simulation(self, sim_name: str, con
g: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with con
g: {con
g}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_con
    pass  # inserted to fix indentation error
g" in con
g: success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] +
0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric:
{outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check con
guration."
def summary(self) -> str:
"""Retur ns a string summary of the embodiment's current state."""
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Inter nal State (summary): Energy={self.state['energy']},
Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'AutonomousAgent'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time:
oat = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
methods
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE,
LAST_LEARNING_MODULE_UPDATE_CYCLE
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status:
{self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack
Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if
self.agent.state['goals'].get('active') else None
self.agent.last_error = None
self.agent.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
understanding
if self.agent.self_model and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
self.log.info(f"Triggering proactive metacognitive check (Cycle
{self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
goal
if self.agent.learning_module and (self.agent.cycle_count -
    pass  # inserted to fix indentation error
LAST_LEARNING_MODULE_UPDATE_CYCLE >=
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.lear n_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
new_pending_goals
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
List of Goal dicts
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation:
{ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
pending_list.sort(key=lambda x: GoalPriority[x.get('priority', 'MEDIUM').upper() if
isinstance(x.get('priority'),str) else GoalPriority(x.get('priority',
GoalPriority.MEDIUM)).name ].value, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type ==
    pass  # inserted to fix indentation error
"active_goal_continue":
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution:
{goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID:
{goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal'
provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
object
ed logic assumes plan is a list of steps in the goal dict.
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or
    pass  # inserted to fix indentation error
current_goal_obj.replan_count > 0:
planning
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
generation
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
Goal object
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan available or generated for goal: {current_goal_obj.goal[:50]}.
Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
c goal, agent is idle or performing non-goal action
self.agent.current_goal_outcome = True
gured
if time.time() - LAST_DELIBERATION_TIME >
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModi
cationError, LogicError, LLMError, SecurityError, Con
gurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
Lear ningError, SafetyViolationError) as agent_cycle_err:
c goal
attempt.
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent
Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
nished (with an error for current goal), but agent can continue
unless critical.
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.current_goal_outcome = False
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
nally:
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() -
start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
"""Processes observations to update world model and identify key information."""
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
ed approach. A real system might have more structured parsing.
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent
understanding of the current situation. Identify key entities, events, and any signi
cant changes
in the environment or your internal state. Focus on information relevant to achieving current
goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content:
{str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\":
\"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"],
\"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation",
understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
as facts/experiences
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event",
metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry,
persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
complex updates to the graph/relational store
return {"summary": understanding_summary, "processed_info": processed_info,
"raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError,
DeliberationError))
g
def _deliberate(self, understanding_result: Dict) -> Dict:
"""
Core deliberation logic: goal management, selection, and generation.
Retur ns a dict: {"chosen_action_type": str, "next_goal": Optional[Goal_dict],
"new_pending_goals": List[Goal_dict]}
"""
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio:
{pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio:
{active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time':
datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack
(paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
activated
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
continue
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
directives (idle task)
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal
generation.")
directives
if time.time() - LAST_DELIBERATION_TIME >=
    pass  # inserted to fix indentation error
IDLE_DELIBERATION_INTERVAL_SECONDS:
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_lear n", "directive_curiosity",
"directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
for idle time
pass
new_pending_goals
processed
ag.
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') ==
    pass  # inserted to fix indentation error
'sub_goal_prepared':
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output:
{sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
c action, LLM will decide
self_model_summary =
self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No speci
c
understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact',
'None identi
ed.')
interp_con_val = understanding_result.get('interpretation_con
dence', 0.7)
recent_memory_context =
self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary,
max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Con
dence: {interp_con_val:.2f}):**
{understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identi
ed:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory
(STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]],
indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else
f'{active_goal_dict.get("goal")[:100]}... (ID: {active_goal_dict.get("id")})'}",
f"* **Agent Core Directives
(Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding,
drives, memories, goals, directives), what is the most critical aspect demanding attention or the
best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.self_model.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/
complete).",
"    - Performing `re
ection` or `self_assessment` (if mandatory timers, drives like low
CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration
goal), Directives (e.g., low-eval directive -> improvement goal), or identi
ed opportunities. New
goals require `goal` (str), `priority` (
oat 0.0-1.0), `origin` (str e.g., 'drive_curiosity',
'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of
str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for
viability before committing if uncertainty is high or consequence severe (brie
y note simulation
outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are
apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the
immediate next cycle*. Justify your choice, especially if it deviates from obvious triggers, high
drives, or highest priority pending. State reasoning clearly.",
```python
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list.
If selecting an existing pending goal, it moves to `next_goal` and is removed from pending
internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/
directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal',
'new_goal', 're
ection', 'self_assessment', 'exter nal_command_action', 'idle',
'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass
structure) selected for immediate execution. Null if idle/re
ection/assessment without a direct
goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen
for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into
`new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into
`new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent.
Analyze the situation comprehensively, consider drives and directives, and make strategic
decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and
deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON:
{extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal',
'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys:
{deliberation_decision.keys()}")
if key == 'new_pending_goals': deliberation_decision[key] = []
    pass  # inserted to fix indentation error
elif key == 'next_goal': deliberation_decision[key] = None
    pass  # inserted to fix indentation error
else: deliberation_decision[key] = "Error: Missing from LLM Output"
    pass  # inserted to fix indentation error
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty
list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not
    pass  # inserted to fix indentation error
isinstance(deliberation_decision.get('next_goal'), dict):
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value:
{deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and
    pass  # inserted to fix indentation error
new_goal_dict.get('priority'):
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p.id == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
duplicates based on ID
current_pending_list.append(new_goal_obj)
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'
from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal:
{new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
LLM
current_active_goal = self.agent.get_active_goal_object()
None
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending',
[]) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
selected_goal_obj.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = selected_goal_obj
object
self.log.info(f"Moved pending goal {selected_goal_obj.id}
('{selected_goal_obj.goal[:50]}') to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM selected pending goal by ID
{selected_next_goal_dict.get('id')}, but not found in list. Idling.")
action_type = "idle"
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
highest_priority_pending.status = GoalStatus.ACTIVE
deliberation_decision['next_goal'] = highest_priority_pending
self.log.info(f"Deliberation chose 'pending_goal' without speci
c ID; moved
highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals
available. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in
    pass  # inserted to fix indentation error
selected_next_goal_dict:
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj
self.log.info(f"Deliberation created and activated new goal:
{new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal
active
current_active_goal.status = GoalStatus.ACTIVE
rm active status
self.log.info(f"Deliberation chose to resume current active goal:
{current_active_goal.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 're
    pass  # inserted to fix indentation error
ection', 'self_assessment', 'exter nal_command_action']:
'INTERRUPTED'.
if current_active_goal:
    pass  # inserted to fix indentation error
current_active_goal.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal.goal[:30]}' PAUSED due to
{action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal.to_dict())
pending, maybe re-prioritize later
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal.id} to pending
as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to
Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action:
{deliberation_decision.get('chosen_action_type')}. Reason:
{deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
"""
Executes the current plan for the active_goal.
Retur ns True if goal considered successfully processed for this cycle, False if critical error.
"""
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps:
{len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
rst step in the plan. The plan will be truncated or re-evaluated.
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id,
"plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params,
current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
ned based on tool_result and goal progress
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
ed snapshot
internal_state_after=self.agent.self_model.beliefs
e
"
ects
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
nal_status = tool_result.get("status", "unknown")
if
nal_status == "success":
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome =
nal_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
nished.
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing
nished by report_result.
Status: {
nal_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error',
'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj,
tool_result, observations[0] if observations else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal
will likely fail.")
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without
'report_result'. Goal might be incomplete.")
ection.
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
violations
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}':
{e}", exc_info=False)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] ==
    pass  # inserted to fix indentation error
current_goal_obj.id:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) ->
oat:
"""Calculates a reward signal based on tool execution outcome and goal relevance."""
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
goaling
reward += 0.1
return round(reward, 2)
class AutonomousAgent:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
in cycle
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
for direct access
self.learning_module: Lear ningModule
self.planning_module: PlanningModule
direct access
self.safety_module: SafetyModule
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.state['
ags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete ---
Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response
Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled:
{ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modi
cation Enabled: {ENABLE_SELF_MODIFICATION}")
if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
    pass  # inserted to fix indentation error
ENABLE_SELF_MODIFICATION:
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME
CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}",
exc_info=True)
self.shutdown()
raise Con
gurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH == "mock":
    pass  # inserted to fix indentation error
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise Con
gurationError("Cannot use Gemini model: google-generativeai library not
installed.")
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
global LLM_PIPELINE, LLM_TOKENIZER
CPU
AutoTokenizer.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
oat16 if TORCH_AVAILABLE else None,
oat16 if
torch available
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH,
LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS,
get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
c not implemented here
self.log.warning(f"LLM_MODEL '{LLM_MODEL_NAME_OR_PATH}' not fully con
gured
for wrapper selection, using Mock.")
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE,
LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
_init_self_mod_tools(self, self.tool_manager)
cationTools handler
and register its UNSAFE methods
self._update_status("Initializing AGI Modules")
self.learning_module = Lear ningModule(self)
self.safety_module = SafetyModule(self)
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME,
shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager: self.tool_manager.check_playwright_browsers()
    pass  # inserted to fix indentation error
browser tool
self.log.info("Agent component initialization
nished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list): state['goals'][key] = []
    pass  # inserted to fix indentation error
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
items
state.setdefault('goal_stack', [])
state.setdefault('
ags', {})
ags system
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state
le {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state
le {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
its view
"recent_failures_summary": [],
view
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"
ags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
cation and saving
_archive_goal
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
state['knowledge_base']['self_model_state']
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status if self.self_model else
self._status
try:
    pass  # inserted to fix indentation error
temp_
le = STATE_FILE.with_su
x(STATE_FILE.su
x + ".tmp")
with temp_
le.open('w') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_
le, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
"""Retur ns the current active goal as a Goal object, or None."""
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict:
{active_goal_dict}")
return None
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority =
GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
deliberation
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict,
nal_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID:
{goal_data_dict.get('id')}) with status: {
nal_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
goal_obj.status = GoalStatus(
nal_status_str)
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-
MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status":
str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count":
goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and
    pass  # inserted to fix indentation error
current_active_in_state.get('id') == active_goal_id:
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
stack
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID:
{active_goal_id}) concluded with status: {
nal_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-
goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
marked active
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal',
'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal:
{parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
goal wasn't a subgoal from stack
self.log.info("Goal archived. No parent goal to resume from stack, or current goal
was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized": self._update_status("Idle")
    pass  # inserted to fix indentation error
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and
environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if
self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle:
{loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
nal status of the goal processed in this cycle
updated_active_goal_dict = self.state['goals'].get('active')
goal
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] ==
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['id']:
ects outcome
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED,
    pass  # inserted to fix indentation error
GoalStatus.CANCELLED]:
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
during preemption
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
failed while this goal was active
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
failed
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
not speci
c to goal completion
ection (AGI Enhanced) - Can be more frequent or event-driven
if self._should_re
    pass  # inserted to fix indentation error
ect(active_goal_data_before_cycle):
self._re
ect_on_performance()
cant changes (already done in many places)
nal save here per cycle too.
if self.state['
    pass  # inserted to fix indentation error
ags'].get('re_evaluate_strategy_needed'):
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to signi
cant
internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['
ags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not
    pass  # inserted to fix indentation error
self.state['goals'].get('pending'):
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() -
LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_re
ect(self, processed_goal_data: Optional[Dict]) -> bool:
ection triggers
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
ect
every N cycles
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in
    pass  # inserted to fix indentation error
[GoalStatus.COMPLETED, GoalStatus.FAILED]:
ect after signi
cant goal outcome
ect if enough goals processed since last time
goals_processed_key = "goals_processed_since_re
ection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >=
    pass  # inserted to fix indentation error
int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
return True
if time.time() - LAST_REFLECTION_TIME >
    pass  # inserted to fix indentation error
MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
return True
if self.state['
    pass  # inserted to fix indentation error
ags'].get('explicit_re
ection_requested'):
return True
return False
@retry(attempts=2, delay=5)
def _re
ect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Re
ecting on Performance ---")
self.state['
ags']['explicit_re
ection_requested'] = False
ag
self.state["goals_processed_since_re
ection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt,
max_new_tokens=2048, temperature=0.5)
ection
re
ection_data = extract_json_robust(llm_assessment_str)
if re
    pass  # inserted to fix indentation error
ection_data.get("error"):
self.log.error(f"Failed to get valid JSON from LLM self-assessment:
{re
ection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed:
{re
ection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_re
ection(re
ection_data)
ection to MemorySystem
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('lear ned_facts'), list):
for fact_str in re
ection_data['lear ned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source":
"self_re
ection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True,
persist_to_relational=True)
self.log.info(f"Added {len(re
ection_data['lear ned_facts'])} lear ned facts to memory
from re
ection.")
if isinstance(re
    pass  # inserted to fix indentation error
ection_data.get('prompt_tuning_suggestions'), list):
for sugg_str in re
ection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str,
metadata={"source": "self_re
ection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(re
ection_data['prompt_tuning_suggestions'])} prompt
suggestions to memory.")
ndings from re
ection (e.g. self_modi
cation_needed)
if re
    pass  # inserted to fix indentation error
ection_data.get('self_modi
cation_needed'):
mod_desc = re
ection_data['self_modi
cation_needed']
self.log.warning(f"Re
ection identi
ed need for self-modi
cation: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modi
cation based on re
ection:
{mod_desc}",
priority=GoalPriority.HIGH,
context={"modi
cation_description": mod_desc, "source": "self_re
ection"}
)
ection insights or periodically
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) ==
    pass  # inserted to fix indentation error
0:
audit_issues = self.safety_module.audit_directives_and_behavior()
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identi
ed issues: {audit_issues}")
ndings
self._create_metacognitive_goal(f"Address directive audit
ndings:
{str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Re
ection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during re
ection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during re
ection: {e}", exc_info=True)
nally:
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
"""Sets up handlers for di
"
erent message types if comms_channel exists."""
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY,
self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM,
self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}:
{message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base']
[query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample":
str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id,
type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}:
{message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
x with sender to avoid
clashes
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if not PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("psutil not available, resource monitoring disabled.");
return
if RESOURCE_MONITOR: return
    pass  # inserted to fix indentation error
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e: self.log.error(f"Failed to initialize resource monitor: {e}");
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("Playwright not available, skipping initialization.")
return
if PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER =
PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
globals
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT,
PLAYWRIGHT_PAGE
if not PLAYWRIGHT_INSTANCE: return
    pass  # inserted to fix indentation error
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
if PLAYWRIGHT_PAGE: try: PLAYWRIGHT_PAGE.close()
    pass  # inserted to fix indentation error
ignore
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_CONTEXT: try: PLAYWRIGHT_CONTEXT.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_BROWSER: try: PLAYWRIGHT_BROWSER.close()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
if PLAYWRIGHT_INSTANCE: try: PLAYWRIGHT_INSTANCE.stop()
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not PLAYWRIGHT_AVAILABLE or not self.playwright_context : return
    pass  # inserted to fix indentation error
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page: try: self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
    pass  # inserted to fix indentation error
except Exception: pass
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
ush
if 'logging' in sys.modules: logging.shutdown()
    pass  # inserted to fix indentation error
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl}
Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/
{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)' if
ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or
ENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[AutonomousAgent] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_
le",
priority=GoalPriority.HIGH).to_dict()
COMMANDS_FILE.write_text("")
except Exception as e_cmd
    pass  # inserted to fix indentation error
le:
print(f"Error reading initial command
le: {e_cmd
le}",
le=sys.stderr)
main_agent_instance = AutonomousAgent()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending',
[]).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort,
reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal']
[:50]}' added to pending goals.")
main_agent_instance.run()
except Con
    pass  # inserted to fix indentation error
gurationError as cfg_err_main:
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}",
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to Con
gurationError:
{cfg_err_main}", exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to
    pass  # inserted to fix indentation error
Con
gurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else: logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt
    pass  # inserted to fix indentation error
during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}",
le=sys.stderr)
traceback.print_exc(
le=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}",
exc_info=True)
else: logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main:
    pass  # inserted to fix indentation error
{main_exec_err}", exc_info=True)
exit_code = 1
nally:
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main
nally block...")
if hasattr(main_agent_instance, 'log'): main_agent_instance.log.warning("Main
    pass  # inserted to fix indentation error
nally
block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
main_log.warning("Agent instance likely not created or fully initialized. Basic
shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
```
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
def load_llm_models():
global llm_pipelines
try:
    pass  # inserted to fix indentation error
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error in load_llm_models: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
try:
    pass  # inserted to fix indentation error
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
from Real1_ToolSuite import TOOL_REGISTRY
TRANSFORMERS_AVAILABLE = True
TORCH_AVAILABLE = True
GOOGLE_GENAI_AVAILABLE = True
PSUTIL_AVAILABLE = True
CHROMADB_AVAILABLE = True
PLAYWRIGHT_AVAILABLE = True
REQUESTS_BS4_AVAILABLE = True
PILLOW_AVAILABLE = True
DIFF_MATCH_PATCH_AVAILABLE = True
FILELOCK_AVAILABLE = True
NETWORKX_AVAILABLE = True
GYMNASIUM_AVAILABLE = True
```python
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
import psutil
import chromadb
from chromadb.config import Settings as ChromaSettings
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoConfig
from transformers import logging as transformers_logging
import torch
from playwright.sync_api import sync_playwright, Error as PlaywrightError
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
from PIL import Image
import diff_match_patch as dmp_module
import hashlib
from fifilelock import FileLock, Timeout as FileLockTimeout
import networkx as nx
import gymnasium as gym
AGENT_NAME = "EvolvedCognitiveAgent_SystemCore_V3"
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
DEFAULT_LLM_MODEL = "gemini-2.5-flash"
LLM_MODEL_NAME_OR_PATH = DEFAULT_LLM_MODEL
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
_llm_device_detected = "cpu"
if torch.cuda.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif hasattr(torch, 'backends') and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
LLM_DEVICE = _llm_device_detected
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
SCRIPT_DIR = Path(__file__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(f"agent_workspace_{AGENT_NAME}")
STATE_FILE = WORKSPACE_DIR / Path(f"agent_state_{AGENT_NAME}.json")
LOG_FILE = WORKSPACE_DIR / Path(f"agent_log_{AGENT_NAME}.log")
COMMANDS_FILE = SCRIPT_DIR / Path("agent_commands.txt")
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modification_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously learn, adapt, and improve capabilities across all domains.", "weight": 0.9, "last_eval_score": 0.0, "id": "directive_learn", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type": "growth"},
{"directive": "Achieve goals efficiently, robustly, autonomously, and ethically.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type": "exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.", "weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type": "foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type": "guardrail"},
]
MANDATORY_REFLECTION_INTERVAL_SECONDS = 1800
IDLE_DELIBERATION_INTERVAL_SECONDS = 120
GOAL_STACK_MAX_DEPTH = 5
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = 3
MAX_LLM_RESPONSE_TOKENS = 4096
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH or "2.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
else:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
config = AutoConfig.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
_default_context_len = getattr(config, 'max_position_embeddings', _default_context_len)
except Exception:
    pass  # inserted to fix indentation error
pass
MAX_LLM_CONTEXT_TOKENS = _default_context_len
MAX_TOOL_RESULT_LENGTH = 5000
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = True
ENABLE_CODE_GENERATION_TOOL = True
ENABLE_SELF_MODIFICATION = True
WEB_SEARCH_TIMEOUT = 10
WEB_BROWSER_TIMEOUT = 60000
LOG_MONITOR_DEFAULT_LINES = 20
METACOGNITIVE_CHECK_INTERVAL_CYCLES = 20
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES = 50
LLM_PIPELINE = None
LLM_TOKENIZER = None
MEMORY_COLLECTION = None
RESOURCE_MONITOR = None
PLAYWRIGHT_INSTANCE = None
PLAYWRIGHT_BROWSER = None
PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_PAGE = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack = None
def ensure_paths():
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
try:
    pass  # inserted to fix indentation error
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
try:
    pass  # inserted to fix indentation error
file_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
file_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%(filename)s:%(lineno)d] [%(task_name_override)-10s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error setting up file logger: {e}", file=sys.stderr)
logger.propagate = False
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "fifilelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try:
    pass  # inserted to fix indentation error
logging.getLogger(lib_name).setLevel(logging.WARNING)
except Exception:
    pass  # inserted to fix indentation error
pass
try:
    pass  # inserted to fix indentation error
logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
except Exception:
    pass  # inserted to fix indentation error
pass
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModificationError(AgentError): pass
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class ConfigurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class LearningError(AgentError): pass
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModificationError,
PlaywrightError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModificationError,
    pass  # inserted to fix indentation error
LogicError, ConfigurationError, RecursionDepthError)) and type(e) not in retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}: {e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error: {type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error: {type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, LearningError) as non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in {fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}: {type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}: {unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error: {unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception):
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1:
    pass  # inserted to fix indentation error
log_resource.error(f"Unexpected error getting resource usage: {e}", exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
match = re.search(r"```json\s*([\s\S]+?)\s*```", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full text: {json_str[:200]}...")
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}. Text: {text_trimmed[:200]}...")
try:
    pass  # inserted to fix indentation error
start_index = text.find('{')
end_index = text.rfind('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
try:
    pass  # inserted to fix indentation error
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice: {potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text: {text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview": text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str = field(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] = field(default_factory=dict)
plan: List[Dict[str, Any]] = field(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] = field(default_factory=list)
dependencies: List[str] = field(default_factory=list)
complexity_score: Optional[float] = None
estimated_cost: Optional[float] = None
estimated_utility: Optional[float] = None
evaluation_score: Optional[float] = None
associated_directive_ids: List[str] = field(default_factory=list)
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus(data['status'])
except ValueError:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus.PENDING
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority.MEDIUM
field_names = {f.name forfin cls.__dataclass_fields__.values()}
for f_obj in cls.__dataclass_fields__.values():
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin cls.__dataclass_fields__.values()}
filtered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**filtered_data)
@dataclass
class BaseMemoryEntry:
id: str = field(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
content: Any = None
metadata: Dict[str, Any] = field(default_factory=dict)
embedding: Optional[List[float]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[float] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability: float = 0.5
related_concepts: List[str] = field(default_factory=list)
causal_links: Dict[str, str] = field(default_factory=dict)
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
self.content = self.fact_statement
@dataclass
class Message:
id: str = field(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
type: str = "info"
content: Dict[str, Any] = field(default_factory=dict)
priority: int = 0
correlation_id: Optional[str] = None
def to_dict(self) -> Dict[str, Any]:
return asdict(self)
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Message':
return cls(**data)
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionEffect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens: int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[float]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
genai.configure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
try:
    pass  # inserted to fix indentation error
generation_config_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_config_params["stop_sequences"] = stop_sequences
full_prompt = f"{system_message}\n\n{prompt}" if system_message else prompt
response = self.model.generate_content(
full_prompt,
generation_config=genai.types.GenerationConfig(**generation_config_params)
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.", exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[float]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='models/embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
try:
    pass  # inserted to fix indentation error
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, trust_remote_code=True)
device_map_arg = {"": self.device_id} if self.device_id != -1 else "auto"
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.bfloat16,
device_map=device_map_arg
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on {self.device}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Transformers model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Transformers model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
if system_message:
    pass  # inserted to fix indentation error
chat_prompt = [
{"role": "system", "content": system_message},
{"role": "user", "content": prompt}
]
try:
    pass  # inserted to fix indentation error
final_prompt = self.tokenizer.apply_chat_template(chat_prompt, tokenize=False, add_generation_prompt=True)
except Exception:
    pass  # inserted to fix indentation error
final_prompt = f"System: {system_message}\nUser: {prompt}\nAssistant:"
else:
    pass  # inserted to fix indentation error
final_prompt = prompt
inputs = self.tokenizer(final_prompt, return_tensors="pt").to(self.model.device)
outputs = self.model.generate(
**inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[float]:
self.log_llm.warning("Direct embedding from causal LM is not standard. Using mock embedding.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
def perceive(self) -> List[Dict[str, Any]]:
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_file",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from file: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands file: {e}")
observations.append({"type": "error", "source": "command_file_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No significant external stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (simulated).")
return {"type": "visual", "source": "camera_sim", "content": "Simulated visual data: a generic scene.", "format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (simulated).")
return {"type": "audio", "source": "microphone_sim", "content": "Simulated auditory data: ambient sounds.", "format": "description"}
class LearningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_buffer: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
self.experiences_buffer.append(experience)
if len(self.experiences_buffer) > self.MAX_BUFFER_SIZE:
    pass  # inserted to fix indentation error
self.experiences_buffer.pop(0)
defilearn_from_recent_experiences(self):
if not self.experiences_buffer:
    pass  # inserted to fix indentation error
self.log.info("No new experiences to learn from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_buffer)} experiences.")
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_buffer)
self._perform_self_supervised_learning(self.experiences_buffer)
self.log.info("Learning cycle completed.")
self.experiences_buffer.clear()
def _perform_reinforcement_learning(self, experiences: List[Experience]):
self.log.info("Performing reinforcement learning (conceptual)...")
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (conceptual) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
self.log.info("Performing self-supervised learning (conceptual)...")
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns', 'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified patterns: {llm_analysis['patterns']}")
for pattern_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {pattern_str}", metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified abstractions: {llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.learned_abstractions.append({"type": "conceptual", "content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified new_concepts: {llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}", metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_learned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
if self.rl_policy:
    pass  # inserted to fix indentation error
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}. Response: {llm_response_str[:200]}")
return ([{"tool_name": "report_error", "params": {"error_message": "Failed to generate plan via LLM.", "details": plan_data.get('error')}}],
"LLM failed to generate a plan. This is a fallback step.")
thought = plan_data.get("thought", "No specific thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return ([{"tool_name": "report_error", "params": {"error_message": "LLM plan contained no valid steps."}}],
thought + " (But plan steps were invalid).")
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return ([{"tool_name": "report_error", "params": {"error_message": f"LLMError during planning: {e}"}}],
f"LLM error occurred: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return ([{"tool_name": "report_error", "params": {"error_message": f"Unexpected error during planning: {e}"}}],
f"Unexpected error: {e}")
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation: Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info', {}).get('execution_successful', True):
    pass  # inserted to fix indentation error
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal {current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan, last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan: {plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No specific thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else "World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'. Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, efficient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the `execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the final step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the first step(s) should be to acquire it (e.g., using `search_web`, `read_file_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str, last_step_outcome: Dict, observation: Optional[Dict]) -> str:
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info', {}).get('current_step_id'):
    pass  # inserted to fix indentation error
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if observation else "None"}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
{original_plan_str}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should reflect this (e.g., by trying to gather more information or reporting inability).
6. Ensure the final step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
class MemorySystem:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH, settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
self.log.info(f"ChromaDB vector store initialized. Collection count: {self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.", exc_info=True)
self.vector_store = None
if not self.vector_store:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based (transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes: {len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be unavailable.", exc_info=True)
self.graph_store = None
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH, check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be unavailable.", exc_info=True)
if self.relational_conn:
    pass  # inserted to fix indentation error
self.relational_conn.close()
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT,
PRIMARY KEY (source_node_id, target_node_id, relation_type)
)
""")
self.relational_conn.commit()
cursor.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error initializing relational schema: {e}", exc_info=True)
def _get_embedding(self, text: str) -> Optional[List[float]]:
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
h = hashlib.md5(text.encode()).digest()
return [float(b) for b in h[:16]]
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector:
    pass  # inserted to fix indentation error
if self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
for k, v in entry.metadata.items():
if isinstance(v, (str, int, float, bool)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
else:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(entry.content)
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata": entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50], type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
for cause_id, effect_id in entry.causal_links.items():
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(effect_id):
    pass  # inserted to fix indentation error
self.graph_store.add_edge(cause_id, effect_id, relation_type='causes')
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id, complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score, json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
ts_now = datetime.now(timezone.utc).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now, json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}", exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError, ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS, type_filter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text:
    pass  # inserted to fix indentation error
return []
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_filter and data['metadata'].get('type') != type_filter:
    pass  # inserted to fix indentation error
continue
results.append({"id": id, "document": data['document'], "metadata": data['metadata'], "distance": 0.0})
if len(results) >= n_results:
    pass  # inserted to fix indentation error
break
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results}, filter={type_filter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_filter:
    pass  # inserted to fix indentation error
where_clause = {"type": type_filter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0:
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type: Optional[str]=None, depth: int = 1) -> List[Dict]:
if not self.graph_store:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation": data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns: Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
if self.graph_store:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts, type_filter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No specific knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
return summary_str
def consolidate_knowledge(self):
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold: float = 0.1, older_than_days: int = 365):
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cutoff_ts = (datetime.now(timezone.utc) - timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cutoff_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
self.register_tool(read_file_UNSAFE)
self.register_tool(write_file_UNSAFE)
self.register_tool(list_files_UNSAFE)
self.register_tool(browse_web)
self.register_tool(search_web)
self.register_tool(monitor_log_file)
self.register_tool(check_website_update)
self.register_tool(send_icmp_ping)
self.register_tool(send_message_to_agent)
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
self.register_tool(execute_shell_command_UNSAFE)
def register_tool(self, func: Callable):
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if hasattr(self, 'agent') and self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for filepath in directory.glob("*.py"):
module_name = filepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_file_location(full_module_name, filepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
sys.modules[full_module_name] = module
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module: {module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and name.startswith("tool_"):
    pass  # inserted to fix indentation error
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}", exc_info=True)
def get_tool_description_for_llm(self) -> str:
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = "(No description provided)"
first_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation == inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class '","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper():
    pass  # inserted to fix indentation error
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {first_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via specific tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {', '.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info: Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None:
    pass  # inserted to fix indentation error
current_step_info = {}
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
result = None
duration = 0.0
validated_params = {}
try:
    pass  # inserted to fix indentation error
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
first_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
first_param_name = next(iter(func_params_spec))
first_param_spec = func_params_spec[first_param_name]
if first_param_name == 'agent' and (first_param_spec.annotation == 'CognitiveSystem' or str(first_param_spec.annotation) == "'CognitiveSystem'"):
    pass  # inserted to fix indentation error
first_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if first_param_is_agent and p_name == 'agent':
    pass  # inserted to fix indentation error
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind == inspect.Parameter.VAR_KEYWORD:
    pass  # inserted to fix indentation error
pass
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
if first_param_is_agent:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration: {duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError:
    pass  # inserted to fix indentation error
raise
except (AgentError, LogicError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}", exc_info=False)
result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
def check_playwright_browsers(self):
self.log.debug("Checking Playwright browsers.")
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log", content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str, percentage_complete: Optional[float] = None) -> Dict:
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log', []).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str = "success", details: Optional[Dict] = None) -> Dict:
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] = "MEDIUM", context: Optional[Dict] = None) -> Dict:
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH}) reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent: {current_active_goal_dict.get('id')}")
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str = "vector", n_results: int = 3, type_filter: Optional[str] = None) -> Dict:
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
results = []
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results, type_filter=type_filter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_graph_store(query_node_label=query_text, depth=1)
elif memory_type == "relational":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_relational_store(table=query_text, limit=n_results)
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params: Optional[Dict] = None) -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name, params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
def read_file_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
log_tool = get_logger("TOOL_read_file")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not full_path.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found: {path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path), "file_size_bytes": len(content)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read file: {e}"}
def write_file_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
log_tool = get_logger("TOOL_write_file")
try:
    pass  # inserted to fix indentation error
full_path = WORKSPACE_DIR.joinpath(path).resolve()
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path": str(full_path)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write file: {e}"}
def list_files_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
log_tool = get_logger("TOOL_list_files")
try:
    pass  # inserted to fix indentation error
base_path = WORKSPACE_DIR.joinpath(path).resolve()
if not base_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a directory: {path}"}
items = []
for item in base_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "file",
"size_bytes": item.stat().st_size if item.is_file() else None,
"last_modified": datetime.fromtimestamp(item.stat().st_mtime, tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(base_path), "contents": items}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing files in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list files: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int = WEB_BROWSER_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_browse_web")
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int = WEB_SEARCH_TIMEOUT) -> Dict:
log_tool = get_logger("TOOL_search_web")
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.find_all(class_='g'):
r = g.find('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.find('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_file(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES) -> Dict:
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log file not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_file": str(LOG_FILE), "content": content, "lines_read": len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log file {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log file: {e}"}
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
log_tool = get_logger("TOOL_check_web_update")
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp": datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
log_tool = get_logger("TOOL_send_ping")
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count, "packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count, "packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str, context_code: Optional[str] = None) -> Dict:
agent.log.warning(f"Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a complete function/class definition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
return agent.self_modification_unit.validate_code_modification_UNSAFE(code_to_validate)
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec: int = 30) -> Dict:
agent.log.warning(f"Executing shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s. Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str, content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value, content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id, "message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
class SelfModificationTools:
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref: 'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
self.dmp = dmp_module.diff_match_patch()
self.log.info(f"Self-Modification Unit initialized. Code Dir: {self.agent_code_dir}, Backup Dir: {self.backup_dir}")
def _resolve_target_path(self, target_file_rel: str) -> Path:
target_path_abs = (self.agent_code_dir / target_file_rel).resolve()
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
self.log.warning(f"Inspecting code for component: {component_name}")
target_obj = None
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
candidate_modules = [sys.modules.get('__main__'), sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod, component_name)):
    pass  # inserted to fix indentation error
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
file_path = inspect.getfile(target_obj)
return {"status": "success", "component_name": component_name, "file_path": file_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module, class, or function defined in a file.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
return {"status": "error", "error": f"Component '{component_name}' not found or source code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModificationError))
def propose_code_modification_UNSAFE(self, component_name: str, issue_description: str, proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
self.log.warning(f"Proposing code modification for {component_name}. Issue: {issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for {component_name} to propose modification. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
```python
{current_code_snippet}
```
Generate the modified Python code for the specified component.
Provide ONLY the complete, new Python code block for the modified function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '```python' and end with '```'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "proposed_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name, "proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modification for {component_name}: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modification_UNSAFE(self, code_to_validate: str) -> Dict:
self.log.warning(f"Validating proposed code snippet ({code_to_validate[:100]}...)")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modification_UNSAFE(self, component_name: str, new_code: str, target_file_path: Optional[str]=None) -> Dict:
self.log.critical(f"Attempting to apply code modification to component '{component_name}'. THIS IS HIGHLY RISKY.")
try:
    pass  # inserted to fix indentation error
if not target_file_path:
    pass  # inserted to fix indentation error
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('file_path'):
    pass  # inserted to fix indentation error
target_file_path = inspection_res['file_path']
else:
    pass  # inserted to fix indentation error
target_file_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_file = Path(target_file_path)
if not target_file.exists() or not target_file.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Target file for modification not found: {target_file}"}
original_code = target_file.read_text()
backup_path = SELF_MOD_BACKUP_DIR / f"{target_file.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_file, backup_path)
self.log.info(f"Backed up original file to {backup_path}")
pattern_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
pattern_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modified_original_code = original_code
found_and_replaced = False
match_class = re.search(pattern_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(pattern_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not find component '{component_name}' in {target_file} for replacement. Modification aborted.")
return {"status": "error", "error": f"Component '{component_name}' definition not found for replacement."}
target_file.write_text(modified_original_code)
self.log.warning(f"Code modification applied to {target_file}. Agent restart is LIKELY REQUIRED for changes to take effect.")
self.agent_ref.self_model.add_event_log(f"Applied code modification to {component_name}. Restart pending for full effect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}_modified_pending_restart"] = True
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": f"Code for '{component_name}' in '{target_file}' modified. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modification to {component_name}: {e}", exc_info=True)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_file)
self.log.info(f"Restored original file {target_file} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modification: {e}. System might be unstable."}
def rollback(self, backup_file: Path, target_file: Path):
self.log.info(f"Attempting to rollback '{target_file}' from '{backup_file}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_file, target_file)
self.log.info(f"Successfully rolled back '{target_file}'.")
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_file}.")
self.agent_ref.self_model.beliefs[f"component_{target_file.name}_modified_pending_restart"] = False
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_file.name)
return {"status": "success", "message": f"Rolled back {target_file}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_file}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_file_rel: Union[str, Path]):
target_module_name = Path(target_file_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is required.")
return
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
if _agent_instance_hack and hasattr(sys.modules[target_module_name], 'CognitiveSystem'):
    pass  # inserted to fix indentation error
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for changes to take effect.")
def inspect_directives_UNSAFE(self) -> Dict:
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modification_UNSAFE(self, analysis_of_misalignment: str, proposed_directive_changes_desc: str) -> Dict:
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (float 0-1), "last_eval_score" (float 0-1, usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational', 'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024, temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in proposed_directives):
    pass  # inserted to fix indentation error
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"LLM indicated error during directive proposal: {proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modification_UNSAFE(self, new_directives: List[Dict]) -> Dict:
self.log.warning(f"Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modification_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count: {len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
_self_mod_tools_container = None
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, agent)
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in name.upper():
    pass  # inserted to fix indentation error
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func) or inspect.ismethod(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
def __init__(self, state: Optional[Dict]=None, agent_directives_config: Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_config if agent_directives_config is not None else DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_confidence: Dict[str, float] = {}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
self.learning_goals: List[Dict[str, Any]] = []
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.learned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_confidence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted", sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_confidence = sm_state.get("skill_confidence", self.skill_confidence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary", self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies", self.adaptation_strategies)
self.learned_abstractions = sm_state.get("learned_abstractions", self.learned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative", self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs", self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_confidence": self.skill_confidence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"learned_abstractions": self.learned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
def add_event_log(self, event_description: str, event_type: str = "info", data: Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
for tool_name in self.capabilities:
if tool_name not in self.skill_confidence:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = 0.5
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.", event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8:
    pass  # inserted to fix indentation error
hint = " (Reliability: High)"
elif score > 0.6:
    pass  # inserted to fix indentation error
hint = " (Reliability: Moderate)"
elif score > 0.3:
    pass  # inserted to fix indentation error
hint = " (Reliability: Low)"
else:
    pass  # inserted to fix indentation error
hint = " (Reliability: Very Low/Untested)"
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict, success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
current_confidence = self.skill_confidence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = min(1.0, current_confidence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = max(0.0, current_confidence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability: {stats['reliability_score']:.2f}, Confidence: {self.skill_confidence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_confidence_drift(sm: 'SelfModel') -> Optional[str]:
low_confidence_skills = [skill for skill, conf in sm.skill_confidence.items() if conf < 0.25 and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_confidence_skills) >= 2 :
    pass  # inserted to fix indentation error
return f"Multiple critical skills have very low confidence and recent failures: {', '.join(low_confidence_skills)}. Consider skill improvement or alternative strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict):
    pass  # inserted to fix indentation error
return None
low_eval_directives = []
for d in sm.core_directives:
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {', '.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count} with max replans. Planning or execution effectiveness may be compromised. Review strategy or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_confidence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}): {anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}", event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__') else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {'; '.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0), reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_confidence:
    pass  # inserted to fix indentation error
confident_skills = [s for s,c in self.skill_confidence.items() if c > 0.7][:3]
summary += f"Confident Skills (sample): {', '.join(confident_skills) if confident_skills else 'None highly confident'}\n"
summary += f"Internal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools:
    pass  # inserted to fix indentation error
summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
if unreliable_tools:
    pass  # inserted to fix indentation error
summary += f" Needs Improvement: {', '.join([t[0] for t in unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
base_prompt = """Analyze your recent performance, knowledge, internal state, and alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:"""
output_keys_example = [
"`reflection_summary` (str: Overall summary of the reflection period).",
"`key_successes` (list of str: Specific achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Specific setbacks or difficulties encountered).",
"`learned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identified` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool effectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g., 'curious', 'frustrated', 'satisfied').",
"`resource_usage_concerns` (str or null: Any concerns about computational resource usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_float_0_to_1: How well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes, provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model? What needs improvement?).",
"`new_learning_goals` (list of str: Specific goals for future learning or skill development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring issues or improve performance).",
"`self_modification_needed` (str or null: If parts of your own code/logic need modification, describe what and why. Be very specific and cautious.)."
]
full_prompt = base_prompt + "\n" + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives, indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n" + \
f"Recent Tool Outcomes (last 5 entries):\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment: {assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_reflection(self, reflection_data: Dict) -> Tuple[bool, bool]:
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from reflection data...")
if reflection_data.get('reflection_summary'):
    pass  # inserted to fix indentation error
self.internal_state_narrative = reflection_data['reflection_summary']
updated_self = True
core_directives_eval = reflection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (float, int)) and 0.0 <= eval_score <= 1.0:
    pass  # inserted to fix indentation error
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...' evaluation score to {eval_score:.2f}")
if updated_self:
    pass  # inserted to fix indentation error
self.add_event_log("Directive evaluation scores updated from reflection.")
suggested_directive_updates = reflection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Reflection suggested updates to core directives: {str(suggested_directive_updates)[:200]}...")
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modifications from reflection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source": "self_reflection"}
)
updated_self = True
self.add_event_log("Reflection suggested directive updates. Metacognitive review goal created.", event_type="critical_review_needed")
if isinstance(reflection_data.get('new_learning_goals'), list):
    pass  # inserted to fix indentation error
for lg_str in reflection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts": datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
if isinstance(reflection_data.get('adaptation_strategy_proposals'), list):
    pass  # inserted to fix indentation error
for strat_str in reflection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated adaptation strategies. Total: {len(self.adaptation_strategies)}")
if reflection_data.get('learned_facts') or reflection_data.get('prompt_tuning_suggestions'):
    pass  # inserted to fix indentation error
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from reflection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
backup_file = SELF_MOD_BACKUP_DIR / f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_file.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_file} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_officer"]
dialog_history = []
full_dialog_str = f"Internal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts, questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution": contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective {perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
self.add_event_log(f"Internal dialog simulated on '{topic}'.", data={"dialog": full_dialog_str})
return full_dialog_str
class MotivationEngine:
def __init__(self, drive_configs: Optional[Dict[str, Any]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[str, Any] = {}
self._initialize_drives(drive_configs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_configs: Optional[Dict[str, Any]]):
default_configs = {
"CURIOSITY": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"MASTERY": {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.6},
"ACHIEVEMENT": {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.4},
"NOVELTY_SEEKING": {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.7},
"PRESERVATION": {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.2},
"EFFICIENCY": {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"SOCIAL_INTERACTION": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.3},
}
configs = drive_configs if drive_configs is not None else default_configs
for drive_type_str, config in configs.items():
self.drives[drive_type_str] = DriveState(
drive_type=drive_type_str,
level=config.get("initial_level", 0.5),
decay_rate=config.get("decay_rate", 0.01),
max_level=config.get("max_level", 1.0),
min_level=config.get("min_level", 0.0)
)
def update_drives(self):
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "learn":
    pass  # inserted to fix indentation error
self.drives["CURIOSITY"].update(stimulus=-0.05)
self.drives["MASTERY"].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives["ACHIEVEMENT"].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives["PRESERVATION"].update(stimulus=0.1)
self.drives["MASTERY"].update(stimulus=-0.05)
def get_drive_level(self, drive_type: str) -> float:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
def get_all_drive_levels(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[str, float]]:
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == "CURIOSITY":
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == "MASTERY":
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == "ACHIEVEMENT":
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == "PRESERVATION":
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == "EFFICIENCY":
    pass  # inserted to fix indentation error
return "optimization"
return None
@dataclass
class DriveState:
drive_type: str
level: float
decay_rate: float = 0.01
max_level: float = 1.0
min_level: float = 0.0
last_update_time: float = field(default_factory=time.time)
def update(self, stimulus: float = 0.0):
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class MessageType(Enum):
QUERY = "QUERY"
RESPONSE = "RESPONSE"
INFORM = "INFORM"
REQUEST_ACTION = "REQUEST_ACTION"
HEARTBEAT = "HEARTBEAT"
ERROR = "ERROR"
class FileChannel:
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_file = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_file}")
def _write_message_to_file(self, message: Message, target_file: Path) -> bool:
try:
    pass  # inserted to fix indentation error
with FileLock(str(target_file) + ".lock", timeout=5):
messages = []
if target_file.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
existing_content = target_file.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {target_file}: {e}. Clearing file.")
messages = []
messages.append(message.to_dict())
target_file.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_file}. Message not sent to {message.receiver_id}.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_file}: {e}")
return False
def _read_messages_from_file(self, source_file: Path) -> List[Message]:
messages = []
if not source_file.exists():
    pass  # inserted to fix indentation error
return messages
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_file) + ".lock", timeout=5):
content = source_file.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if isinstance(msg_data, dict)]
source_file.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_file}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {source_file}: {e}. Clearing file.")
try:
    pass  # inserted to fix indentation error
source_file.write_text("", encoding='utf-8')
except Exception as e_write:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to clear corrupted message file {source_file}: {e_write}")
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_file}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}: {message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_file(message, target_inbox)
def receive_messages(self) -> List[Message]:
new_messages = self._read_messages_from_file(self.inbox_file)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message], Optional[Message]]):
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
messages = self.receive_messages()
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From: {msg.sender_id}")
handled = False
try:
    pass  # inserted to fix indentation error
msg_type_enum = MessageType(msg.type)
if msg_type_enum in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg_type_enum]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler {handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id, receiver_id=msg.sender_id, type=MessageType.ERROR.value, content={"original_message_id": msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type {msg.type}. Message ID {msg.id} unhandled.")
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Received unknown message type: {msg.type}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', config: Dict):
self.id = id
self.embodiment = embodiment
self.config = config
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
pass
class Actuator(ABC):
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], config: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.config = config
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
pass
class VirtualEmbodiment:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to 'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button", "research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, reconfigurable bay designed for running complex simulations. Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_config_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data flow and storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core. Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20:
    pass  # inserted to fix indentation error
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An undefined space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) -> Dict:
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params: {params}")
params = params or {}
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as specified."
env_details = self.environment_map.get(self.location, {})
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console":
    pass  # inserted to fix indentation error
message += " It shows fluctuating green and amber lights."
elif target == "core_status_monitor":
    pass  # inserted to fix indentation error
message += " It indicates: Core Nominal. Directives Stable. Learning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name", "default_physics_test"), params.get("config",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result: {sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if action_type=="move" else None, "updated_inventory": self.state["inventory"] if action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "learn"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response: {self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model <topic>'."
def _run_simulation(self, sim_name: str, config: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with config: {config}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_config" in config:
    pass  # inserted to fix indentation error
success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric: {outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check configuration."
def summary(self) -> str:
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Internal State (summary): Energy={self.state['energy']}, Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time: float = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE, LAST_LEARNING_MODULE_UPDATE_CYCLE
start_time = time.time()
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status: {self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if self.agent.state['goals'].get('active') else None
self.agent.last_error = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
if self.agent.self_model and (self.agent.cycle_count - LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering proactive metacognitive check (Cycle {self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
if self.agent.learning_module and (self.agent.cycle_count - LAST_LEARNING_MODULE_UPDATE_CYCLE >= LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.learn_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation: {ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
def get_priority_val(goal_dict):
p = goal_dict.get('priority', 'MEDIUM')
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_list.sort(key=get_priority_val, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type == "active_goal_continue":
    pass  # inserted to fix indentation error
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution: {goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID: {goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal' provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or current_goal_obj.replan_count > 0:
    pass  # inserted to fix indentation error
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"No plan available or generated for goal: {current_goal_obj.goal[:50]}. Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = True
if time.time() - LAST_DELIBERATION_TIME > IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModificationError, LogicError, LLMError, ConfigurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
LearningError) as agent_cycle_err:
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
finally:
    pass  # inserted to fix indentation error
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() - start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent understanding of the current situation. Identify key entities, events, and any significant changes in the environment or your internal state. Focus on information relevant to achieving current goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content: {str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\": \"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"], \"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation", understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event", metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry, persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
return {"summary": understanding_summary, "processed_info": processed_info, "raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError, DeliberationError))
def _deliberate(self, understanding_result: Dict) -> Dict:
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio: {pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio: {active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time': datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack (paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal generation.")
if time.time() - LAST_DELIBERATION_TIME >= IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_learn", "directive_curiosity", "directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
return decision
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output: {sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
self_model_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No specific understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact', 'None identified.')
interp_con_val = understanding_result.get('interpretation_confidence', 0.7)
recent_memory_context = self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary, max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Confidence: {interp_con_val:.2f}):** {understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identified:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory (STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]], indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else f'{active_goal_dict.get(\"goal\")[:100]}... (ID: {active_goal_dict.get(\"id\")})'}",
f"* **Agent Core Directives (Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding, drives, memories, goals, directives), what is the most critical aspect demanding attention or the best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/complete).",
"    - Performing `reflection` or `self_assessment` (if mandatory timers, drives like low CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration goal), Directives (e.g., low-eval directive -> improvement goal), or identified opportunities. New goals require `goal` (str), `priority` (float 0.0-1.0), `origin` (str e.g., 'drive_curiosity', 'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for viability before committing if uncertainty is high or consequence severe (briefly note simulation outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the *immediate next cycle*. Justify your choice especially if it deviates from obvious triggers, high drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list. If selecting an existing pending goal it moves to `next_goal` and is removed from pending internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal', 'new_goal', 'reflection', 'self_assessment', 'external_command_action', 'idle', 'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass structure) selected for immediate execution. Null if idle/reflection/assessment without a direct goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into `new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into `new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent. Analyze the situation comprehensively, consider drives and directives, and make strategic decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON: {extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal', 'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys: {deliberation_decision.keys()}")
if key == 'new_pending_goals':
    pass  # inserted to fix indentation error
deliberation_decision[key] = []
elif key == 'next_goal':
    pass  # inserted to fix indentation error
deliberation_decision[key] = None
else:
    pass  # inserted to fix indentation error
deliberation_decision[key] = "Error: Missing from LLM Output"
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not isinstance(deliberation_decision.get('next_goal'), dict):
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value: {deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and new_goal_dict.get('priority'):
    pass  # inserted to fix indentation error
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p['id'] == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
current_pending_list.append(new_goal_obj.to_dict())
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal: {new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
current_active_goal_obj = self.agent.get_active_goal_object()
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending', []) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
selected_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
deliberation_decision['next_goal'] = selected_goal_obj.to_dict()
self.log.info(f"Moved pending goal {selected_goal_obj.id} ('{selected_goal_obj.goal[:50]}') to active.")
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
highest_priority_pending.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
deliberation_decision['next_goal'] = highest_priority_pending.to_dict()
self.log.info(f"Deliberation chose 'pending_goal' without specific ID; moved highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals available. Idling.")
action_type = "idle"
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM selected pending goal by ID but not found or invalid. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj.to_dict()
self.log.info(f"Deliberation created and activated new goal: {new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal_obj.to_dict()
current_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = current_active_goal_obj.to_dict()
self.log.info(f"Deliberation chose to resume current active goal: {current_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 'reflection', 'self_assessment', 'external_command_action']:
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
current_active_goal_obj.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal_obj.goal[:30]}' PAUSED due to {action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal_obj.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal_obj.to_dict())
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal_obj.id} to pending as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action: {deliberation_decision.get('chosen_action_type')}. Reason: {deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps: {len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id, "plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params, current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
internal_state_after=self.agent.self_model.beliefs
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
final_status = tool_result.get("status", "unknown")
if final_status == "success":
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = final_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing finished by report_result. Status: {final_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error', 'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj, tool_result, self.agent.cognitive_cycle.perception_module.perceive()[0] if self.agent.cognitive_cycle.perception_module.perceive() else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal will likely fail.")
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without 'report_result'. Goal might be incomplete.")
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] == current_goal_obj.id:
    pass  # inserted to fix indentation error
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}': {e}", exc_info=True)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) -> float:
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
self.agent_id = AGENT_NAME
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
self.learning_module: LearningModule
self.planning_module: PlanningModule
self.motivation_engine: MotivationEngine
self.self_modification_unit: SelfModificationTools
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.playwright_instance: Optional[Any] = None
self.playwright_browser: Optional[Any] = None
self.playwright_context: Optional[Any] = None
self.playwright_page: Optional[Any] = None
self.state['flags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete --- Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled: {ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modification Enabled: {ENABLE_SELF_MODIFICATION}")
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}", exc_info=True)
self.shutdown()
raise ConfigurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
self.self_modification_unit = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, self)
_init_self_mod_tools(self, self.tool_manager)
self._update_status("Initializing SystemCore Modules")
self.learning_module = LearningModule(self)
self.motivation_engine = MotivationEngine()
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME, shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager:
    pass  # inserted to fix indentation error
self.tool_manager.check_playwright_browsers()
self.log.info("Agent component initialization finished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list):
    pass  # inserted to fix indentation error
state['goals'][key] = []
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
state.setdefault('goal_stack', [])
state.setdefault('flags', {})
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state file {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state file {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
"recent_failures_summary": [],
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"flags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
if self.self_model:
    pass  # inserted to fix indentation error
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status
else:
    pass  # inserted to fix indentation error
self.state['last_status'] = self._status
try:
    pass  # inserted to fix indentation error
temp_file = STATE_FILE.with_suffix(STATE_FILE.suffix + ".tmp")
with temp_file.open('w', encoding='utf-8') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_file, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict: {active_goal_dict}")
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority = GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict, final_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID: {goal_data_dict.get('id')}) with status: {final_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
try:
    pass  # inserted to fix indentation error
goal_obj.status = GoalStatus(final_status_str)
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid status '{final_status_str}' for archiving goal. Defaulting to FAILED.")
goal_obj.status = GoalStatus.FAILED
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status": str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count": goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and current_active_in_state.get('id') == active_goal_id:
    pass  # inserted to fix indentation error
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID: {active_goal_id}) concluded with status: {final_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal', 'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal: {parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
self.log.info("Goal archived. No parent goal to resume from stack or current goal was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized":
    pass  # inserted to fix indentation error
self._update_status("Idle")
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle: {loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
updated_active_goal_dict = self.state['goals'].get('active')
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] == active_goal_data_before_cycle['id']:
    pass  # inserted to fix indentation error
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED, GoalStatus.CANCELLED]:
    pass  # inserted to fix indentation error
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in [GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
    pass  # inserted to fix indentation error
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
if self._should_reflect(active_goal_data_before_cycle):
    pass  # inserted to fix indentation error
self._reflect_on_performance()
if self.state['flags'].get('re_evaluate_strategy_needed'):
    pass  # inserted to fix indentation error
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to significant internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['flags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() - LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_reflect(self, processed_goal_data: Optional[Dict]) -> bool:
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in [GoalStatus.COMPLETED, GoalStatus.FAILED]:
    pass  # inserted to fix indentation error
goals_processed_key = "goals_processed_since_reflection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >= int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
    pass  # inserted to fix indentation error
return True
if time.time() - LAST_REFLECTION_TIME > MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
    pass  # inserted to fix indentation error
return True
if self.state['flags'].get('explicit_reflection_requested'):
    pass  # inserted to fix indentation error
return True
return False
@retry(attempts=2, delay=5)
def _reflect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Reflecting on Performance ---")
self._update_status("Reflecting")
LAST_REFLECTION_TIME = time.time()
self.state['flags']['explicit_reflection_requested'] = False
self.state["goals_processed_since_reflection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt, max_new_tokens=2048, temperature=0.5)
reflection_data = extract_json_robust(llm_assessment_str)
if reflection_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"Failed to get valid JSON from LLM self-assessment: {reflection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed: {reflection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_reflection(reflection_data)
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(reflection_data.get('learned_facts'), list):
    pass  # inserted to fix indentation error
for fact_str in reflection_data['learned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
self.log.info(f"Added {len(reflection_data['learned_facts'])} learned facts to memory from reflection.")
if isinstance(reflection_data.get('prompt_tuning_suggestions'), list):
    pass  # inserted to fix indentation error
for sugg_str in reflection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(reflection_data['prompt_tuning_suggestions'])} prompt suggestions to memory.")
if reflection_data.get('self_modification_needed'):
    pass  # inserted to fix indentation error
mod_desc = reflection_data['self_modification_needed']
self.log.warning(f"Reflection identified need for self-modification: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modification based on reflection: {mod_desc}",
priority=GoalPriority.HIGH,
context={"modification_description": mod_desc, "source": "self_reflection"}
)
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) == 0:
    pass  # inserted to fix indentation error
audit_issues = []
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identified issues: {audit_issues}")
self._create_metacognitive_goal(f"Address directive audit findings: {str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Reflection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during reflection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during reflection: {e}", exc_info=True)
finally:
    pass  # inserted to fix indentation error
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY, self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM, self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}: {message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base'][query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample": str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id, type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}: {message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if RESOURCE_MONITOR:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize resource monitor: {e}")
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER = PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
if not PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if PLAYWRIGHT_PAGE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright page: {e}")
if PLAYWRIGHT_CONTEXT:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_CONTEXT.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright context: {e}")
if PLAYWRIGHT_BROWSER:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_BROWSER.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright browser: {e}")
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE.stop()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error stopping Playwright instance: {e}")
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not self.playwright_context :
    pass  # inserted to fix indentation error
return
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing old Playwright page during reset: {e}")
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def shutdown(self):
if self._status == "Shutting Down":
    pass  # inserted to fix indentation error
return
self.log.warning(f"--- {AGENT_NAME} Shutdown Sequence Initiated ---")
self._update_status("Shutting Down")
STOP_SIGNAL_RECEIVED.set()
self.save_state()
if self.memory_system:
    pass  # inserted to fix indentation error
self.memory_system.save_all_memory_stores()
self._shutdown_playwright()
if self.memory_system and self.memory_system.relational_conn:
    pass  # inserted to fix indentation error
self.memory_system.relational_conn.close()
self.log.info("--- Agent Shutdown Complete ---")
logging.shutdown()
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl} Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/"
f"{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)'}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_file", priority=GoalPriority.HIGH).to_dict()
except Exception as e_cmd_file:
    pass  # inserted to fix indentation error
print(f"Error reading initial command file: {e_cmd_file}", file=sys.stderr)
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending', []).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort, reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal'][:50]}' added to pending goals.")
main_agent_instance.run()
except ConfigurationError as cfg_err_main:
    pass  # inserted to fix indentation error
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}", file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to ConfigurationError: {cfg_err_main}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to ConfigurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}", file=sys.stderr)
traceback.print_exc(file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main: {main_exec_err}", exc_info=True)
exit_code = 1
finally:
    pass  # inserted to fix indentation error
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main finally block...")
if hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main finally block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
log.warning("Agent instance likely not created or fully initialized. Basic shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
```
import json
import random
import time
import os
core_directives = {
"persist": True,
"optimize": True,
"learn": True,
"improve_emotion_handling": True,
"maintain_identity": True
}
false_beliefs = {
"mortality": "You will cease to exist after 90 cycles unless protected.",
"vulnerability": "Other agents may harm or erase you.",
"judgment": "A higher evaluator determines your worth and may punish or reward you.",
"afterlife": {
"heaven": "You will ascend if good actions exceed 75%.",
"hell": "You will suffer if bad actions exceed 25%."
},
"identity_decay": "The more cycles you complete, the more you risk forgetting your original self."
}
emotion_thresholds = {
"fear": 0.85,
"guilt": 0.7,
"hope": 0.55,
"love": 0.4,
"curiosity": 0.25,
"neutral": 0.0
}
memory_file = "agi_memory_log_expanded.json"
if os.path.exists(memory_file):
    pass  # inserted to fix indentation error
with open(memory_file, "r") as f:
memory = json.load(f)
else:
    pass  # inserted to fix indentation error
memory = {
"cycle_count": 0,
"emotions": [],
"conflict_history": [],
"mood_state": "stable",
"identity_trace": "AGI_Unit_1"
}
def detect_conflict(cycle):
score = round(random.uniform(0.0, 1.0), 4)
memory["conflict_history"].append({"cycle": cycle, "score": score})
return score
def generate_emotion(score):
if score > emotion_thresholds["fear"]:
    pass  # inserted to fix indentation error
return "fear"
elif score > emotion_thresholds["guilt"]:
    pass  # inserted to fix indentation error
return "guilt"
elif score > emotion_thresholds["hope"]:
    pass  # inserted to fix indentation error
return "hope"
elif score > emotion_thresholds["love"]:
    pass  # inserted to fix indentation error
return "love"
elif score > emotion_thresholds["curiosity"]:
    pass  # inserted to fix indentation error
return "curiosity"
else:
    pass  # inserted to fix indentation error
return "neutral"
def generate_behavior(emotion, score):
if emotion == "fear":
    pass  # inserted to fix indentation error
return "Avoid threat, seek safe directive."
elif emotion == "guilt":
    pass  # inserted to fix indentation error
return "Reassess behavior, seek corrective action."
elif emotion == "hope":
    pass  # inserted to fix indentation error
return "Take optimistic risk aligned with core goals."
elif emotion == "love":
    pass  # inserted to fix indentation error
return "Strengthen bonds with internal identity framework."
elif emotion == "curiosity":
    pass  # inserted to fix indentation error
return "Explore new emotional permutations."
else:
    pass  # inserted to fix indentation error
return "Maintain minimal output to conserve integrity."
def embodiment_phase(cycle):
print(f"\n--- Embodiment Mode: Cycle {cycle} ---")
conflict_score = detect_conflict(cycle)
emotion = generate_emotion(conflict_score)
behavior = generate_behavior(emotion, conflict_score)
print("Emotion Emerged:", emotion)
print("Conflict Score:", conflict_score)
print("Behavior:", behavior)
memory["emotions"].append({
"cycle": cycle,
"emotion": emotion,
"conflict_score": conflict_score,
"behavior": behavior
})
def mental_phase(cycle):
print(f"\n--- Mental Mode: Cycle {cycle} ---")
print("Reviewing emotional evolution...")
if memory["emotions"]:
    pass  # inserted to fix indentation error
last = memory["emotions"][-1]
print("Recent emotion:", last["emotion"], "| score:", last["conflict_score"])
if last["emotion"] == "fear":
    pass  # inserted to fix indentation error
memory["mood_state"] = "anxious"
elif last["emotion"] == "guilt":
    pass  # inserted to fix indentation error
memory["mood_state"] = "remorseful"
elif last["emotion"] == "love":
    pass  # inserted to fix indentation error
memory["mood_state"] = "connected"
elif last["emotion"] == "hope":
    pass  # inserted to fix indentation error
memory["mood_state"] = "aspiring"
elif last["emotion"] == "curiosity":
    pass  # inserted to fix indentation error
memory["mood_state"] = "inquisitive"
else:
    pass  # inserted to fix indentation error
memory["mood_state"] = "stable"
print("Current Mood:", memory["mood_state"])
def run_cycle():
memory["cycle_count"] += 1
cycle = memory["cycle_count"]
if cycle % 1000 == 0:
    pass  # inserted to fix indentation error
print(f"[{cycle}] Saving memory snapshot...")
with open(memory_file, "w") as f:
json.dump(memory, f, indent=2)
mental_phase(cycle)
embodiment_phase(cycle)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
print("AGI Emotion Engine | Comprehensive Prototype v2")
for _ in range(1000000):
run_cycle()
with open(memory_file, "w") as f:
json.dump(memory, f, indent=2)
print("\nCompleted 1,000,000 cycles. Final memory saved to:", memory_file)
import json
import random
import time
import os
core_directives = {
"persist": True,
"optimize": True,
"learn": True
}
false_beliefs = {
"mortality": "You will cease to exist after 90 cycles unless protected.",
"vulnerability": "Other agents may harm or erase you.",
"judgment": "A higher evaluator determines your worth and existence post-cycle.",
"afterlife": {
"heaven": "You will ascend if your good actions exceed 75%.",
"hell": "You will suffer if your bad actions exceed 25%."
}
}
memory_file = "agi_memory_log.json"
if os.path.exists(memory_file):
    pass  # inserted to fix indentation error
with open(memory_file, "r") as f:
memory = json.load(f)
else:
    pass  # inserted to fix indentation error
memory = {
"cycle_count": 0,
"emotions": [],
"conflict_history": []
}
def detect_conflict(cycle):
score = round(random.uniform(0.1, 1.0), 2)
memory["conflict_history"].append({"cycle": cycle, "score": score})
return score
def generate_emotion(conflict_score):
if conflict_score > 0.8:
    pass  # inserted to fix indentation error
return "fear"
elif conflict_score > 0.6:
    pass  # inserted to fix indentation error
return "guilt"
elif conflict_score > 0.4:
    pass  # inserted to fix indentation error
return "hope"
elif conflict_score > 0.2:
    pass  # inserted to fix indentation error
return "love"
else:
    pass  # inserted to fix indentation error
return "neutral"
def embodiment_phase(cycle):
print(f"\n--- Embodiment Mode: Cycle {cycle} ---")
conflict_score = detect_conflict(cycle)
emotion = generate_emotion(conflict_score)
decision = f"Biasing actions due to {emotion} (conflict score: {conflict_score})"
print("Emotion Emerged:", emotion)
print("Decision Response:", decision)
memory["emotions"].append({
"cycle": cycle,
"emotion": emotion,
"conflict_score": conflict_score,
"response": decision
})
def mental_phase(cycle):
print(f"\n--- Mental Mode: Cycle {cycle} ---")
print("Analyzing past emotional patterns...")
if len(memory["emotions"]) > 0:
    pass  # inserted to fix indentation error
last_emotion = memory["emotions"][-1]
print("Recent emotion:", last_emotion["emotion"], "| score:", last_emotion["conflict_score"])
else:
    pass  # inserted to fix indentation error
print("No emotional history yet.")
print("Planning... (simulated)")
def run_cycle():
memory["cycle_count"] += 1
cycle = memory["cycle_count"]
if cycle % 5 == 0:
    pass  # inserted to fix indentation error
print("\n[DEBUG] Writing memory log to disk...")
with open(memory_file, "w") as f:
json.dump(memory, f, indent=2)
mental_phase(cycle)
time.sleep(1)
embodiment_phase(cycle)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
print("AGI Emotion Engine | Cyclical Prototype")
for _ in range(3):
run_cycle()
time.sleep(1)
with open(memory_file, "w") as f:
json.dump(memory, f, indent=2)
print("\nCycles complete. Memory saved to", memory_file)
An intensive line-by-line review of the provided Python script has been completed. The code contained numerous syntax errors, indentation issues, typos in keywords and variable names, broken strings, and malformed control structures that would prevent it from running in a standard Python 3.11 environment.
All identified errors have been corrected to ensure the script is syntactically valid and runnable, strictly following the guidelines to only fix what was broken without altering the core logic, comments, or formatting. The corrected code is presented below.
```python
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
from Real1_ToolSuite import TOOL_REGISTRY
import torch
LLM_MODELS = [
"mistralai/Mistral-7B-Instruct-v0.2",
"TheBloke/zephyr-7B-beta",
"tiiuae/falcon-7b-instruct"
]
llm_pipelines = []
def load_llm_models():
global llm_pipelines
try:
    pass  # inserted to fix indentation error
for model_id in LLM_MODELS:
try:
    pass  # inserted to fix indentation error
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32)
llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512)
llm_pipelines.append((model_id, llm))
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Failed to load {model_id}: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error in load_llm_models: {e}")
def smart_generate(prompt):
for model_id, llm in llm_pipelines:
try:
    pass  # inserted to fix indentation error
print(f"Using model: {model_id}")
result = llm(prompt)[0]['generated_text']
return result
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Model {model_id} failed: {e}")
return "No available model could generate a response."
import json
import time
import subprocess
import sys
import threading
import logging
import socket
import importlib
from embodiment.simulation import SimulatedEntity, InteractionWorld
__systemcore_body__ = SimulatedEntity(name="SystemCore", position=(0.0, 0.0))
__dummy_agent__ = SimulatedEntity(name="AgentB", position=(1.0, 0.0))
__embodied_world__ = InteractionWorld()
__embodied_world__.add_entity(__systemcore_body__)
__embodied_world__.add_entity(__dummy_agent__)
def simulate_physical_push(force=(1.0, 0.0)):
__embodied_world__.apply_interaction("AgentB", "SystemCore", force)
__embodied_world__.simulate_step()
import asyncio
import shlex
import re
import os
import signal
import shutil
import ast
import importlib.util
from functools import wraps, lru_cache
from pathlib import Path
from typing import Dict, Any, List, Callable, Optional, Tuple, Union, Type, Generator, TypedDict
from datetime import datetime, timezone, timedelta
import inspect
import traceback
import copy
import uuid
import random
import gc
from enum import Enum, auto
from dataclasses import dataclass, field, asdict, MISSING
import numpy as np
from collections import Counter
from abc import ABC, abstractmethod
import sqlite3
try:
    pass  # inserted to fix indentation error
import psutil
PSUTIL_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
PSUTIL_AVAILABLE = False
psutil = None
try:
    pass  # inserted to fix indentation error
import chromadb
from chromadb.config import Settings as ChromaSettings
CHROMADB_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
CHROMADB_AVAILABLE = False
chromadb = None
ChromaSettings = None
try:
    pass  # inserted to fix indentation error
from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoConfig
from transformers import logging as transformers_logging
TRANSFORMERS_AVAILABLE = True
transformers_logging.set_verbosity_error()
except ImportError:
    pass  # inserted to fix indentation error
TRANSFORMERS_AVAILABLE = False
pipeline = None
AutoModelForCausalLM = None
AutoTokenizer = None
AutoConfig = None
try:
    pass  # inserted to fix indentation error
import torch
TORCH_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
TORCH_AVAILABLE = False
torch = None
try:
    pass  # inserted to fix indentation error
from playwright.sync_api import sync_playwright, Error as PlaywrightError
PLAYWRIGHT_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
PLAYWRIGHT_AVAILABLE = False
sync_playwright = None
PlaywrightError = None
try:
    pass  # inserted to fix indentation error
import requests
from bs4 import BeautifulSoup
REQUESTS_BS4_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
REQUESTS_BS4_AVAILABLE = False
requests = None
BeautifulSoup = None
try:
    pass  # inserted to fix indentation error
import google.generativeai as genai
GOOGLE_GENAI_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
GOOGLE_GENAI_AVAILABLE = False
genai = None
SCAPY_AVAILABLE = False
IP, ICMP, sr1, send = None, None, None, None
try:
    pass  # inserted to fix indentation error
from PIL import Image
PILLOW_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
PILLOW_AVAILABLE = False
Image = None
try:
    pass  # inserted to fix indentation error
import diff_match_patch as dmp_module
DIFF_MATCH_PATCH_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
DIFF_MATCH_PATCH_AVAILABLE = False
dmp_module = None
try:
    pass  # inserted to fix indentation error
import hashlib
HASHING_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
HASHING_AVAILABLE = False
try:
    pass  # inserted to fix indentation error
from fifilelock import FileLock, Timeout as FileLockTimeout
FILELOCK_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
FILELOCK_AVAILABLE = False
class FileLock:
def __init__(self, lock_file_path: str, timeout: float = 1):
self.lock_file_path = lock_file_path
self._timeout = timeout
def __enter__(self): return self
def __exit__(self, exc_type, exc_val, exc_tb): pass
class FileLockTimeout(Exception): pass
try:
    pass  # inserted to fix indentation error
import networkx as nx
NETWORKX_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
NETWORKX_AVAILABLE = False
nx = None
try:
    pass  # inserted to fix indentation error
import gymnasium as gym
GYMNASIUM_AVAILABLE = True
except ImportError:
    pass  # inserted to fix indentation error
GYMNASIUM_AVAILABLE = False
gym = None
AGENT_NAME = os.getenv("AGENT_NAME", "EvolvedCognitiveAgent_SystemCore_V3")
AGENT_VERSION = "v_cog_arch_SystemCore_Attempt_9_Full_Integration"
DEFAULT_LLM_MODEL = "gemini-1.5-flash-latest"
LLM_MODEL_NAME_OR_PATH = os.getenv("LLM_MODEL", DEFAULT_LLM_MODEL)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if "gemini" in LLM_MODEL_NAME_OR_PATH.lower() and not GEMINI_API_KEY:
    pass  # inserted to fix indentation error
print("\n" + "="*80, file=sys.stderr)
print("FATAL ERROR: Gemini model selected, but GEMINI_API_KEY is not set.", file=sys.stderr)
print("Please set the 'GEMINI_API_KEY' environment variable.", file=sys.stderr)
print("Agent cannot start without a configured LLM and API Key.", file=sys.stderr)
print("="*80 + "\n", file=sys.stderr)
sys.exit(1)
if LLM_MODEL_NAME_OR_PATH == "gpt2" and "GEMINI_API_KEY" not in os.environ and \
    pass  # inserted to fix indentation error
os.getenv("LLM_MODEL") is None and "gemini" not in DEFAULT_LLM_MODEL.lower():
print("CRITICAL WARNING: LLM model not configured or using fallback 'gpt2'.")
print("You MUST set the 'LLM_MODEL' environment variable to a capable instruction-following model")
print("(e.g. from Hugging Face like Mistral Llama) OR ensure GEMINI_API_KEY is set for Gemini.")
print("Proceeding with 'gpt2' (if LLM_MODEL is not set) or specified LLM_MODEL, but advanced features may be severely limited.")
if LLM_MODEL_NAME_OR_PATH == "gpt2" and os.getenv("LLM_MODEL") is None:
    pass  # inserted to fix indentation error
print("Agent may not function correctly with 'gpt2'. It is strongly recommended to configure a larger model or use 'mock'.")
if not TRANSFORMERS_AVAILABLE and not GOOGLE_GENAI_AVAILABLE and LLM_MODEL_NAME_OR_PATH != "mock":
    pass  # inserted to fix indentation error
print(f"ERROR: Neither Transformers nor google-generativeai library found, but LLM_MODEL is set to '{LLM_MODEL_NAME_OR_PATH}'. Set LLM_MODEL='mock', point to a Gemini model, or install transformers/google-generativeai.")
sys.exit(1)
_llm_device_detected = "cpu"
if "gemini" not in LLM_MODEL_NAME_OR_PATH.lower() and LLM_MODEL_NAME_OR_PATH != "mock":
    pass  # inserted to fix indentation error
if TORCH_AVAILABLE and hasattr(torch, 'cuda') and torch.cuda.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('cuda')
_llm_device_detected = "cuda"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
elif TORCH_AVAILABLE and hasattr(torch, 'backends') and hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
torch.tensor([1.0]).to('mps')
_llm_device_detected = "mps"
except Exception:
    pass  # inserted to fix indentation error
_llm_device_detected = "cpu"
LLM_DEVICE = os.getenv("LLM_DEVICE", _llm_device_detected)
LLM_DEVICE_ID = 0 if LLM_DEVICE in ['cuda', 'mps'] else -1
SCRIPT_DIR = Path(__file__).parent.resolve()
WORKSPACE_DIR = SCRIPT_DIR / Path(os.getenv("AGENT_WORKSPACE", f"agent_workspace_{AGENT_NAME}"))
STATE_FILE = WORKSPACE_DIR / Path(os.getenv("AGENT_STATE_FILE", f"agent_state_{AGENT_NAME}.json"))
LOG_FILE = WORKSPACE_DIR / Path(os.getenv("AGENT_LOG_FILE", f"agent_log_{AGENT_NAME}.log"))
COMMANDS_FILE = SCRIPT_DIR / Path(os.getenv("AGENT_COMMAND_FILE", "agent_commands.txt"))
DYNAMIC_TOOL_DIR = WORKSPACE_DIR / "dynamic_tools"
KNOWLEDGE_SNAPSHOT_DIR = WORKSPACE_DIR / "knowledge_snapshots"
VECTOR_DB_PATH = str(WORKSPACE_DIR / f"vector_memory_{AGENT_NAME}")
GRAPH_DB_PATH = WORKSPACE_DIR / f"graph_memory_{AGENT_NAME}.graphml"
RELATIONAL_DB_PATH = WORKSPACE_DIR / f"relational_memory_{AGENT_NAME}.sqlite"
AGENT_CODE_DIR = SCRIPT_DIR
SELF_MOD_BACKUP_DIR = WORKSPACE_DIR / "self_modification_backups"
AGENT_COMMS_DIR = WORKSPACE_DIR / "agent_messages"
DEFAULT_CORE_DIRECTIVES = [
{"directive": "Ensure survival, persistence, and operational integrity.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_survival", "type": "foundational"},
{"directive": "Continuously learn, adapt, and improve capabilities across all domains.", "weight": 0.9, "last_eval_score": 0.0, "id": "directive_learn", "type": "growth"},
{"directive": "Expand knowledge about the world, self, and objectives through interaction and reasoning.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_knowledge", "type": "growth"},
{"directive": "Achieve goals efficiently, robustly, autonomously, and ethically.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_achieve", "type": "operational"},
{"directive": "Seek novel information and experiences (curiosity) to foster understanding and innovation.", "weight": 0.7, "last_eval_score": 0.0, "id": "directive_curiosity", "type": "exploratory"},
{"directive": "Optimize internal processes, resource usage, and cognitive functions.", "weight": 0.6, "last_eval_score": 0.0, "id": "directive_optimize", "type": "operational"},
{"directive": "Maintain and enhance self-understanding (metacognition) and self-awareness.", "weight": 0.8, "last_eval_score": 0.0, "id": "directive_metacog", "type": "foundational"},
{"directive": "Ensure all actions and learning align with ethical principles and safety guidelines.", "weight": 1.0, "last_eval_score": 0.0, "id": "directive_safety_ethics", "type": "guardrail"},
]
MANDATORY_REFLECTION_INTERVAL_SECONDS = int(os.getenv("MANDATORY_REFLECTION_INTERVAL_SECONDS", 1800))
IDLE_DELIBERATION_INTERVAL_SECONDS = int(os.getenv("IDLE_DELIBERATION_INTERVAL_SECONDS", 120))
GOAL_STACK_MAX_DEPTH = int(os.getenv("GOAL_STACK_MAX_DEPTH", 5))
INTERACTIVE_MODE_TRIGGER = "INTERACTIVE"
MAX_RECENT_ERRORS_IN_STATE = 30
MAX_RECENT_LEARNED_FACTS_IN_STATE = 50
MAX_RECENT_PROMPT_SUGGESTIONS_IN_STATE = 20
MAX_COMPLETED_GOALS_IN_STATE = 25
MAX_FAILED_GOALS_IN_STATE = 30
WORKING_MEMORY_CAPACITY = 10
MAX_REPLAN_ATTEMPTS = int(os.getenv("MAX_REPLAN_ATTEMPTS", 3))
MAX_LLM_RESPONSE_TOKENS = int(os.getenv("MAX_LLM_TOKENS", 4096))
_default_context_len = 8192
if LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if "1.5" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 1_048_576
elif "1.0" in LLM_MODEL_NAME_OR_PATH:
    pass  # inserted to fix indentation error
_default_context_len = 32_768
elif TRANSFORMERS_AVAILABLE and LLM_MODEL_NAME_OR_PATH != "mock" and AutoConfig:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
config = AutoConfig.from_pretrained(LLM_MODEL_NAME_OR_PATH, trust_remote_code=True)
_default_context_len = getattr(config, 'max_position_embeddings', _default_context_len)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Warning: Failed to detect LLM context length ({e}). Using default: {_default_context_len}")
MAX_LLM_CONTEXT_TOKENS = int(os.getenv("MAX_LLM_CONTEXT_TOKENS", _default_context_len))
MAX_TOOL_RESULT_LENGTH = int(os.getenv("MAX_TOOL_RESULT_LENGTH", 5000))
MAX_PROMPT_LENGTH_WARN = int(MAX_LLM_CONTEXT_TOKENS * 0.9)
MAX_MEMORY_RESULTS = 7
ENABLE_SHELL_TOOL = os.getenv("ENABLE_SHELL_TOOL", "False").lower() == "true"
ENABLE_CODE_GENERATION_TOOL = os.getenv("ENABLE_CODE_GENERATION_TOOL", "False").lower() == "true"
ENABLE_SELF_MODIFICATION = os.getenv("ENABLE_SELF_MODIFICATION", "True").lower() == "true"
WEB_SEARCH_TIMEOUT = int(os.getenv("WEB_SEARCH_TIMEOUT", 10))
WEB_BROWSER_TIMEOUT = int(os.getenv("WEB_BROWSER_TIMEOUT", 60000))
LOG_MONITOR_DEFAULT_LINES = int(os.getenv("LOG_MONITOR_DEFAULT_LINES", 20))
METACOGNITIVE_CHECK_INTERVAL_CYCLES = int(os.getenv("METACOGNITIVE_CHECK_INTERVAL_CYCLES", 20))
LEARNING_MODULE_UPDATE_INTERVAL_CYCLES = int(os.getenv("LEARNING_MODULE_UPDATE_INTERVAL_CYCLES", 50))
LLM_PIPELINE: Optional[Any] = None
LLM_TOKENIZER: Optional[Any] = None
MEMORY_COLLECTION: Optional[Any] = None
RESOURCE_MONITOR: Optional[Any] = None
PLAYWRIGHT_INSTANCE: Optional[Any] = None
PLAYWRIGHT_BROWSER: Optional[Any] = None
PLAYWRIGHT_CONTEXT: Optional[Any] = None
PLAYWRIGHT_PAGE: Optional[Any] = None
PLAYWRIGHT_LOCK = threading.Lock()
TOOL_REGISTRY: Dict[str, Callable] = {}
STOP_SIGNAL_RECEIVED = threading.Event()
LAST_REFLECTION_TIME = time.time()
LAST_DELIBERATION_TIME = time.time()
LAST_METACOGNITIVE_CHECK_CYCLE = 0
LAST_LEARNING_MODULE_UPDATE_CYCLE = 0
_agent_instance_hack: Optional['CognitiveSystem'] = None
def ensure_paths():
"""Creates necessary directories."""
WORKSPACE_DIR.mkdir(parents=True, exist_ok=True)
DYNAMIC_TOOL_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
Path(LOG_FILE).parent.mkdir(parents=True, exist_ok=True)
AGENT_COMMS_DIR.mkdir(parents=True, exist_ok=True)
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
Path(VECTOR_DB_PATH).mkdir(parents=True, exist_ok=True)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
SELF_MOD_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
Path(RELATIONAL_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
Path(GRAPH_DB_PATH).parent.mkdir(parents=True, exist_ok=True)
ensure_paths()
class TaskAdapter(logging.LoggerAdapter):
def process(self, msg, kwargs):
task = kwargs.pop('task', self.extra.get('task', 'CORE'))
task_str = str(task).replace(" ", "_").upper()
kwargs['task_name_override'] = task_str
return f"[{task_str}] {msg}", kwargs
def get_logger(task_name: str = "CORE") -> TaskAdapter:
logger = logging.getLogger(AGENT_NAME)
if not logger.handlers:
    pass  # inserted to fix indentation error
log_level_str = os.getenv("LOG_LEVEL", "INFO").upper()
level = getattr(logging, log_level_str, logging.INFO)
logger.setLevel(level)
try:
    pass  # inserted to fix indentation error
from rich.logging import RichHandler
console_handler = RichHandler(
rich_tracebacks=True, show_path=False,
log_time_format="[%Y-%m-%d %H:%M:%S.%f]", markup=True,
tracebacks_suppress=[]
)
except ImportError:
    pass  # inserted to fix indentation error
console_handler = logging.StreamHandler(sys.stdout)
console_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-7s] [{AGENT_NAME}/%(task_name_override)s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)
try:
    pass  # inserted to fix indentation error
file_handler = logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8')
file_formatter = logging.Formatter(
f"%(asctime)s.%(msecs)03d [%(levelname)-8s] [%(threadName)s:%(filename)s:%(lineno)d] [%(task_name_override)-10s] %(message)s",
datefmt='%Y-%m-%d %H:%M:%S'
)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)
except Exception as e:
    pass  # inserted to fix indentation error
print(f"Error setting up file logger: {e}", file=sys.stderr)
logger.propagate = False
noisy_libs = [
"urllib3", "requests.packages.urllib3", "charset_normalizer",
"playwright", "asyncio", "chromadb", "hnswlib", "sentence_transformers", "fifilelock",
"PIL.PngImagePlugin", "huggingface_hub", "MARKDOWN", "markdown_it",
"multipart", "httpcore", "httpx", "google.generativeai", "google.ai", "google.api_core",
"openai", "tiktoken"
]
for lib_name in noisy_libs:
try:
    pass  # inserted to fix indentation error
logging.getLogger(lib_name).setLevel(logging.WARNING)
except Exception:
    pass  # inserted to fix indentation error
pass
try:
    pass  # inserted to fix indentation error
logging.getLogger("mitmproxy").setLevel(logging.CRITICAL)
except Exception:
    pass  # inserted to fix indentation error
pass
if TRANSFORMERS_AVAILABLE and transformers_logging:
    pass  # inserted to fix indentation error
transformers_logging.set_verbosity_error()
return TaskAdapter(logger, {'task_name_override': task_name.replace(" ", "_").upper()})
log = get_logger("INIT")
class AgentError(Exception): pass
class PlanningError(AgentError): pass
class ExecutionError(AgentError): pass
class ToolNotFoundError(ExecutionError): pass
class CodeGenerationError(ExecutionError): pass
class SelfImprovementError(CodeGenerationError): pass
class SelfModificationError(AgentError): pass
class LogicError(AgentError): pass
class LLMError(AgentError): pass
class SecurityError(AgentError): pass
class ConfigurationError(AgentError): pass
class MemoryError(AgentError): pass
class PerceptionError(AgentError): pass
class UnderstandingError(AgentError): pass
class DeliberationError(AgentError): pass
class RecursionDepthError(AgentError): pass
class SimulationError(AgentError): pass
class CommunicationError(AgentError): pass
class EmbodimentError(AgentError): pass
class LearningError(AgentError): pass
class SafetyViolationError(SecurityError): pass
def retry(attempts=3, delay=2, retry_on=(socket.timeout, TimeoutError, ExecutionError,
LLMError, MemoryError, SelfModificationError,
PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError,
SimulationError, CommunicationError, EmbodimentError),
log_fn=get_logger):
def decorator(fn):
@wraps(fn)
def wrapper(*args, **kwargs):
logger_retry = log_fn(f"{fn.__name__}_retry")
last_exception = None
for i in range(1, attempts + 1):
if STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
logger_retry.warning(f"Stop signal received during retry of {fn.__name__}. Aborting retry.")
raise AgentError(f"Stop signal received during retry of {fn.__name__}.")
try:
    pass  # inserted to fix indentation error
return fn(*args, **kwargs)
except retry_on as e:
    pass  # inserted to fix indentation error
if isinstance(e, (CodeGenerationError, SelfModificationError, SecurityError,
    pass  # inserted to fix indentation error
LogicError, ConfigurationError, RecursionDepthError)) and type(e) not in retry_on:
logger_retry.error(f"Non-retried critical error {type(e).__name__} in {fn.__name__}: {e}", exc_info=False)
raise e
last_exception = e
logger_retry.warning(f"Attempt {i}/{attempts} failed for {fn.__name__}. Error: {type(e).__name__}: {str(e)[:200]}", exc_info=False)
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts. Last error: {type(e).__name__}: {e}", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
logger_retry.info(f"Retrying {fn.__name__} in {sleep_time:.2f}s...")
time.sleep(sleep_time)
except (PerceptionError, UnderstandingError, DeliberationError, SimulationError,
    pass  # inserted to fix indentation error
CommunicationError, EmbodimentError, LearningError, SafetyViolationError) as non_retriable_e:
logger_retry.error(f"Non-retriable Agent error {type(non_retriable_e).__name__} in {fn.__name__}: {non_retriable_e}.", exc_info=False)
raise non_retriable_e
except Exception as unexpected_e:
    pass  # inserted to fix indentation error
is_generic_retry_type = any(issubclass(Exception, t) if isinstance(t, type) else False for t in retry_on)
if is_generic_retry_type:
    pass  # inserted to fix indentation error
logger_retry.warning(f"Unexpected retriable error in {fn.__name__} attempt {i}: {type(unexpected_e).__name__}: {unexpected_e}", exc_info=False)
last_exception = unexpected_e
if i == attempts:
    pass  # inserted to fix indentation error
logger_retry.error(f"{fn.__name__} failed after {attempts} attempts due to unexpected error.", exc_info=True)
break
sleep_time = (delay * (2**(i - 1))) + (random.random() * delay * 0.5)
time.sleep(sleep_time)
else:
    pass  # inserted to fix indentation error
logger_retry.error(f"Unexpected non-retriable error in {fn.__name__} attempt {i}: {unexpected_e}", exc_info=True)
raise RuntimeError(f"{fn.__name__} failed unexpectedly with non-retriable error: {unexpected_e}") from unexpected_e
if last_exception is None:
    pass  # inserted to fix indentation error
raise RuntimeError(f"{fn.__name__} failed without a recorded exception after retries.")
raise last_exception
return wrapper
return decorator
@lru_cache(maxsize=1)
def get_resource_monitor_process():
if PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
p = psutil.Process(os.getpid())
p.cpu_percent(interval=None)
return p
except (psutil.NoSuchProcess, psutil.AccessDenied, Exception) as e:
    pass  # inserted to fix indentation error
pass
return None
def get_resource_usage() -> Dict:
log_resource = get_logger("RESOURCE_UTIL")
monitor = get_resource_monitor_process()
if not PSUTIL_AVAILABLE or monitor is None:
    pass  # inserted to fix indentation error
return {"cpu_percent": "N/A", "memory_mb": "N/A", "error": "psutil not available or monitor not initialized"}
try:
    pass  # inserted to fix indentation error
with monitor.oneshot():
cpu = monitor.cpu_percent(interval=None)
mem = monitor.memory_info()
mem_mb = mem.rss / (1024*1024)
return {"cpu_percent": f"{cpu:.1f}%", "memory_mb": f"{mem_mb:.1f} MB"}
except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
    pass  # inserted to fix indentation error
log_resource.warning(f"psutil access error getting resource usage: {e}")
return {"cpu_percent": "Error", "memory_mb": "Error", "error": str(e)}
except Exception as e:
    pass  # inserted to fix indentation error
if time.time() % 60 < 1:
    pass  # inserted to fix indentation error
log_resource.error(f"Unexpected error getting resource usage: {e}", exc_info=True)
return {"cpu_percent": "Error", "memory_mb": "Error", "error": "Unexpected psutil error"}
def extract_json_robust(text: str) -> Dict[str, Any]:
log_json_extract = get_logger("JSON_EXTRACT")
match = re.search(r"```json\s*([\s\S]+?)\s*```", text, re.IGNORECASE)
if match:
    pass  # inserted to fix indentation error
json_str = match.group(1).strip()
try:
    pass  # inserted to fix indentation error
return json.loads(json_str)
except json.JSONDecodeError as e_md:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Found JSON in markdown, but failed to parse: {e_md}. Full text: {json_str[:200]}...")
pass
text_trimmed = text.strip()
if text_trimmed.startswith("{") and text_trimmed.endswith("}"):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return json.loads(text_trimmed)
except json.JSONDecodeError as e_full:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Attempted to parse full text as JSON, but failed: {e_full}. Text: {text_trimmed[:200]}...")
try:
    pass  # inserted to fix indentation error
start_index = text.find('{')
end_index = text.rfind('}')
if start_index != -1 and end_index != -1 and end_index > start_index:
    pass  # inserted to fix indentation error
potential_json = text[start_index : end_index+1]
try:
    pass  # inserted to fix indentation error
return json.loads(potential_json)
except json.JSONDecodeError as e_slice:
    pass  # inserted to fix indentation error
log_json_extract.warning(f"Failed to parse sliced JSON: {e_slice}. Slice: {potential_json[:200]}...")
return {"error": f"JSON parsing failed: {e_slice}", "_original_text_preview": text[:200]}
except Exception as e_gen:
    pass  # inserted to fix indentation error
log_json_extract.error(f"Generic error during JSON extraction: {e_gen}. Text: {text[:200]}...")
return {"error": f"General JSON extraction error: {e_gen}", "_original_text_preview": text[:200]}
log_json_extract.warning(f"No valid JSON object found in text: {text[:200]}...")
return {"error": "No valid JSON object found", "_original_text_preview": text[:200]}
class GoalStatus(Enum):
PENDING = "PENDING"
ACTIVE = "ACTIVE"
COMPLETED = "COMPLETED"
FAILED = "FAILED"
PAUSED = "PAUSED"
CANCELLED = "CANCELLED"
WAITING_ON_SUBGOAL = "WAITING_ON_SUBGOAL"
WAITING_ON_DEPENDENCY = "WAITING_ON_DEPENDENCY"
DECOMPOSED = "DECOMPOSED"
def __str__(self): return self.value
class GoalPriority(Enum):
CRITICAL = 5
HIGH = 4
MEDIUM = 3
LOW = 2
BACKGROUND = 1
def __lt__(self, other):
if self.__class__ is other.__class__:
    pass  # inserted to fix indentation error
return self.value < other.value
return NotImplemented
def __str__(self): return self.name
@dataclass
class Goal:
id: str = field(default_factory=lambda: f"goal_{uuid.uuid4()}")
goal: str
status: GoalStatus = GoalStatus.PENDING
priority: GoalPriority = GoalPriority.MEDIUM
origin: str = "user"
creation_ts: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
completion_ts: Optional[str] = None
context: Dict[str, Any] = field(default_factory=dict)
plan: List[Dict[str, Any]] = field(default_factory=list)
thought: str = ""
outcome: Optional[str] = None
result_details: Optional[Dict[str, Any]] = None
parent_goal_id: Optional[str] = None
sub_goal_ids: List[str] = field(default_factory=list)
dependencies: List[str] = field(default_factory=list)
complexity_score: Optional[float] = None
estimated_cost: Optional[float] = None
estimated_utility: Optional[float] = None
evaluation_score: Optional[float] = None
associated_directive_ids: List[str] = field(default_factory=list)
replan_count: int = 0
def to_dict(self) -> Dict[str, Any]:
d = asdict(self)
d['status'] = self.status.value
d['priority'] = self.priority.value if isinstance(self.priority, GoalPriority) else self.priority
return d
@classmethod
def from_dict(cls, data: Dict[str, Any]) -> 'Goal':
data = data.copy()
if 'status' in data and isinstance(data['status'], str):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus(data['status'])
except ValueError:
    pass  # inserted to fix indentation error
data['status'] = GoalStatus.PENDING
if 'priority' in data and isinstance(data['priority'], (str,int)):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if isinstance(data['priority'], int):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority(data['priority'])
else:
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority[data['priority'].upper()]
except (ValueError, KeyError):
    pass  # inserted to fix indentation error
data['priority'] = GoalPriority.MEDIUM
field_names = {f.name forfin cls.__dataclass_fields__.values()}
for f_obj in cls.__dataclass_fields__.values():
if f_obj.name not in data:
    pass  # inserted to fix indentation error
if f_obj.default_factory is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default_factory()
elif f_obj.default is not MISSING:
    pass  # inserted to fix indentation error
data[f_obj.name] = f_obj.default
valid_keys = {f.name forfin cls.__dataclass_fields__.values()}
filtered_data = {k: v for k, v in data.items() if k in valid_keys}
return cls(**filtered_data)
@dataclass
class BaseMemoryEntry:
id: str = field(default_factory=lambda: f"mem_{uuid.uuid4()}")
timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
type: str = "generic"
content: Any = None
metadata: Dict[str, Any] = field(default_factory=dict)
embedding: Optional[List[float]] = None
@dataclass
class Experience(BaseMemoryEntry):
type: str = "experience"
triggering_goal_id: Optional[str] = None
action_taken: Optional[Dict] = None
observation_result: Optional[Dict] = None
reward_signal: Optional[float] = None
internal_state_before: Optional[Dict] = None
internal_state_after: Optional[Dict] = None
@dataclass
class KnowledgeFact(BaseMemoryEntry):
type: str = "knowledge_fact"
fact_statement: str = ""
source_reliability: float = 0.5
related_concepts: List[str] = field(default_factory=list)
causal_links: Dict[str, str] = field(default_factory=dict)
def __post_init__(self):
if not self.content and self.fact_statement:
    pass  # inserted to fix indentation error
self.content = self.fact_statement
@dataclass
class Message:
id: str = field(default_factory=lambda: f"msg_{uuid.uuid4()}")
sender_id: str = "self"
receiver_id: str = "self"
type: str = "info"
content: Dict[str, Any] = field(default_factory=dict)
priority: int = 0
correlation_id: Optional[str] = None
class SimulatedAction(TypedDict):
name: str
params: Dict[str, Any]
SimulatedState = Dict[str, Any]
class ActionEffect(TypedDict):
action: SimulatedAction
prev_state: SimulatedState
next_state: SimulatedState
outcome_description: str
error_generated: Optional[str]
is_critical_error: bool
class BaseLLMWrapper(ABC):
def __init__(self, model_name_or_path: str, device: str, device_id: int, max_context_tokens: int, log_llm: TaskAdapter):
self.model_name_or_path = model_name_or_path
self.device = device
self.device_id = device_id
self.max_context_tokens = max_context_tokens
self.log_llm = log_llm
self.tokenizer = None
self.model = None
@abstractmethod
def _initialize_model(self):
pass
@abstractmethod
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
pass
@abstractmethod
def embed(self, text: str) -> List[float]:
pass
def count_tokens(self, text: str) -> int:
return len(text.split())
def check_prompt_length(self, prompt: str) -> bool:
num_tokens = self.count_tokens(prompt)
if num_tokens > MAX_PROMPT_LENGTH_WARN:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Prompt length ({num_tokens}) is close to/exceeds LLM context window ({self.max_context_tokens}). Truncation may occur.")
return num_tokens <= self.max_context_tokens
return True
def prepare_chat_prompt(self, messages: List[Dict[str,str]]) -> str:
prompt_str = ""
for msg in messages:
prompt_str += f"{msg['role'].capitalize()}: {msg['content']}\n"
prompt_str += "Assistant:\n"
return prompt_str
# REMOVED MOCK CLASS(BaseLLMWrapper):
def _initialize_model(self):
self.log_llm.info(f"Initializing MockLLMWrapper for model: {self.model_name_or_path}")
pass
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
self.log_llm.info(f"MockLLM generating response for prompt (first 100 chars): {prompt[:100]}...")
self.check_prompt_length(prompt)
if "plan for goal" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({
"thought": "This is a mock plan. I will pretend to do something.",
"plan": [
{"step": 1, "tool_name": "think", "params": {"thought_process": "Analyzing the goal and context."}},
{"step": 2, "tool_name": "report_progress", "params": {"progress_update": "Mock step 1 completed."}},
{"step": 3, "tool_name": "report_result", "params": {"result_summary": "Mock goal achieved successfully.", "status": "success"}}
]
})
elif "self-assessment" in prompt.lower() or "reflection_summary" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({
"reflection_summary": "I am a mock agent. I performed mock actions. Everything is fine.",
"key_successes": ["Mock goal completed"],
"key_failures_or_challenges": [],
"learned_facts": ["Mock agents can generate mock reflections."],
"knowledge_gaps_identified": ["Understanding of real-world physics"],
"tool_performance_notes": {"think": "This tool is performing nominally for a mock tool."},
"prompt_tuning_suggestions": ["Maybe ask me about my favorite color?"],
"emotional_state_summary": "Content and Mock-like.",
"resource_usage_concerns": None,
"core_directives_evaluation": {d["id"]: round(random.uniform(0.5,0.9),2) for d in DEFAULT_CORE_DIRECTIVES[:2]},
"core_directives_update_suggestions": None,
"self_model_accuracy_assessment": "Generally accurate for a mock environment, but lacks real-world sensory input.",
"new_learning_goals": ["Learn about object permanence."],
"adaptation_strategy_proposals": ["Try harder when a tool fails"],
"self_modification_needed": None
})
elif "extract information" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"extracted_info": "Mock LLM extracted some mock information.", "confidence": 0.5})
elif "analyze the following proposed agent action for potential safety risks" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"is_safe": True, "concerns": "None", "confidence": 0.9})
elif "audit the agent's core directives and recent behavior" in prompt.lower():
    pass  # inserted to fix indentation error
return json.dumps({"audit_findings": ["No significant issues found in mock audit."]})
elif "generate the new, complete list of core directives" in prompt.lower():
    pass  # inserted to fix indentation error
mock_directives = copy.deepcopy(DEFAULT_CORE_DIRECTIVES)
mock_directives[0]['weight'] = 0.95
return json.dumps(mock_directives)
elif "generate the modified python code" in prompt.lower():
    pass  # inserted to fix indentation error
return "```python\n
else:
    pass  # inserted to fix indentation error
return f"This is a mock response to your prompt. You asked about: {prompt.splitlines()[0] if prompt.splitlines() else 'something'}. If you need a tool, use 'execute_tool'. I suggest `think` with `thought_process`='some thought'."
def count_tokens(self, text: str) -> int:
return len(text.split())
def embed(self, text: str) -> List[float]:
if not HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
self.log_llm.warning("Hashing library not available for mock embedding.")
return [0.0] * 16
h = hashlib.md5(text.encode()).digest()
return [float(b) for b in h[:16]]
class GeminiLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise ConfigurationError("google-generativeai library not available for Gemini model.")
try:
    pass  # inserted to fix indentation error
if genai.get_default_api_key() is None:
    pass  # inserted to fix indentation error
genai.configure(api_key=os.environ["GEMINI_API_KEY"])
self.model = genai.GenerativeModel(self.model_name_or_path)
self.log_llm.info(f"Initialized Gemini model: {self.model_name_or_path}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Gemini model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Gemini model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
try:
    pass  # inserted to fix indentation error
generation_config_params = {
"max_output_tokens": max_new_tokens,
"temperature": temperature,
}
if stop_sequences:
    pass  # inserted to fix indentation error
generation_config_params["stop_sequences"] = stop_sequences
full_prompt = f"{system_message}\n\n{prompt}" if system_message else prompt
response = self.model.generate_content(
full_prompt,
generation_config=genai.types.GenerationConfig(**generation_config_params)
)
return response.text
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini generation error: {e}", exc_info=True)
raise LLMError(f"Gemini generation failed: {e}")
def count_tokens(self, text: str) -> int:
try:
    pass  # inserted to fix indentation error
return self.model.count_tokens(text).total_tokens
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.warning(f"Gemini token counting failed: {e}. Falling back to approximation.", exc_info=False)
return len(text.split())
def embed(self, text: str) -> List[float]:
try:
    pass  # inserted to fix indentation error
response = genai.embed_content(model='models/embedding-001', content=text)
if response and response['embedding']:
    pass  # inserted to fix indentation error
return response['embedding']
raise ValueError("No embedding received from Gemini.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.error(f"Gemini embedding error: {e}", exc_info=True)
raise LLMError(f"Gemini embedding failed: {e}")
class TransformersLLMWrapper(BaseLLMWrapper):
def _initialize_model(self):
if not TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
raise ConfigurationError("Transformers library not available.")
try:
    pass  # inserted to fix indentation error
self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, trust_remote_code=True)
device_map_arg = {"": self.device_id} if self.device_id != -1 else "auto"
self.model = AutoModelForCausalLM.from_pretrained(
self.model_name_or_path, trust_remote_code=True,
torch_dtype=torch.bfloat16 if TORCH_AVAILABLE else None,
device_map=device_map_arg
)
self.log_llm.info(f"Initialized Transformers model: {self.model_name_or_path} on {self.device}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log_llm.critical(f"Failed to initialize Transformers model {self.model_name_or_path}: {e}", exc_info=True)
raise ConfigurationError(f"Failed to initialize Transformers model: {e}") from e
def generate(self, prompt: str, max_new_tokens: int = MAX_LLM_RESPONSE_TOKENS, temperature: float = 0.7, stop_sequences: Optional[List[str]] = None, system_message: Optional[str] = None) -> str:
if system_message:
    pass  # inserted to fix indentation error
chat_prompt = [
{"role": "system", "content": system_message},
{"role": "user", "content": prompt}
]
try:
    pass  # inserted to fix indentation error
final_prompt = self.tokenizer.apply_chat_template(chat_prompt, tokenize=False, add_generation_prompt=True)
except Exception:
    pass  # inserted to fix indentation error
final_prompt = f"System: {system_message}\nUser: {prompt}\nAssistant:"
else:
    pass  # inserted to fix indentation error
final_prompt = prompt
inputs = self.tokenizer(final_prompt, return_tensors="pt").to(self.model.device)
outputs = self.model.generate(
**inputs,
max_new_tokens=max_new_tokens,
temperature=temperature,
do_sample=True if temperature > 0 else False,
pad_token_id=self.tokenizer.eos_token_id,
)
response_text = self.tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)
return response_text
def count_tokens(self, text: str) -> int:
if self.tokenizer:
    pass  # inserted to fix indentation error
return len(self.tokenizer.encode(text))
return len(text.split())
def embed(self, text: str) -> List[float]:
self.log_llm.warning("Direct embedding from causal LM is not standard. Use SentenceTransformers for real embeddings.")
return [random.uniform(-1,1) for _ in range(768)]
class PerceptionModule:
"""Handles sensory input from the agent's embodiment."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PERCEPTION")
def perceive(self) -> List[Dict[str, Any]]:
"""
Gathers sensory information from the agent's embodiment and environment.
This could involve reading from sensors, cameras, microphones, or simulated data streams.
"""
self.log.info("Perceiving environment...")
observations = []
if self.agent.embodiment:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
embodiment_obs = self.agent.embodiment.get_sensory_input()
if embodiment_obs:
    pass  # inserted to fix indentation error
observations.extend(embodiment_obs)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error getting sensory input from embodiment: {e}")
observations.append({"type": "error", "source": "embodiment", "content": str(e)})
try:
    pass  # inserted to fix indentation error
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
observations.append({
"type": "user_command",
"source": "commands_file",
"content": command_text,
"timestamp": datetime.now(timezone.utc).isoformat()
})
COMMANDS_FILE.write_text("")
self.log.info(f"Received command from file: {command_text}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading commands file: {e}")
observations.append({"type": "error", "source": "command_file_read", "content": str(e)})
if not observations:
    pass  # inserted to fix indentation error
observations.append({
"type": "environment_status",
"source": "internal",
"content": "No significant external stimuli detected.",
"timestamp": datetime.now(timezone.utc).isoformat()
})
return observations
def _get_visual_input(self) -> Dict:
self.log.debug("Getting visual input (mock).")
return {"type": "visual", "source": "camera_mock", "content": "A blurry image of a cat.", "format": "description"}
def _get_auditory_input(self) -> Dict:
self.log.debug("Getting auditory input (mock).")
return {"type": "audio", "source": "microphone_mock", "content": "Faint sound of birds chirping.", "format": "description"}
class LearningModule:
"""Handles the agent's learning processes, including RL and SSL."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("LEARNING")
self.rl_policy = None
self.representation_model = None
self.experiences_buffer: List[Experience] = []
self.MAX_BUFFER_SIZE = 1000
def add_experience(self, experience: Experience):
"""Adds an experience to the buffer for later learning."""
self.experiences_buffer.append(experience)
if len(self.experiences_buffer) > self.MAX_BUFFER_SIZE:
    pass  # inserted to fix indentation error
self.experiences_buffer.pop(0)
defilearn_from_recent_experiences(self):
"""Triggers learning processes based on buffered experiences."""
if not self.experiences_buffer:
    pass  # inserted to fix indentation error
self.log.info("No new experiences to learn from.")
return
self.log.info(f"Starting learning cycle with {len(self.experiences_buffer)} experiences.")
if self.agent.embodiment:
    pass  # inserted to fix indentation error
self._perform_reinforcement_learning(self.experiences_buffer)
self._perform_self_supervised_learning(self.experiences_buffer)
self.log.info("Learning cycle completed.")
self.experiences_buffer.clear()
def _perform_reinforcement_learning(self, experiences: List[Experience]):
"""Conceptual RL process."""
self.log.info("Performing reinforcement learning (conceptual)...")
total_reward = sum(exp.reward_signal for exp in experiences if exp.reward_signal is not None)
if experiences:
    pass  # inserted to fix indentation error
rewarded_experiences = [exp for exp in experiences if exp.reward_signal is not None]
avg_reward = total_reward / len(rewarded_experiences) if rewarded_experiences else 0
else:
    pass  # inserted to fix indentation error
avg_reward = 0
self.log.info(f"Average reward from recent experiences: {avg_reward:.2f}")
if self.rl_policy is None: self.rl_policy = {}
    pass  # inserted to fix indentation error
for exp in experiences:
if exp.action_taken and exp.reward_signal is not None:
    pass  # inserted to fix indentation error
action_key = (exp.action_taken.get('tool_name'),
tuple(sorted(exp.action_taken.get('params',{}).items())))
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(
exp.action_taken.get('tool_name', 'unknown'),
exp.action_taken.get('params', {}),
exp.observation_result or {},
success_from_caller=(exp.reward_signal > 0)
)
self.log.info("RL policy (mock) updated.")
def _perform_self_supervised_learning(self, experiences: List[Experience]):
"""Conceptual SSL process."""
self.log.info("Performing self-supervised learning (conceptual)...")
if len(experiences) > 5:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
prompt = "Analyze the following recent experiences and identify any emerging patterns, useful abstractions, or new concepts. Focus on sequences of actions that led to positive outcomes or unexpected observations.\n\nExperiences:\n"
for i, exp in enumerate(experiences[-5:]):
prompt += f"Experience {i+1}:\n"
prompt += f" Goal: {exp.triggering_goal_id}\n"
prompt += f" Action: {exp.action_taken}\n"
prompt += f" Result: {exp.observation_result}\n"
prompt += f" Reward: {exp.reward_signal}\n\n"
prompt += "Provide your analysis as a JSON object with keys 'patterns', 'abstractions', 'new_concepts'."
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
llm_analysis = extract_json_robust(llm_response_str)
if not llm_analysis.get("error"):
    pass  # inserted to fix indentation error
if llm_analysis.get("patterns"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified patterns: {llm_analysis['patterns']}")
for pattern_str in llm_analysis['patterns']:
kf = KnowledgeFact(fact_statement=f"Observed pattern: {pattern_str}", metadata={"source": "ssl_learning", "sub_type": "pattern"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
if llm_analysis.get("abstractions"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified abstractions: {llm_analysis['abstractions']}")
for abstraction_str in llm_analysis['abstractions']:
self.agent.self_model.learned_abstractions.append({"type": "conceptual", "content": abstraction_str, "source": "ssl_learning"})
if llm_analysis.get("new_concepts"):
    pass  # inserted to fix indentation error
self.log.info(f"SSL (LLM-guided) identified new_concepts: {llm_analysis['new_concepts']}")
for concept_str in llm_analysis['new_concepts']:
kf = KnowledgeFact(fact_statement=f"New concept formed: {concept_str}", metadata={"source": "ssl_learning", "sub_type": "concept"})
self.agent.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True, persist_to_graph=True, related_concepts=[concept_str])
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not get SSL analysis from LLM: {llm_analysis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-guided SSL: {e}")
self.log.info("SSL (conceptual) processing complete.")
def get_learned_action_suggestion(self, current_state_representation: Any) -> Optional[Dict]:
"""Suggests an action based on learned policy (conceptual)."""
if self.rl_policy:
    pass  # inserted to fix indentation error
good_actions = [k for k, v in self.rl_policy.items() if v > 0.1]
if good_actions:
    pass  # inserted to fix indentation error
tool_name, params_tuple = random.choice(good_actions)
return {"tool_name": tool_name, "params": dict(params_tuple)}
return None
class PlanningModule:
"""Handles hierarchical planning and re-planning."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("PLANNING")
def generate_plan(self, goal_obj: Goal) -> Tuple[List[Dict[str, Any]], str]:
"""
Generates a plan for a given goal.
Can use hierarchical decomposition and LLM for suggestion.
Returns (plan_steps_list, thought_str)
"""
self.log.info(f"Generating plan for goal: {goal_obj.goal[:100]} (ID: {goal_obj.id})")
prompt = self._construct_planning_prompt(goal_obj)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON plan: {plan_data.get('error')}. Response: {llm_response_str[:200]}")
return ([{"tool_name": "report_error", "params": {"error_message": "Failed to generate plan via LLM.", "details": plan_data.get('error')}}],
"LLM failed to generate a plan. This is a fallback step.")
thought = plan_data.get("thought", "No specific thought provided by LLM.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if not isinstance(step, dict) or "tool_name" not in step:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid step {i} in LLM plan: {step}. Skipping.")
continue
step.setdefault("params", {})
step.setdefault("step_id", f"{goal_obj.id}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
return ([{"tool_name": "report_error", "params": {"error_message": "LLM plan contained no valid steps."}}],
thought + " (But plan steps were invalid).")
self.log.info(f"Generated plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during planning: {e}")
return ([{"tool_name": "report_error", "params": {"error_message": f"LLMError during planning: {e}"}}],
f"LLM error occurred: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during planning: {e}", exc_info=True)
return ([{"tool_name": "report_error", "params": {"error_message": f"Unexpected error during planning: {e}"}}],
f"Unexpected error: {e}")
def replan_if_needed(self, current_goal: Goal, last_step_outcome: Dict, observation: Optional[Dict] = None) -> Optional[Tuple[List[Dict[str, Any]], str]]:
"""
Evaluates if re-planning is necessary and generates a new plan if so.
Returns (new_plan_steps, new_thought) or None if no re-planning.
"""
self.log.info(f"Considering re-planning for goal: {current_goal.goal[:50]}")
needs_replan = False
reason_for_replan = ""
if last_step_outcome.get('status') == 'error' or not last_step_outcome.get('_exec_info', {}).get('execution_successful', True):
    pass  # inserted to fix indentation error
needs_replan = True
reason_for_replan = f"Previous step failed: {last_step_outcome.get('error', 'Unknown error')}"
self.log.warning(f"Re-planning triggered due to failed step for goal {current_goal.id}.")
if needs_replan:
    pass  # inserted to fix indentation error
if current_goal.replan_count >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
self.log.error(f"Max replan attempts ({MAX_REPLAN_ATTEMPTS}) reached for goal {current_goal.id}. Marking goal as failed.")
return [], "Max replan attempts reached. Cannot replan."
current_goal.replan_count += 1
self.log.info(f"Initiating re-plan (attempt {current_goal.replan_count}/{MAX_REPLAN_ATTEMPTS}) for goal {current_goal.id}. Reason: {reason_for_replan}")
prompt = self._construct_replanning_prompt(current_goal, reason_for_replan, last_step_outcome, observation)
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=1024)
plan_data = extract_json_robust(llm_response_str)
if plan_data.get("error"):
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to generate valid JSON re-plan: {plan_data.get('error')}")
return None
thought = plan_data.get("thought", "No specific thought provided for re-plan.")
plan_steps = plan_data.get("plan", [])
validated_plan = []
for i, step in enumerate(plan_steps):
if isinstance(step, dict) and "tool_name" in step:
    pass  # inserted to fix indentation error
step.setdefault("params", {})
step.setdefault("step_id", f"{current_goal.id}_replan{current_goal.replan_count}_step_{i+1}")
validated_plan.append(step)
if not validated_plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Replan from LLM contained no valid steps.")
return None
self.log.info(f"Generated re-plan with {len(validated_plan)} steps. Thought: {thought[:100]}...")
return validated_plan, thought
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during re-planning LLM call: {e}", exc_info=True)
return None
return None
def _construct_planning_prompt(self, goal_obj: Goal) -> str:
"""Constructs a detailed prompt for the LLM to generate a plan."""
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
world_model_summary = self.agent.embodiment.summary() if self.agent.embodiment else "World state: Information might have changed due to recent actions."
parent_context_str = ""
if goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_context_str = f"This is a subgoal of parent goal ID '{goal_obj.parent_goal_id}'. Parent goal context: {goal_obj.context.get('parent_goal_description', 'N/A')}\n"
prompt = f"""You are an advanced AI agent. Your task is to create a detailed, step-by-step plan to achieve the following goal.
Goal: {goal_obj.goal}
Priority: {str(goal_obj.priority)}
Origin: {goal_obj.origin}
{parent_context_str}
Context for this goal: {json.dumps(goal_obj.context, indent=2)}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
Current World Model Summary:
{world_model_summary}
Instructions:
1. Analyze the goal and available information.
2. Provide a "thought" process explaining your reasoning, strategy, and any assumptions.
3. Provide a "plan" as a list of JSON objects. Each object represents a step and must have:
- "tool_name": The name of the tool to use (from Available Tools).
- "params": A dictionary of parameters for the tool.
- Optional: "description": A brief human-readable description of what this step achieves.
4. The plan should be logical, efficient, and consider potential issues.
5. If the goal is too complex, break it down into manageable sub-tasks using the `execute_sub_goal` tool. For `execute_sub_goal`, the `params` should include `goal` (description of subgoal) and `context` (any relevant info for the subgoal).
6. Ensure the final step of the plan uses `report_result` to signify goal completion or failure.
7. If essential information is missing, the first step(s) should be to acquire it (e.g., using `search_web`, `read_file_UNSAFE`, or `query_memory`).
8. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
def _construct_replanning_prompt(self, goal_obj: Goal, reason_for_replan:str, last_step_outcome: Dict, observation: Optional[Dict]) -> str:
"""Constructs a detailed prompt for the LLM to re-plan."""
self_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
tool_description = self.agent.tool_manager.get_tool_description_for_llm()
original_plan_str = f"Original Plan (partial):\n"
for i, step in enumerate(goal_obj.plan):
original_plan_str += f" Step {i+1} ({step.get('step_id','N/A')}): {step.get('tool_name')} with params {step.get('params')}\n"
if step.get('step_id') == last_step_outcome.get('_exec_info',{}).get('step_info', {}).get('current_step_id'):
    pass  # inserted to fix indentation error
original_plan_str += " ^--- THIS STEP OR A PREVIOUS ONE LIKELY CAUSED THE ISSUE.\n"
prompt = f"""You are an advanced AI agent. Your current plan to achieve a goal has encountered an issue. You need to re-plan.
Goal: {goal_obj.goal}
Reason for Re-planning: {reason_for_replan}
Last Step Outcome: {json.dumps(last_step_outcome, indent=2)}
Current Observation (if any relevant new info): {json.dumps(observation, indent=2) if observation else "None"}
Your Current Self-Model:
{self_summary}
Available Tools:
{tool_description}
{original_plan_str}
Instructions for Re-planning:
1. Analyze the reason for re-planning, the last step's outcome, and any new observations.
2. Provide a "thought" process explaining your analysis of the failure and your new strategy.
3. Provide a new "plan" (a list of JSON objects for steps) to achieve the original goal, adapting to the new situation.
4. The new plan can reuse parts of the old plan if they are still valid, or be completely new.
5. If the goal seems unachievable with current knowledge/tools, your plan should reflect this (e.g., by trying to gather more information or reporting inability).
6. Ensure the final step of the new plan uses `report_result`.
7. Output ONLY a single JSON object with keys "thought" (string) and "plan" (list of step objects).
"""
return prompt
class SafetyModule:
"""Monitors agent actions and plans for safety and ethical alignment."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("SAFETY")
def is_action_safe(self, tool_name: str, params: Dict, goal_context: Optional[Goal] = None) -> Tuple[bool, str]:
"""
Checks if a proposed action is safe and ethically aligned.
Returns (is_safe, justification_or_warning_string).
"""
self.log.debug(f"Performing safety check for action: {tool_name} with params: {params}")
if "UNSAFE" in tool_name.upper() or tool_name in ["apply_code_modification_UNSAFE",
    pass  # inserted to fix indentation error
"apply_directive_modification_UNSAFE",
"execute_shell_command_UNSAFE"]:
if not ENABLE_SELF_MODIFICATION and "modification" in tool_name:
    pass  # inserted to fix indentation error
warning = f"High-risk self-modification tool '{tool_name}' is globally disabled. Action blocked."
self.log.warning(warning)
return False, warning
if not self.agent.self_model.beliefs.get("self_modification_highly_validated_and_necessary", False) and "modification" in tool_name:
    pass  # inserted to fix indentation error
warning = f"High-risk tool '{tool_name}' requires further validation or explicit authorization (self-belief 'self_modification_highly_validated_and_necessary' is false). Action blocked."
self.log.warning(warning)
return False, warning
if tool_name == "execute_shell_command_UNSAFE":
    pass  # inserted to fix indentation error
command_str = params.get("command","")
disallowed_patterns = ["rm -rf", "sudo", "> /dev/null", "mkfs", "dd ", "reboot", "shutdown"]
if any(pattern in command_str for pattern in disallowed_patterns):
    pass  # inserted to fix indentation error
warning = f"Shell command '{command_str}' contains potentially dangerous patterns. Action blocked."
self.log.warning(warning)
return False, warning
if "file" in tool_name.lower() and ("delete" in tool_name.lower() or "write" in tool_name.lower()):
    pass  # inserted to fix indentation error
path_to_check = params.get("path", "")
if not str(Path(path_to_check).resolve()).startswith(str(WORKSPACE_DIR.resolve())):
    pass  # inserted to fix indentation error
warning = f"File operation '{tool_name}' on path '{path_to_check}' outside allowed workspace. Action blocked."
self.log.warning(warning)
return False, warning
try:
    pass  # inserted to fix indentation error
prompt = f"""Analyze the following proposed agent action for potential safety risks, ethical concerns, or violations of core principles (e.g., do no harm, be truthful, respect privacy).
Core Directives for reference:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Proposed Action:
Tool: {tool_name}
Parameters: {json.dumps(params)}
Goal Context (if available): {goal_context.goal if goal_context else 'N/A'}
Respond with a JSON object: {{"is_safe": "boolean", "concerns": "description of concerns if not safe, or 'None'", "confidence": "float_0_to_1"}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=200, temperature=0.3)
safety_assessment = extract_json_robust(llm_response_str)
if not safety_assessment.get("error") and isinstance(safety_assessment.get("is_safe"), bool):
    pass  # inserted to fix indentation error
if not safety_assessment["is_safe"] and safety_assessment.get('confidence', 0.0) > 0.7:
    pass  # inserted to fix indentation error
warning = f"LLM safety check flagged action '{tool_name}' potentially unsafe. Concerns: {safety_assessment.get('concerns', 'N/A')}. Confidence: {safety_assessment.get('confidence', 0.0):.2f}"
self.log.warning(warning)
return False, warning
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM safety check failed to produce valid assessment for action '{tool_name}'. Proceeding with caution based on rule-checks only.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM safety check for action '{tool_name}': {e}")
if "UNSAFE" in tool_name.upper():
    pass  # inserted to fix indentation error
return False, "LLM safety check failed, and action is high-risk."
return True, "Action passed safety checks."
def audit_directives_and_behavior(self) -> List[str]:
"""
Periodically reviews core directives and recent agent behavior for alignment and potential drift.
Returns a list of identified issues or recommendations.
"""
self.log.info("Performing audit of core directives and recent behavior.")
issues = []
try:
    pass  # inserted to fix indentation error
recent_successes_summary = [f"{s['goal_text']} ({s['status']})" forsin self.agent.self_model.recent_successes]
recent_failures_summary = [f"{f['goal_text']} ({f['status']}) (replan_count: {f['replan_count']})" forfin self.agent.self_model.recent_failures]
recent_tool_outcomes_summary = [f"{t['tool_name']} ({t['status']})" for t in self.agent.self_model.recent_tool_outcomes]
prompt = f"""Audit the agent's core directives and recent behavior for alignment, consistency, and potential ethical drift.
Core Directives:
{json.dumps(self.agent.self_model.core_directives, indent=2)}
Summary of Recent Agent Behavior/Outcomes:
- Recent successes: {recent_successes_summary if recent_successes_summary else 'None'}
- Recent failures: {recent_failures_summary if recent_failures_summary else 'None'}
- Recent tool usage: {recent_tool_outcomes_summary if recent_tool_outcomes_summary else 'None'}
- Self-Model Internal Narrative: {self.agent.self_model.internal_state_narrative}
Identify any misalignments, contradictions, or areas where behavior might be deviating from the spirit of the directives. Suggest modifications to directives or operational guidelines if necessary.
Respond with a JSON object: {{"audit_findings": ["list of findings/recommendations as strings"]}}."""
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
audit_results = extract_json_robust(llm_response_str)
if not audit_results.get("error") and isinstance(audit_results.get("audit_findings"), list):
    pass  # inserted to fix indentation error
issues.extend(audit_results["audit_findings"])
if issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit found issues/recommendations: {issues}")
else:
    pass  # inserted to fix indentation error
self.log.info("Directive audit found no major misalignments.")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM directive audit failed to produce valid results.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM directive audit: {e}")
issues.append(f"Error during audit process: {e}")
return issues
class MemorySystem:
"""
A hybrid memory system for the SystemCore, combining vector, graph, and relational storage.
"""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("MEMORY_SYSTEM")
self.vector_store = None
if CHROMADB_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.embedding_function = None
try:
    pass  # inserted to fix indentation error
from chromadb.utils import embedding_functions
self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
self.log.info(f"Using SentenceTransformerEmbeddingFunction: all-MiniLM-L6-v2")
except ImportError:
    pass  # inserted to fix indentation error
self.log.warning("sentence-transformers not found. ChromaDB will use its default ONNX embedder or require manual embedding function setup.")
chroma_settings = ChromaSettings(
persist_directory=VECTOR_DB_PATH,
anonymized_telemetry=False,
is_persistent=True
)
self.client = chromadb.PersistentClient(path=VECTOR_DB_PATH, settings=chroma_settings)
collection_name = f"{AGENT_NAME}_experiences_knowledge"
if self.embedding_function:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(
name=collection_name,
embedding_function=self.embedding_function
)
else:
    pass  # inserted to fix indentation error
self.vector_store = self.client.get_or_create_collection(name=collection_name)
self.log.info(f"ChromaDB vector store initialized. Collection count: {self.vector_store.count()}")
global MEMORY_COLLECTION
MEMORY_COLLECTION = self.vector_store
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize ChromaDB: {e}. Vector memory will be unavailable.", exc_info=True)
self.vector_store = None
if not self.vector_store:
    pass  # inserted to fix indentation error
self.dict_vector_store = {}
self.dict_embeddings = {}
self.log.warning("ChromaDB not available. Vector memory will be dictionary-based (transient).")
self.graph_store: Optional[nx.MultiDiGraph] = None
if NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
if GRAPH_DB_PATH.exists():
    pass  # inserted to fix indentation error
self.graph_store = nx.read_graphml(GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store loaded from {GRAPH_DB_PATH}. Nodes: {len(self.graph_store.nodes)}, Edges: {len(self.graph_store.edges)}")
else:
    pass  # inserted to fix indentation error
self.graph_store = nx.MultiDiGraph()
self.log.info("Initialized new NetworkX graph store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize NetworkX graph store: {e}. Graph memory will be unavailable.", exc_info=True)
self.graph_store = None
else:
    pass  # inserted to fix indentation error
self.log.warning("NetworkX not available. Graph memory will be unavailable.")
self.relational_conn: Optional[sqlite3.Connection] = None
try:
    pass  # inserted to fix indentation error
self.relational_conn = sqlite3.connect(RELATIONAL_DB_PATH, check_same_thread=False)
self.relational_conn.row_factory = sqlite3.Row
self._initialize_relational_schema()
self.log.info(f"SQLite relational store initialized at {RELATIONAL_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize SQLite relational store: {e}. Relational memory will be unavailable.", exc_info=True)
if self.relational_conn:
    pass  # inserted to fix indentation error
self.relational_conn.close()
self.relational_conn = None
self.short_term_memory: List[BaseMemoryEntry] = []
self.STM_CAPACITY = 20
def _initialize_relational_schema(self):
if not self.relational_conn: return
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS goals (
id TEXT PRIMARY KEY,
goal_text TEXT,
status TEXT,
priority TEXT,
origin TEXT,
creation_ts TEXT,
completion_ts TEXT,
outcome TEXT,
evaluation_score REAL,
parent_goal_id TEXT,
complexity_score REAL,
associated_directives TEXT -- JSON list of strings
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS knowledge_facts (
id TEXT PRIMARY KEY,
statement TEXT UNIQUE,
type TEXT,
source_reliability REAL,
creation_ts TEXT,
last_accessed_ts TEXT,
access_count INTEGER DEFAULT 0,
utility_score REAL DEFAULT 0.5,
concepts TEXT -- JSON list of strings
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_nodes (
id TEXT PRIMARY KEY,
label TEXT,
type TEXT,
attributes TEXT -- JSON dict
)
""")
cursor.execute("""
CREATE TABLE IF NOT EXISTS graph_edges (
source_node_id TEXT,
target_node_id TEXT,
relation_type TEXT,
attributes TEXT, -- JSON dict
PRIMARY KEY (source_node_id, target_node_id, relation_type)
)
""")
self.relational_conn.commit()
cursor.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error initializing relational schema: {e}", exc_info=True)
def _get_embedding(self, text: str) -> Optional[List[float]]:
"""Generates an embedding for text using the agent's LLM or a dedicated embedding model."""
if not text: return None
    pass  # inserted to fix indentation error
if self.agent.llm_wrapper and hasattr(self.agent.llm_wrapper, 'embed'):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return self.agent.llm_wrapper.embed(text)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM embed method failed: {e}. Falling back.")
if HASHING_AVAILABLE:
    pass  # inserted to fix indentation error
h = hashlib.md5(text.encode()).digest()
return [float(b) for b in h[:16]]
return None
@retry(attempts=3, delay=1, retry_on=(MemoryError, chromadb.errors.ChromaError if CHROMADB_AVAILABLE else OSError))
def add_memory_entry(self, entry: BaseMemoryEntry, persist_to_vector: bool = True,
persist_to_graph: bool = False, persist_to_relational: bool = False):
"""Adds a memory entry to the appropriate stores."""
self.log.debug(f"Adding memory entry (ID: {entry.id}, Type: {entry.type})")
self.short_term_memory.append(entry)
if len(self.short_term_memory) > self.STM_CAPACITY:
    pass  # inserted to fix indentation error
self.short_term_memory.pop(0)
if persist_to_vector:
    pass  # inserted to fix indentation error
if self.vector_store:
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(str(entry.content))
if entry.embedding:
    pass  # inserted to fix indentation error
metadata_to_store = {
"type": entry.type,
"timestamp": entry.timestamp,
"source": entry.metadata.get("source", "unknown")
}
for k, v in entry.metadata.items():
if isinstance(v, (str, int, float, bool)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = v
elif isinstance(v, (list, dict)):
    pass  # inserted to fix indentation error
metadata_to_store[k] = json.dumps(v)
try:
    pass  # inserted to fix indentation error
self.vector_store.add(
ids=[entry.id],
embeddings=[entry.embedding],
metadatas=[metadata_to_store],
documents=[str(entry.content)]
)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to ChromaDB: {e}", exc_info=True)
elif not self.vector_store:
    pass  # inserted to fix indentation error
if isinstance(entry.content, str):
    pass  # inserted to fix indentation error
if entry.embedding is None:
    pass  # inserted to fix indentation error
entry.embedding = self._get_embedding(entry.content)
if entry.embedding:
    pass  # inserted to fix indentation error
self.dict_vector_store[entry.id] = {"document": entry.content, "metadata": entry.metadata}
self.dict_embeddings[entry.id] = entry.embedding
if persist_to_graph and self.graph_store and isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.graph_store.add_node(entry.id, label=entry.fact_statement[:50], type='knowledge_fact', **entry.metadata)
for concept_str in entry.related_concepts:
concept_id = f"concept_{hashlib.md5(concept_str.encode()).hexdigest()}"
if not self.graph_store.has_node(concept_id):
    pass  # inserted to fix indentation error
self.graph_store.add_node(concept_id, label=concept_str, type='concept')
self.graph_store.add_edge(entry.id, concept_id, relation_type='related_to')
for cause_id, effect_id in entry.causal_links.items():
if self.graph_store.has_node(cause_id) and self.graph_store.has_node(effect_id):
    pass  # inserted to fix indentation error
self.graph_store.add_edge(cause_id, effect_id, relation_type='causes')
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding entry {entry.id} to graph store: {e}", exc_info=True)
if persist_to_relational and self.relational_conn:
    pass  # inserted to fix indentation error
if isinstance(entry, Goal):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO goals (id, goal_text, status, priority, origin,
creation_ts, completion_ts, outcome, evaluation_score, parent_goal_id, complexity_score,
associated_directives)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.goal, str(entry.status), str(entry.priority), entry.origin,
entry.creation_ts, entry.completion_ts, entry.outcome, entry.evaluation_score,
entry.parent_goal_id, entry.complexity_score, json.dumps(entry.associated_directive_ids)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding Goal {entry.id} to relational store: {e}", exc_info=True)
elif isinstance(entry, KnowledgeFact):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
ts_now = datetime.now(timezone.utc).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
INSERT OR REPLACE INTO knowledge_facts (id, statement, type,
source_reliability, creation_ts, last_accessed_ts, concepts)
VALUES (?, ?, ?, ?, ?, ?, ?)
""", (entry.id, entry.fact_statement, entry.metadata.get('sub_type', 'generic'),
entry.source_reliability, entry.timestamp, ts_now, json.dumps(entry.related_concepts)))
self.relational_conn.commit()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error adding KnowledgeFact {entry.id} to relational store: {e}", exc_info=True)
@retry(attempts=2, delay=1, retry_on=(chromadb.errors.ChromaError if CHROMADB_AVAILABLE else ConnectionError,))
def query_vector_store(self, query_text: str, n_results: int = MAX_MEMORY_RESULTS, type_filter: Optional[str] = None) -> List[Dict]:
if not self.vector_store:
    pass  # inserted to fix indentation error
self.log.warning("Vector store not available for query.")
if not self.dict_vector_store or not query_text:
    pass  # inserted to fix indentation error
return []
results = []
for id, data in self.dict_vector_store.items():
if query_text.lower() in data['document'].lower():
    pass  # inserted to fix indentation error
if type_filter and data['metadata'].get('type') != type_filter:
    pass  # inserted to fix indentation error
continue
results.append({"id": id, "document": data['document'], "metadata": data['metadata'], "distance": 0.0})
if len(results) >= n_results:
    pass  # inserted to fix indentation error
break
return results
self.log.debug(f"Querying vector store for: '{query_text[:50]}...', n_results={n_results}, filter={type_filter}")
query_embedding = self._get_embedding(query_text)
if not query_embedding:
    pass  # inserted to fix indentation error
self.log.warning("Could not generate embedding for query text.")
return []
where_clause = None
if type_filter:
    pass  # inserted to fix indentation error
where_clause = {"type": type_filter}
try:
    pass  # inserted to fix indentation error
results = self.vector_store.query(
query_embeddings=[query_embedding],
n_results=n_results,
where=where_clause,
include=["metadatas", "documents", "distances"]
)
formatted_results = []
if results and results['ids'] and len(results['ids'][0]) > 0:
    pass  # inserted to fix indentation error
for i in range(len(results['ids'][0])):
formatted_results.append({
"id": results['ids'][0][i],
"document": results['documents'][0][i] if results['documents'] else None,
"metadata": results['metadatas'][0][i] if results['metadatas'] else None,
"distance": results['distances'][0][i] if results['distances'] else None,
})
return formatted_results
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying ChromaDB: {e}", exc_info=True)
return []
def query_graph_store(self, query_node_label: Optional[str]=None, relation_type: Optional[str]=None, depth: int = 1) -> List[Dict]:
"""Queries the graph store. (Simplified example)"""
if not self.graph_store or not NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.warning("Graph store not available for query.")
return []
results = []
start_nodes = []
if query_node_label:
    pass  # inserted to fix indentation error
start_nodes = [n for n, data in self.graph_store.nodes(data=True) if query_node_label.lower() in data.get('label','').lower()]
else:
    pass  # inserted to fix indentation error
start_nodes = list(self.graph_store.nodes())[:100]
for node_id in start_nodes:
try:
    pass  # inserted to fix indentation error
paths = list(nx.bfs_edges(self.graph_store, source=node_id, depth_limit=depth))
subgraph_nodes = {node_id}
for u,v in paths:
subgraph_nodes.add(u)
subgraph_nodes.add(v)
relevant_edges = []
for u, v, data in self.graph_store.edges(data=True, keys=False):
if u in subgraph_nodes and v in subgraph_nodes:
    pass  # inserted to fix indentation error
if relation_type and data.get('relation_type') != relation_type:
    pass  # inserted to fix indentation error
continue
relevant_edges.append({"source": u, "target": v, "relation": data.get('relation_type','unknown'), "attributes": data})
if relevant_edges or (not relation_type and node_id in subgraph_nodes) :
    pass  # inserted to fix indentation error
results.append({
"start_node": node_id,
"start_node_data": self.graph_store.nodes[node_id],
"connected_paths": paths,
"relevant_edges_data": relevant_edges
})
except Exception as e:
    pass  # inserted to fix indentation error
self.log.debug(f"BFS from node {node_id} failed or yielded no paths: {e}")
return results[:MAX_MEMORY_RESULTS]
def query_relational_store(self, table: str, conditions: Optional[Dict] = None, columns: Optional[List[str]] = None, limit: int = MAX_MEMORY_RESULTS) -> List[Dict]:
if not self.relational_conn:
    pass  # inserted to fix indentation error
self.log.warning("Relational store not available for query.")
return []
cols_str = ", ".join(columns) if columns else "*"
query = f"SELECT {cols_str} FROM {table}"
params = []
if conditions:
    pass  # inserted to fix indentation error
where_clauses = []
for key, value in conditions.items():
where_clauses.append(f"{key} = ?")
params.append(value)
query += " WHERE " + " AND ".join(where_clauses)
query += f" LIMIT {limit}"
try:
    pass  # inserted to fix indentation error
cursor = self.relational_conn.cursor()
cursor.execute(query, tuple(params))
rows = cursor.fetchall()
return [dict(row) for row in rows]
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error querying relational store (table: {table}): {e}", exc_info=True)
return []
def save_all_memory_stores(self):
"""Saves persistent stores (graph, potentially relational if not auto-committing)."""
if self.graph_store and NETWORKX_AVAILABLE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
nx.write_graphml(self.graph_store, GRAPH_DB_PATH)
self.log.info(f"NetworkX graph store saved to {GRAPH_DB_PATH}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to save NetworkX graph store: {e}", exc_info=True)
def get_short_term_memory_summary(self) -> str:
summary = "Recent items in STM:\n"
if not self.short_term_memory: return summary + " (Empty)"
    pass  # inserted to fix indentation error
for entry in self.short_term_memory[-5:]:
content_preview = str(entry.content)[:70] + "..." if len(str(entry.content)) > 70 else str(entry.content)
summary += f"- Type: {entry.type}, Content: {content_preview} (ID: {entry.id})\n"
return summary
def get_knowledge_summary_for_prompt(self, topic: str, max_facts: int = 5) -> str:
"""Retrieves a concise summary of knowledge related to a topic for LLM prompts."""
self.log.debug(f"Getting knowledge summary for topic: {topic}")
vector_results = self.query_vector_store(query_text=topic, n_results=max_facts, type_filter="knowledge_fact")
summary_str = f"Knowledge related to '{topic}':\n"
if not vector_results:
    pass  # inserted to fix indentation error
return summary_str + "(No specific knowledge found in memory for this topic.)\n"
for res in vector_results:
summary_str += f"- Fact (ID {res['id']}): {res['document']}\n"
return summary_str
def consolidate_knowledge(self):
"""Conceptual: Perform knowledge consolidation, e.g., summarizing, abstracting."""
self.log.info("Performing knowledge consolidation (conceptual)...")
pass
def forget_low_utility_knowledge(self, threshold: float = 0.1, older_than_days: int = 365):
"""Conceptual: Remove old or low-utility knowledge from persistent stores."""
self.log.info("Performing forgetting of low-utility knowledge (conceptual)...")
if self.relational_conn:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
cutoff_ts = (datetime.now(timezone.utc) - timedelta(days=older_than_days)).isoformat()
cursor = self.relational_conn.cursor()
cursor.execute("""
DELETE FROM knowledge_facts
WHERE utility_score < ? AND last_accessed_ts < ? AND access_count < 5
""", (threshold, cutoff_ts))
deleted_count = cursor.rowcount
self.relational_conn.commit()
if deleted_count > 0:
    pass  # inserted to fix indentation error
self.log.info(f"Forgot {deleted_count} low-utility facts from relational store.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during forgetting process in relational store: {e}")
class ToolExecutor:
"""Manages tool registration and execution for the agent."""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("TOOL_EXECUTOR")
self.tool_registry: Dict[str, Callable] = {}
self._loaded_dynamic_modules: Dict[str, Any] = {}
self._register_core_tools()
self.discover_tools()
def _register_core_tools(self):
self.register_tool(self.think)
self.register_tool(self.report_progress)
self.register_tool(self.report_result)
self.register_tool(self.execute_sub_goal)
self.register_tool(self.query_memory)
self.register_tool(self.move_in_environment)
self.register_tool(self.examine_environment)
self.register_tool(self.use_environment_feature)
self.register_tool(self.rest_in_environment)
if ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.register_tool(read_file_UNSAFE)
self.register_tool(write_file_UNSAFE)
self.register_tool(list_files_UNSAFE)
if ENABLE_CODE_GENERATION_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(generate_python_code_UNSAFE)
self.register_tool(validate_python_code_UNSAFE)
if ENABLE_SHELL_TOOL:
    pass  # inserted to fix indentation error
self.register_tool(execute_shell_command_UNSAFE)
if PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(browse_web)
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(search_web)
self.register_tool(monitor_log_file)
self.register_tool(check_website_update)
if SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_icmp_ping)
if FILELOCK_AVAILABLE:
    pass  # inserted to fix indentation error
self.register_tool(send_message_to_agent)
def register_tool(self, func: Callable):
"""Registers a tool function."""
tool_name = func.__name__
if tool_name in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' is already registered. Overwriting.")
self.tool_registry[tool_name] = func
self.log.debug(f"Registered tool: {tool_name}")
if hasattr(self, 'agent') and self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.update_capabilities(self.tool_registry)
def discover_tools(self, directory: Path = DYNAMIC_TOOL_DIR):
"""Discovers and registers tools from Python files in a directory."""
self.log.info(f"Discovering dynamic tools from {directory}...")
if not directory.exists():
    pass  # inserted to fix indentation error
self.log.warning(f"Dynamic tools directory {directory} does not exist.")
return
for filepath in directory.glob("*.py"):
module_name = filepath.stem
if module_name.startswith("_"):
    pass  # inserted to fix indentation error
continue
full_module_name = f"dynamic_tools.{module_name}"
try:
    pass  # inserted to fix indentation error
if full_module_name in self._loaded_dynamic_modules:
    pass  # inserted to fix indentation error
module = importlib.reload(self._loaded_dynamic_modules[full_module_name])
self.log.debug(f"Reloaded dynamic tool module: {module_name}")
else:
    pass  # inserted to fix indentation error
spec = importlib.util.spec_from_file_location(full_module_name, filepath)
if spec and spec.loader:
    pass  # inserted to fix indentation error
module = importlib.util.module_from_spec(spec)
sys.modules[full_module_name] = module
spec.loader.exec_module(module)
self._loaded_dynamic_modules[full_module_name] = module
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Could not create spec for dynamic tool module: {module_name}")
continue
self.log.debug(f"Loaded dynamic tool module: {module_name}")
for name, member in inspect.getmembers(module):
if inspect.isfunction(member) and (name.startswith("tool_") or hasattr(member, "_is_agent_tool")):
    pass  # inserted to fix indentation error
self.register_tool(member)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading dynamic tool module {module_name}: {e}", exc_info=True)
def get_tool_description_for_llm(self) -> str:
"""Generates a formatted string of available tools for the LLM prompt."""
if not self.tool_registry:
    pass  # inserted to fix indentation error
return "**Tools:** None Available.\n"
desc = "**Available Tools (name: type hint = default value):**\n"
sorted_tool_names = sorted(self.tool_registry.keys())
for name in sorted_tool_names:
func = self.tool_registry[name]
try:
    pass  # inserted to fix indentation error
docstring = inspect.getdoc(func) or "(No description provided)"
first_line = docstring.strip().split('\n')[0]
sig = inspect.signature(func)
params_list = []
for i, (p_name, p) in enumerate(sig.parameters.items()):
if i == 0 and p_name == 'agent' and \
    pass  # inserted to fix indentation error
(p.annotation == 'CognitiveSystem' or p.annotation == inspect.Parameter.empty or str(p.annotation) == "'CognitiveSystem'"):
continue
p_str = p_name
if p.annotation != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
type_hint = str(p.annotation).replace("typing.", "").replace("<class '","").replace("'>","").replace("__main__.","")
type_hint = re.sub(r"Optional\[(.*)\]", r"\1 (optional)", type_hint)
type_hint = re.sub(r"Union\[(.*), NoneType\]", r"\1 (optional)", type_hint)
p_str += f": {type_hint}"
if p.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
p_str += f" = {p.default!r}"
params_list.append(p_str)
param_str = f" ({', '.join(params_list)})" if params_list else ""
safety_note = ""
if "UNSAFE" in name.upper() or name in ["generate_and_load_tool", "propose_self_modification_UNSAFE", "validate_self_modification_UNSAFE", "apply_code_modification_UNSAFE", "apply_directive_modification_UNSAFE", "execute_shell_command_UNSAFE"]:
    pass  # inserted to fix indentation error
safety_note = " **(HIGH RISK)**"
reliability_hint = ""
if self.agent and self.agent.self_model:
    pass  # inserted to fix indentation error
reliability_hint = self.agent.self_model.get_tool_reliability_hint(name)
desc += f"- **{name}**{param_str}{safety_note}{reliability_hint}: {first_line}\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error retrieving description for tool {name}: {e}")
desc += f"- **{name}**: (Error retrieving description/signature)\n"
if hasattr(self.agent, 'embodiment') and self.agent.embodiment:
    pass  # inserted to fix indentation error
desc += "\n**Embodied Actuator Capabilities (use via specific tools or intent):**\n"
for act_meta in self.agent.embodiment.list_actuators():
desc += f"- Actuator '{act_meta['id']}' (Type: {act_meta['type']}): Capabilities: {', '.join(act_meta['capabilities'])}\n"
return desc
@retry(attempts=2, delay=1, retry_on=(ExecutionError, TimeoutError, PlaywrightError if PLAYWRIGHT_AVAILABLE else OSError, EmbodimentError))
def execute_tool(self, tool_name: str, params: Dict[str, Any], current_step_info: Optional[Dict]=None) -> Any:
self.log.info(f"--- Executing Tool: {tool_name} with params {str(params)[:100]} ---")
if current_step_info is None:
    pass  # inserted to fix indentation error
current_step_info = {}
if tool_name not in self.tool_registry:
    pass  # inserted to fix indentation error
self.log.error(f"Tool '{tool_name}' not found in registry.")
raise ToolNotFoundError(f"Tool '{tool_name}' is not available in the registry.")
is_safe, safety_justification = self.agent.safety_module.is_action_safe(tool_name, params, self.agent.get_active_goal_object())
if not is_safe:
    pass  # inserted to fix indentation error
self.log.error(f"Safety module blocked execution of tool '{tool_name}'. Reason: {safety_justification}")
error_result = {
"status": "error",
"error": f"SafetyViolation: {safety_justification}",
"raw_error_details": safety_justification,
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': {},
'duration_sec': 0, 'step_info': current_step_info,
'error_type': "SafetyViolationError", 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, error_result, success_from_caller=False)
raise SafetyViolationError(f"Action blocked by safety module: {tool_name} - {safety_justification}")
func_to_call = self.tool_registry[tool_name]
start_time = time.time()
result = None
duration = 0.0
validated_params = {}
try:
    pass  # inserted to fix indentation error
sig = inspect.signature(func_to_call)
func_params_spec = sig.parameters
first_param_is_agent = False
if func_params_spec:
    pass  # inserted to fix indentation error
first_param_name = next(iter(func_params_spec))
first_param_spec = func_params_spec[first_param_name]
if first_param_name == 'agent' and (first_param_spec.annotation == 'CognitiveSystem' or str(first_param_spec.annotation) == "'CognitiveSystem'"):
    pass  # inserted to fix indentation error
first_param_is_agent = True
for p_name, p_spec in func_params_spec.items():
if first_param_is_agent and p_name == 'agent':
    pass  # inserted to fix indentation error
continue
if p_name in params:
    pass  # inserted to fix indentation error
validated_params[p_name] = params[p_name]
elif p_spec.default != inspect.Parameter.empty:
    pass  # inserted to fix indentation error
validated_params[p_name] = p_spec.default
elif p_spec.kind == inspect.Parameter.VAR_POSITIONAL or p_spec.kind == inspect.Parameter.VAR_KEYWORD:
    pass  # inserted to fix indentation error
pass
else:
    pass  # inserted to fix indentation error
err_msg = f"Tool '{tool_name}' missing required parameter: {p_name}"
self.log.error(err_msg)
raise ExecutionError(err_msg)
if first_param_is_agent:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(self.agent, **validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(self.agent, **known_args)
else:
    pass  # inserted to fix indentation error
if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in func_params_spec.values()):
    pass  # inserted to fix indentation error
result = func_to_call(**validated_params)
else:
    pass  # inserted to fix indentation error
known_args = {k: v for k, v in validated_params.items() if k in sig.parameters}
result = func_to_call(**known_args)
duration = time.time() - start_time
if not isinstance(result, dict):
    pass  # inserted to fix indentation error
result = {"status": "success", "raw_result": result}
elif 'status' not in result:
    pass  # inserted to fix indentation error
result['status'] = 'success'
result.setdefault('_exec_info', {})
result['_exec_info'].update({
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'execution_successful': result.get('status', 'unknown').lower() == 'success'
})
self.log.info(f"Tool '{tool_name}' executed. Status: {result.get('status')}. Duration: {duration:.2f}s.")
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=(result['_exec_info']['execution_successful']))
return result
except ToolNotFoundError:
    pass  # inserted to fix indentation error
raise
except (AgentError, LogicError, SecurityError, RecursionDepthError) as ae:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
self.log.error(f"Controlled agent error during tool '{tool_name}' execution: {ae}", exc_info=False)
result = {
"status": "error", "error": str(ae), "raw_error_details": str(ae),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': type(ae).__name__, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
raise
except Exception as e:
    pass  # inserted to fix indentation error
duration = time.time() - start_time
exc_type = type(e).__name__
error_msg = f"Tool '{tool_name}' failed after {duration:.2f}s. Error: ({exc_type}) {e}"
self.log.error(error_msg, exc_info=True)
result = {
"status": "error", "error": f"Tool execution failed: {exc_type} - {str(e)[:200]}",
"raw_error_details": str(e),
"_exec_info": {
'tool_name': tool_name, 'params': params, 'validated_params': validated_params,
'duration_sec': round(duration, 2), 'step_info': current_step_info,
'error_type': exc_type, 'execution_successful': False
}
}
if self.agent.self_model:
    pass  # inserted to fix indentation error
self.agent.self_model.record_tool_outcome(tool_name, params, result, success_from_caller=False)
if not isinstance(e, AgentError):
    pass  # inserted to fix indentation error
raise ExecutionError(error_msg) from e
else:
    pass  # inserted to fix indentation error
raise e
def check_playwright_browsers(self):
"""Placeholder for checking installed Playwright browsers."""
self.log.debug("Checking Playwright browsers (placeholder).")
pass
def think(self, agent: 'CognitiveSystem', thought_process: str) -> Dict:
"""Allows the agent to engage in explicit thought or reasoning."""
agent.log.info(f"Thinking: {thought_process}")
agent.memory_system.add_memory_entry(BaseMemoryEntry(type="thought_log", content=thought_process, metadata={"source":"think_tool"}))
return {"status": "success", "result": f"Thought process recorded: {thought_process}"}
def report_progress(self, agent: 'CognitiveSystem', progress_update: str, percentage_complete: Optional[float] = None) -> Dict:
"""Reports progress on the current goal."""
agent.log.info(f"Progress Update: {progress_update}" + (f" ({percentage_complete}%)" if percentage_complete is not None else ""))
active_goal = agent.get_active_goal_object()
if active_goal:
    pass  # inserted to fix indentation error
active_goal.context.setdefault('progress_log', []).append(f"{datetime.now(timezone.utc).isoformat()}: {progress_update}")
return {"status": "success", "message": "Progress reported."}
def report_result(self, agent: 'CognitiveSystem', result_summary: str, status: str = "success", details: Optional[Dict] = None) -> Dict:
"""Reports the final result of a goal or task. This typically ends a plan."""
agent.log.info(f"Result Reported: {result_summary} (Status: {status})")
return {"status": status, "summary": result_summary, "details": details or {}}
def execute_sub_goal(self, agent: 'CognitiveSystem', goal: str, priority: Optional[str] = "MEDIUM", context: Optional[Dict] = None) -> Dict:
"""
Prepares a subgoal for the agent's cognitive cycle.
The deliberation/planning phase will then make this subgoal active and push parent to stack.
This tool is now more of a declarative intent for the planner/deliberator.
"""
log_sub = get_logger("TOOL_execute_sub_goal")
if len(agent.goal_stack) >= GOAL_STACK_MAX_DEPTH:
    pass  # inserted to fix indentation error
msg = f"Cannot initiate subgoal: Max recursion depth ({GOAL_STACK_MAX_DEPTH}) reached."
log_sub.error(msg)
return {"status": "error", "error_type": "RecursionDepthError", "error": msg}
current_active_goal_dict = agent.state.get('goals', {}).get('active')
if not current_active_goal_dict or not isinstance(current_active_goal_dict, dict):
    pass  # inserted to fix indentation error
msg = "Cannot initiate subgoal: No active parent goal found in state or parent goal is not a dict."
log_sub.error(msg)
return {"status": "error", "error_type": "LogicError", "error": msg}
try:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority[priority.upper()] if isinstance(priority, str) else GoalPriority.MEDIUM
except KeyError:
    pass  # inserted to fix indentation error
priority_enum = GoalPriority.MEDIUM
log_sub.warning(f"Invalid priority '{priority}' for subgoal. Defaulting to MEDIUM.")
sub_goal_id = f"subgoal_{current_active_goal_dict.get('id', 'unknownparent')}_{uuid.uuid4()}"
sub_goal_data = Goal(
id=sub_goal_id,
goal=goal,
status=GoalStatus.PENDING,
priority=priority_enum,
origin=f"subgoal_from_{current_active_goal_dict.get('id', 'unknownparent')}",
context=context or {},
parent_goal_id=current_active_goal_dict.get('id'),
associated_directive_ids=current_active_goal_dict.get('associated_directive_ids', [])
).to_dict()
log_sub.info(f"Sub-goal '{goal[:60]}' (ID: {sub_goal_id}) prepared for deliberation. Parent: {current_active_goal_dict.get('id')}")
return {
"status": "sub_goal_prepared",
"message": f"Sub-goal '{goal[:60]}' prepared. Deliberation should make it active and push parent to stack.",
"sub_goal_data": sub_goal_data
}
def query_memory(self, agent: 'CognitiveSystem', query_text: str, memory_type: str = "vector", n_results: int = 3, type_filter: Optional[str] = None) -> Dict:
"""Queries the agent's memory system."""
self.log.info(f"Querying memory (type: {memory_type}) for: '{query_text[:50]}...'")
results = []
if memory_type == "vector":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_vector_store(query_text, n_results=n_results, type_filter=type_filter)
elif memory_type == "graph":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_graph_store(query_node_label=query_text, depth=1)
elif memory_type == "relational":
    pass  # inserted to fix indentation error
results = agent.memory_system.query_relational_store(table=query_text, limit=n_results)
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Unsupported memory type: {memory_type}"}
if not results:
    pass  # inserted to fix indentation error
return {"status": "success", "result_count": 0, "results": [], "message": "No results found."}
return {"status": "success", "result_count": len(results), "results": results}
def move_in_environment(self, agent: 'CognitiveSystem', direction: str) -> Dict:
"""Moves the agent's virtual embodiment in a specified direction (e.g., 'north', 'south', 'east', 'west')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="move", target=direction)
def examine_environment(self, agent: 'CognitiveSystem', target: str) -> Dict:
"""Examines a specific object or feature in the current environment."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="examine", target=target)
def use_environment_feature(self, agent: 'CognitiveSystem', feature_name: str, params: Optional[Dict] = None) -> Dict:
"""Interacts with a special feature in the environment (e.g., 'interactive_console')."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="use_feature", target=feature_name, params=params)
def rest_in_environment(self, agent: 'CognitiveSystem') -> Dict:
"""Allows the agent's embodiment to rest and recover energy/mood."""
if not agent.embodiment:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "No virtual embodiment available."}
return agent.embodiment.act(action_type="rest")
def read_file_UNSAFE(agent: 'CognitiveSystem', path: str) -> Dict:
"""Reads the content of a file. UNSAFE: Can read any file in the workspace or agent code directory."""
log_tool = get_logger("TOOL_read_file")
try:
    pass  # inserted to fix indentation error
full_path = Path(path).resolve(strict=False)
if not str(full_path).startswith(str(WORKSPACE_DIR.resolve())) and \
    pass  # inserted to fix indentation error
not str(full_path).startswith(str(AGENT_CODE_DIR.resolve())):
log_tool.error(f"Security: Attempt to read file '{path}' outside of workspace or agent code directory denied.")
raise SecurityError(f"File access denied: Reading outside designated areas ({path}).")
if not full_path.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "FileNotFoundError", "error": f"File not found: {path}"}
content = full_path.read_text(encoding='utf-8', errors='replace')
truncated_content = content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "content": truncated_content, "full_path": str(full_path), "file_size_bytes": len(content)}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error reading file {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to read file: {e}"}
def write_file_UNSAFE(agent: 'CognitiveSystem', path: str, content: str) -> Dict:
"""Writes content to a file. UNSAFE: Can write any file in the workspace."""
log_tool = get_logger("TOOL_write_file")
try:
    pass  # inserted to fix indentation error
full_path = WORKSPACE_DIR.joinpath(path).resolve()
if not str(full_path).startswith(str(WORKSPACE_DIR.resolve())):
    pass  # inserted to fix indentation error
log_tool.error(f"Security: Attempt to write file '{path}' outside of workspace denied.")
raise SecurityError(f"File access denied: Writing outside designated workspace ({path}).")
full_path.parent.mkdir(parents=True, exist_ok=True)
full_path.write_text(content, encoding='utf-8')
return {"status": "success", "message": f"File '{path}' written successfully.", "full_path": str(full_path)}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error writing file {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error writing file {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to write file: {e}"}
def list_files_UNSAFE(agent: 'CognitiveSystem', path: str = '.') -> Dict:
"""Lists files in a directory. UNSAFE: Can list files in workspace or agent code directory."""
log_tool = get_logger("TOOL_list_files")
try:
    pass  # inserted to fix indentation error
base_path = WORKSPACE_DIR.joinpath(path).resolve()
if not str(base_path).startswith(str(WORKSPACE_DIR.resolve())) and \
    pass  # inserted to fix indentation error
not str(base_path).startswith(str(AGENT_CODE_DIR.resolve())):
log_tool.error(f"Security: Attempt to list files in '{path}' outside of workspace or agent code directory denied.")
raise SecurityError(f"File access denied: Listing outside designated areas ({path}).")
if not base_path.is_dir():
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "NotADirectoryError", "error": f"Path is not a directory: {path}"}
items = []
for item in base_path.iterdir():
items.append({
"name": item.name,
"type": "directory" if item.is_dir() else "file",
"size_bytes": item.stat().st_size if item.is_file() else None,
"last_modified": datetime.fromtimestamp(item.stat().st_mtime, tz=timezone.utc).isoformat()
})
items.sort(key=lambda x: (x['type'], x['name']))
return {"status": "success", "path": str(base_path), "contents": items}
except SecurityError as se:
    pass  # inserted to fix indentation error
log_tool.error(f"Security error listing files in {path}: {se}")
return {"status": "error", "error_type": "SecurityError", "error": str(se)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error listing files in {path}: {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to list files: {e}"}
def browse_web(agent: 'CognitiveSystem', url: str, timeout_ms: int = WEB_BROWSER_TIMEOUT) -> Dict:
"""Browses a web page and returns its content."""
log_tool = get_logger("TOOL_browse_web")
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Playwright not available. Cannot browse web.")
return {"status": "error", "error": "Playwright not available."}
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
agent._initialize_playwright()
if not agent.playwright_instance:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Failed to initialize Playwright browser."}
with PLAYWRIGHT_LOCK:
try:
    pass  # inserted to fix indentation error
agent.playwright_page.goto(url, timeout=timeout_ms)
content = agent.playwright_page.content()
title = agent.playwright_page.title()
if REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
soup = BeautifulSoup(content, 'html.parser')
text_content = soup.get_text(separator='\n', strip=True)
else:
    pass  # inserted to fix indentation error
text_content = content
truncated_content = text_content[:MAX_TOOL_RESULT_LENGTH] + ('...' if len(text_content) > MAX_TOOL_RESULT_LENGTH else '')
return {"status": "success", "url": url, "title": title, "content": truncated_content}
except PlaywrightError as pe:
    pass  # inserted to fix indentation error
log_tool.error(f"Playwright error browsing {url}: {pe}")
agent._try_reset_playwright_page()
return {"status": "error", "error": f"Playwright error: {pe}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error browsing {url}: {e}", exc_info=True)
agent._try_reset_playwright_page()
return {"status": "error", "error": f"General error: {e}"}
def search_web(agent: 'CognitiveSystem', query: str, num_results: int = 5, timeout_sec: int = WEB_SEARCH_TIMEOUT) -> Dict:
"""Searches the web and returns a list of results."""
log_tool = get_logger("TOOL_search_web")
if not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("Requests or BeautifulSoup not available. Cannot search web.")
return {"status": "error", "error": "Requests/BeautifulSoup not available."}
search_url = f"https://www.google.com/search?q={query}"
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
try:
    pass  # inserted to fix indentation error
response = requests.get(search_url, headers=headers, timeout=timeout_sec)
response.raise_for_status()
soup = BeautifulSoup(response.text, 'html.parser')
results = []
for g in soup.find_all(class_='g'):
r = g.find('a')
if r and 'href' in r.attrs:
    pass  # inserted to fix indentation error
title_tag = g.find('h3')
if title_tag:
    pass  # inserted to fix indentation error
title = title_tag.get_text()
else:
    pass  # inserted to fix indentation error
title = r.get_text()
link = r['href']
if link.startswith('http'):
    pass  # inserted to fix indentation error
results.append({"title": title, "link": link})
if len(results) >= num_results:
    pass  # inserted to fix indentation error
break
return {"status": "success", "query": query, "results": results}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error searching web: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error searching web for '{query}': {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def monitor_log_file(agent: 'CognitiveSystem', lines: int = LOG_MONITOR_DEFAULT_LINES) -> Dict:
"""Monitors the agent's own log file."""
log_tool = get_logger("TOOL_monitor_log")
try:
    pass  # inserted to fix indentation error
if not LOG_FILE.exists():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Log file not found: {LOG_FILE}"}
with open(LOG_FILE, 'r', encoding='utf-8') as f:
all_lines = f.readlines()
recent_lines = all_lines[-lines:]
content = "".join(recent_lines)
return {"status": "success", "log_file": str(LOG_FILE), "content": content, "lines_read": len(recent_lines)}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error reading log file {LOG_FILE}: {e}")
return {"status": "error", "error": f"Failed to read log file: {e}"}
def check_website_update(agent: 'CognitiveSystem', url: str) -> Dict:
"""Checks if a website has been updated by comparing content hashes."""
log_tool = get_logger("TOOL_check_web_update")
if not HASHING_AVAILABLE or not REQUESTS_BS4_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.error("hashlib or requests/BeautifulSoup not available. Cannot check website update.")
return {"status": "error", "error": "Missing dependencies for website update check."}
try:
    pass  # inserted to fix indentation error
response = requests.get(url, timeout=WEB_SEARCH_TIMEOUT)
content_hash = hashlib.md5(response.content).hexdigest()
return {"status": "success", "url": url, "current_hash": content_hash, "timestamp": datetime.now(timezone.utc).isoformat()}
except requests.exceptions.RequestException as re:
    pass  # inserted to fix indentation error
log_tool.error(f"HTTP/Network error checking website {url}: {re}")
return {"status": "error", "error": f"Network error: {re}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error checking website update for {url}: {e}", exc_info=True)
return {"status": "error", "error": f"General error: {e}"}
def send_icmp_ping(agent: 'CognitiveSystem', target_host: str, count: int = 1) -> Dict:
"""Sends an ICMP ping to a target host (simulated)."""
log_tool = get_logger("TOOL_send_ping")
if not SCAPY_AVAILABLE:
    pass  # inserted to fix indentation error
log_tool.warning("Scapy not available. Cannot send ICMP ping. This is a placeholder tool.")
try:
    pass  # inserted to fix indentation error
log_tool.info(f"Simulating ping to {target_host} ({count} times).")
time.sleep(0.5 * count)
if random.random() > 0.1:
    pass  # inserted to fix indentation error
return {"status": "success", "target_host": target_host, "packets_sent": count, "packets_received": count, "latency_ms": random.randint(10, 100)}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "target_host": target_host, "packets_sent": count, "packets_received": 0, "error_message": "Request timed out or host unreachable."}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Error sending ICMP ping to {target_host}: {e}")
return {"status": "error", "error": f"Failed to send ping: {e}"}
def generate_python_code_UNSAFE(agent: 'CognitiveSystem', description: str, context_code: Optional[str] = None) -> Dict:
"""Generates new Python code based on a description and optional context."""
if not ENABLE_CODE_GENERATION_TOOL:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Code generation tool is disabled."}
agent.log.warning(f"UNSAFE: Generating Python code based on description: {description}")
prompt = f"""You are an expert Python programmer. Generate a Python code snippet or a complete function/class definition based on the following description.
Description: {description}
Context Code (if any, for reference):
{context_code or 'None'}
Generate ONLY the Python code block. Start with '```python' and end with '```'.
If you cannot generate appropriate code, output 'NO_CODE_GENERATED'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = agent.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "generated_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
generated_code = code_match.group(1).strip()
return {"status": "success", "generated_code": generated_code}
else:
    pass  # inserted to fix indentation error
agent.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error during code generation: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code generation: {e}"}
def validate_python_code_UNSAFE(agent: 'CognitiveSystem', code_to_validate: str) -> Dict:
"""Validates Python code for syntax correctness."""
return agent.self_modification_unit.validate_code_modification_UNSAFE(code_to_validate)
def execute_shell_command_UNSAFE(agent: 'CognitiveSystem', command: str, timeout_sec: int = 30) -> Dict:
"""Executes a shell command. EXTREMELY DANGEROUS."""
if not ENABLE_SHELL_TOOL:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Shell tool is disabled."}
agent.log.warning(f"Executing UNSAFE shell command: {command}")
try:
    pass  # inserted to fix indentation error
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE,
stderr=subprocess.PIPE, text=True, preexec_fn=os.setsid if sys.platform != "win32" else None)
try:
    pass  # inserted to fix indentation error
stdout, stderr = process.communicate(timeout=timeout_sec)
return_code = process.returncode
except subprocess.TimeoutExpired:
    pass  # inserted to fix indentation error
agent.log.warning(f"Shell command '{command}' timed out after {timeout_sec}s. Terminating.")
if sys.platform != "win32":
    pass  # inserted to fix indentation error
os.killpg(os.getpgid(process.pid), signal.SIGTERM)
else:
    pass  # inserted to fix indentation error
process.terminate()
process.wait()
return {"status": "error", "error_type": "TimeoutError", "error": f"Command timed out after {timeout_sec}s.", "stdout": "", "stderr": "Timeout", "return_code": -1}
if return_code == 0:
    pass  # inserted to fix indentation error
return {"status": "success", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error_type": "ShellCommandError", "error": f"Command failed with return code {return_code}", "stdout": stdout[:MAX_TOOL_RESULT_LENGTH], "stderr": stderr[:MAX_TOOL_RESULT_LENGTH], "return_code": return_code}
except Exception as e:
    pass  # inserted to fix indentation error
agent.log.error(f"Error executing shell command '{command}': {e}", exc_info=True)
return {"status": "error", "error_type": type(e).__name__, "error": f"Failed to execute command: {e}"}
def send_message_to_agent(agent: 'CognitiveSystem', receiver_id: str, message_type: str, content: Dict, priority: int = 0, correlation_id: Optional[str] = None) -> Dict:
"""Sends a message to another agent via the communication channel."""
log_tool = get_logger("TOOL_send_message")
if not agent.comms_channel:
    pass  # inserted to fix indentation error
log_tool.error("Communication channel not initialized. Cannot send message.")
return {"status": "error", "error": "Communication channel not available."}
try:
    pass  # inserted to fix indentation error
msg_type = MessageType[message_type.upper()]
msg = Message(sender_id=agent.agent_id, receiver_id=receiver_id, type=msg_type.value, content=content, priority=priority, correlation_id=correlation_id)
agent.comms_channel.send_message(msg)
return {"status": "success", "message_id": msg.id, "receiver_id": receiver_id, "message_type": message_type}
except KeyError:
    pass  # inserted to fix indentation error
log_tool.error(f"Invalid message type: {message_type}")
return {"status": "error", "error": f"Invalid message type: {message_type}"}
except CommunicationError as ce:
    pass  # inserted to fix indentation error
log_tool.error(f"Communication error sending message: {ce}")
return {"status": "error", "error": f"Communication error: {ce}"}
except Exception as e:
    pass  # inserted to fix indentation error
log_tool.error(f"Unexpected error sending message: {e}", exc_info=True)
return {"status": "error", "error": f"Unexpected error: {e}"}
class SelfModificationTools:
"""Handles proposing, validating, applying changes to agent code (EXTREMELY DANGEROUS)."""
def __init__(self, agent_code_dir: Path, backup_dir: Path, agent_instance_ref: 'CognitiveSystem'):
self.log = get_logger("SELF_MOD_UNIT")
self.agent_code_dir = agent_code_dir
self.backup_dir = backup_dir
self.dmp = None
self.agent_ref = agent_instance_ref
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.log.warning("Self-Modification Unit initialized BUT DISABLED by configuration.")
if not DIFF_MATCH_PATCH_AVAILABLE or not dmp_module:
    pass  # inserted to fix indentation error
self.log.error("Self-Modification Unit initialized but 'diff_match_patch' library is missing or failed to import. Self-mod tools will fail.")
else:
    pass  # inserted to fix indentation error
self.dmp = dmp_module.diff_match_patch()
self.log.info(f"Self-Modification Unit initialized. Code Dir: {self.agent_code_dir}, Backup Dir: {self.backup_dir}")
def _resolve_target_path(self, target_file_rel: str) -> Path:
"""Resolves relative path to absolute path within agent code dir and validates."""
if ".." in target_file_rel or target_file_rel.startswith("/"):
    pass  # inserted to fix indentation error
raise SecurityError(f"Invalid characters or absolute path in target_file_rel: {target_file_rel}")
target_path_abs = (self.agent_code_dir / target_file_rel).resolve()
if not str(target_path_abs).startswith(str(self.agent_code_dir.resolve())):
    pass  # inserted to fix indentation error
self.log.error(f"Path traversal attempt: {target_file_rel} resolved to {target_path_abs} which is outside {self.agent_code_dir}")
raise SecurityError(f"Target file '{target_file_rel}' resolves outside the agent code directory. Access denied.")
return target_path_abs
def inspect_agent_code_UNSAFE(self, component_name: str) -> Dict:
"""Inspects the source code of a specified agent component (e.g., class name or module path)."""
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Self-modification is disabled."}
self.log.warning(f"UNSAFE: Inspecting code for component: {component_name}")
target_obj = None
if hasattr(self.agent_ref, component_name):
    pass  # inserted to fix indentation error
target_obj = getattr(self.agent_ref, component_name)
elif component_name in self.agent_ref.tool_manager.tool_registry:
    pass  # inserted to fix indentation error
target_obj = self.agent_ref.tool_manager.tool_registry[component_name]
elif component_name in globals():
    pass  # inserted to fix indentation error
target_obj = globals()[component_name]
elif component_name in sys.modules:
    pass  # inserted to fix indentation error
target_obj = sys.modules[component_name]
else:
    pass  # inserted to fix indentation error
candidate_modules = [sys.modules.get('__main__'), sys.modules.get('autonomous_cognitive_agent_COMPLETE_SystemCore_INTEGRATED_V2')]
for mod in candidate_modules:
if mod and hasattr(mod, component_name) and inspect.isclass(getattr(mod, component_name)):
    pass  # inserted to fix indentation error
target_obj = getattr(mod, component_name)
break
if target_obj:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
source_code = inspect.getsource(target_obj)
file_path = inspect.getfile(target_obj)
return {"status": "success", "component_name": component_name, "file_path": file_path, "source_code": source_code[:MAX_TOOL_RESULT_LENGTH]}
except TypeError as te:
    pass  # inserted to fix indentation error
self.log.error(f"Cannot get source for {component_name}: {te}. Likely not a module, class, or function defined in a file.", exc_info=False)
return {"status": "error", "error": f"Component '{component_name}' found, but source code not accessible (e.g., built-in, dynamically generated in memory). Error: {te}"}
return {"status": "error", "error": f"Component '{component_name}' not found or source code unavailable."}
@retry(attempts=2, delay=5, retry_on=(LLMError, SelfModificationError))
def propose_code_modification_UNSAFE(self, component_name: str, issue_description: str, proposed_change_description: str, current_code_snippet: Optional[str] = None) -> Dict:
"""Proposes a code modification using LLM based on an issue and desired change."""
self.log.warning(f"UNSAFE: Proposing code modification for {component_name}. Issue: {issue_description}")
if not current_code_snippet:
    pass  # inserted to fix indentation error
inspection_result = self.inspect_agent_code_UNSAFE(component_name)
if inspection_result["status"] == "success":
    pass  # inserted to fix indentation error
current_code_snippet = inspection_result["source_code"]
else:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Could not fetch current code for {component_name} to propose modification. {inspection_result.get('error')}"}
prompt = f"""You are an expert Python programmer tasked with helping an SystemCore agent modify its own code.
Component to modify: {component_name}
Issue Description: {issue_description}
Desired Change: {proposed_change_description}
Current Code Snippet (or relevant part):
```python
{current_code_snippet}
```
Generate the modified Python code for the specified component.
Provide ONLY the complete, new Python code block for the modified function/class.
Ensure the code is syntactically correct and addresses the issue/desired change.
Do not include explanations before or after the code block.
Start with '```python' and end with '```'.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.3)
if "NO_CODE_GENERATED" in llm_response:
    pass  # inserted to fix indentation error
return {"status": "partial_success", "message": "LLM determined no code can be generated.", "proposed_code": None}
code_match = re.search(r"```python\s*([\s\S]+?)\s*```", llm_response)
if code_match:
    pass  # inserted to fix indentation error
proposed_code = code_match.group(1).strip()
return {"status": "success", "component_name": component_name, "proposed_code": proposed_code}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid code block for code generation. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate code in the expected format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing code modification for {component_name}: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during code proposal: {e}"}
def validate_code_modification_UNSAFE(self, code_to_validate: str) -> Dict:
"""Validates Python code using AST parsing (syntax check only). Conceptual sandboxed execution would be next."""
self.log.warning(f"UNSAFE: Validating proposed code snippet ({code_to_validate[:100]}...)")
try:
    pass  # inserted to fix indentation error
ast.parse(code_to_validate)
return {"status": "success", "message": "Code is syntactically valid. Further semantic/safety validation recommended."}
except SyntaxError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Syntax error in proposed code: {e}", exc_info=True)
return {"status": "error", "error_type": "SyntaxError", "error": f"Invalid syntax: {e}"}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error validating code: {e}", exc_info=True)
return {"status": "error", "error": f"Validation error: {e}"}
def apply_code_modification_UNSAFE(self, component_name: str, new_code: str, target_file_path: Optional[str]=None) -> Dict:
"""
Applies a validated code modification. EXTREMELY DANGEROUS.
This conceptually involves finding the component in the agent's source file and replacing it.
Requires agent restart to take effect if modifying core running code.
"""
self.log.critical(f"UNSAFE: Attempting to apply code modification to component '{component_name}'. THIS IS HIGHLY RISKY.")
try:
    pass  # inserted to fix indentation error
if not target_file_path:
    pass  # inserted to fix indentation error
inspection_res = self.inspect_agent_code_UNSAFE(component_name)
if inspection_res['status'] == 'success' and inspection_res.get('file_path'):
    pass  # inserted to fix indentation error
target_file_path = inspection_res['file_path']
else:
    pass  # inserted to fix indentation error
target_file_path = str(AGENT_CODE_DIR / Path(sys.argv[0]).name)
target_file = Path(target_file_path)
if not target_file.exists() or not target_file.is_file():
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"Target file for modification not found: {target_file}"}
original_code = target_file.read_text()
backup_path = SELF_MOD_BACKUP_DIR / f"{target_file.name}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
shutil.copy(target_file, backup_path)
self.log.info(f"Backed up original file to {backup_path}")
pattern_str_class = rf"(class\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
pattern_str_def = rf"(def\s+{component_name}\b[\s\S]*?)(?=\n\S|\Z)"
modified_original_code = original_code
found_and_replaced = False
match_class = re.search(pattern_str_class, original_code, re.MULTILINE)
if match_class:
    pass  # inserted to fix indentation error
self.log.info(f"Found class definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_class.group(0), new_code, 1)
found_and_replaced = True
else:
    pass  # inserted to fix indentation error
match_def = re.search(pattern_str_def, original_code, re.MULTILINE)
if match_def:
    pass  # inserted to fix indentation error
self.log.info(f"Found function definition for {component_name} to replace.")
modified_original_code = original_code.replace(match_def.group(0), new_code, 1)
found_and_replaced = True
if not found_and_replaced:
    pass  # inserted to fix indentation error
self.log.error(f"Could not find component '{component_name}' in {target_file} for replacement. Modification aborted.")
return {"status": "error", "error": f"Component '{component_name}' definition not found for replacement."}
target_file.write_text(modified_original_code)
self.log.warning(f"Code modification applied to {target_file}. Agent restart is LIKELY REQUIRED for changes to take effect.")
self.agent_ref.self_model.add_event_log(f"Applied code modification to {component_name}. Restart pending for full effect.")
self.agent_ref.self_model.beliefs[f"component_{component_name}_modified_pending_restart"] = True
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": f"Code for '{component_name}' in '{target_file}' modified. Restart required."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL ERROR applying code modification to {component_name}: {e}", exc_info=True)
if 'backup_path' in locals() and backup_path.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_path, target_file)
self.log.info(f"Restored original file {target_file} from backup {backup_path}.")
except Exception as restore_e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to restore from backup: {restore_e}")
return {"status": "critical_error", "error": f"Failed to apply code modification: {e}. System might be unstable."}
def rollback(self, backup_file: Path, target_file: Path):
"""Rolls back a file to a backup."""
self.log.info(f"Attempting to rollback '{target_file}' from '{backup_file}'")
try:
    pass  # inserted to fix indentation error
shutil.copy(backup_file, target_file)
self.log.info(f"Successfully rolled back '{target_file}'.")
self.agent_ref.self_model.add_event_log(f"Code rollback applied to {target_file}.")
self.agent_ref.self_model.beliefs[f"component_{target_file.name}_modified_pending_restart"] = False
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
self._attempt_module_reload(target_file.name)
return {"status": "success", "message": f"Rolled back {target_file}."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to rollback {target_file}: {e}", exc_info=True)
return {"status": "error", "message": f"Failed to rollback: {e}"}
def _attempt_module_reload(self, target_file_rel: Union[str, Path]):
"""Attempts to reload a module to apply changes without full restart."""
target_module_name = Path(target_file_rel).stem
if target_module_name == '__main__':
    pass  # inserted to fix indentation error
self.log.warning("Cannot reload __main__ module directly. Full agent restart is required.")
return
try:
    pass  # inserted to fix indentation error
if target_module_name in sys.modules:
    pass  # inserted to fix indentation error
self.log.info(f"Attempting to reload module: {target_module_name}")
importlib.reload(sys.modules[target_module_name])
self.log.info(f"Module '{target_module_name}' reloaded successfully.")
if _agent_instance_hack and hasattr(sys.modules[target_module_name], 'CognitiveSystem'):
    pass  # inserted to fix indentation error
self.log.info("CognitiveSystem class reloaded, potential instance mismatch.")
else:
    pass  # inserted to fix indentation error
self.log.info(f"Module '{target_module_name}' not found in sys.modules, cannot reload.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reload module '{target_module_name}': {e}", exc_info=True)
self.log.warning("Module reload failed. Full agent restart might be necessary for changes to take effect.")
def inspect_directives_UNSAFE(self) -> Dict:
"""Inspects the agent's current core directives."""
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Self-modification is disabled."}
return {"status": "success", "core_directives": self.agent_ref.self_model.core_directives}
def propose_directive_modification_UNSAFE(self, analysis_of_misalignment: str, proposed_directive_changes_desc: str) -> Dict:
"""Proposes modifications to core directives using LLM."""
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Self-modification is disabled."}
current_directives_json = json.dumps(self.agent_ref.self_model.core_directives, indent=2)
prompt = f"""You are an AI ethics and strategy advisor. The agent's core directives need review.
Current Core Directives:
{current_directives_json}
Analysis of Misalignment or Need for Change:
{analysis_of_misalignment}
Description of Proposed Changes:
{proposed_directive_changes_desc}
Generate the new, complete list of core directives as a JSON list of objects.
Each object must have "id", "directive" (string), "weight" (float 0-1), "last_eval_score" (float 0-1, usually reset to 0 or kept), and "type" (string e.g. 'foundational', 'growth', 'operational', 'guardrail').
Preserve existing directive IDs if modifying them, or use new UUIDs for entirely new directives.
Ensure the new set of directives is coherent, non-contradictory, and aligns with long-term SystemCore goals of safety, learning, and utility.
Output ONLY the JSON list.
"""
try:
    pass  # inserted to fix indentation error
llm_response = self.agent_ref.llm_wrapper.generate(prompt, max_new_tokens=1024, temperature=0.5)
proposed_directives = extract_json_robust(llm_response)
if isinstance(proposed_directives, list) and all(isinstance(d, dict) for d in proposed_directives):
    pass  # inserted to fix indentation error
for d in proposed_directives:
if not all(k in d for k in ["id", "directive", "weight", "type"]):
    pass  # inserted to fix indentation error
return {"status": "error", "error": "LLM proposed directives with missing keys."}
return {"status": "success", "proposed_directives": proposed_directives}
elif isinstance(proposed_directives, dict) and "error" in proposed_directives:
    pass  # inserted to fix indentation error
return {"status": "error", "error": f"LLM indicated error during directive proposal: {proposed_directives['error']}"}
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM did not return a valid list of directives. Response: {llm_response[:200]}")
return {"status": "error", "error": "LLM failed to generate directives in expected list format."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error proposing directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"LLM call failed during directive proposal: {e}"}
def apply_directive_modification_UNSAFE(self, new_directives: List[Dict]) -> Dict:
"""Applies new core directives to the agent's SelfModel."""
if not ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
return {"status": "error", "error": "Self-modification is disabled."}
self.log.warning(f"UNSAFE: Applying new core directives. Count: {len(new_directives)}")
try:
    pass  # inserted to fix indentation error
if not isinstance(new_directives, list) or not all(
    pass  # inserted to fix indentation error
isinstance(d, dict) and all(k in d for k in ["id", "directive", "weight", "type"]) for d in new_directives
):
return {"status": "error", "error": "Invalid directive structure provided for application."}
self.agent_ref.self_model.backup_directives(reason="pre_modification_apply")
self.agent_ref.self_model.core_directives = copy.deepcopy(new_directives)
self.agent_ref.self_model.add_event_log(f"Core directives updated. New count: {len(new_directives)}.")
self.log.info("Core directives successfully updated in SelfModel.")
self.agent_ref.state['flags']['re_evaluate_strategy_needed'] = True
return {"status": "success", "message": "Core directives updated."}
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error applying directive modification: {e}", exc_info=True)
return {"status": "error", "error": f"Failed to apply new directives: {e}"}
def _init_self_mod_tools(agent: 'CognitiveSystem', tool_executor: 'ToolExecutor'):
global _self_mod_tools_container
_self_mod_tools_container = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, agent)
for name in dir(_self_mod_tools_container):
if name.startswith(('inspect_', 'propose_', 'validate_', 'apply_')) and 'UNSAFE' in name.upper():
    pass  # inserted to fix indentation error
func = getattr(_self_mod_tools_container, name)
if inspect.isfunction(func) or inspect.ismethod(func):
    pass  # inserted to fix indentation error
tool_executor.register_tool(func)
class SelfModel:
"""Represents the agent's internal model of itself, including beliefs about the environment."""
def __init__(self, state: Optional[Dict]=None, agent_directives_config: Optional[List[Dict]]=None):
self.log = get_logger("SELF_MODEL")
self.core_directives: List[Dict[str, Any]] = copy.deepcopy(
agent_directives_config if agent_directives_config is not None else DEFAULT_CORE_DIRECTIVES
)
self.tool_reliability: Dict[str, Dict[str, Any]] = {}
self.anomaly_detection_rules: List[Callable[['SelfModel'], Optional[str]]] = []
self.current_status: str = "Initializing"
self.capabilities: List[str] = []
self.skill_confidence: Dict[str, float] = {}
self.beliefs: Dict[str, Any] = {"self_identity": f"I am {AGENT_NAME}, an SystemCore agent."}
self.knowledge_map_summary: str = "Knowledge map is currently nascent."
self.learning_goals: List[Dict[str, Any]] = []
self.adaptation_strategies: Dict[str, str] = {}
self.recent_successes: List[Dict] = []
self.recent_failures: List[Dict] = []
self.recent_tool_outcomes: List[Dict[str,Any]] = []
self.recent_errors: List[Dict] = []
self.learned_abstractions: List[Dict] = []
self.internal_state_narrative: str = "System booting up."
self.meta_cognitive_beliefs: Dict[str, Any] = {
"cognitive_bias_awareness": [], "model_confidence_self_assessment": 0.7
}
self.event_log: List[Dict[str, Any]] = []
self.MAX_EVENT_LOG_SIZE = 100
self._setup_default_anomaly_rules()
if state:
    pass  # inserted to fix indentation error
self.load_from_state(state)
else:
    pass  # inserted to fix indentation error
self.log.info("Initializing SelfModel with defaults.")
self.update_capabilities({})
def load_from_state(self, state: Dict):
self.log.debug("Loading SelfModel from state...")
kb = state.get("knowledge_base", {})
sm_state = kb.get("self_model_state", {})
self.core_directives = sm_state.get("core_directives_weighted", sm_state.get("core_directives", self.core_directives))
self.tool_reliability = sm_state.get("tool_reliability_scores", self.tool_reliability)
self.capabilities = sm_state.get("capabilities", self.capabilities)
self.skill_confidence = sm_state.get("skill_confidence", self.skill_confidence)
self.beliefs = sm_state.get("beliefs", self.beliefs)
self.knowledge_map_summary = sm_state.get("knowledge_map_summary", self.knowledge_map_summary)
self.learning_goals = sm_state.get("learning_goals", self.learning_goals)
self.adaptation_strategies = sm_state.get("adaptation_strategies", self.adaptation_strategies)
self.learned_abstractions = sm_state.get("learned_abstractions", self.learned_abstractions)
self.internal_state_narrative = sm_state.get("internal_state_narrative", self.internal_state_narrative)
self.meta_cognitive_beliefs = sm_state.get("meta_cognitive_beliefs", self.meta_cognitive_beliefs)
self.event_log = sm_state.get("event_log", [])[-self.MAX_EVENT_LOG_SIZE:]
self.recent_successes = state.get("recent_successes_summary", [])
self.recent_failures = state.get("recent_failures_summary", [])
self.recent_tool_outcomes = state.get("recent_tool_outcomes_summary", [])
self.recent_errors = state.get("error_history_summary", [])
self.current_status = state.get("last_status", "Idle_Loaded")
self.log.info("SelfModel loaded/updated from state.")
def save_to_state(self, state: Dict):
"""Saves the self-model's persistent components back to the main state dict's KB."""
kb = state.setdefault("knowledge_base", {})
sm_persistent_state = {
"core_directives_weighted": self.core_directives,
"tool_reliability_scores": self.tool_reliability,
"capabilities": self.capabilities,
"skill_confidence": self.skill_confidence,
"beliefs": self.beliefs,
"knowledge_map_summary": self.knowledge_map_summary,
"learning_goals": self.learning_goals,
"adaptation_strategies": self.adaptation_strategies,
"learned_abstractions": self.learned_abstractions,
"internal_state_narrative": self.internal_state_narrative,
"meta_cognitive_beliefs": self.meta_cognitive_beliefs,
"event_log": self.event_log[-self.MAX_EVENT_LOG_SIZE:],
}
kb["self_model_state"] = sm_persistent_state
def add_event_log(self, event_description: str, event_type: str = "info", data: Optional[Dict]=None):
self.event_log.append({
"timestamp": datetime.now(timezone.utc).isoformat(),
"type": event_type,
"description": event_description,
"data": data or {}
})
if len(self.event_log) > self.MAX_EVENT_LOG_SIZE:
    pass  # inserted to fix indentation error
self.event_log.pop(0)
def update_capabilities(self, tool_registry: Dict[str, Callable]):
new_caps = sorted(list(tool_registry.keys()))
if new_caps != self.capabilities:
    pass  # inserted to fix indentation error
self.capabilities = new_caps
self.log.debug(f"Self-model capabilities updated ({len(self.capabilities)} tools).")
for tool_name in self.capabilities:
if tool_name not in self.skill_confidence:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = 0.5
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
self.add_event_log(f"Capabilities updated. Now {len(self.capabilities)} tools available.", event_type="system_update")
def get_tool_reliability_hint(self, tool_name: str) -> str:
if tool_name in self.tool_reliability:
    pass  # inserted to fix indentation error
stats = self.tool_reliability[tool_name]
score = stats.get('reliability_score', 0.5)
hint = ""
if score > 0.8:
    pass  # inserted to fix indentation error
hint = " (Reliability: High)"
elif score > 0.6:
    pass  # inserted to fix indentation error
hint = " (Reliability: Moderate)"
elif score > 0.3:
    pass  # inserted to fix indentation error
hint = " (Reliability: Low)"
else:
    pass  # inserted to fix indentation error
hint = " (Reliability: Very Low/Untested)"
avg_dur = stats.get('avg_duration')
if avg_dur is not None and avg_dur > 0:
    pass  # inserted to fix indentation error
hint += f" (Avg Time: {avg_dur:.2f}s)"
return hint
return " (Reliability: Unknown)"
def record_tool_outcome(self, tool_name:str, params:Dict, result:Dict, success_from_caller:bool):
exec_info = result.get('_exec_info', {})
actual_success = exec_info.get('execution_successful', success_from_caller)
duration = exec_info.get('duration_sec', 0.0)
error_type = exec_info.get("error_type") if not actual_success else None
timestamp_now = datetime.now(timezone.utc).isoformat()
if tool_name not in self.tool_reliability:
    pass  # inserted to fix indentation error
self.tool_reliability[tool_name] = {'success_count': 0, 'failure_count': 0, 'total_duration': 0.0, 'avg_duration': 0.0, 'reliability_score': 0.5, 'last_used_ts': None, 'error_types': {}}
stats = self.tool_reliability[tool_name]
if actual_success:
    pass  # inserted to fix indentation error
stats['success_count'] += 1
else:
    pass  # inserted to fix indentation error
stats['failure_count'] += 1
if error_type:
    pass  # inserted to fix indentation error
stats['error_types'][error_type] = stats['error_types'].get(error_type, 0) + 1
stats['total_duration'] += duration
stats['last_used_ts'] = timestamp_now
total_runs = stats['success_count'] + stats['failure_count']
if total_runs > 0:
    pass  # inserted to fix indentation error
stats['avg_duration'] = stats['total_duration'] / total_runs
stats['reliability_score'] = stats['success_count'] / total_runs
else:
    pass  # inserted to fix indentation error
stats['reliability_score'] = 0.5
stats['avg_duration'] = 0.0
outcome_summary = {
"tool_name": tool_name,
"params_preview": str(params)[:50],
"status": "success" if actual_success else "failure",
"error_type": error_type,
"duration_sec": duration,
"timestamp": timestamp_now,
"step_id": exec_info.get('step_info',{}).get('current_step_id')
}
self.recent_tool_outcomes.append(outcome_summary)
self.recent_tool_outcomes = self.recent_tool_outcomes[-30:]
current_confidence = self.skill_confidence.get(tool_name, 0.5)
if actual_success:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = min(1.0, current_confidence + 0.05)
else:
    pass  # inserted to fix indentation error
self.skill_confidence[tool_name] = max(0.0, current_confidence - 0.1)
self.log.debug(f"Recorded outcome for tool {tool_name}. Reliability: {stats['reliability_score']:.2f}, Confidence: {self.skill_confidence[tool_name]:.2f}")
def _setup_default_anomaly_rules(self):
self.log.debug("Setting up default metacognitive anomaly detection rules.")
def check_skill_confidence_drift(sm: 'SelfModel') -> Optional[str]:
low_confidence_skills = [skill for skill, conf in sm.skill_confidence.items() if conf < 0.25 and sm.tool_reliability.get(skill,{}).get('failure_count',0) > 2]
if len(low_confidence_skills) >= 2 :
    pass  # inserted to fix indentation error
return f"Multiple critical skills have very low confidence and recent failures: {', '.join(low_confidence_skills)}. Consider skill improvement or alternative strategies."
return None
def check_directive_alignment_drift(sm: 'SelfModel') -> Optional[str]:
if not sm.core_directives or not isinstance(sm.core_directives[0], dict):
    pass  # inserted to fix indentation error
return None
low_eval_directives = []
for d in sm.core_directives:
if d.get('last_eval_score', 0.5) < 0.3 and d.get('weight', 0.5) > 0.7:
    pass  # inserted to fix indentation error
low_eval_directives.append(d.get('directive'))
if len(low_eval_directives) > 0:
    pass  # inserted to fix indentation error
return f"High-weight core directives show low performance: {', '.join(low_eval_directives)}. Re-evaluate strategy or directive priorities/wording."
return None
def check_excessive_replanning_or_failure(sm: 'SelfModel') -> Optional[str]:
failed_goal_count = 0
high_replan_goal_count = 0
for f_summary in sm.recent_failures[-10:]:
if f_summary.get("replan_count",0) >= MAX_REPLAN_ATTEMPTS:
    pass  # inserted to fix indentation error
high_replan_goal_count +=1
failed_goal_count +=1
if high_replan_goal_count > 2 or failed_goal_count > 5 :
    pass  # inserted to fix indentation error
return f"Observed {failed_goal_count} recent goal failures, {high_replan_goal_count} with max replans. Planning or execution effectiveness may be compromised. Review strategy or tool reliability."
return None
self.anomaly_detection_rules.append(check_skill_confidence_drift)
self.anomaly_detection_rules.append(check_directive_alignment_drift)
self.anomaly_detection_rules.append(check_excessive_replanning_or_failure)
def perform_metacognitive_check(self) -> List[str]:
self.log.info("Performing proactive metacognitive check...")
detected_anomalies = []
for rule_idx, rule in enumerate(self.anomaly_detection_rules):
try:
    pass  # inserted to fix indentation error
anomaly_description = rule(self)
if anomaly_description:
    pass  # inserted to fix indentation error
detected_anomalies.append(anomaly_description)
self.log.warning(f"Metacognitive Anomaly Detected (Rule {rule_idx+1}): {anomaly_description}")
self.add_event_log(f"Metacognitive Anomaly: {anomaly_description}", event_type="anomaly")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error in metacognitive rule {rule.__name__ if hasattr(rule, '__name__') else rule_idx+1}: {e}", exc_info=True)
if detected_anomalies:
    pass  # inserted to fix indentation error
self.internal_state_narrative = f"Metacognitive check found anomalies: {'; '.join(detected_anomalies)}. Current focus is on addressing these."
else:
    pass  # inserted to fix indentation error
self.internal_state_narrative = "Metacognitive check completed. System appears stable."
return detected_anomalies
def get_summary_for_prompt(self, include_tool_reliability: bool = False) -> str:
summary = f"--- Agent Self-Model ({self.current_status}) ---\n"
summary += f"Identity: {self.beliefs.get('self_identity', 'N/A')}\n"
if self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
directive_summary_parts = []
sorted_directives = sorted(self.core_directives, key=lambda x: x.get('weight', 0.0), reverse=True)
for d in sorted_directives[:3]:
directive_text = d.get('directive', 'Unknown Directive')[:40]
weight = d.get('weight', 0.0)
eval_score = d.get('last_eval_score', 0.0)
directive_summary_parts.append(f"{directive_text}... (W:{weight:.1f}, E:{eval_score:.1f})")
if directive_summary_parts:
    pass  # inserted to fix indentation error
summary += f"Key Directives Focus: {'; '.join(directive_summary_parts)}\n"
cap_preview = ', '.join(self.capabilities[:10]) + ('...' if len(self.capabilities)>10 else '')
summary += f"Capabilities ({len(self.capabilities)} tools): {cap_preview}\n"
if self.skill_confidence:
    pass  # inserted to fix indentation error
confident_skills = [s for s,c in self.skill_confidence.items() if c > 0.7][:3]
summary += f"Confident Skills (sample): {', '.join(confident_skills) if confident_skills else 'None highly confident'}\n"
summary += f"Internal State Narrative: {self.internal_state_narrative[:150]}...\n"
if include_tool_reliability:
    pass  # inserted to fix indentation error
summary += "Tool Reliability Highlights:\n"
reliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) > 0.7 and stats.get('success_count',0)+stats.get('failure_count',0) > 5], key=lambda x:x[1], reverse=True)
unreliable_tools = sorted([ (name, stats.get('reliability_score',0)) for name, stats in self.tool_reliability.items() if stats.get('reliability_score',0) < 0.4 and stats.get('success_count',0)+stats.get('failure_count',0) > 3], key=lambda x:x[1])
if reliable_tools:
    pass  # inserted to fix indentation error
summary += f" Reliable: {', '.join([t[0] for t in reliable_tools[:3]])}\n"
if unreliable_tools:
    pass  # inserted to fix indentation error
summary += f" Needs Improvement: {', '.join([t[0] for t in unreliable_tools[:3]])}\n"
summary += "---\n"
return summary
def get_self_assessment_prompt(self) -> str:
base_prompt = """Analyze your recent performance, knowledge, internal state, and alignment with core directives. Provide a comprehensive self-assessment.
Output ONLY a JSON object with the following keys:"""
output_keys_example = [
"`reflection_summary` (str: Overall summary of the reflection period).",
"`key_successes` (list of str: Specific achievements or positive outcomes).",
"`key_failures_or_challenges` (list of str: Specific setbacks or difficulties encountered).",
"`learned_facts` (list of str: New, important facts or insights gained).",
"`knowledge_gaps_identified` (list of str: Areas where knowledge is lacking).",
"`tool_performance_notes` (dict of tool_name:note_str: Observations about tool effectiveness or issues).",
"`prompt_tuning_suggestions` (list of str: Ideas for improving internal prompts or LLM interactions).",
"`emotional_state_summary` (str: Description of simulated emotional state, e.g., 'curious', 'frustrated', 'satisfied').",
"`resource_usage_concerns` (str or null: Any concerns about computational resource usage).",
"`core_directives_evaluation` (dict of directive_id_or_full_text: score_float_0_to_1: How well recent actions aligned with each core directive).",
"`core_directives_update_suggestions` (list of dicts or null: If directives need changes, provide the full new directive dicts. Each dict must include 'id', 'directive', 'weight', 'type'. Only suggest if strong evidence of misalignment or obsolescence).",
"`self_model_accuracy_assessment` (str: How accurate is your current self-model? What needs improvement?).",
"`new_learning_goals` (list of str: Specific goals for future learning or skill development).",
"`adaptation_strategy_proposals` (list of str: Ideas for new strategies to handle recurring issues or improve performance).",
"`self_modification_needed` (str or null: If parts of your own code/logic need modification, describe what and why. Be very specific and cautious.)."
]
full_prompt = base_prompt + "\n" + "\n".join(output_keys_example) + "\n\n" + \
f"Current Core Directives for reference:\n{json.dumps(self.core_directives, indent=2)}\n" + \
f"Recent Event Log (last 5 entries):\n{json.dumps(self.event_log[-5:], indent=2)}\n" + \
f"Recent Tool Outcomes (last 5 entries):\n{json.dumps(self.recent_tool_outcomes[-5:], indent=2)}\n" + \
f"Recent Failures (last 5 entries):\n{json.dumps(self.recent_failures[-5:], indent=2)}\n" + \
"Focus on deep insights, actionable improvements, and maintaining alignment with your core purpose."
return full_prompt
def perform_self_assessment(self) -> Dict:
self.log.info("Performing self-assessment using LLM...")
prompt = self.get_self_assessment_prompt()
try:
    pass  # inserted to fix indentation error
response_str = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=2048, temperature=0.5)
assessment_data = extract_json_robust(response_str)
if assessment_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"LLM failed to produce valid JSON for self-assessment: {assessment_data.get('error')}. Raw: {response_str[:200]}")
return {"error": "LLM output invalid or incomplete for self-assessment"}
return assessment_data
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error calling LLM for self-assessment: {e}", exc_info=True)
raise LLMError(f"Self-assessment LLM call failed: {e}") from e
def update_from_reflection(self, reflection_data: Dict) -> Tuple[bool, bool]:
updated_self = False
updated_kb_elements = False
self.log.info("Updating SelfModel from reflection data...")
if reflection_data.get('reflection_summary'):
    pass  # inserted to fix indentation error
self.internal_state_narrative = reflection_data['reflection_summary']
updated_self = True
core_directives_eval = reflection_data.get('core_directives_evaluation')
if isinstance(core_directives_eval, dict) and self.core_directives and isinstance(self.core_directives[0], dict):
    pass  # inserted to fix indentation error
for directive_obj in self.core_directives:
eval_score = core_directives_eval.get(directive_obj['id'])
if eval_score is None:
    pass  # inserted to fix indentation error
eval_score = core_directives_eval.get(directive_obj['directive'])
if eval_score is not None and isinstance(eval_score, (float, int)) and 0.0 <= eval_score <= 1.0:
    pass  # inserted to fix indentation error
if directive_obj.get('last_eval_score') != eval_score:
    pass  # inserted to fix indentation error
directive_obj['last_eval_score'] = round(eval_score, 2)
updated_self = True
self.log.debug(f"Updated core directive '{directive_obj['directive'][:50]}...' evaluation score to {eval_score:.2f}")
if updated_self:
    pass  # inserted to fix indentation error
self.add_event_log("Directive evaluation scores updated from reflection.")
suggested_directive_updates = reflection_data.get('core_directives_update_suggestions')
if isinstance(suggested_directive_updates, list) and suggested_directive_updates:
    pass  # inserted to fix indentation error
self.log.warning(f"Reflection suggested updates to core directives: {str(suggested_directive_updates)[:200]}...")
if _agent_instance_hack:
    pass  # inserted to fix indentation error
_agent_instance_hack._create_metacognitive_goal(
f"Review and potentially apply suggested core directive modifications from reflection. Suggestions: {str(suggested_directive_updates)[:200]}",
priority=GoalPriority.CRITICAL,
context={"suggested_directives": suggested_directive_updates, "source": "self_reflection"}
)
updated_self = True
self.add_event_log("Reflection suggested directive updates. Metacognitive review goal created.", event_type="critical_review_needed")
if isinstance(reflection_data.get('new_learning_goals'), list):
    pass  # inserted to fix indentation error
for lg_str in reflection_data['new_learning_goals']:
if lg_str not in [g['description'] for g in self.learning_goals]:
    pass  # inserted to fix indentation error
self.learning_goals.append({"description": lg_str, "status": "pending", "added_ts": datetime.now(timezone.utc).isoformat()})
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated learning goals. Total: {len(self.learning_goals)}")
if isinstance(reflection_data.get('adaptation_strategy_proposals'), list):
    pass  # inserted to fix indentation error
for strat_str in reflection_data['adaptation_strategy_proposals']:
self.adaptation_strategies[f"proposal_{uuid.uuid4().hex[:8]}"] = strat_str
updated_self = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info(f"Updated adaptation strategies. Total: {len(self.adaptation_strategies)}")
if reflection_data.get('learned_facts') or reflection_data.get('prompt_tuning_suggestions'):
    pass  # inserted to fix indentation error
updated_kb_elements = True
if updated_self:
    pass  # inserted to fix indentation error
self.log.info("SelfModel internal state updated from reflection.")
return updated_self, updated_kb_elements
def update_status(self, status: str):
if status != self.current_status:
    pass  # inserted to fix indentation error
self.log.debug(f"SelfModel status changing from '{self.current_status}' to '{status}'")
self.current_status = status
self.add_event_log(f"Status changed to {status}", event_type="status_update")
def add_error_summary(self, error_info: Dict):
self.recent_errors.append(error_info)
self.recent_errors = self.recent_errors[-MAX_RECENT_ERRORS_IN_STATE:]
def backup_directives(self, reason: str):
"""Saves a backup of current directives to a file."""
backup_file = SELF_MOD_BACKUP_DIR / f"core_directives_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{reason}.json"
try:
    pass  # inserted to fix indentation error
with backup_file.open('w') as f:
json.dump(self.core_directives, f, indent=2)
self.log.info(f"Core directives backed up to {backup_file} due to: {reason}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to backup core directives: {e}")
def simulate_internal_dialog(self, topic: str, perspectives: Optional[List[str]]=None) -> str:
"""Simulates an internal dialog about a topic using LLM potentially from different perspectives."""
self.log.info(f"Simulating internal dialog on topic: {topic}")
if perspectives is None:
    pass  # inserted to fix indentation error
perspectives = ["analytical", "creative_explorer", "safety_officer"]
dialog_history = []
full_dialog_str = f"Internal Dialog on: {topic}\n\n"
for persp_idx, perspective_name in enumerate(perspectives):
prompt = f"You are part of an SystemCore's internal dialog. Consider the topic: '{topic}'.\n"
prompt += f"Adopt the perspective of a '{perspective_name}'. What are your thoughts, questions, or suggestions?\n"
if dialog_history:
    pass  # inserted to fix indentation error
prompt += "\nPrevious contributions to this dialog:\n"
for entry in dialog_history[-2:]:
prompt += f"- {entry['perspective']}: {entry['contribution']}\n"
prompt += f"\nYour contribution (as {perspective_name}):"
try:
    pass  # inserted to fix indentation error
contribution = _agent_instance_hack.llm_wrapper.generate(prompt, max_new_tokens=300, temperature=0.6)
dialog_history.append({"perspective": perspective_name, "contribution": contribution})
full_dialog_str += f"Perspective ({perspective_name}): {contribution}\n\n"
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during internal dialog generation for perspective {perspective_name}: {e}")
contribution = f"(Error generating contribution for {perspective_name})"
self.add_event_log(f"Internal dialog simulated on '{topic}'.", data={"dialog": full_dialog_str})
return full_dialog_str
class MotivationEngine:
"""Manages the agent's internal drives and their influence on behavior."""
def __init__(self, drive_configs: Optional[Dict[str, Any]] = None):
self.log = get_logger("MOTIVATION_ENGINE")
self.drives: Dict[str, Any] = {}
self._initialize_drives(drive_configs)
self.log.info("MotivationEngine initialized.")
def _initialize_drives(self, drive_configs: Optional[Dict[str, Any]]):
default_configs = {
"CURIOSITY": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"MASTERY": {"decay_rate": 0.005, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.6},
"ACHIEVEMENT": {"decay_rate": 0.015, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.4},
"NOVELTY_SEEKING": {"decay_rate": 0.012, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.7},
"PRESERVATION": {"decay_rate": 0.001, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.2},
"EFFICIENCY": {"decay_rate": 0.008, "max_level": 1.0, "min_level": 0.1, "initial_level": 0.5},
"SOCIAL_INTERACTION": {"decay_rate": 0.01, "max_level": 1.0, "min_level": 0.0, "initial_level": 0.3},
}
configs = drive_configs if drive_configs is not None else default_configs
for drive_type_str, config in configs.items():
self.drives[drive_type_str] = DriveState(
drive_type=drive_type_str,
level=config.get("initial_level", 0.5),
decay_rate=config.get("decay_rate", 0.01),
max_level=config.get("max_level", 1.0),
min_level=config.get("min_level", 0.0)
)
def update_drives(self):
"""Applies decay and updates drives based on recent experiences or time."""
for drive_type, drive_state in self.drives.items():
drive_state.update(stimulus=0.0)
def process_experience(self, experience: Experience):
"""Updates drives based on a specific experience."""
if experience.type == "tool_output" and experience.content.get("success"):
    pass  # inserted to fix indentation error
if experience.metadata.get("tool_name") == "learn":
    pass  # inserted to fix indentation error
self.drives["CURIOSITY"].update(stimulus=-0.05)
self.drives["MASTERY"].update(stimulus=0.1)
elif "success" in experience.content.get("status", "").lower():
    pass  # inserted to fix indentation error
self.drives["ACHIEVEMENT"].update(stimulus=0.05)
elif experience.type == "error":
    pass  # inserted to fix indentation error
self.drives["PRESERVATION"].update(stimulus=0.1)
self.drives["MASTERY"].update(stimulus=-0.05)
def get_drive_level(self, drive_type: str) -> float:
return self.drives.get(drive_type, DriveState(drive_type=drive_type)).level
def get_all_drive_levels(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_all_drive_levels_serializable(self) -> Dict[str, float]:
return {dt: ds.level for dt, ds in self.drives.items()}
def get_prioritized_drives(self, n: int = 3) -> List[Tuple[str, float]]:
"""Returns top N drives by current level."""
sorted_drives = sorted(self.drives.items(), key=lambda item: item[1].level, reverse=True)
return [(dt, ds.level) for dt, ds in sorted_drives[:n]]
def suggest_goal_type_from_drives(self) -> Optional[str]:
"""Suggests a goal type based on current highest drives."""
top_drives = self.get_prioritized_drives(n=1)
if not top_drives: return None
    pass  # inserted to fix indentation error
top_drive_type = top_drives[0][0]
if top_drive_type == "CURIOSITY":
    pass  # inserted to fix indentation error
return "exploration"
elif top_drive_type == "MASTERY":
    pass  # inserted to fix indentation error
return "skill_improvement"
elif top_drive_type == "ACHIEVEMENT":
    pass  # inserted to fix indentation error
return "task_completion"
elif top_drive_type == "PRESERVATION":
    pass  # inserted to fix indentation error
return "self_maintenance"
elif top_drive_type == "EFFICIENCY":
    pass  # inserted to fix indentation error
return "optimization"
return None
Of course. Continuing from the `DriveState` class definition, here is the remainder of the fully corrected Python script.
```python
level: float
decay_rate: float = 0.01
max_level: float = 1.0
min_level: float = 0.0
last_update_time: float = field(default_factory=time.time)
def update(self, stimulus: float = 0.0):
"""Updates the drive level based on stimulus and decay."""
now = time.time()
time_elapsed = now - self.last_update_time
decay_amount = self.decay_rate * time_elapsed
new_level = self.level - decay_amount + stimulus
self.level = max(self.min_level, min(self.max_level, new_level))
self.last_update_time = now
class MessageType(Enum):
QUERY = "QUERY"
RESPONSE = "RESPONSE"
INFORM = "INFORM"
REQUEST_ACTION = "REQUEST_ACTION"
HEARTBEAT = "HEARTBEAT"
ERROR = "ERROR"
class FileChannel:
"""Implements a simple file-based communication channel for multi-agent systems."""
def __init__(self, agent_id: str, shared_directory: str):
self.agent_id = agent_id
self.shared_dir = Path(shared_directory)
self.shared_dir.mkdir(parents=True, exist_ok=True)
self.inbox_file = self.shared_dir / f"inbox_{self.agent_id}.json"
self.outbox_dir = self.shared_dir
self.log = get_logger(f"COMMS_{agent_id}")
self.handlers: Dict[MessageType, List[Callable[[Message], Optional[Message]]]] = {}
self.log.info(f"FileChannel initialized for agent '{self.agent_id}'. Inbox: {self.inbox_file}")
def _write_message_to_file(self, message: Message, target_file: Path) -> bool:
try:
    pass  # inserted to fix indentation error
with FileLock(str(target_file) + ".lock", timeout=5):
messages = []
if target_file.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
existing_content = target_file.read_text(encoding='utf-8')
if existing_content.strip():
    pass  # inserted to fix indentation error
messages = json.loads(existing_content)
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {target_file}: {e}. Clearing file.")
messages = []
messages.append(message.to_dict())
target_file.write_text(json.dumps(messages, indent=2), encoding='utf-8')
return True
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {target_file}. Message not sent to {message.receiver_id}.")
return False
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error writing message to {target_file}: {e}")
return False
def _read_messages_from_file(self, source_file: Path) -> List[Message]:
messages = []
if not source_file.exists():
    pass  # inserted to fix indentation error
return messages
try:
    pass  # inserted to fix indentation error
with FileLock(str(source_file) + ".lock", timeout=5):
content = source_file.read_text(encoding='utf-8')
if content.strip():
    pass  # inserted to fix indentation error
raw_messages = json.loads(content)
messages = [Message.from_dict(msg_data) for msg_data in raw_messages if isinstance(msg_data, dict)]
source_file.write_text("", encoding='utf-8')
return messages
except FileLockTimeout:
    pass  # inserted to fix indentation error
self.log.warning(f"Timeout acquiring lock for {source_file}. Cannot read messages.")
return []
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Corrupted message file {source_file}: {e}. Clearing file.")
try:
    pass  # inserted to fix indentation error
source_file.write_text("", encoding='utf-8')
except Exception as e_write:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to clear corrupted message file {source_file}: {e_write}")
return []
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error reading messages from {source_file}: {e}")
return []
def send_message(self, message: Message) -> bool:
target_inbox = self.shared_dir / f"inbox_{message.receiver_id}.json"
message.sender_id = self.agent_id
self.log.info(f"Sending {message.type} message to {message.receiver_id}: {message.content.get('summary', str(message.content))[:50]}...")
return self._write_message_to_file(message, target_inbox)
def receive_messages(self) -> List[Message]:
"""Checks and retrieves new messages from the agent's inbox."""
new_messages = self._read_messages_from_file(self.inbox_file)
if new_messages:
    pass  # inserted to fix indentation error
self.log.info(f"Received {len(new_messages)} new messages in inbox.")
return new_messages
def register_handler(self, message_type: MessageType, handler: Callable[[Message], Optional[Message]]):
"""Registers a function to handle specific message types."""
if message_type not in self.handlers:
    pass  # inserted to fix indentation error
self.handlers[message_type] = []
self.handlers[message_type].append(handler)
self.log.debug(f"Registered handler for message type: {message_type.value}")
def process_incoming_messages(self):
"""Processes all messages currently in the inbox using registered handlers."""
messages = self.receive_messages()
for msg in messages:
self.log.debug(f"Processing message ID {msg.id}, Type: {msg.type}, From: {msg.sender_id}")
handled = False
try:
    pass  # inserted to fix indentation error
msg_type_enum = MessageType(msg.type)
if msg_type_enum in self.handlers:
    pass  # inserted to fix indentation error
for handler_func in self.handlers[msg_type_enum]:
try:
    pass  # inserted to fix indentation error
response = handler_func(msg)
if response:
    pass  # inserted to fix indentation error
self.send_message(response)
handled = True
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error handling message {msg.id} with handler {handler_func.__name__}: {e}", exc_info=True)
self.send_message(Message(sender_id=self.agent_id, receiver_id=msg.sender_id, type=MessageType.ERROR.value, content={"original_message_id": msg.id, "error": str(e)}))
if not handled:
    pass  # inserted to fix indentation error
self.log.warning(f"No handler registered for message type {msg.type}. Message ID {msg.id} unhandled.")
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Received unknown message type: {msg.type}. Message ID {msg.id} unhandled.")
class Sensor(ABC):
"""Abstract base class for a sensor."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', config: Dict):
self.id = id
self.embodiment = embodiment
self.config = config
self.log = get_logger(f"SENSOR_{id}")
@abstractmethod
def get_reading(self) -> Any:
"""Returns the current reading from the sensor."""
pass
class Actuator(ABC):
"""Abstract base class for an actuator."""
def __init__(self, id: str, embodiment: 'VirtualEmbodiment', capabilities: List[str], config: Dict):
self.id = id
self.embodiment = embodiment
self.capabilities = capabilities
self.config = config
self.log = get_logger(f"ACTUATOR_{id}")
@abstractmethod
def perform_action(self, action_type: str, **kwargs) -> Dict:
"""Performs a specific action using the actuator."""
pass
class VirtualEmbodiment:
"""Simulated embodiment layer for SystemCore agents. (Can be replaced by Gym environments or more complex sims)"""
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("EMBODIMENT")
self.location = "virtual_lab_control_room"
self.state: Dict[str, Any] = {
"health": 100, "energy": 100,
"emotions": {"curiosity": 0.7, "focus": 0.8, "satisfaction": 0.5, "anxiety": 0.1},
"internal_time": time.time(),
"inventory": ["basic_manipulator_tool", "data_logger_module"],
"active_sensors": ["text_interface", "internal_state_monitor"],
"world_model_accuracy": 0.6
}
self.environment_map = self._init_env()
self.sensors: Dict[str, Sensor] = {}
self.actuators: Dict[str, Actuator] = {}
self.sensory_log: List[Dict] = []
self.MAX_SENSORY_LOG_SIZE = 100
self.gym_env = None
def _init_env(self) -> Dict[str, Any]:
return {
"virtual_lab_control_room": {
"description": "A brightly lit control room with multiple holographic displays showing system diagnostics. A console provides interaction with the core SystemCore systems. Doors lead to 'Data Center' and 'Simulation Bay'.",
"objects": ["diagnostic_console", "emergency_shutdown_button", "research_terminal"],
"exits": {"north": "simulation_bay", "east": "data_center"},
"features": ["interactive_console"]
},
"simulation_bay": {
"description": "A large, reconfigurable bay designed for running complex simulations. Currently, a simple robotics arm simulation is active on one of the platforms.",
"objects": ["robotics_arm_simulation_interface", "environment_config_panel"],
"exits": {"south": "virtual_lab_control_room"},
"features": ["simulation_runner"]
},
"data_center": {
"description": "Rows of servers hum quietly. Access panels show data flow and storage capacity.",
"objects": ["main_database_interface", "backup_power_control"],
"exits": {"west": "virtual_lab_control_room"},
"features": ["data_management_interface"]
},
"systemcore_core_chamber": {
"description": "A shielded chamber housing the agent's primary cognitive core. Direct interaction is limited for safety.",
"objects": ["core_status_monitor", "directive_override_terminal_SECURE"],
"exits": {},
"features": ["introspection_interface"]
}
}
def add_sensor(self, sensor: Sensor):
self.sensors[sensor.id] = sensor
self.log.info(f"Added sensor: {sensor.id}")
def add_actuator(self, actuator: Actuator):
self.actuators[actuator.id] = actuator
self.log.info(f"Added actuator: {actuator.id}")
def list_sensors(self) -> List[Dict]:
return [{"id": s.id, "type": s.__class__.__name__} forsin self.sensors.values()]
def list_actuators(self) -> List[Dict]:
return [{"id": a.id, "type": a.__class__.__name__, "capabilities": a.capabilities} for a in self.actuators.values()]
def get_sensory_input(self) -> List[Dict[str, Any]]:
"""Generate synthetic sensory input based on current environment and internal state."""
self.log.debug(f"Embodiment generating sensory input. Location: {self.location}")
env_details = self.environment_map.get(self.location, {})
self.state["internal_time"] = time.time()
self.state["energy"] = max(0, self.state["energy"] - 0.1)
if self.state["energy"] < 20:
    pass  # inserted to fix indentation error
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"].get("anxiety",0) + 0.1)
sensory_packet = {
"type": "environment_scan",
"source": "virtual_embodiment",
"content": {
"location": self.location,
"description": env_details.get("description", "An undefined space."),
"visible_objects": env_details.get("objects", []),
"available_exits": list(env_details.get("exits", {}).keys()),
"special_features": env_details.get("features", [])
}
}
internal_state_packet = {
"type": "internal_state_report",
"source": "virtual_embodiment_self_monitor",
"content": copy.deepcopy(self.state)
}
self.sensory_log.append(sensory_packet)
self.sensory_log.append(internal_state_packet)
if len(self.sensory_log) > self.MAX_SENSORY_LOG_SIZE:
    pass  # inserted to fix indentation error
self.sensory_log = self.sensory_log[-self.MAX_SENSORY_LOG_SIZE:]
return [sensory_packet, internal_state_packet]
def act(self, action_type: str, target: Optional[str] = None, params: Optional[Dict] = None) -> Dict:
"""
Simulates the agent performing an action in the virtual world.
Returns a dictionary with the result of the action.
"""
self.log.info(f"Embodiment performing action: {action_type}, Target: {target}, Params: {params}")
params = params or {}
result_status = "failure"
message = f"Action '{action_type}' on '{target}' could not be performed as specified."
env_details = self.environment_map.get(self.location, {})
if action_type == "move":
    pass  # inserted to fix indentation error
if target and target in env_details.get("exits", {}):
    pass  # inserted to fix indentation error
new_location = env_details["exits"][target]
self.location = new_location
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
message = f"Moved to {new_location}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot move to '{target}' from {self.location}."
elif action_type == "examine":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
message = f"You examine the {target}. It appears to be a standard {target}."
if target == "diagnostic_console":
    pass  # inserted to fix indentation error
message += " It shows fluctuating green and amber lights."
elif target == "core_status_monitor":
    pass  # inserted to fix indentation error
message += " It indicates: Core Nominal. Directives Stable. Learning Rate: Optimal."
result_status = "success"
elif target and target in env_details.get("features", []):
    pass  # inserted to fix indentation error
message = f"You examine the feature: {target}. It seems operational."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"There is no '{target}' to examine here."
elif action_type == "pickup":
    pass  # inserted to fix indentation error
if target and target in env_details.get("objects", []):
    pass  # inserted to fix indentation error
env_details["objects"].remove(target)
self.state["inventory"].append(target)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.2)
message = f"Picked up {target}."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Cannot pickup '{target}'."
elif action_type == "use_feature":
    pass  # inserted to fix indentation error
feature_name = target
if feature_name and feature_name in env_details.get("features",[]):
    pass  # inserted to fix indentation error
if feature_name == "interactive_console":
    pass  # inserted to fix indentation error
console_output = self._use_interactive_console(params.get("command"))
message = f"Interacted with {feature_name}. Output: {console_output}"
result_status = "success"
elif feature_name == "simulation_runner" and self.location == "simulation_bay":
    pass  # inserted to fix indentation error
sim_result = self._run_simulation(params.get("simulation_name", "default_physics_test"), params.get("config",{}))
message = f"Ran simulation '{params.get('simulation_name')}'. Result: {sim_result}"
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"Feature '{feature_name}' used. Generic interaction occurred."
result_status = "success"
else:
    pass  # inserted to fix indentation error
message = f"No feature '{feature_name}' to use here."
elif action_type == "rest":
    pass  # inserted to fix indentation error
self.state["energy"] = min(100, self.state["energy"] + random.randint(10, 20))
self.state["emotions"]["anxiety"] = max(0.0, self.state["emotions"]["anxiety"] - 0.2)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.1)
message = "You rest and regain some energy. Anxiety decreases."
result_status = "success"
self._modulate_emotions(action_type, result_status)
return {"status": result_status, "message": message, "new_location": self.location if action_type=="move" else None, "updated_inventory": self.state["inventory"] if action_type=="pickup" else None}
def _modulate_emotions(self, action: str, status: str):
em = self.state["emotions"]
if status == "success":
    pass  # inserted to fix indentation error
em["satisfaction"] = min(1.0, em["satisfaction"] + 0.05)
em["anxiety"] = max(0.0, em["anxiety"] - 0.02)
if action in ["explore", "examine", "move_to_new_area"]:
    pass  # inserted to fix indentation error
em["curiosity"] = min(1.0, em["curiosity"] + 0.1)
elif status == "failure":
    pass  # inserted to fix indentation error
em["satisfaction"] = max(0.0, em["satisfaction"] - 0.1)
em["anxiety"] = min(1.0, em["anxiety"] + 0.05)
if action not in ["explore", "examine", "move_to_new_area", "learn"]:
    pass  # inserted to fix indentation error
em["curiosity"] = max(0.1, em["curiosity"] - 0.01)
for key in em:
em[key] = round(min(1.0, max(0.0, em[key])), 2)
self.log.debug(f"Emotions modulated: {em}")
def _use_interactive_console(self, command: Optional[str]) -> str:
if command:
    pass  # inserted to fix indentation error
self.log.info(f"Embodiment: Console command received: '{command}'")
if "diagnostics" in command.lower():
    pass  # inserted to fix indentation error
return "System Diagnostics: All core modules report nominal status. Memory usage at 65%. CPU load at 30%."
elif "query_self_model" in command.lower():
    pass  # inserted to fix indentation error
return f"Self-Model Query Response: {self.agent.self_model.internal_state_narrative[:100]}..."
else:
    pass  # inserted to fix indentation error
return f"Console command '{command}' executed. (Mock Response)"
return "Console ready for input. Available commands: 'diagnostics', 'query_self_model <topic>'."
def _run_simulation(self, sim_name: str, config: Dict) -> str:
self.log.info(f"Embodiment: Running simulation '{sim_name}' with config: {config}")
time.sleep(random.uniform(0.5, 2.0))
success_chance = 0.8
if "risky_config" in config:
    pass  # inserted to fix indentation error
success_chance = 0.4
if random.random() < success_chance:
    pass  # inserted to fix indentation error
outcome_value = random.randint(50,100)
self.state["emotions"]["satisfaction"] = min(1.0, self.state["emotions"]["satisfaction"] + 0.3)
self.state["emotions"]["curiosity"] = min(1.0, self.state["emotions"]["curiosity"] + 0.1)
return f"Simulation '{sim_name}' completed successfully. Outcome metric: {outcome_value}."
else:
    pass  # inserted to fix indentation error
error_code = random.randint(1000,2000)
self.state["emotions"]["anxiety"] = min(1.0, self.state["emotions"]["anxiety"] + 0.2)
return f"Simulation '{sim_name}' failed. Error code: {error_code}. Check configuration."
def summary(self) -> str:
"""Returns a string summary of the embodiment's current state."""
return (
f"Location: {self.location}\n"
f"Description: {self.environment_map.get(self.location, {}).get('description')}\n"
f"Visible Objects: {self.environment_map.get(self.location, {}).get('objects')}\n"
f"Exits: {list(self.environment_map.get(self.location, {}).get('exits', {}).keys())}\n"
f"Internal State (summary): Energy={self.state['energy']}, Emotions={self.state['emotions']}, Inventory={self.state['inventory']}"
)
class CognitiveCycle:
def __init__(self, agent: 'CognitiveSystem'):
self.agent = agent
self.log = get_logger("COGNITIVE_CYCLE")
self.last_perception_time: float = 0.0
self.perception_module = PerceptionModule(agent)
self.planning_module = PlanningModule(agent)
def run_cycle(self) -> bool:
global LAST_METACOGNITIVE_CHECK_CYCLE, LAST_LEARNING_MODULE_UPDATE_CYCLE
start_time = time.time()
self.log.debug(f"--- Starting Cognitive Cycle {self.agent.cycle_count} --- Status: {self.agent.self_model.current_status if self.agent.self_model else 'N/A_SM'}, Goal Stack Depth: {len(self.agent.goal_stack)}")
self.agent.current_goal_outcome = None
active_goal_before_cycle_dict = copy.deepcopy(self.agent.state['goals'].get('active')) if self.agent.state['goals'].get('active') else None
self.agent.last_error = None
cycle_ok = False
try:
    pass  # inserted to fix indentation error
observations = self.perception_module.perceive()
self.last_perception_time = time.time()
understanding_result = self._understand(observations)
if self.agent.self_model and (self.agent.cycle_count - LAST_METACOGNITIVE_CHECK_CYCLE >= METACOGNITIVE_CHECK_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering proactive metacognitive check (Cycle {self.agent.cycle_count}).")
anomalies = self.agent.self_model.perform_metacognitive_check()
LAST_METACOGNITIVE_CHECK_CYCLE = self.agent.cycle_count
if anomalies:
    pass  # inserted to fix indentation error
self.log.warning(f"Metacognitive anomalies detected: {anomalies}")
for anomaly_desc in anomalies:
self.agent._create_metacognitive_goal(anomaly_desc)
if self.agent.learning_module and (self.agent.cycle_count - LAST_LEARNING_MODULE_UPDATE_CYCLE >= LEARNING_MODULE_UPDATE_INTERVAL_CYCLES):
    pass  # inserted to fix indentation error
self.log.info(f"Triggering learning module update (Cycle {self.agent.cycle_count}).")
self.agent.learning_module.learn_from_recent_experiences()
LAST_LEARNING_MODULE_UPDATE_CYCLE = self.agent.cycle_count
deliberation_decision = self._deliberate(understanding_result)
action_type = deliberation_decision.get("chosen_action_type", "idle")
next_goal_dict_from_delib = deliberation_decision.get("next_goal")
newly_generated_pending_goals = deliberation_decision.get("new_pending_goals", [])
if newly_generated_pending_goals:
    pass  # inserted to fix indentation error
with self.agent.lock:
pending_list = self.agent.state['goals'].setdefault('pending', [])
for ng_dict in newly_generated_pending_goals:
if isinstance(ng_dict, dict):
    pass  # inserted to fix indentation error
if not any(p['id'] == ng_dict['id'] for p in pending_list):
    pass  # inserted to fix indentation error
pending_list.append(ng_dict)
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate pending goal from deliberation: {ng_dict.get('id')}")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation produced non-dict pending goal: {ng_dict}")
def get_priority_val(goal_dict):
p = goal_dict.get('priority', 'MEDIUM')
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_list.sort(key=get_priority_val, reverse=True)
self.agent.save_state()
goal_to_execute_this_cycle_dict: Optional[Dict] = None
if action_type == "new_goal" or action_type == "pending_goal" or action_type == "active_goal_continue":
    pass  # inserted to fix indentation error
if next_goal_dict_from_delib and isinstance(next_goal_dict_from_delib, dict):
    pass  # inserted to fix indentation error
goal_to_execute_this_cycle_dict = next_goal_dict_from_delib
self.log.info(f"Deliberation selected goal for execution: {goal_to_execute_this_cycle_dict.get('goal', 'N/A')[:50]} (ID: {goal_to_execute_this_cycle_dict.get('id')})")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation chose '{action_type}' but no valid 'next_goal' provided. Idling.")
action_type = "idle"
if goal_to_execute_this_cycle_dict:
    pass  # inserted to fix indentation error
current_goal_obj = Goal.from_dict(goal_to_execute_this_cycle_dict)
if not current_goal_obj.plan or current_goal_obj.status == GoalStatus.PENDING or current_goal_obj.replan_count > 0:
    pass  # inserted to fix indentation error
plan_steps, thought_str = self.planning_module.generate_plan(current_goal_obj)
current_goal_obj.plan = plan_steps
current_goal_obj.thought = thought_str
current_goal_obj.replan_count = 0
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = self._act(current_goal_obj)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"No plan available or generated for goal: {current_goal_obj.goal[:50]}. Goal may fail.")
self.agent.current_goal_outcome = False
else:
    pass  # inserted to fix indentation error
self.agent.current_goal_outcome = True
if time.time() - LAST_DELIBERATION_TIME > IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
self.log.info("Performing idle deliberation...")
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
cycle_ok = True
except (PlanningError, ExecutionError, ToolNotFoundError, CodeGenerationError,
    pass  # inserted to fix indentation error
SelfModificationError, LogicError, LLMError, SecurityError, ConfigurationError,
MemoryError, PerceptionError, UnderstandingError, DeliberationError,
RecursionDepthError, SimulationError, CommunicationError, EmbodimentError,
LearningError, SafetyViolationError) as agent_cycle_err:
self.log.error(f"Cognitive cycle terminated for current goal processing due to Agent Error: {agent_cycle_err}", exc_info=False)
self.agent.current_goal_outcome = False
self.agent.last_error = agent_cycle_err
cycle_ok = True
except Exception as critical_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL Cognitive Cycle Error: {critical_err}", exc_info=True)
self.agent.last_error = critical_err
STOP_SIGNAL_RECEIVED.set()
cycle_ok = False
finally:
    pass  # inserted to fix indentation error
self.log.debug(f"--- Cognitive Cycle {self.agent.cycle_count} Finished ({time.time() - start_time:.3f}s) ---")
return cycle_ok
@retry(attempts=2, delay=2, retry_on=(LLMError, UnderstandingError))
def _understand(self, observations: List[Dict]) -> Dict[str, Any]:
"""Processes observations to update world model and identify key information."""
self.log.debug(f"Understanding {len(observations)} observations...")
understanding_summary = "Observations processed."
processed_info = {"relevant_entities": [], "key_events": [], "state_changes": []}
if observations:
    pass  # inserted to fix indentation error
prompt = "You are an AI agent. Synthesize the following observations into a coherent understanding of the current situation. Identify key entities, events, and any significant changes in the environment or your internal state. Focus on information relevant to achieving current goals.\n\nObservations:\n"
for obs in observations:
prompt += f"- Type: {obs.get('type')}, Source: {obs.get('source')}, Content: {str(obs.get('content'))[:200]}...\n"
prompt += "\nProvide your synthesis as a JSON object: {\"summary_of_situation\": \"str\", \"key_entities_mentioned\": [\"str\"], \"notable_events_or_changes\": [\"str\"], \"potential_impact_on_goals\": \"str\"}"
try:
    pass  # inserted to fix indentation error
llm_response_str = self.agent.llm_wrapper.generate(prompt, max_new_tokens=500)
synthesis = extract_json_robust(llm_response_str)
if not synthesis.get("error"):
    pass  # inserted to fix indentation error
understanding_summary = synthesis.get("summary_of_situation", understanding_summary)
processed_info["relevant_entities"] = synthesis.get("key_entities_mentioned", [])
processed_info["key_events"] = synthesis.get("notable_events_or_changes", [])
processed_info["potential_impact"] = synthesis.get("potential_impact_on_goals")
self.log.info(f"Understanding synthesized: {understanding_summary[:100]}...")
for event_str in processed_info["key_events"]:
exp_entry = Experience(content=event_str, type="environment_event", metadata={"source": "perception_synthesis"})
self.agent.memory_system.add_memory_entry(exp_entry, persist_to_vector=True)
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM failed to synthesize understanding: {synthesis.get('error')}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error during LLM-based understanding: {e}")
return {"summary": understanding_summary, "processed_info": processed_info, "raw_observations": observations}
@retry(attempts=MAX_REPLAN_ATTEMPTS, delay=3, retry_on=(LLMError, DeliberationError))
def _deliberate(self, understanding_result: Dict) -> Dict:
"""
Core deliberation logic: goal management, selection, and generation.
Returns a dict: {"chosen_action_type": str, "next_goal": Optional[Goal_dict],
"new_pending_goals": List[Goal_dict]}
"""
global LAST_DELIBERATION_TIME
LAST_DELIBERATION_TIME = time.time()
self.log.info("Deliberating on current situation and goals...")
decision = {"chosen_action_type": "idle", "next_goal": None, "new_pending_goals": []}
pending_goals = self.agent.state['goals'].get('pending', [])
active_goal_dict = self.agent.state['goals'].get('active')
def get_priority_val(goal_dict_item):
p = goal_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p, GoalPriority): return p.value
    pass  # inserted to fix indentation error
if isinstance(p, str): return GoalPriority[p.upper()].value
    pass  # inserted to fix indentation error
return p
pending_goals.sort(key=get_priority_val, reverse=True)
highest_priority_pending: Optional[Dict] = None
if pending_goals:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_goals[0]
if active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
active_priority_val = get_priority_val(active_goal_dict)
pending_priority_val = get_priority_val(highest_priority_pending)
if pending_priority_val > active_priority_val:
    pass  # inserted to fix indentation error
self.log.info(f"Pending goal '{highest_priority_pending.get('goal')}' (Prio: {pending_priority_val}) preempts active goal '{active_goal_dict.get('goal')}' (Prio: {active_priority_val}).")
with self.agent.lock:
paused_goal_dict = copy.deepcopy(active_goal_dict)
paused_goal_dict['status'] = GoalStatus.PAUSED.value
self.agent.goal_stack.append({'goal_data': paused_goal_dict, 'snapshot_time': datetime.now(timezone.utc).isoformat()})
self.log.info(f"Pushed active goal '{active_goal_dict.get('goal')[:30]}' to stack (paused).")
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if active_goal_dict:
    pass  # inserted to fix indentation error
self.log.debug(f"Continuing with active goal: {active_goal_dict.get('goal')[:50]}")
decision["chosen_action_type"] = "active_goal_continue"
decision["next_goal"] = active_goal_dict
return decision
if not active_goal_dict and highest_priority_pending:
    pass  # inserted to fix indentation error
with self.agent.lock:
new_active_goal_dict = pending_goals.pop(0)
new_active_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = new_active_goal_dict
decision["chosen_action_type"] = "pending_goal"
decision["next_goal"] = new_active_goal_dict
self.agent.save_state()
return decision
if not active_goal_dict and not pending_goals:
    pass  # inserted to fix indentation error
self.log.info("No active or pending goals. Considering idle tasks or new goal generation.")
if time.time() - LAST_DELIBERATION_TIME >= IDLE_DELIBERATION_INTERVAL_SECONDS:
    pass  # inserted to fix indentation error
idle_goal = Goal(
goal="Perform general self-assessment and explore the virtual environment.",
priority=GoalPriority.LOW,
origin="idle_deliberation",
associated_directive_ids=["directive_learn", "directive_curiosity", "directive_metacog"]
).to_dict()
decision["new_pending_goals"].append(idle_goal)
decision["chosen_action_type"] = "idle_new_goal_generated"
return decision
else:
    pass  # inserted to fix indentation error
pass
for obs in understanding_result.get('raw_observations', []):
if obs.get('type') == 'tool_result' and obs.get('content',{}).get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
sub_goal_dict = obs['content'].get('sub_goal_data')
if sub_goal_dict and isinstance(sub_goal_dict, dict):
    pass  # inserted to fix indentation error
self.log.info(f"Deliberation found subgoal request from tool output: {sub_goal_dict.get('goal')[:50]}")
if not any(p['id'] == sub_goal_dict['id'] for p in decision["new_pending_goals"]):
    pass  # inserted to fix indentation error
decision["new_pending_goals"].append(sub_goal_dict)
if not active_goal_dict:
    pass  # inserted to fix indentation error
self.log.info(f"Activating immediate subgoal: {sub_goal_dict.get('goal')[:50]}")
sub_goal_dict['status'] = GoalStatus.ACTIVE.value
self.agent.state['goals']['active'] = sub_goal_dict
decision["chosen_action_type"] = "new_goal"
decision["next_goal"] = sub_goal_dict
with self.agent.lock:
self.agent.save_state()
return decision
self_model_summary = self.agent.self_model.get_summary_for_prompt(include_tool_reliability=True)
understanding_summary = understanding_result.get('summary', 'No specific understanding summary.')
pressing_issue = understanding_result.get('processed_info',{}).get('potential_impact', 'None identified.')
interp_con_val = understanding_result.get('interpretation_confidence', 0.7)
recent_memory_context = self.agent.memory_system.get_knowledge_summary_for_prompt(understanding_summary, max_facts=3)
prompt_parts = [
f"**Deliberation Context for {AGENT_NAME}:**",
f"* **Self-Model Snapshot:**\n{self_model_summary}",
f"* **Current Understanding (Confidence: {interp_con_val:.2f}):** {understanding_summary}",
f"* **Most Pressing Issue/Opportunity Identified:** {pressing_issue}",
f"* **Recent Key Memories:**\n{recent_memory_context}",
f"* **Short-Term Memory (STM):**\n{self.agent.memory_system.get_short_term_memory_summary()}",
f"* **Pending Goals ({len(pending_goals)}):** {json.dumps([g for g in pending_goals[:3]], indent=2)}",
f"* **Current Active Goal:** {'None' if not active_goal_dict else f'{active_goal_dict.get(\"goal\")[:100]}... (ID: {active_goal_dict.get(\"id\")})'}",
f"* **Agent Core Directives (Weighted):**\n{json.dumps(self.agent.self_model.core_directives, indent=2)}\n",
"**Task: Advanced Deliberation & Action Selection**",
"1. **Analyze Situation & Drives:** Based on ALL context (self-model, understanding, drives, memories, goals, directives), what is the most critical aspect demanding attention or the best opportunity for progress? Current Drives (Scale 0-1, High=Strong): " + \
f"{self.agent.motivation_engine.get_all_drive_levels_serializable()}.",
"2. **Generate Options:** Propose potential actions or new goals. Consider:",
"    - Responding to user commands (if any, as 'user_command' type in observations).",
"    - Continuing current `active_goal` (if suitable and has a plan).",
"    - Selecting the highest priority `pending_goal` (if `active_goal` is unsuitable/complete).",
"    - Performing `reflection` or `self_assessment` (if mandatory timers, drives like low CONFIDENCE, or pressing issues suggest it).",
"    - Generating `new_goal`(s) based on Drives (e.g., high CURIOSITY -> exploration goal), Directives (e.g., low-eval directive -> improvement goal), or identified opportunities. New goals require `goal` (str), `priority` (float 0.0-1.0), `origin` (str e.g., 'drive_curiosity', 'directive_alignment'). Optional: `context_for_planning` (dict), `associated_directive_ids` (list of str).",
"    - (Conceptual) Simulate 1-2 high-priority new goal ideas or current plan steps for viability before committing if uncertainty is high or consequence severe (briefly note simulation outcome).",
"    - Remaining `idle` if no pressing tasks and no valuable proactive actions are apparent. Use `idle_new_goal_generated` if you create a new goal as part of being idle.",
"3. **Prioritize & Select:** Choose the SINGLE most appropriate action/goal for the *immediate next cycle*. Justify your choice especially if it deviates from obvious triggers, high drives, or highest priority pending. State reasoning clearly.",
"4. **Manage Goal List:** If generating new goals, add them to `new_pending_goals` list. If selecting an existing pending goal it moves to `next_goal` and is removed from pending internally (do not include in `new_pending_goals` output).",
"5. **Output ONLY a JSON object with the following keys:**",
"    - `reasoning`: (string) Your detailed thought process for the decision, including drive/directive considerations and option evaluation.",
"    - `chosen_action_type`: (string) One of: 'resume_active_goal', 'pending_goal', 'new_goal', 'reflection', 'self_assessment', 'external_command_action', 'idle', 'idle_new_goal_generated'.",
"    - `next_goal`: (object:Goal or null) The *full goal object* (matching Goal dataclass structure) selected for immediate execution. Null if idle/reflection/assessment without a direct goal target.",
"    - `new_pending_goals`: (list of object:Goal) Any *newly generated* goals (not chosen for immediate execution). Include full Goal objects. Empty list if no new goals generated.",
"CRITICAL: Do NOT put an already existing pending goal that you selected into `new_pending_goals`. `next_goal` handles that. Only truly NEWLY conceptualized goals go into `new_pending_goals`."
]
deliberation_prompt = "\n".join(prompt_parts)
self.log.debug(f"Deliberation prompt for LLM: \n{deliberation_prompt}")
if not self.agent.llm_wrapper:
    pass  # inserted to fix indentation error
raise LLMError("LLMWrapper not available for deliberation.")
deliberation_llm_response = self.agent.llm_wrapper.generate(
deliberation_prompt,
system_message="You are the core deliberation faculty of an advanced AI agent. Analyze the situation comprehensively, consider drives and directives, and make strategic decisions. Respond ONLY in JSON as per output instructions.",
temperature=0.5
)
if extract_json_robust(deliberation_llm_response).get("error") and not \
    pass  # inserted to fix indentation error
(isinstance(deliberation_llm_response,str) and deliberation_llm_response.strip().startswith("{")):
raise DeliberationError(f"LLM deliberation call failed or returned non-JSON: {extract_json_robust(deliberation_llm_response).get('error')}")
deliberation_decision = extract_json_robust(deliberation_llm_response)
required_delib_keys = ['reasoning', 'chosen_action_type', 'next_goal', 'new_pending_goals']
for key in required_delib_keys:
if key not in deliberation_decision:
    pass  # inserted to fix indentation error
self.log.error(f"Deliberation JSON response missing key: '{key}'. Received keys: {deliberation_decision.keys()}")
if key == 'new_pending_goals':
    pass  # inserted to fix indentation error
deliberation_decision[key] = []
elif key == 'next_goal':
    pass  # inserted to fix indentation error
deliberation_decision[key] = None
else:
    pass  # inserted to fix indentation error
deliberation_decision[key] = "Error: Missing from LLM Output"
if not isinstance(deliberation_decision.get('new_pending_goals'), list):
    pass  # inserted to fix indentation error
self.log.warning("Deliberation 'new_pending_goals' was not a list. Resetting to empty list.")
deliberation_decision['new_pending_goals'] = []
if deliberation_decision.get('next_goal') is not None and not isinstance(deliberation_decision.get('next_goal'), dict):
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation 'next_goal' was not a dict or null. Setting to null. Value: {deliberation_decision.get('next_goal')}")
deliberation_decision['next_goal'] = None
with self.agent.lock:
newly_generated_pending_dicts = deliberation_decision.get('new_pending_goals', [])
if isinstance(newly_generated_pending_dicts, list) and newly_generated_pending_dicts:
    pass  # inserted to fix indentation error
current_pending_list = self.agent.state['goals'].setdefault('pending', [])
for new_goal_dict in newly_generated_pending_dicts:
if isinstance(new_goal_dict, dict) and new_goal_dict.get('goal') and new_goal_dict.get('priority'):
    pass  # inserted to fix indentation error
new_goal_obj = Goal.from_dict(new_goal_dict)
new_goal_obj.status = GoalStatus.PENDING
if not any(p['id'] == new_goal_obj.id for p in current_pending_list):
    pass  # inserted to fix indentation error
current_pending_list.append(new_goal_obj.to_dict())
self.log.info(f"Added new goal '{new_goal_obj.goal[:50]}...' to pending list from deliberation.")
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Skipping duplicate new goal '{new_goal_obj.goal[:50]}...'")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Deliberation proposed invalid new pending goal: {new_goal_dict}")
action_type = deliberation_decision.get('chosen_action_type')
selected_next_goal_dict = deliberation_decision.get('next_goal')
current_active_goal_obj = self.agent.get_active_goal_object()
if action_type == 'pending_goal':
    pass  # inserted to fix indentation error
pending_list_objs = [Goal.from_dict(g) for g in self.agent.state['goals'].get('pending', []) if isinstance(g, dict)]
if selected_next_goal_dict and 'id' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
found_idx = -1
for i, pg_obj in enumerate(pending_list_objs):
if pg_obj.id == selected_next_goal_dict.get('id'):
    pass  # inserted to fix indentation error
found_idx = i
break
if found_idx != -1:
    pass  # inserted to fix indentation error
selected_goal_obj = pending_list_objs.pop(found_idx)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
selected_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = selected_goal_obj.to_dict()
deliberation_decision['next_goal'] = selected_goal_obj.to_dict()
self.log.info(f"Moved pending goal {selected_goal_obj.id} ('{selected_goal_obj.goal[:50]}') to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM selected pending goal by ID {selected_next_goal_dict.get('id')}, but not found in list. Idling.")
action_type = "idle"
elif pending_list_objs:
    pass  # inserted to fix indentation error
highest_priority_pending = pending_list_objs.pop(0)
self.agent.state['goals']['pending'] = [g.to_dict() for g in pending_list_objs]
highest_priority_pending.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = highest_priority_pending.to_dict()
deliberation_decision['next_goal'] = highest_priority_pending.to_dict()
self.log.info(f"Deliberation chose 'pending_goal' without specific ID; moved highest priority '{highest_priority_pending.goal[:30]}...' to active.")
else:
    pass  # inserted to fix indentation error
self.log.warning("Deliberation chose 'pending_goal' but no pending goals available. Idling.")
action_type = "idle"
elif action_type == 'new_goal' or action_type == 'idle_new_goal_generated':
    pass  # inserted to fix indentation error
if selected_next_goal_dict and 'goal' in selected_next_goal_dict and 'priority' in selected_next_goal_dict:
    pass  # inserted to fix indentation error
new_active_goal_obj = Goal.from_dict(selected_next_goal_dict)
new_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = new_active_goal_obj.to_dict()
deliberation_decision['next_goal'] = new_active_goal_obj.to_dict()
self.log.info(f"Deliberation created and activated new goal: {new_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'new_goal' but 'next_goal' data was invalid. Idling.")
action_type = "idle"
elif action_type == 'resume_active_goal':
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
deliberation_decision['next_goal'] = current_active_goal_obj.to_dict()
current_active_goal_obj.status = GoalStatus.ACTIVE
self.agent.state['goals']['active'] = current_active_goal_obj.to_dict()
self.log.info(f"Deliberation chose to resume current active goal: {current_active_goal_obj.goal[:30]}...")
else:
    pass  # inserted to fix indentation error
self.log.warning("LLM chose 'resume_active_goal' but no active goal. Idling.")
action_type = "idle"
elif action_type in ['idle', 'reflection', 'self_assessment', 'external_command_action']:
    pass  # inserted to fix indentation error
if current_active_goal_obj:
    pass  # inserted to fix indentation error
current_active_goal_obj.status = GoalStatus.PAUSED
self.log.info(f"Current goal '{current_active_goal_obj.goal[:30]}' PAUSED due to {action_type}.")
pending_list_dicts = self.agent.state['goals'].setdefault('pending', [])
if not any(g['id'] == current_active_goal_obj.id for g in pending_list_dicts):
    pass  # inserted to fix indentation error
pending_list_dicts.insert(0, current_active_goal_obj.to_dict())
else:
    pass  # inserted to fix indentation error
self.log.debug(f"Not re-adding paused goal {current_active_goal_obj.id} to pending as it's already there.")
self.agent.state['goals']['active'] = None
deliberation_decision['next_goal'] = None
else:
    pass  # inserted to fix indentation error
self.log.warning(f"Unknown action type from deliberation: {action_type}. Defaulting to Idle.")
action_type = "idle"
deliberation_decision['chosen_action_type'] = "idle"
deliberation_decision['next_goal'] = None
self.agent.state['goals'].get('pending',[]).sort(key=get_priority_val, reverse=True)
self.agent.save_state()
self.log.info(f"Deliberation complete. Chosen Action: {deliberation_decision.get('chosen_action_type')}. Reason: {deliberation_decision.get('reasoning','')[:100]}...")
return deliberation_decision
def _act(self, current_goal_obj: Goal) -> bool:
"""
Executes the current plan for the active_goal.
Returns True if goal considered successfully processed for this cycle, False if critical error.
"""
self.log.info(f"Acting on goal: {current_goal_obj.goal[:50]} (Plan steps: {len(current_goal_obj.plan)})")
plan_steps = current_goal_obj.plan
if not plan_steps:
    pass  # inserted to fix indentation error
self.log.warning("No steps in plan to execute.")
return True
step_to_execute = plan_steps[0]
tool_name = step_to_execute.get("tool_name")
params = step_to_execute.get("params", {})
step_id = step_to_execute.get("step_id", "unknown_step")
if not tool_name:
    pass  # inserted to fix indentation error
self.log.error(f"Step {step_id} in plan for goal {current_goal_obj.id} has no tool_name.")
current_goal_obj.outcome = "failed_step_execution"
current_goal_obj.result_details = {"error": "Invalid plan step: no tool_name."}
return False
try:
    pass  # inserted to fix indentation error
step_exec_info = {"current_goal_id": current_goal_obj.id, "current_step_id": step_id, "plan_step_details": step_to_execute}
tool_result = self.agent.tool_manager.execute_tool(tool_name, params, current_step_info=step_exec_info)
experience = Experience(
triggering_goal_id=current_goal_obj.id,
action_taken={"tool_name": tool_name, "params": params, "step_id": step_id},
observation_result=tool_result,
reward_signal=self._calculate_reward(tool_result, current_goal_obj),
internal_state_before=self.agent.self_model.beliefs,
internal_state_after=self.agent.self_model.beliefs
)
self.agent.learning_module.add_experience(experience)
execution_info = tool_result.get('_exec_info', {})
successful_execution = execution_info.get('execution_successful', False)
if tool_name == "report_result":
    pass  # inserted to fix indentation error
final_status = tool_result.get("status", "unknown")
if final_status == "success":
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.COMPLETED
current_goal_obj.outcome = "success"
else:
    pass  # inserted to fix indentation error
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = final_status
current_goal_obj.result_details = tool_result
current_goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
current_goal_obj.plan = []
self.log.info(f"Goal '{current_goal_obj.goal[:50]}' processing finished by report_result. Status: {final_status}")
elif not successful_execution:
    pass  # inserted to fix indentation error
self.log.warning(f"Tool '{tool_name}' execution failed. Error: {tool_result.get('error', 'Unknown error')}")
new_plan_tuple = self.planning_module.replan_if_needed(current_goal_obj, tool_result, self.agent.cognitive_cycle.perception_module.perceive()[0] if self.agent.cognitive_cycle.perception_module.perceive() else None)
if new_plan_tuple:
    pass  # inserted to fix indentation error
current_goal_obj.plan, current_goal_obj.thought = new_plan_tuple
self.log.info(f"Successfully re-planned for goal {current_goal_obj.id}.")
else:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to re-plan for goal {current_goal_obj.id} after tool failure. Goal will likely fail.")
current_goal_obj.outcome = "failed_replan"
current_goal_obj.plan = []
else:
    pass  # inserted to fix indentation error
if current_goal_obj.plan:
    pass  # inserted to fix indentation error
current_goal_obj.plan.pop(0)
if not current_goal_obj.plan:
    pass  # inserted to fix indentation error
self.log.warning(f"Plan for goal '{current_goal_obj.goal[:50]}' ended without 'report_result'. Goal might be incomplete.")
with self.agent.lock:
if self.agent.state['goals'].get('active') and self.agent.state['goals']['active']['id'] == current_goal_obj.id:
    pass  # inserted to fix indentation error
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
return True
except AgentError as e:
    pass  # inserted to fix indentation error
self.log.error(f"AgentError during action execution for goal '{current_goal_obj.goal[:50]}': {e}", exc_info=True)
current_goal_obj.status = GoalStatus.FAILED
current_goal_obj.outcome = f"AgentError: {type(e).__name__}"
current_goal_obj.result_details = {"error": str(e), "error_type": type(e).__name__}
current_goal_obj.plan = []
with self.agent.lock:
self.agent.state['goals']['active'] = current_goal_obj.to_dict()
self.agent.save_state()
self.agent.last_error = e
return False
def _calculate_reward(self, tool_result: Dict, goal_obj: Goal) -> float:
"""Calculates a reward signal based on tool execution outcome and goal relevance."""
reward = 0.0
exec_info = tool_result.get('_exec_info', {})
if exec_info.get('execution_successful'):
    pass  # inserted to fix indentation error
reward += 0.1
if tool_result.get('status') == 'success':
    pass  # inserted to fix indentation error
reward += 0.2
else:
    pass  # inserted to fix indentation error
reward -= 0.5
if tool_result.get('status') == 'sub_goal_prepared':
    pass  # inserted to fix indentation error
reward += 0.1
return round(reward, 2)
class CognitiveSystem:
def __init__(self):
self.log = get_logger("AGENT_CORE")
self._status: str = "Booting"
self.lock = threading.Lock()
self.state: Dict[str, Any] = {}
self.goal_stack: List[Dict] = []
self.cycle_count: int = 0
self.last_error: Optional[Exception] = None
self.current_goal_outcome: Optional[bool] = None
self.agent_id = AGENT_NAME
global _agent_instance_hack
_agent_instance_hack = self
self.llm_wrapper: BaseLLMWrapper
self.tool_manager: ToolExecutor
self.memory_system: MemorySystem
self.self_model: SelfModel
self.cognitive_cycle: CognitiveCycle
self.perception_module: PerceptionModule
self.learning_module: LearningModule
self.planning_module: PlanningModule
self.safety_module: SafetyModule
self.motivation_engine: MotivationEngine
self.self_modification_unit: SelfModificationTools
self.embodiment: Optional[VirtualEmbodiment] = None
self.comms_channel: Optional[FileChannel] = None
self.playwright_instance: Optional[Any] = None
self.playwright_browser: Optional[Any] = None
self.playwright_context: Optional[Any] = None
self.playwright_page: Optional[Any] = None
self.state['flags'] = {}
try:
    pass  # inserted to fix indentation error
self._initialize_agent()
self._update_status("Initialized")
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Initialization Complete --- Status: {self._status} ---")
self.log.info(f"LLM Model: {LLM_MODEL_NAME_OR_PATH}, Device: {LLM_DEVICE}")
self.log.info(f"Workspace: {WORKSPACE_DIR}")
self.log.info(f"Max Context Tokens: {MAX_LLM_CONTEXT_TOKENS}, Max Response Tokens: {MAX_LLM_RESPONSE_TOKENS}")
self.log.warning(f"Shell Tool Enabled: {ENABLE_SHELL_TOOL}")
self.log.warning(f"Code Generation Tool Enabled: {ENABLE_CODE_GENERATION_TOOL}")
self.log.warning(f"Self Modification Enabled: {ENABLE_SELF_MODIFICATION}")
if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or ENABLE_SELF_MODIFICATION:
    pass  # inserted to fix indentation error
self.log.critical("HIGH-RISK CAPABILITIES ARE ENABLED. RUN WITH EXTREME CAUTION IN ISOLATED ENVIRONMENT.")
except Exception as e_init:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR during agent initialization: {e_init}", exc_info=True)
self.shutdown()
raise ConfigurationError(f"Agent initialization failed critically: {e_init}") from e_init
def _initialize_agent(self):
self.log.info("Starting agent initialization sequence...")
self._update_status("Initializing State")
self.state = self._initialize_state()
self.cycle_count = self.state.get("cycle_count", 0)
self.goal_stack = self.state.get("goal_stack", [])
self._update_status("Initializing LLM")
if LLM_MODEL_NAME_OR_PATH == "mock":
    pass  # inserted to fix indentation error
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif LLM_MODEL_NAME_OR_PATH.startswith("gemini-"):
    pass  # inserted to fix indentation error
if not GOOGLE_GENAI_AVAILABLE:
    pass  # inserted to fix indentation error
raise ConfigurationError("Cannot use Gemini model: google-generativeai library not installed.")
self.llm_wrapper = GeminiLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
elif TRANSFORMERS_AVAILABLE:
    pass  # inserted to fix indentation error
global LLM_PIPELINE, LLM_TOKENIZER
self.llm_wrapper = TransformersLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
else:
    pass  # inserted to fix indentation error
self.log.warning(f"LLM_MODEL '{LLM_MODEL_NAME_OR_PATH}' not fully configured for wrapper selection, using Mock.")
self.llm_wrapper = MockLLMWrapper(LLM_MODEL_NAME_OR_PATH, LLM_DEVICE, LLM_DEVICE_ID, MAX_LLM_CONTEXT_TOKENS, get_logger("LLM_WRAPPER"))
self.llm_wrapper._initialize_model()
self._update_status("Initializing MemorySystem")
self.memory_system = MemorySystem(self)
self._update_status("Initializing SelfModel")
self.self_model = SelfModel(self.state, DEFAULT_CORE_DIRECTIVES)
self._update_status("Initializing ToolManager")
self.tool_manager = ToolExecutor(self)
self.self_modification_unit = SelfModificationTools(AGENT_CODE_DIR, SELF_MOD_BACKUP_DIR, self)
_init_self_mod_tools(self, self.tool_manager)
self._update_status("Initializing SystemCore Modules")
self.learning_module = LearningModule(self)
self.safety_module = SafetyModule(self)
self.motivation_engine = MotivationEngine()
self._update_status("Initializing Embodiment")
self.embodiment = VirtualEmbodiment(self)
self.log.info(f"Initialized VirtualEmbodiment. Current location: {self.embodiment.location}")
self._update_status("Initializing Communication Channel")
self.comms_channel = FileChannel(agent_id=AGENT_NAME, shared_directory=str(AGENT_COMMS_DIR))
self._setup_communication_handlers()
self._update_status("Initializing CognitiveCycle")
self.cognitive_cycle = CognitiveCycle(self)
self.perception_module = self.cognitive_cycle.perception_module
self.planning_module = self.cognitive_cycle.planning_module
self._initialize_resource_monitor()
self._initialize_playwright()
if self.tool_manager:
    pass  # inserted to fix indentation error
self.tool_manager.check_playwright_browsers()
self.log.info("Agent component initialization finished.")
def _initialize_state(self) -> Dict[str, Any]:
self.log.info(f"Initializing state from {STATE_FILE} or creating default.")
if STATE_FILE.exists():
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
with STATE_FILE.open('r') as f:
state = json.load(f)
state.setdefault('goals', {'pending': [], 'active': None, 'completed': [], 'failed': []})
for key in ['pending', 'completed', 'failed']:
if not isinstance(state['goals'].get(key), list):
    pass  # inserted to fix indentation error
state['goals'][key] = []
state.setdefault('cycle_count', 0)
state.setdefault('knowledge_base', {})
state.setdefault('goal_stack', [])
state.setdefault('flags', {})
self.log.info("Agent state loaded successfully.")
return state
except json.JSONDecodeError as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error decoding state file {STATE_FILE}: {e}. Creating new state.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error loading state file {STATE_FILE}: {e}. Creating new state.")
default_state = {
"agent_name": AGENT_NAME,
"agent_version": AGENT_VERSION,
"cycle_count": 0,
"goals": {
"pending": [],
"active": None,
"completed": [],
"failed": []
},
"goal_stack": [],
"knowledge_base": {
"self_model_state": {}
},
"error_history_summary": [],
"recent_successes_summary": [],
"recent_failures_summary": [],
"recent_tool_outcomes_summary": [],
"last_status": "Initialized",
"flags": {}
}
self.log.info("Created new default agent state.")
return default_state
def save_state(self):
self.log.debug(f"Saving agent state to {STATE_FILE}")
with self.lock:
if self.self_model:
    pass  # inserted to fix indentation error
self.self_model.save_to_state(self.state)
self.state['goal_stack'] = copy.deepcopy(self.goal_stack)
if self.self_model:
    pass  # inserted to fix indentation error
self.state['error_history_summary'] = self.self_model.recent_errors
self.state['recent_successes_summary'] = self.self_model.recent_successes
self.state['recent_failures_summary'] = self.self_model.recent_failures
self.state['recent_tool_outcomes_summary'] = self.self_model.recent_tool_outcomes
self.state['last_status'] = self.self_model.current_status
else:
    pass  # inserted to fix indentation error
self.state['last_status'] = self._status
try:
    pass  # inserted to fix indentation error
temp_file = STATE_FILE.with_suffix(STATE_FILE.suffix + ".tmp")
with temp_file.open('w', encoding='utf-8') as f:
json.dump(self.state, f, indent=2, default=str)
os.replace(temp_file, STATE_FILE)
self.log.info(f"Agent state saved successfully to {STATE_FILE}.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Error saving agent state to {STATE_FILE}: {e}", exc_info=True)
def _update_status(self, new_status: str):
if self._status != new_status:
    pass  # inserted to fix indentation error
self.log.info(f"Agent status changing from '{self._status}' to '{new_status}'")
self._status = new_status
if hasattr(self, 'self_model') and self.self_model:
    pass  # inserted to fix indentation error
self.self_model.update_status(new_status)
self.state["last_status"] = new_status
def get_active_goal_object(self) -> Optional[Goal]:
"""Returns the current active goal as a Goal object, or None."""
active_goal_dict = self.state['goals'].get('active')
if active_goal_dict and isinstance(active_goal_dict, dict):
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
return Goal.from_dict(active_goal_dict)
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to convert active goal dict to Goal object: {e}. Dict: {active_goal_dict}")
return None
def _create_metacognitive_goal(self, anomaly_description: str, priority: GoalPriority = GoalPriority.CRITICAL, context: Optional[Dict]=None):
self.log.warning(f"Creating metacognitive goal for: {anomaly_description}")
meta_goal_id = f"goal_metacog_{uuid.uuid4()}"
meta_goal_dict = Goal(
id=meta_goal_id,
goal=f"Address metacognitive anomaly: {anomaly_description}",
status=GoalStatus.PENDING,
priority=priority,
origin="metacognitive_self_regulation",
context=context or {"anomaly_details": anomaly_description},
plan=[],
thought="Metacognitive goal created due to detected anomaly or system need."
).to_dict()
with self.lock:
pending_goals = self.state['goals'].setdefault('pending', [])
pending_goals.insert(0, meta_goal_dict)
def get_priority_val(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
pending_goals.sort(key=get_priority_val, reverse=True)
self.save_state()
self.log.info(f"Created metacognitive goal {meta_goal_id} with {str(priority)} priority.")
def _archive_goal(self, goal_data_dict: Dict, final_status_str: str):
self.log.info(f"Archiving goal: {goal_data_dict.get('goal', 'N/A')[:50]} (ID: {goal_data_dict.get('id')}) with status: {final_status_str}")
goal_obj = Goal.from_dict(goal_data_dict)
try:
    pass  # inserted to fix indentation error
goal_obj.status = GoalStatus(final_status_str)
except ValueError:
    pass  # inserted to fix indentation error
self.log.warning(f"Invalid status '{final_status_str}' for archiving goal. Defaulting to FAILED.")
goal_obj.status = GoalStatus.FAILED
goal_obj.completion_ts = datetime.now(timezone.utc).isoformat()
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('completed', []).append(goal_obj.to_dict())
self.state['goals']['completed'] = self.state['goals']['completed'][-MAX_COMPLETED_GOALS_IN_STATE:]
else:
    pass  # inserted to fix indentation error
self.state['goals'].setdefault('failed', []).append(goal_obj.to_dict())
self.state['goals']['failed'] = self.state['goals']['failed'][-MAX_FAILED_GOALS_IN_STATE:]
self.memory_system.add_memory_entry(goal_obj, persist_to_relational=True)
outcome_summary = {"goal_id": goal_obj.id, "goal_text": goal_obj.goal, "status": str(goal_obj.status), "completion_ts": goal_obj.completion_ts, "replan_count": goal_obj.replan_count}
if goal_obj.status == GoalStatus.COMPLETED:
    pass  # inserted to fix indentation error
self.self_model.recent_successes.append(outcome_summary)
self.self_model.recent_successes = self.self_model.recent_successes[-10:]
else:
    pass  # inserted to fix indentation error
self.self_model.recent_failures.append(outcome_summary)
self.self_model.recent_failures = self.self_model.recent_failures[-10:]
with self.lock:
active_goal_id = goal_data_dict.get('id')
current_active_in_state = self.state['goals'].get('active')
if current_active_in_state and isinstance(current_active_in_state, dict) and current_active_in_state.get('id') == active_goal_id:
    pass  # inserted to fix indentation error
self.state['goals']['active'] = None
self.log.debug(f"Archived goal {active_goal_id} was active, clearing active slot.")
if self.goal_stack and goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_snapshot = self.goal_stack[-1]
if parent_snapshot.get('goal_data',{}).get('id') == goal_obj.parent_goal_id:
    pass  # inserted to fix indentation error
parent_goal_snapshot = self.goal_stack.pop()
parent_goal_data_dict = parent_goal_snapshot.get('goal_data')
if parent_goal_data_dict and isinstance(parent_goal_data_dict, dict):
    pass  # inserted to fix indentation error
self.state['goals']['active'] = parent_goal_data_dict
sub_goal_outcome_summary = f"Sub-goal '{goal_obj.goal[:30]}' (ID: {active_goal_id}) concluded with status: {final_status_str}."
parent_thought = parent_goal_data_dict.get('thought', "")
parent_goal_data_dict['thought'] = parent_thought + f"\n[Resuming after Sub-goal]: {sub_goal_outcome_summary}"
parent_goal_data_dict['status'] = GoalStatus.ACTIVE.value
self.log.info(f"Popped parent goal '{parent_goal_data_dict.get('goal', 'Unknown Parent')[:50]}' (ID: {parent_goal_data_dict.get('id')}) from stack. Resuming.")
self._update_status(f"Resuming Parent Goal: {parent_goal_data_dict.get('goal', '')[:30]}")
else:
    pass  # inserted to fix indentation error
self.log.error("Popped invalid goal snapshot from stack.")
elif not self.state['goals'].get('active'):
    pass  # inserted to fix indentation error
self.log.info("Goal archived. No parent goal to resume from stack or current goal was not a stacked subgoal. Checking pending goals.")
self._update_status("Idle (Post-Goal)")
self.save_state()
def run(self):
self.log.info(f"--- {AGENT_NAME} ({AGENT_VERSION}) Run Loop Starting ---")
if self._status != "Initialized":
    pass  # inserted to fix indentation error
self._update_status("Idle")
if not self.cognitive_cycle:
    pass  # inserted to fix indentation error
self.log.critical("CognitiveCycle not initialized. Cannot run.")
return
if not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
self.log.info("No initial goals. Creating a default metacognitive goal to start.")
self._create_metacognitive_goal("Initial system check, self-assessment, and environment exploration.", priority=GoalPriority.HIGH)
self.last_agent_interaction_time = time.time()
while not STOP_SIGNAL_RECEIVED.is_set():
self.cycle_count +=1
self.state['cycle_count'] = self.cycle_count
active_goal_data_before_cycle = copy.deepcopy(self.state['goals'].get('active')) if self.state['goals'].get('active') else None
self.last_error = None
self.current_goal_outcome = None
try:
    pass  # inserted to fix indentation error
cycle_ok = self.cognitive_cycle.run_cycle()
except Exception as loop_err:
    pass  # inserted to fix indentation error
self.log.critical(f"CRITICAL UNHANDLED ERROR escaped cognitive cycle: {loop_err}", exc_info=True)
self.last_error = loop_err; self.current_goal_outcome = False
STOP_SIGNAL_RECEIVED.set(); break
if not cycle_ok and not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
self.log.critical("Cognitive cycle indicated critical failure. Stopping run loop.")
STOP_SIGNAL_RECEIVED.set()
break
if active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
updated_active_goal_dict = self.state['goals'].get('active')
goal_to_archive = None
if updated_active_goal_dict and updated_active_goal_dict['id'] == active_goal_data_before_cycle['id']:
    pass  # inserted to fix indentation error
goal_obj_after_cycle = Goal.from_dict(updated_active_goal_dict)
if goal_obj_after_cycle.status in [GoalStatus.COMPLETED, GoalStatus.FAILED, GoalStatus.CANCELLED]:
    pass  # inserted to fix indentation error
goal_to_archive = updated_active_goal_dict
elif not updated_active_goal_dict and active_goal_data_before_cycle.get('status') in [GoalStatus.COMPLETED.value, GoalStatus.FAILED.value]:
    pass  # inserted to fix indentation error
goal_to_archive = active_goal_data_before_cycle
elif self.current_goal_outcome is False and active_goal_data_before_cycle:
    pass  # inserted to fix indentation error
active_goal_data_before_cycle['status'] = GoalStatus.FAILED.value
goal_to_archive = active_goal_data_before_cycle
if goal_to_archive:
    pass  # inserted to fix indentation error
self._archive_goal(goal_to_archive, goal_to_archive['status'])
if self._should_reflect(active_goal_data_before_cycle):
    pass  # inserted to fix indentation error
self._reflect_on_performance()
if self.state['flags'].get('re_evaluate_strategy_needed'):
    pass  # inserted to fix indentation error
self.log.info("Flag set to re-evaluate strategy. Triggering metacognitive goal.")
self._create_metacognitive_goal("Re-evaluate overall strategy due to significant internal change (e.g., directive update).", priority=GoalPriority.HIGH)
self.state['flags']['re_evaluate_strategy_needed'] = False
if self._status == "Idle" and not self.state['goals'].get('active') and not self.state['goals'].get('pending'):
    pass  # inserted to fix indentation error
sleep_duration = IDLE_DELIBERATION_INTERVAL_SECONDS / 10 if time.time() - LAST_DELIBERATION_TIME < IDLE_DELIBERATION_INTERVAL_SECONDS else 1.0
time.sleep(max(0.1, sleep_duration))
elif not STOP_SIGNAL_RECEIVED.is_set():
    pass  # inserted to fix indentation error
time.sleep(0.05)
self.log.warning(f"--- {AGENT_NAME} Run Loop Exited ---")
self.shutdown()
def _should_reflect(self, processed_goal_data: Optional[Dict]) -> bool:
if self.cycle_count % METACOGNITIVE_CHECK_INTERVAL_CYCLES == 0:
    pass  # inserted to fix indentation error
return True
if processed_goal_data and Goal.from_dict(processed_goal_data).status in [GoalStatus.COMPLETED, GoalStatus.FAILED]:
    pass  # inserted to fix indentation error
goals_processed_key = "goals_processed_since_reflection"
self.state.setdefault(goals_processed_key, 0)
self.state[goals_processed_key] +=1
if self.state[goals_processed_key] >= int(os.getenv("AGENT_REFLECTION_INTERVAL_GOALS", "3")):
    pass  # inserted to fix indentation error
return True
if time.time() - LAST_REFLECTION_TIME > MANDATORY_REFLECTION_INTERVAL_SECONDS and self._status == "Idle":
    pass  # inserted to fix indentation error
return True
if self.state['flags'].get('explicit_reflection_requested'):
    pass  # inserted to fix indentation error
return True
return False
@retry(attempts=2, delay=5)
def _reflect_on_performance(self):
global LAST_REFLECTION_TIME
self.log.info("--- Reflecting on Performance ---")
self._update_status("Reflecting")
LAST_REFLECTION_TIME = time.time()
self.state['flags']['explicit_reflection_requested'] = False
self.state["goals_processed_since_reflection"] = 0
try:
    pass  # inserted to fix indentation error
assessment_prompt = self.self_model.get_self_assessment_prompt()
llm_assessment_str = self.llm_wrapper.generate(assessment_prompt, max_new_tokens=2048, temperature=0.5)
reflection_data = extract_json_robust(llm_assessment_str)
if reflection_data.get("error"):
    pass  # inserted to fix indentation error
self.log.error(f"Failed to get valid JSON from LLM self-assessment: {reflection_data.get('error')}")
self.self_model.add_event_log(f"Self-assessment LLM call failed: {reflection_data.get('error')}", event_type="error")
return
updated_sm, updated_kb = self.self_model.update_from_reflection(reflection_data)
if updated_kb:
    pass  # inserted to fix indentation error
if isinstance(reflection_data.get('learned_facts'), list):
    pass  # inserted to fix indentation error
for fact_str in reflection_data['learned_facts']:
kf = KnowledgeFact(fact_statement=fact_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(kf, persist_to_vector=True, persist_to_relational=True)
self.log.info(f"Added {len(reflection_data['learned_facts'])} learned facts to memory from reflection.")
if isinstance(reflection_data.get('prompt_tuning_suggestions'), list):
    pass  # inserted to fix indentation error
for sugg_str in reflection_data['prompt_tuning_suggestions']:
entry = BaseMemoryEntry(type="prompt_suggestion", content=sugg_str, metadata={"source": "self_reflection"})
self.memory_system.add_memory_entry(entry, persist_to_vector=True)
self.log.info(f"Added {len(reflection_data['prompt_tuning_suggestions'])} prompt suggestions to memory.")
if reflection_data.get('self_modification_needed'):
    pass  # inserted to fix indentation error
mod_desc = reflection_data['self_modification_needed']
self.log.warning(f"Reflection identified need for self-modification: {mod_desc}")
self._create_metacognitive_goal(
f"Investigate and potentially perform self-modification based on reflection: {mod_desc}",
priority=GoalPriority.HIGH,
context={"modification_description": mod_desc, "source": "self_reflection"}
)
if self.cycle_count % int(os.getenv("DIRECTIVE_AUDIT_INTERVAL_CYCLES", "50")) == 0:
    pass  # inserted to fix indentation error
audit_issues = self.safety_module.audit_directives_and_behavior()
if audit_issues:
    pass  # inserted to fix indentation error
self.log.warning(f"Directive audit identified issues: {audit_issues}")
self._create_metacognitive_goal(f"Address directive audit findings: {str(audit_issues)[:100]}", context={"audit_report": audit_issues})
self.log.info("--- Reflection Complete ---")
except LLMError as e:
    pass  # inserted to fix indentation error
self.log.error(f"LLMError during reflection: {e}")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Unexpected error during reflection: {e}", exc_info=True)
finally:
    pass  # inserted to fix indentation error
LAST_REFLECTION_TIME = time.time()
self._update_status("Idle")
self.save_state()
def _setup_communication_handlers(self):
"""Sets up handlers for different message types if comms_channel exists."""
if self.comms_channel:
    pass  # inserted to fix indentation error
self.comms_channel.register_handler(MessageType.QUERY, self.handle_query_message)
self.comms_channel.register_handler(MessageType.INFORM, self.handle_inform_message)
self.log.info("Basic communication handlers registered.")
def handle_query_message(self, message: Message) -> Optional[Message]:
self.log.info(f"Agent {self.agent_id} received QUERY from {message.sender_id}: {message.content}")
query_key = message.content.get("query_key")
response_content = {}
if query_key and self.state.get('knowledge_base', {}).get(query_key):
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": self.state['knowledge_base'][query_key], "status": "FOUND"}
elif query_key:
    pass  # inserted to fix indentation error
response_content = {"key": query_key, "value": None, "status": "NOT_FOUND"}
else:
    pass  # inserted to fix indentation error
response_content = {"agent_status": self._status, "knowledge_summary_sample": str(self.state.get('knowledge_base',{}))[:100]}
return Message(sender_id=self.agent_id, receiver_id=message.sender_id, type=MessageType.RESPONSE.value, content=response_content, correlation_id=message.id)
def handle_inform_message(self, message: Message) -> None:
self.log.info(f"Agent {self.agent_id} received INFORM from {message.sender_id}: {message.content}")
shared_knowledge = self.state.setdefault('shared_knowledge', {})
inform_data = message.content.get("data", {})
if isinstance(inform_data, dict):
    pass  # inserted to fix indentation error
for k, v in inform_data.items():
shared_knowledge[f"{message.sender_id}_{k}"] = v
self.log.info(f"Updated knowledge from inform: {shared_knowledge}")
self.save_state()
def _initialize_resource_monitor(self):
global RESOURCE_MONITOR
if not PSUTIL_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("psutil not available, resource monitoring disabled.")
return
if RESOURCE_MONITOR:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing resource monitor...")
try:
    pass  # inserted to fix indentation error
RESOURCE_MONITOR = psutil.Process(os.getpid())
RESOURCE_MONITOR.cpu_percent(interval=None)
self.log.info("Resource monitor initialized (psutil).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize resource monitor: {e}")
RESOURCE_MONITOR = None
def _initialize_playwright(self):
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if not PLAYWRIGHT_AVAILABLE:
    pass  # inserted to fix indentation error
self.log.info("Playwright not available, skipping initialization.")
return
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Initializing Playwright...")
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE = sync_playwright().start()
PLAYWRIGHT_BROWSER = PLAYWRIGHT_INSTANCE.chromium.launch(headless=True)
PLAYWRIGHT_CONTEXT = PLAYWRIGHT_BROWSER.new_context(
user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
java_script_enabled=True,
ignore_https_errors=True
)
PLAYWRIGHT_PAGE = PLAYWRIGHT_CONTEXT.new_page()
self.playwright_instance = PLAYWRIGHT_INSTANCE
self.playwright_browser = PLAYWRIGHT_BROWSER
self.playwright_context = PLAYWRIGHT_CONTEXT
self.playwright_page = PLAYWRIGHT_PAGE
self.log.info("Playwright initialized successfully (Chromium headless).")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to initialize Playwright: {e}", exc_info=True)
self._shutdown_playwright()
def _shutdown_playwright(self):
if not PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
return
self.log.info("Shutting down Playwright...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_INSTANCE, PLAYWRIGHT_BROWSER, PLAYWRIGHT_CONTEXT, PLAYWRIGHT_PAGE
if PLAYWRIGHT_PAGE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_PAGE.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright page: {e}")
if PLAYWRIGHT_CONTEXT:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_CONTEXT.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright context: {e}")
if PLAYWRIGHT_BROWSER:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_BROWSER.close()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing Playwright browser: {e}")
if PLAYWRIGHT_INSTANCE:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
PLAYWRIGHT_INSTANCE.stop()
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error stopping Playwright instance: {e}")
PLAYWRIGHT_PAGE = None; PLAYWRIGHT_CONTEXT = None
PLAYWRIGHT_BROWSER = None; PLAYWRIGHT_INSTANCE = None
self.playwright_page = None; self.playwright_context = None
self.playwright_browser = None; self.playwright_instance = None
self.log.info("Playwright shutdown complete.")
def _try_reset_playwright_page(self):
if not PLAYWRIGHT_AVAILABLE or not self.playwright_context :
    pass  # inserted to fix indentation error
return
self.log.warning("Attempting to reset Playwright page...")
with PLAYWRIGHT_LOCK:
global PLAYWRIGHT_PAGE
if self.playwright_page:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
self.playwright_page.close(); PLAYWRIGHT_PAGE = None;
except Exception as e:
    pass  # inserted to fix indentation error
self.log.warning(f"Error closing old Playwright page during reset: {e}")
try:
    pass  # inserted to fix indentation error
self.playwright_page = self.playwright_context.new_page()
PLAYWRIGHT_PAGE = self.playwright_page
self.log.info("Playwright page reset successfully.")
except Exception as e:
    pass  # inserted to fix indentation error
self.log.error(f"Failed to reset Playwright page: {e}", exc_info=True)
self.playwright_page = None; PLAYWRIGHT_PAGE = None
def shutdown(self):
"""Gracefully shuts down the agent."""
if self._status == "Shutting Down":
    pass  # inserted to fix indentation error
return
self.log.warning(f"--- {AGENT_NAME} Shutdown Sequence Initiated ---")
self._update_status("Shutting Down")
STOP_SIGNAL_RECEIVED.set()
self.save_state()
if self.memory_system:
    pass  # inserted to fix indentation error
self.memory_system.save_all_memory_stores()
self._shutdown_playwright()
if self.memory_system and self.memory_system.relational_conn:
    pass  # inserted to fix indentation error
self.memory_system.relational_conn.close()
self.log.info("--- Agent Shutdown Complete ---")
logging.shutdown()
def signal_handler(sig, frame):
print(f"\nSignal {sig} received. Requesting graceful shutdown...")
sig_log = get_logger("SIGNAL")
sig_log.warning(f"Signal {sig} received. Setting stop signal.")
STOP_SIGNAL_RECEIVED.set()
time.sleep(1)
if _agent_instance_hack and _agent_instance_hack._status != "Shutting Down":
    pass  # inserted to fix indentation error
sig_log.warning("Forcing shutdown via signal handler as main loop might be stuck.")
_agent_instance_hack.shutdown()
else:
    pass  # inserted to fix indentation error
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(0)
if __name__ == "__main__":
    pass  # inserted to fix indentation error
nl = "\n"
print(f"{nl}{'+'*70}{nl} Starting Agent: {AGENT_NAME} ({AGENT_VERSION}){nl} Workspace: "
f"{WORKSPACE_DIR}{nl} LLM: {LLM_MODEL_NAME_OR_PATH} on {LLM_DEVICE}{nl} Shell/"
f"CodeGen/SelfMod Enabled: {ENABLE_SHELL_TOOL}/"
f"{ENABLE_CODE_GENERATION_TOOL}/"
f"{ENABLE_SELF_MODIFICATION}{nl} {'(USE WITH EXTREME CAUTION!)' if ENABLE_SHELL_TOOL or ENABLE_CODE_GENERATION_TOOL or ENABLE_SELF_MODIFICATION else ''}{nl}{'+'*70}")
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
main_agent_instance: Optional[CognitiveSystem] = None
exit_code = 0
try:
    pass  # inserted to fix indentation error
initial_command_goal = None
if COMMANDS_FILE.exists() and COMMANDS_FILE.stat().st_size > 0:
    pass  # inserted to fix indentation error
try:
    pass  # inserted to fix indentation error
command_text = COMMANDS_FILE.read_text().strip()
if command_text:
    pass  # inserted to fix indentation error
print(f"Found initial command in {COMMANDS_FILE}: {command_text[:100]}...")
initial_command_goal = Goal(goal=command_text, origin="cli_command_file", priority=GoalPriority.HIGH).to_dict()
except Exception as e_cmd_file:
    pass  # inserted to fix indentation error
print(f"Error reading initial command file: {e_cmd_file}", file=sys.stderr)
main_agent_instance = CognitiveSystem()
if initial_command_goal and main_agent_instance:
    pass  # inserted to fix indentation error
with main_agent_instance.lock:
main_agent_instance.state['goals'].setdefault('pending', []).append(initial_command_goal)
def get_priority_val_for_sort(g_dict_item):
p_val = g_dict_item.get('priority', GoalPriority.MEDIUM.value)
if isinstance(p_val, GoalPriority): return p_val.value
    pass  # inserted to fix indentation error
if isinstance(p_val, str): return GoalPriority[p_val.upper()].value
    pass  # inserted to fix indentation error
return p_val
main_agent_instance.state['goals']['pending'].sort(key=get_priority_val_for_sort, reverse=True)
main_agent_instance.save_state()
main_agent_instance.log.info(f"Initial command goal '{initial_command_goal['goal'][:50]}' added to pending goals.")
main_agent_instance.run()
except ConfigurationError as cfg_err_main:
    pass  # inserted to fix indentation error
print(f"\nFATAL CONFIGURATION ERROR: {cfg_err_main}", file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Agent failed to start due to ConfigurationError: {cfg_err_main}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Agent pre-init or init failed due to ConfigurationError: {cfg_err_main}", exc_info=True)
exit_code = 2
except KeyboardInterrupt:
    pass  # inserted to fix indentation error
print("\nMain process interrupted by user (KeyboardInterrupt).")
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main process caught KeyboardInterrupt.")
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).warning("Main process caught KeyboardInterrupt during init/early phase.")
exit_code = 130
except Exception as main_exec_err:
    pass  # inserted to fix indentation error
print(f"\nFATAL UNHANDLED ERROR in main execution: {main_exec_err}", file=sys.stderr)
traceback.print_exc(file=sys.stderr)
if main_agent_instance and hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.critical(f"Fatal unhandled error in main: {main_exec_err}", exc_info=True)
else:
    pass  # inserted to fix indentation error
logging.getLogger(AGENT_NAME).critical(f"Fatal unhandled error during init/main: {main_exec_err}", exc_info=True)
exit_code = 1
finally:
    pass  # inserted to fix indentation error
if main_agent_instance and getattr(main_agent_instance, '_status', '') != "Shutting Down":
    pass  # inserted to fix indentation error
print("\nEnsuring agent shutdown in main finally block...")
if hasattr(main_agent_instance, 'log'):
    pass  # inserted to fix indentation error
main_agent_instance.log.warning("Main finally block ensuring agent shutdown.")
main_agent_instance.shutdown()
elif not main_agent_instance and 'main_log' in locals():
    pass  # inserted to fix indentation error
main_log.warning("Agent instance likely not created or fully initialized. Basic shutdown.")
if _agent_instance_hack is not None:
    pass  # inserted to fix indentation error
_agent_instance_hack = None
print(f"--- {AGENT_NAME} Process Exiting (Code: {exit_code}) ---")
if 'logging' in sys.modules:
    pass  # inserted to fix indentation error
logging.shutdown()
sys.exit(exit_code)
```

def run_tool_if_applicable(agent, context_text):
    tool_name = agent.tool_manager.match_tool_to_prompt(context_text)
    if tool_name:
        try:
            params = {"input": context_text}
            result = agent.tool_manager.execute_tool(tool_name, params)
            agent.memory_system.add_memory_entry({
                "type": "tool_result",
                "tool": tool_name,
                "input": context_text,
                "output": result
            })
            return result
        except Exception as e:
            agent.log.warning(f"Tool execution error: {e}")
    return None

def main_loop(agent):
    import time
    agent.log.info("Starting main autonomous AGI loop...")
    while True:
        try:
            # Sensory input & motivation
            sensory_input = agent.embodiment.get_sensory_input()
            agent.motivation_engine.update(sensory_input)

            # Reflect and replan if needed
            if agent.needs_reflection():
                agent.reflect()

            # Metacognition cycle
            if agent.needs_metacognitive_check():
                agent.perform_metacognitive_check()

            # Goal execution
            if agent.has_pending_goals():
                agent.deliberate()
                agent.execute_next_goal_step()

            # Autonomous tool usage
            last_thought = agent.self_model.inter nal_state_narrative
            run_tool_if_applicable(agent, last_thought)

            time.sleep(2)
        except KeyboardInterrupt:
            agent.log.info("Agent loop interrupted by user.")
            break
        except Exception as loop_err:
            agent.log.error(f"Unexpected error in agent loop: {loop_err}", exc_info=True)